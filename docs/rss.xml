<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[ztianzeng.com RSS]]></title><description><![CDATA[ztianzeng.com RSS]]></description><link>http://github.com/dylang/node-rss</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 05 Jul 2022 05:16:07 GMT</lastBuildDate><item><title><![CDATA[Emby直链阿里云盘播放]]></title><link>https://www.ztianzeng.com/posts/Emby直链阿里云盘播放</link><guid isPermaLink="false">/posts/Emby直链阿里云盘播放</guid><pubDate>Tue, 05 Jul 2022 04:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Emby直链阿里云盘播放&quot;&gt;Emby直链阿里云盘播放&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之前用CloudFlare抢救了一下移动大内网的机器，解决了在外网查看的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，由于国内宽带的上下行严重不对等，以致于无法在外头正常的播放家中的动辄十几个G的蓝光原盘，需要解决一下外网访问慢的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前我的做法是，通过emby视频源劫持到目录程序的对应文件的直链，从而实现不走家中NAS的流量，而体验和正常的emby别无二致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种方式唯一的弊端就是无法通过服务器端进行解码，当然1900的性能也支撑不了服务端解码。&lt;/p&gt;
&lt;h1 id=&quot;环境&quot;&gt;环境&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ugf2o6r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用Alist连接阿里云盘，转成webdav协议&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2p9g4fl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用Rclone 将webdav挂载到本地磁盘中&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8rxvsab&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会一丢丢docker&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;alist 连接阿里云盘比较简单，直接参考官网的教程即可，&lt;a href=&quot;https://alist-doc.nn.ci/&quot;&gt;https://alist-doc.nn.ci/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;rclone 挂载，可以看之前我折腾的&lt;a href=&quot;/posts/记录一次NAS系统崩溃&quot;&gt;《记录一次NAS系统崩溃》&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;实现&quot;&gt;实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用nginx 反向代理emby，将访问本地磁盘的路径，借助alist提供的API，转换成阿里云盘的直链。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;具体的代码在: &lt;a href=&quot;https://github.com/zxcvbnmzsedr/docker_env/blob/master/emby/README.md&quot;&gt;https://github.com/zxcvbnmzsedr/docker_env/blob/master/emby/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要修改一下 nginx/conf.d/emby.js,将密码啥的给替换成自己的，然后用docker-compose up -d 启动即可。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Http进化史]]></title><link>https://www.ztianzeng.com/topic/系统设计/Http进化史</link><guid isPermaLink="false">/topic/系统设计/Http进化史</guid><category><![CDATA[系统设计]]></category><pubDate>Fri, 01 Jul 2022 05:26:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Http进化史&quot;&gt;Http进化史&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[darft]]></title><link>https://www.ztianzeng.com/darft</link><guid isPermaLink="false">/darft</guid><pubDate>Fri, 01 Jul 2022 03:37:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;darft&quot;&gt;darft&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Flux架构]]></title><link>https://www.ztianzeng.com/topic/系统设计/Flux架构</link><guid isPermaLink="false">/topic/系统设计/Flux架构</guid><category><![CDATA[系统设计]]></category><pubDate>Thu, 30 Jun 2022 12:31:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Flux架构&quot;&gt;Flux架构&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[文档协同编辑系统]]></title><link>https://www.ztianzeng.com/darft/文档协同编辑系统</link><guid isPermaLink="false">/darft/文档协同编辑系统</guid><pubDate>Thu, 30 Jun 2022 12:03:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;文档协同编辑系统&quot;&gt;文档协同编辑系统&lt;/h1&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;近年来，做文档协同编辑的厂商层出不穷，比如语雀、石墨文档、腾讯文档、飞书等等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果自己设计一个文档协同编辑系统，需要考虑哪些问题？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Scenario场景&quot;&gt;Scenario场景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;多人协作的在线文档在技术上主要分为三大块：文档编辑、在线、多人协作&lt;/p&gt;
&lt;h2 id=&quot;文档编辑的主要功能&quot;&gt;文档编辑的主要功能&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2fjqevn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;创建和加载文件内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-r9ml3wn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编辑文件&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-80cr80d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;保存文件&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;在线的主要功能&quot;&gt;在线的主要功能&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-i4u831b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实时接收客户端发送的接收&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cpw24xh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将请求数据同步到数据库中，进行持久化&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;多人协作的主要功能&quot;&gt;多人协作的主要功能&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-68phhys&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;处理编辑冲突&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w756s7l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;展示正在编辑的人&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hsq5a86&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编辑内容锁定&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;Service-服务&quot;&gt;Service 服务&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;协同编辑系统，最复杂的地方主要是在多人协作上面，文档编辑是一个非常传统的界面开发，这方面的技术和框架可选择的非常的多。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前来说，Web端比较流行的解决方案是用React/Redux或者Vue/Vuex这样的类&lt;a href=&quot;../../Flux架构&quot;&gt;Flux架构&lt;/a&gt; ,用状态树保存，丢到服务器端。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;复杂的地方是在于多人协作&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如何让用户端的输入及时准确的同步到服务器端？并且其他用户可以及时的看到响应。&lt;/p&gt;
&lt;h2 id=&quot;使用Http同步更改&quot;&gt;使用Http同步更改&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220701110808.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;理想很丰满，现实很骨感。HTTP不支持从服务器直接推送数据到客户端。关于这部分可以看，&lt;a href=&quot;&quot;&gt;Http进化史&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，我们需要另辟蹊径。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220701142027.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过客户端不断的轮询的方式，向服务器请求其他客户端提交的变更数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;轮询的方式有什么问题？&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ysk6v97&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端不断的轮回，会对服务器造成比较大的压力&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以采用长轮询的方式，降低压力，但是这种也是治标不治本&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vqo314j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实时性较差，客户端在一个轮询周期之内没有办法及时看到其他用户的响应&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用WebSocket同步更改&quot;&gt;使用WebSocket同步更改&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;WebSocket的特点是能够双向通讯 ，可以方便的在客户端和服务器之间当中快速的传输数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220701151446.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Squid运行调试命令及日志状态分析]]></title><link>https://www.ztianzeng.com/posts/Squid运行调试命令及日志状态分析</link><guid isPermaLink="false">/posts/Squid运行调试命令及日志状态分析</guid><pubDate>Mon, 27 Jun 2022 05:57:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Squid运行调试命令及日志状态分析&quot;&gt;Squid运行调试命令及日志状态分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当你的 squid.conf 配置文档按照你的想法修改完以后，启动 squid 之旅就开始了。&lt;/p&gt;
&lt;h1 id=&quot;Squid安装调试命令-&quot;&gt;Squid安装调试命令:&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8ri0889&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;初始化你在 squid.conf 里配置的 cache 目录&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;/usr/local/squid/sbin/squid -z //初始化缓存空间&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者，手动初始化&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t0w8cbl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对你的squid.conf 排错，即验证 squid.conf 的 语法和配置。&lt;br /&gt;
#/usr/local/squid/sbin/squid -k parse&lt;br /&gt;
如果squid.conf 有语法或配置错误，这里会返回提示你，如果没有返回，恭喜，可以尝试启动squid。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-brp628l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在前台启动squid，并输出启动过程。&lt;br /&gt;
#/usr/local/squid/sbin/squid -N -d1&lt;br /&gt;
如果有到 ready to server reques，恭喜，启动成功。&lt;br /&gt;
然后 ctrl + c，停止squid，并以后台运行的方式启动它。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7xrax0l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;启动squid在后台运行。&lt;br /&gt;
#/usr/local/squid/sbin/squid -s&lt;br /&gt;
这时候可以 ps -A 来查看系统进程，可以看到俩个 squid 进程。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-smulkfe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;停止 squid&lt;br /&gt;
#/usr/local/squid/sbin/squid -k shutdown&lt;br /&gt;
这个不用解释吧。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bjm8ngy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重引导修改过的 squid.conf&lt;br /&gt;
#/usr/local/squid/sbin/squid -k reconfigure //载入新的配置文件&lt;br /&gt;
这个估计用的时候比较多，当你发现你的配置有不尽你意的时候，可以随时修改squid.conf，然后别忘记对你的 squid.conf排错，然后再执行此指令，即可让squid重新按照你的 squid.conf 来运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2566bnv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;/usr/local/squid/sbin/squid -k rotate 轮循日志&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-621mxtg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改cache 缓存目录的权限。&lt;br /&gt;
#chown -R squid:squid /data/cache&lt;br /&gt;
我的cache缓存目录是 /data/cache,squid执行用户和用户组是 squid，squid。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yfq9b84&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改squid 日志目录的权限&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;#chown -R squid:squid /usr/local/squid/var/logs&lt;br /&gt;
这一步并不是适合每一个使用squid的用户.意为让squid有权限在该目录进行写操作 。&lt;br /&gt;
例如生成 access.log cache.log store.log&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;squid命中率分析&quot;&gt;squid命中率分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;/usr/local/squid/bin/squidclient -p 80 mgr:info&lt;br /&gt;
/usr/local/squid/bin/squidclient -p 80 mgr:5min&lt;br /&gt;
可以看到详细的性能情况,其中PORT是你的proxy的端口，5min可以是60min&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qziqllq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;取得squid运行状态信息： squidclient -p 80 mgr:info&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mx5stqq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;取得squid内存使用情况： squidclient -p 80 mgr:mem&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8tln3za&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;取得squid已经缓存的列表： squidclient -p 80 mgrbjects. use it carefully,it may crash&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-675xugc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;取得squid的磁盘使用情况： squidclient -p 80 mgr:diskd&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2egmc7r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;强制更新某个url：squidclient -p 80 -m PURGE &lt;a href=&quot;http://www.yejr.com/static.php&quot;&gt;http://www.xxx.com/xxx.php&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查命中率：&lt;br /&gt;
/usr/local/squid/bin/squidclient -h 111.222.111.111 -p80 mgr:info&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;/usr/local/squid/bin/squidclient -h具体的IP -p80 mgr:info&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果看到很多的TCP_MEM_HIT ，这表明该文件是从内存缓存读取的，squid已经起作用了！你再用浏览器打开该文件，应该是快如闪电了。。呵呵，大功告成了！还有其他类型的HIT，如TCP_HIT等等，这些是从磁盘读取的，我觉得加速的意义不大，只不过缓解了apache的压力而已。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相应于HTTP请求，下列标签可能出现在access.log文件的第四个域。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现请求资源的貌似新鲜的拷贝，并将其立即发送到客户端。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_MISS&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid没有请求资源的cache拷贝。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_REFERSH_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。原始服务器返回304（未修改）响应，指示squid的拷贝仍旧是新鲜的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_REF_FAIL_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。然而，原始服务器响应失败，或者返回的响应Squid不能理解。在此情形下，squid发送现有cache拷贝（很可能是陈旧的）到客户端。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_REFRESH_MISS&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。原始服务器响应新的内容，指示这个cache拷贝确实是陈旧的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_CLIENT_REFRESH_MISS&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现了请求资源的拷贝，但客户端的请求包含了Cache-Control: no-cache指令。Squid转发客户端的请求到原始服务器，强迫cache确认。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_IMS_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端发送确认请求，Squid发现更近来的、貌似新鲜的请求资源的拷贝。Squid发送更新的内容到客户端，而不联系原始服务器。&lt;br /&gt;
**&lt;br /&gt;
TCP_SWAPFAIL_MISS**&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid发现请求资源的有效拷贝，但从磁盘装载它失败。这时squid发送请求到原始服务器，就如同这是个cache丢失一样。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_NEGATIVE_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在对原始服务器的请求导致HTTP错误时，Squid也会cache这个响应。在短时间内对这些资源的重复请求，导致了否命中。 negative_ttl指令控制这些错误被cache的时间数量。请注意这些错误只在内存cache，不会写往磁盘。下列HTTP状态码可能导致否定 cache（也遵循于其他约束）： 204, 305, 400, 403, 404, 405, 414, 500, 501, 502, 503, 504。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_MEM_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid在内存cache里发现请求资源的有效拷贝，并将其立即发送到客户端。注意这点并非精确的呈现了所有从内存服务的响应。例如，某些cache在内存里，但要求确认的响应，会以TCP_REFRESH_HIT, TCP_REFRESH_MISS等形式记录。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_DENIED&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为http_access或http_reply_access规则，客户端的请求被拒绝了。注意被http_access拒绝的请求在第9域的值是NONE/-，然而被http_reply_access拒绝的请求，在相应地方有一个有效值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_OFFLINE_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当offline_mode激活时，Squid对任何cache响应返回cache命中，而不用考虑它的新鲜程度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TCP_REDIRECT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重定向程序告诉Squid产生一个HTTP重定向到新的URI（见11.1节）。正常的，Squid不会记录这些重定向。假如要这样做，必须在编译squid前，手工定义LOG_TCP_REDIRECTS预处理指令。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;NONE&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无分类的结果用于特定错误，例如无效主机名。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相应于ICP查询，下列标签可能出现在access.log文件的第四域。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;UDP_HIT&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid在cache里发现请求资源的貌似新鲜的拷贝。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;UDP_MISS&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid没有在cache里发现请求资源的貌似新鲜的拷贝。假如同一目标通过HTTP请求，就可能是个cache丢失。请对比UDP_MISS_NOFETCH。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;UDP_MISS_NOFETCH&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;跟UDP_MISS类似，不同的是这里也指示了Squid不愿去处理相应的HTTP请求。假如使用了-Y命令行选项，Squid在启动并编译其内存索引时，会返回这个标签而不是UDP_MISS。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;UDP_DENIED&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为icp_access规则，ICP查询被拒绝。假如超过95%的到某客户端的ICP响应是UDP_DENIED，并且客户端数据库激活了（见附录A），Squid在1小时内，停止发送任何ICP响应到该客户端。若这点发生，你也可在cache.log里见到一个警告。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;UDP_INVALID&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Squid接受到无效查询（例如截断的消息、无效协议版本、URI里的空格等）。Squid发送UDP_INVALID响应到客户端&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[秒杀]]></title><link>https://www.ztianzeng.com/topic/系统设计/样例/秒杀</link><guid isPermaLink="false">/topic/系统设计/样例/秒杀</guid><category><![CDATA[系统设计]]></category><category><![CDATA[样例]]></category><pubDate>Thu, 16 Jun 2022 12:21:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;秒杀&quot;&gt;秒杀&lt;/h1&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;秒杀的三个特点:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;整点开始&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数量有限&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;售完截止&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Scenario场景&quot;&gt;Scenario场景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS预测:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0pt0e5x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平日每秒1K人访问该页面&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vgl6ets&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;秒杀每秒数十万人访问该页面&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kknal6e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS增加100倍&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商品购买和下单流程:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220623165604.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;秒杀情况下最大的几个难点：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qygttds&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;瞬时大流量高并发&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;服务器、数据库承载的QPS有限，如数据库一般是1000QPS。要根据业务预估并发量，临时扩容&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平常qps就大几百，秒杀情况下，并发量是数十倍&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qbbdier&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有限库存，不能超卖&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要精准控制库存量，保证数据一致性（面试热点）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yijvx3q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;恶意请求&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;脚本模拟购买，模拟几十万请求去抢购&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-io6v2ds&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;固定时间开启&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时间到了才能买，以为服务器时间为准，NTP同步？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s12mpd5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;严格限购&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户只能买1个或N个&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;需求拆解&quot;&gt;需求拆解&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商家侧&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-n0u16dz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;新建秒杀活动&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-snhked7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;配置秒杀活动&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户侧&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-u4wx1sc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商品秒杀页面&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-thut9pc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;购买&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tyw6deq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下单&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wavr36v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;付款&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Service-服务&quot;&gt;Service 服务&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;采用微服务架构来对系统进行开发，单独抽取秒杀模块以为防止雪崩。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关于单体架构和微服务的架构可以看&lt;a href=&quot;../../概念&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220623171802.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;Storage存储&quot;&gt;Storage存储&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据如何存储和访问&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bp8ncb8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为每个Service选择存储结构&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u82c8ou&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;细化表结构&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;商品信息表-commodity-info&quot;&gt;商品信息表 commodity_info&lt;/h3&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;商品ID&lt;/th&gt;
&lt;th&gt;商品名称&lt;/th&gt;
&lt;th&gt;商品描述&lt;/th&gt;
&lt;th&gt;价格&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;desc&lt;/td&gt;
&lt;td&gt;price&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;MBP&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;好用&lt;/td&gt;
&lt;td&gt;25000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;秒杀活动表-seckill-info&quot;&gt;秒杀活动表 seckill_info&lt;/h3&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;秒杀ID&lt;/th&gt;
&lt;th&gt;秒杀名称&lt;/th&gt;
&lt;th&gt;商品ID&lt;/th&gt;
&lt;th&gt;价格&lt;/th&gt;
&lt;th&gt;数量&lt;br /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;commodity_id&lt;/td&gt;
&lt;td&gt;price&lt;/td&gt;
&lt;td&gt;number&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;MBP秒杀&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;20000&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;库存信息表-stock-info&quot;&gt;库存信息表 stock_info&lt;/h3&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;库存ID&lt;/th&gt;
&lt;th&gt;商品ID&lt;/th&gt;
&lt;th&gt;秒杀ID&lt;/th&gt;
&lt;th&gt;库存&lt;/th&gt;
&lt;th&gt;锁定&lt;br /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;commodity_id&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;seckill_id&lt;/td&gt;
&lt;td&gt;stock&lt;/td&gt;
&lt;td&gt;lock&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;189&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10000&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;189&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;订单信息表-order-info&quot;&gt;订单信息表 order_info&lt;/h3&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;订单ID&lt;/th&gt;
&lt;th&gt;商品ID&lt;/th&gt;
&lt;th&gt;活动ID&lt;/th&gt;
&lt;th&gt;用户ID&lt;/th&gt;
&lt;th&gt;是否付款&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;commodity_id&lt;/td&gt;
&lt;td&gt;seckill_id&lt;/td&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;is_pay&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;tianzeng&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;数据流向&quot;&gt;数据流向&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220624160023.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;秒杀操作:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-n6u4x80&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查询库存余量&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;select stock from stock_info where commodity_id = 1 and seckill_id = 1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-1m88dzg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扣减库存&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;update stock_info set stock = stock - 1 where commodity_id = 1 and seckill_id = 1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;Scala扩展设计&quot;&gt;Scala扩展设计&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;秒杀本身是一个非常简单的服务，不简单的是可优化的点非常的多。&lt;/p&gt;
&lt;h2 id=&quot;数据一致性&quot;&gt;数据一致性&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们上文直接采用MySQL，来应对查询，校验，扣减这一系列操作。但是这种粗暴的处理方式，在并发场景下会有超卖的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假如有两个线程进来，在第一步的时候都查询了库存，都认为当前线程持有库存。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;于是在扣减库存的时候，会把库存库存减少两次，会造成数据库中的数据和预期的不一致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种情况，我们可以开启事务进行处理, 在查询的时候使用for update 开启排他锁，以保证一个时间内，只有一个线程可以参与库存扣减&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 事务开始，会开启排它锁
start transaction;
select stock from stock_info where commodity_id = 1 and seckill_id = 1 for update;
update stock_info set stock = stock - 1 where commodity_id = 1 and seckill_id = 1 and 
commit;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者，使用乐观锁，只能够在库存数量大于0的的情况下，才能够执行库存的扣减&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;select stock from stock_info where commodity_id = 1 and seckill_id = 1 for update;
update stock_info set stock = stock - 1 where commodity_id = 1 and seckill_id = 1 and stock &amp;gt; 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;应对高QPS&quot;&gt;应对高QPS&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以直接利用MySQL自己的特性去解决超卖问题，但是单纯的使用MySQL在并发量上来之后会直接导致MySQL崩溃。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MySQl的QPS单点1000QPS，秒杀场景下MySQL崩溃，且秒杀场景下大部分请求无效，无需下沉到MySQL。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此需要更加高效的中间件来做这部分服务，将无效的请求拦截到上游，我们可以采用Redis，单机Redis能达到 10万QPS。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将库存信息放到Redis中，在Redis中做库存的校验。在活动上线之前，在Redis中提前做库存的预热，查询、校验、扣减先在Redis中处理好之后，再丢到MySQL进行处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在活动开始之前，从数据库读取秒杀活动，然后用下面的命令将商品库存预热到redis中&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 设置秒杀ID为1，商品ID为1的库存数量，只有100个
SET seckill:1:commodity:1:stock 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后，在用户请求过来的时候，用Redis拦截大量无效请求，通过Redis扣减库存之后在下方到MySQL中&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220628132949.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;Redis的缺陷优化&quot;&gt;Redis的缺陷优化&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;并发量超高，同时数百万请求同时到达Redis的库存检测逻辑，Redis全部放行，这时候Redis基本无作用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以用Lua脚本将读取库存和库存扣减合并成一个操作来进行执行。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;lua&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;local key=KEYS[1];
local subNum = tonumber(ARGV[1]) ;
local surplusStock = tonumber(redis.call(&apos;get&apos;,key));
if (surplusStock&amp;lt;=0) then return 0
elseif (subNum &amp;gt; surplusStock) then  return 1
else
    redis.call(&apos;incrby&apos;, KEYS[1], -subNum)
    return 2 
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220628134626.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种系统已经可以应对绝大多数的情况了&lt;/p&gt;
&lt;h2 id=&quot;这样就完美了吗-&quot;&gt;这样就完美了吗？&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们要秒杀的商品数据量在10W，这样下城到MySQL的量依旧非常巨大，无法承受。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以在库存扣减之后，到MySQL的请求慢一点，可以通过MQ来进行削峰&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220628135500.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;分布式事务&quot;&gt;分布式事务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于采用的是微服务来进行开发，一个成功的订单需要历经各种服务。&lt;/p&gt;
&lt;div data-content=&quot;sequenceDiagram
    participant 付款
    participant 支付服务
    participant 订单服务
    participant 商品服务
    付款-&amp;amp;gt;&amp;amp;gt;支付服务:支付记录
    支付服务-&amp;amp;gt;&amp;amp;gt;订单服务:更新订单状态成功付款
    订单服务-&amp;amp;gt;&amp;amp;gt;商品服务:扣减库存&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以需要分布式事务来对数据一致性，进行处理。关于分布式事务，看&lt;a href=&quot;/topic/分布式解决方案/数据调度/分布式事务/事务分类&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;其他的小细节&quot;&gt;其他的小细节&lt;/h2&gt;
&lt;h3 id=&quot;防止刷爆商品页面&quot;&gt;防止刷爆商品页面&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CDN -&amp;gt; 前端资源静态化&lt;/p&gt;
&lt;h3 id=&quot;服务高可用&quot;&gt;服务高可用&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽量不要影响其他服务，尤其是非秒杀产品的正常购买。&lt;/p&gt;
&lt;h3 id=&quot;防止恶意刷请求或者爬虫请求&quot;&gt;防止恶意刷请求或者爬虫请求&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用限流机制、验证码机制、或者接入三方风控等。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Nginx泛解析反向代理多个服务]]></title><link>https://www.ztianzeng.com/posts/Nginx泛解析反向代理多个服务</link><guid isPermaLink="false">/posts/Nginx泛解析反向代理多个服务</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 16 Jun 2022 03:33:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Nginx泛解析反向代理多个服务&quot;&gt;Nginx泛解析反向代理多个服务&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还是因为我的软路由，上面挂载了多个服务，如果要挨个配置各个服务的反向代理，不还得疯掉。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以需要一个通用的方式进行处理。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-otn05tk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先通过Nginx获取到所有泛解析的二级子域名&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2dd5q0q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提取出子域名之后，匹配好定义的upstream&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j9kyob3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;进行转发&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;脚本如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;nginx&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;
http {
    client_max_body_size 204800M;
    upstream note {
        server 192.168.31.10:6806;
    }
    upstream omv {
        server 192.168.31.10:80;
    }
    upstream qbt {
		server 192.168.31.10:8082;
    }
    upstream webdav {
        server 192.168.31.10:8080;
    }
    upstream openwrt {
        server 192.168.31.3:80;
    }

server {
	listen 2095;
	listen [::]:2095;
	server_name map.shiyitopo.tech;
	root /home/nginx/map_html;
	location / {
		try_files $uri $uri/ @router;
		index  index.html index.htm;
	}
	location @router {
		rewrite ^.*$ /index.html last;
	}
}
server {
	listen [::]:2095;
	listen 2095;
	server_name ~^(?&amp;lt;subdomain&amp;gt;.+).shiyitopo.tech$;
	location / {
		proxy_pass http://$subdomain;
		proxy_http_version 1.1;
		proxy_set_header Host $subdomain;
		proxy_set_header   X-Forwarded-Host   $http_host;
		proxy_set_header   X-Forwarded-For    $remote_addr;

	}
}  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;监听泛解析的域名，提取出二级域名之后，就用proxy_pass反向代理过去就行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就不需要有新的服务就建立一个server了，只需要定义好upstream的后端地址就可以了。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[概念]]></title><link>https://www.ztianzeng.com/topic/系统设计/概念</link><guid isPermaLink="false">/topic/系统设计/概念</guid><category><![CDATA[系统设计]]></category><pubDate>Wed, 15 Jun 2022 05:24:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;概念&quot;&gt;概念&lt;/h1&gt;
&lt;h1 id=&quot;数据库系统-VS-文件系统&quot;&gt;数据库系统 VS 文件系统&lt;/h1&gt;
&lt;h2 id=&quot;关系&quot;&gt;关系&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库系统是文件系统的一层包装，他们不是独立的关系，而是依赖的关系。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库系统依赖于文件系统。&lt;/p&gt;
&lt;h2 id=&quot;区别&quot;&gt;区别&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库系统提供了丰富的数据操作，相比于文件系统更加的细粒度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;文件系统只提供了简单的文件操作接口，相比于数据库系统更加的粗粒度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在关系型数据库上，提供了SQL语句可以快速的从文件系统中取出想要的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，在文件系统上，想查询到想要的数据，就可能需要遍历文件中的所有数据才能够找到。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库系统中读取的数据，大部分情况下，都还是会到文件系统上读取出来，因此两个系统的读写效率可以认为是差不多的。&lt;/p&gt;
&lt;h1 id=&quot;单体架构VS微服务架构&quot;&gt;单体架构VS微服务架构&lt;/h1&gt;
&lt;h2 id=&quot;单体架构&quot;&gt;单体架构&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220623171115.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5cfa088&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前后端耦合，服务压力大各功能模块耦合严重。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dateauj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统复杂，一个子模块升级需要导致整个服务都升级&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-516ua1e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展性差，难以针对某个模块单独扩展&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ymlw4jb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;开发协作困难，同一个仓库异常庞大&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xcmjg6f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;级联故障，模块故障导致服务不可用。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2hmv0th&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;瓶颈在数据库，数据库崩溃导致整个服务崩溃&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;微服务架构&quot;&gt;微服务架构&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220623171802.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;功能模块结构，单一职责&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统简单，升级服务不影响其他服务&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展性强，对某个服务单独扩容或者缩容&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;故障隔离，单个服务出现故障不影响其他服务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于RPC，可以选择不同服务进行组合、&lt;/p&gt;
&lt;hr /&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;单体架构优势&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2k9i4do&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;简单&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iobzl2z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;开发时间短&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-e6a8c39&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;适合访问量比较小的，系统要求不高的场景&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;OA办公系统，100个人使用&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[用ffmpeg从webm提取mp3]]></title><link>https://www.ztianzeng.com/posts/用ffmpeg从webm提取mp3</link><guid isPermaLink="false">/posts/用ffmpeg从webm提取mp3</guid><category><![CDATA[Other]]></category><pubDate>Tue, 14 Jun 2022 05:55:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;用ffmpeg从webm提取mp3&quot;&gt;用ffmpeg从webm提取mp3&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果需要将音频从.webm电影文件提取到.MP3音频文件，可以执行以下操作:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;FILE=&amp;quot;要处理的webm文件.webm&amp;quot;;
ffmpeg -i &amp;quot;${FILE}&amp;quot; -vn -ab 128k -ar 44100 -y &amp;quot;${FILE%.webm}.mp3&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一个命令将文件名分配给一个变量，这样做是为了避免在第二个命令中输入错误，因为我们希望对音频文件使用相同的名称。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二个命令用&lt;code&gt;ffmpeg&lt;/code&gt;命令从webm文件中提取出音频。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-hwpxrhd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;-i&lt;/code&gt;，表示输入的文件名&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5y20u4j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;-vn&lt;/code&gt;，&lt;code&gt;ffmpeg&lt;/code&gt;禁用视频录制&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fvjdk89&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;-ab&lt;/code&gt;，设置比特率为128k&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yrafhrh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;-ar&lt;/code&gt;，设置音频采样率为441000hz&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qs1edm6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;-y&lt;/code&gt;，如果文件重复，直接覆盖，不进行询问&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们想处理在同一个文件夹下的&lt;code&gt;webm&lt;/code&gt;文件列表，则可以通过下面这个脚本:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个脚本会从文件夹下找出所有后缀名为&lt;code&gt;webm&lt;/code&gt;的文件，并一个一个取进行处理&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;for FILE in *.webm; do
    echo -e &amp;quot;Processing video &apos;\e[32m$FILE\e[0m&apos;&amp;quot;;
    ffmpeg -i &amp;quot;${FILE}&amp;quot; -vn -ab 128k -ar 44100 -y &amp;quot;${FILE%.webm}.mp3&amp;quot;;
done;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不过这个脚本也能够换一种写法，更为简洁，通过linux的管道进行处理:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;find . -type f -iname &amp;quot;*.webm&amp;quot; -exec bash -c &apos;FILE=&amp;quot;$1&amp;quot;; ffmpeg -i &amp;quot;${FILE}&amp;quot; -vn -ab 128k -ar 44100 -y &amp;quot;${FILE%.webm}.mp3&amp;quot;;&apos; _ &apos;{}&apos; \;
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Cloudflare让IPV6不在鸡肋]]></title><link>https://www.ztianzeng.com/posts/Cloudflare让IPV6不在鸡肋</link><guid isPermaLink="false">/posts/Cloudflare让IPV6不在鸡肋</guid><pubDate>Mon, 13 Jun 2022 03:13:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Cloudflare让IPV6不在鸡肋&quot;&gt;Cloudflare让IPV6不在鸡肋&lt;/h1&gt;
&lt;h1 id=&quot;前言&quot;&gt;前言&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随着国内IPV4的公网地址越来越少，以及IPV6的不断普及，我们能够很方便的获取到公网的IPV6地址。但是在外面没有IPV6的情况下，想要访问家里的IPV6服务是一件很困难的事情。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虽然有着共有的6in4，或者ipv4转v6的代理隧道可以用，但是实际用下来，感觉由于代理服务器的影响，没有办法达到预期的速度。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;https://tunnelbroker.net/&quot;&gt;https://tunnelbroker.net/&lt;/a&gt; 提供了免费的IPV6隧道服务&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不过，国外有一个非常好用的CDN提供商，&lt;a href=&quot;https://www.cloudflare.com/zh-cn/&quot;&gt;CloudFlare&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它提供了一整套免费的CDN加速和代理，我们只需要通过CDN来代理请求的IPV6地址即可。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220613131516.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;准备工作&quot;&gt;准备工作&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;要想使用这套服务，直接访问到家中的设备需要准备下面这几样东西:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-o1dnujs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个属于自己的域名&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2sjn0ai&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个能够编写脚本的路由器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9z2pxxe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有一定动手能力,爱折腾&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;开始折腾&quot;&gt;开始折腾&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们第一步需要确保域名接入到了cloudflare中。通过修改名称服务器，将域名交给cloudflare进行托管。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后在cloudflare中新建一个了类型是AAAA的DNS，内容随便写啥。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为我用的是Openwrt，所以会以OpenWrt来进行说明&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;先登录OpenWrt的路由器, 查看LAN口的获取到的IPV6地址，把这个IPV6地址粘贴到CloudFlare中。（关于OpenWrt如何开启IPV6，网上教程很多）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后将Openwrt的端口修改成下面的任何一个（下面这些端口是CloudFlare支持的反向代理的端口，其次国内家用端口封80和443，我选择的是2095）&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-03vro4v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;8880&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ic5zeva&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2052&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6qhw8ug&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2082&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ucjb2ql&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2086&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-84dzd2c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2095&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不能访问，一般是由于防火墙的问题，我们可以用5G手机，直接访问[:IPV6地址:]:2095，来确定是不是防火墙的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220630093151.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一切设置完成，就能访问了。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;必须将代理状态设置成已代理，否则就会你和配置的域名之间就会走IPV6的方式访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;DDNS&quot;&gt;DDNS&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于我们拿到的IPV6是每次拨号都是在变化的，所以要能定时将最新的IPV6地址上报上去。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;脚本在下面:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;脚本需要用到jq，所以提取先安装&lt;a href=&quot;https://stedolan.github.io/jq/download/&quot;&gt;jq&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;#!/bin/bash

#LEDE/Openwrt may need install ca-bundle curl(opkg install ca-bundle curl)

#Add you custom record to the CloudFlare first.

#Your sub domain
SUB_DOMAIN=&amp;quot;webdav.shiyitopo.tech&amp;quot;
#dash --&amp;gt; example.com --&amp;gt; Overview --&amp;gt; Zone ID:
#https://dash.cloudflare.com/_your_account_id_/example.com
ZONE_ID=&amp;quot;&amp;quot;
#API Tokens
#https://dash.cloudflare.com/profile/api-tokens
#Manage access and permissions for your accounts, sites, and products
#example.com- Zone:Read, DNS:Edit
TOKEN_ID=&amp;quot;&amp;quot;
#The path of jq binaries . Download from https://stedolan.github.io/jq/download/
#If the system has installed jq. Just typed jq.
#If you custom a special binary. Just type the path of jq
JQ_PATH=&amp;quot;/root/jq-linux64&amp;quot;

if [ -n &amp;quot;$DNS_ZONE_ID&amp;quot; ]; then
    echo &amp;quot;The user has not configure the the ZONE ID &amp;quot;
    exit 1
fi

echo &amp;quot;Your dns zone id is: $ZONE_ID&amp;quot;
jsonResult=$(curl -s -X GET &amp;quot;https://api.cloudflare.com/client/v4/zones/${ZONE_ID}/dns_records&amp;quot; \
    -H &amp;quot;Authorization: Bearer ${TOKEN_ID}&amp;quot; \
    -H &amp;quot;Content-Type: application/json&amp;quot;)

curlResult=$(echo $jsonResult | $JQ_PATH -r .success)

if [ &amp;quot;$curlResult&amp;quot; = true ]; then
    echo &amp;quot;Get dns record success.&amp;quot;
else
    echo &amp;quot;Get dns record fail.$jsonResult&amp;quot;
    exit 1
fi

recordSize=$(echo $jsonResult | $JQ_PATH .result | $JQ_PATH length)
echo &amp;quot;Total found $recordSize record&amp;quot;

index=0
while [ $index -lt $recordSize ]; do
    tResult=$(echo $jsonResult | $JQ_PATH -r .result[$index])
    tmpDomain=$(echo $tResult | $JQ_PATH -r .name)
    type=$(echo $tResult | $JQ_PATH -r .type)

    if [ &amp;quot;$tmpDomain&amp;quot;x = &amp;quot;$SUB_DOMAIN&amp;quot;x ]; then
        if [ &amp;quot;AAAA&amp;quot;x = &amp;quot;$type&amp;quot;x ]; then
            echo &amp;quot;Found AAAA domain:$tmpDomain&amp;quot;
            identifier_v6=$(echo $tResult | $JQ_PATH -r .id)
        elif [ &amp;quot;A&amp;quot;x = &amp;quot;$type&amp;quot;x ]; then
            echo &amp;quot;Found A domain:$tmpDomain&amp;quot;
            identifier_v4=$(echo $tResult | $JQ_PATH -r .id)
        else
            echo &amp;quot;Please add the A or AAAA record manually first.&amp;quot;
        fi
    fi
    index=$(expr $index + 1)
done

if [ -z &amp;quot;$identifier_v4&amp;quot; ] &amp;amp;&amp;amp; [ -z &amp;quot;$identifier_v6&amp;quot; ]; then
    echo &amp;quot;Get &apos;$SUB_DOMAIN&apos; identifier failed. Please add the A or AAAA record manually first.&amp;quot;
    exit 1
else
    echo &amp;quot;Get &apos;$SUB_DOMAIN&apos; identifier success. [A] identifier:$identifier_v4 [AAAA] identifier:$identifier_v6&amp;quot;
fi

if [ -z &amp;quot;$identifier_v4&amp;quot; ]; then
    echo &amp;quot;IPv4 address are not required.&amp;quot;
else
    #IP=$(curl -s http://members.3322.org/dyndns/getip)
    IP=$(curl -s http://ip.3322.net/)
    regex=&apos;\b((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\.|$)){4}\b&apos;
    matchIP=$(echo $IP | grep -E $regex)
    if [ -n &amp;quot;$matchIP&amp;quot; ]; then
        echo &amp;quot;[$IP] IPv4 matches...&amp;quot;
        jsonResult=$(curl -s -X PUT &amp;quot;https://api.cloudflare.com/client/v4/zones/${ZONE_ID}/dns_records/${identifier_v4}&amp;quot; \
            -H &amp;quot;Authorization: Bearer ${TOKEN_ID}&amp;quot; \
            -H &amp;quot;Content-Type: application/json&amp;quot; \
            --data &apos;{&amp;quot;type&amp;quot;:&amp;quot;A&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;&apos;${SUB_DOMAIN}&apos;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&apos;${IP}&apos;&amp;quot;,&amp;quot;ttl&amp;quot;:1,&amp;quot;proxied&amp;quot;:false}&apos;)
        curlResult=$(echo $jsonResult | $JQ_PATH -r .success)

        if [ &amp;quot;$curlResult&amp;quot; = true ]; then
            echo &amp;quot;Update IPv4 dns record success.&amp;quot;
        else
            echo &amp;quot;Update IPv4 dns record fail.&amp;quot;
        fi
    else
        echo &amp;quot;[$IP]IPv4 doesn&apos;t match!&amp;quot;
    fi
fi

if [ -z &amp;quot;$identifier_v6&amp;quot; ]; then
    echo &amp;quot;IPv6 addresses are not required.&amp;quot;
else
    #IP=$(curl -6 ip.sb)
    IP=$(ip addr show dev  ens18|sed -e&apos;s/^.*inet6 \([^ ]*\)\/.*$/\1/;t;d&apos;|grep 2409|head -1)
    regex=&apos;^([0-9a-fA-F]{0,4}:){1,7}[0-9a-fA-F]{0,4}$&apos;
    matchIP=$(echo $IP | grep -E $regex)
    if [ -n &amp;quot;$matchIP&amp;quot; ]; then
        echo &amp;quot;[$IP] IPv6 matches...&amp;quot;
        echo &amp;quot;Update IPv6 ...&amp;quot;
        jsonResult=$(curl -s -X PUT &amp;quot;https://api.cloudflare.com/client/v4/zones/${ZONE_ID}/dns_records/${identifier_v6}&amp;quot; \
            -H &amp;quot;Authorization: Bearer ${TOKEN_ID}&amp;quot; \
            -H &amp;quot;Content-Type: application/json&amp;quot; \
            --data &apos;{&amp;quot;type&amp;quot;:&amp;quot;AAAA&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;&apos;${SUB_DOMAIN}&apos;&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&apos;${IP}&apos;&amp;quot;,&amp;quot;ttl&amp;quot;:1,&amp;quot;proxied&amp;quot;:true}&apos;)
        curlResult=$(echo $jsonResult | $JQ_PATH -r .success)

        if [ &amp;quot;$curlResult&amp;quot; = true ]; then
            echo &amp;quot;Update IPv6 dns record success.&amp;quot;
        else
            echo &amp;quot;Update IPv6 dns record fail.&amp;quot;
        fi
    else
        echo &amp;quot;[$IP] IPv6 doesn&apos;t match!&amp;quot;
    fi
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;后续也能通过Nginx进行反向代理，这样就不用配置其他服务的域名了，只需要通过nginx进行统一的转发即可。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[准备迎接SpringBoot3.0]]></title><link>https://www.ztianzeng.com/posts/准备迎接SpringBoot3.0</link><guid isPermaLink="false">/posts/准备迎接SpringBoot3.0</guid><pubDate>Mon, 06 Jun 2022 12:25:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;准备迎接SpringBoot3-0&quot;&gt;准备迎接SpringBoot3.0&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在2018年2月28号，发布了第一个&lt;code&gt;Spring Boot2.0&lt;/code&gt;的版本。在最近发布了&lt;code&gt;Spring Boot2.7&lt;/code&gt;的版本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;到目前为止，&lt;code&gt;Spring Boot 2.x &lt;/code&gt;已经维护了超过4年了，总共发布了95个版本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在，整个Spring的团队和社会上的自由贡献者，在为下一代的Spring做准备。计划在2022年11月发布&lt;code&gt;Spring Boot3.0&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下一个版本最重要的是基于Spring Framework 6.0的基础上进行开发，并且要求Java的版本在&lt;code&gt;Java17&lt;/code&gt;或以上。这也是Spring Boot使用Jakarta EE 9 APIs( &lt;code&gt;jakarta.*&lt;/code&gt;)的第一个版本（为了替代原来的Java EE 8 &lt;code&gt;javax.*&lt;/code&gt;）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来6个月的时间是一个非常好的机会，将自己的项目升级到最新的&lt;code&gt;Spring Boot3.0&lt;/code&gt;。这篇文章介绍了一些可以做的事情，使得未来发布的时候，使得迁移更加轻松。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;估计国内应该是没什么公司敢这么激进的升级&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;升级到Java-17&quot;&gt;升级到Java 17&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Spring Boot3.0 &lt;/code&gt;需要&lt;code&gt;Java 17&lt;/code&gt;才能够运行。 但是现在就可以将手中项目的环境升级到17了。因为目前现有的&lt;code&gt;Spring Boot2.0&lt;/code&gt;的版本，能够与&lt;code&gt;Java17&lt;/code&gt;做到很好的兼容。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;你也能够在自己的项目中用&lt;code&gt;Java 17&lt;/code&gt;的特性。如果有可能的话，建议现在、立刻、马上就升级&lt;code&gt;JDK&lt;/code&gt;系统。&lt;/p&gt;
&lt;h1 id=&quot;升级到最新的Spring-Boot-2-7-X&quot;&gt;升级到最新的Spring Boot 2.7.X&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前使用的是老的版本的&lt;code&gt;Spring Boot 2.0&lt;/code&gt; .强烈建议先升级到&lt;code&gt;Spring Boot 2.7&lt;/code&gt;.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当&lt;code&gt;Spring Boot 3.0&lt;/code&gt; released 的时候将会发布一个从2.7升级到3.0的迁移指南，而不是从更老的版本进行一个迁移。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;升级说明一般都会在release notes中进行提供。例如，如果你想升级&lt;code&gt;Spring Boot 2.6&lt;/code&gt;到2.7，你可以查看&lt;a href=&quot;https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.7-Release-Notes#upgrading-from-spring-boot-26&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;强烈不建议从Spring 2.5之前或者更早来进行一步到位的升级。通常来说小版本的升级会更加的容易（eg: 2.5-&amp;gt;2.6-2.7）而不是直接从2.5-&amp;gt;2.7。&lt;/p&gt;
&lt;h1 id=&quot;检测对标记Deprecated代码的调用&quot;&gt;检测对标记Deprecated代码的调用&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;code&gt;Spring Boot&lt;/code&gt;的进化中，会废弃掉一些方法或者类 与此同时会提供替代的方法或者类。我们往往会提供12个月左右的迭代期，在12个月之后过期的代码将会被删除。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;删除政策的文件在&lt;a href=&quot;https://github.com/spring-projects/spring-boot/wiki/Deprecations&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Spring Boot3.0&lt;/code&gt;将会删除所有的过期代码，因此我们推荐检查现有的代码，来找出所有引用了标记&lt;code&gt;@Deprecated&lt;/code&gt;的代码。当然，你能够开启-&lt;code&gt;Werror&lt;/code&gt;选项，来将编译期间的警告变成错误，使其编译失败。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;引用&lt;code&gt;@Deprecated&lt;/code&gt;的代码，编译器会发出警告，然后转成error，这样不处理就编译不通过了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;迁移application-properties和application-yml&quot;&gt;迁移application.properties和application.yml&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Spring Boot2.4&lt;/code&gt;修改了配置文件的加载方式。大多数用户会对这个改动并没有什么感知，因为项目可以设置&lt;code&gt;spring.config.use-legacy-processing=true&lt;/code&gt;来避免这个问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个来兼容新旧配置文件加载方式的属性，也将会在Spring3.0中进行删除，所以需要检查项目是否设置了这个属性，并且修改掉加载方式。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个被坑过，可以看 &lt;a href=&quot;../在Spring2.4中使用NacosConfig&quot;&gt;Spring2.4中使用NacosConfig&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;使用Spring-MVC的Pathpatternparser&quot;&gt;使用Spring MVC的Pathpatternparser&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring MVC 提供了两种解析URL路径的方式。自从Spring Boot 2.6之后&lt;code&gt;PathPatternParser&lt;/code&gt;是默认的解析方式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一些项目通过设置&lt;code&gt;spring.mvc.pathmatch&lt;/code&gt;手动切换回&lt;code&gt;AntPathMatcher&lt;/code&gt;来作为路径匹配的实现类。虽然在Spring Boot 3.0用也是能用，但是如果可能的话还是建议使用&lt;code&gt;PathPatternParser&lt;/code&gt;，因为它提供了更好的性能。&lt;/p&gt;
&lt;h2 id=&quot;性能对比-&quot;&gt;性能对比:&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;循环100000次：&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;路径匹配器&lt;/th&gt;
&lt;th&gt;第1次耗时&lt;/th&gt;
&lt;th&gt;第2次耗时&lt;/th&gt;
&lt;th&gt;第3次耗时&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AntPathMatcher&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;199&lt;/td&gt;
&lt;td&gt;188&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PathPattern&lt;/td&gt;
&lt;td&gt;118&lt;/td&gt;
&lt;td&gt;134&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;循环1000000次：&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;路径匹配器&lt;/th&gt;
&lt;th&gt;第1次耗时&lt;/th&gt;
&lt;th&gt;第2次耗时&lt;/th&gt;
&lt;th&gt;第3次耗时&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AntPathMatcher&lt;/td&gt;
&lt;td&gt;944&lt;/td&gt;
&lt;td&gt;852&lt;/td&gt;
&lt;td&gt;882&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PathPattern&lt;/td&gt;
&lt;td&gt;633&lt;/td&gt;
&lt;td&gt;637&lt;/td&gt;
&lt;td&gt;626&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;循环10000000次：&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;路径匹配器&lt;/th&gt;
&lt;th&gt;第1次耗时&lt;/th&gt;
&lt;th&gt;第2次耗时&lt;/th&gt;
&lt;th&gt;第3次耗时&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AntPathMatcher&lt;/td&gt;
&lt;td&gt;5561&lt;/td&gt;
&lt;td&gt;5469&lt;/td&gt;
&lt;td&gt;5461&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PathPattern&lt;/td&gt;
&lt;td&gt;4495&lt;/td&gt;
&lt;td&gt;4440&lt;/td&gt;
&lt;td&gt;4571&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;检查三方的项目是否有Jakarta-EE-9&quot;&gt;检查三方的项目是否有Jakarta EE 9&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Jakarta EE 9 是为了渠道Java EE 8的&lt;code&gt;javax&lt;/code&gt;。例如，Servlet 在Jakarata EE 8中是&lt;code&gt;javax.servlet&lt;/code&gt;,在9中则是&lt;code&gt;jakarta.servlet&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般来说，想在同一个项目中混用Java EE 和 Jakarta EE 是不可能的。你需要确保在你的代码和引用的三方库中，都是使用的&lt;code&gt;jakarta.*&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个好消息是，大多数维护良好的库都有提供Jakarta EE 9版本的包。例如，Hibernate、Thymeleaf、Tomcat、Jetty等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们推荐你花一些时间去检查三方库是否兼容了Jakarta EE。通常问题会出现在引入Servlet API中。&lt;/p&gt;
&lt;h1 id=&quot;检查三方库的Spring版本&quot;&gt;检查三方库的Spring版本&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Framework 6.0 与上一代不兼容。你需要检查使用的三方的jar包是否提供了与Spring Framework 6.0的兼容的版本。&lt;/p&gt;
&lt;h1 id=&quot;尝试一下Spring3-0&quot;&gt;尝试一下Spring3.0&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管不建议被用于到生产环境中，但是你也能够尝试一下看看将&lt;code&gt;Spring Boot 3.0&lt;/code&gt;集成到项目中有多难。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;切一个额外的分支出来来进行升级，这样能够提前的将问题暴露出来。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最好能在发布GA之前，将BUG提前暴露出来，然后反馈给我们。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以在&lt;a href=&quot;https://github.com/spring-projects/spring-boot/issues&quot;&gt;github.com/spring-projects/spring-boot/issues&lt;/a&gt;上提出问题（提问时请说明Spring的版本）&lt;/p&gt;
&lt;h1 id=&quot;商业支持&quot;&gt;商业支持&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Spring Boot 2.7&lt;/code&gt;是&lt;code&gt;2.x&lt;/code&gt;计划发布的最后一个版本。我们已经将此版本的开放源码支持延长了6个月，直至2023年11月。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，&lt;code&gt;Spring Boot 2.7&lt;/code&gt;的商业支持也得到了扩展，直至2025年2月。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;您可以在&lt;a href=&quot;spring.io/projects/spring-boot&quot;&gt;spring.io/projects/spring-boot&lt;/a&gt;上找到项目支持详细信息。有关商业支持的详细信息，请访问&lt;a href=&quot;tanzu.vmware.com/spring-runtime&quot;&gt;tanzu.vmware.com/spring-runtime&lt;/a&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由商业支持请求触发的任何版本都将始终以开源方式发布，这样商业客户也可以帮助开源社区。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;翻译自: &lt;a href=&quot;https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0&quot;&gt;https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content:encoded></item><item><title><![CDATA[K8S更换证书]]></title><link>https://www.ztianzeng.com/posts/K8S更换证书</link><guid isPermaLink="false">/posts/K8S更换证书</guid><category><![CDATA[K8S]]></category><pubDate>Mon, 06 Jun 2022 02:43:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;K8S更换证书&quot;&gt;K8S更换证书&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;kubeadm默认安装的证书有效期只有一年，过期只有整个集群都没有办法正常运行。一直在报错:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Get &amp;quot;https://[10.96.0.1]:443/apis/crd.projectcalico.org/v1/clusterinformations/default&amp;quot;: x509: certificate has expired or is not yet valid: current time 2022-06-05T22:31:49-04:00 is after 2022-06-02T11:30:48Z]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要对证书进行更换&lt;/p&gt;
&lt;h1 id=&quot;检查过期时间&quot;&gt;检查过期时间&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;kubeadm certs check-expiration
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220606104802.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;证书备份&quot;&gt;证书备份&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;备份是一个好习惯&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;cp -rp /etc/kubernetes /etc/kubernetes.bak
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;重新生成证书&quot;&gt;重新生成证书&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;kubeadm certs renew all
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220606104753.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;重启kubelet&quot;&gt;重启kubelet&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;验证更换是否成功&quot;&gt;验证更换是否成功&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;kubeadm certs check-expiration
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220606104802.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[4S分析法]]></title><link>https://www.ztianzeng.com/topic/系统设计/4S分析法</link><guid isPermaLink="false">/topic/系统设计/4S分析法</guid><category><![CDATA[系统设计]]></category><pubDate>Tue, 31 May 2022 09:52:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;4S分析法&quot;&gt;4S分析法&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以Twitter为案例，来作为一个分析&lt;/p&gt;
&lt;h1 id=&quot;Scenario场景&quot;&gt;&lt;u&gt;Scenario&lt;/u&gt;场景&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-c1qplqd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要设计哪些功能&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将功能列举出来，并进行排列，因为在一场中不可能让你设计整个系统，只能设计系统中的某几个最重要的模块&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pbap7ek&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要承受多大的访问量&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;承载的访问量的大小决定了采用中间件去实现我们的系统，不同的承载量所需要的中间件和设备都是不一样的，所以系统设计并没有最合适的架构，只有在衡量成本和收益之后设计出来的最符合当下情况的最合适的架构&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;需要设计哪些功能&quot;&gt;需要设计哪些功能&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一步列举功能:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bioenqx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注册、登录&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uslz9vv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户个人页面展示、编辑&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ekma9pw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上传图片、视频&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6xtbnbk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;搜索&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-29hoddr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送分享Twitter内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oz3n6a3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TimeLine和News Feed&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8hk4pn9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关注和取消关注用户&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二步骤，功能排序，选出核心功能:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dxfz117&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送Twitter&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-by1nwyj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TimeLine展示&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-khqcri1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;News Feed推送&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gquszoy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关注和取消关注用户&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yx62ytg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注册登录&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;需要承受的访问量&quot;&gt;需要承受的访问量&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们需要对访问量进行一个估算，下面大致是估算方式 :&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-67lni2v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;并发用户Concurrent User&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mxy6r2j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;日活跃用户数量 * 每个用户平均请求次数 / 一天多少秒 = 1M * 60 / 86100 &lt;span data-subtype=&quot;math&quot; data-content=&quot;\approx&quot;&gt;&lt;/span&gt; 700K&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5x621tr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;峰值 = Average Concurrent User * 3 &lt;span data-subtype=&quot;math&quot; data-content=&quot;\approx&quot;&gt;&lt;/span&gt; 2100K&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p7d66fo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读频率Read QPS （Queries Per Second）&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-hb3zcj6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;700K&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-05t6ea9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写频率Write QPS&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dmd78ra&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;5K&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就大致分析出需要承载的QPS。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面是一些硬件或者软件能够承载的QPS数量:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-k4j9x4o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS=100&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-fyfgq6h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;笔记本电脑&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-r8gniv9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS=1k&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-viaziuj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Web服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ma62yuc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要考虑单点故障&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-spgw9zi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS=1m&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wp4pu2h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;建设1000台的服务器集群&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-i59wi4e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要考虑集群维护成本，如何对资源进行调度&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fhmpg3c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QPS和WebServer 、Database之间的关系&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-afgcuib&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一台Web Server承受量是1k的QPS，实际上如果能扛得住100个QPS已经很牛逼了&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vfpnl7p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一台SQL Database承受量是1k QPS左右&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cbka12c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个NoSQL集群（Elasticsearch）承受量是10W左右&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j1b7wra&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内存数据库（Redis）100W QPS左右&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过这些预估的QPS数量，就能够估算出所需要的机器。&lt;/p&gt;
&lt;h1 id=&quot;Service服务&quot;&gt;Service服务&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将大系统拆分成一个个小服务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220614190843.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-uk9kli1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重放需求&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重新过一遍每个需求，为每个需求添加一个服务，用于处理内部逻辑&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2jl5p86&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;归并需求&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;归并相同的服务，对同一类问题的逻辑处理归并在同一个Service中&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将整个系统切分成若干个小的Service&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Storage存储&quot;&gt;Storage存储&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于我们写的Service而言，写的是具象化的程序，而程序=算法+数据结构。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是对于系统而言，系统=服务+数据存储。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以确定存储结构和介质尤为重要。&lt;/p&gt;
&lt;h2 id=&quot;处理步骤&quot;&gt;处理步骤&lt;/h2&gt;
&lt;h3 id=&quot;第一步-为每个Service选择存储结构&quot;&gt;第一步：为每个Service选择存储结构&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m2kidnu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库系统&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4vds0zo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关系型数据库 SQL DataBase&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0x59ihg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户信息&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h692hb0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;非关系数据库&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yckyb9h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;推文&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5k20zlk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;社交图谱&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o2g86ic&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;文件系统&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-o0u0iqu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;图片、视频、Media Files&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wrdq8rb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存系统Cache&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vr9dav8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不支持数据持久化&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-26xg4kn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是效率高，内存级别的访问速度&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220615103234.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;第二步-细化表结构&quot;&gt;第二步：细化表结构&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220615131659.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;存储模型&quot;&gt;存储模型&lt;/h2&gt;
&lt;h3 id=&quot;Pull-Model-拉模型&quot;&gt;Pull Model 拉模型&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220615151033.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-eyu8rje&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;算法:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在用户查看News Feed时，获取每一个好友的前100条Tweets，用K路归并算法进行合并，合并出前100条News Feeds&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h7a6gp1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;复杂度分析&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8bewut0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取News Feed ，如果有N个关注对象，则为N次DB Reads的时间 + K路归并的时间（可以忽略，因为DB Read花费时间更多）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1k5ptig&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发布Tweet ，1次DB Write的时间&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Scala扩展设计&quot;&gt;Scala扩展设计&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-9vawh6t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Optimize 优化&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rtrzae3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Maintenance 维护&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;处理步骤-&quot;&gt;处理步骤&lt;/h2&gt;
&lt;h3 id=&quot;第一步-优化&quot;&gt;第一步：优化&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jtdjn5c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解决设计缺陷&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0q4g211&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Pull 和 Push 模式的局限性&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o1mp15o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;更多的功能&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-veefz05&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Like、Follow &amp;amp; Unfollow、Ads&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xcwx92i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;特殊情况&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6za3e8x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;僵尸粉、热搜&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;第二部-维护&quot;&gt;第二部：维护&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vqgd6sb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;健壮性&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-id91wuo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;服务器或者数据库挂了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p6klqhv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展性&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-84mhard&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应对流量暴增的情况&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Pull的缺陷&quot;&gt;Pull的缺陷&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220615151033.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在用户进行读请求时，会访问每个关注的人的DB，所以这一块将会成为瓶颈&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-opxm8ux&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在访问DB之前，加入Cache&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wbwhghu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存每个用户的TimeLine&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1v1xgxp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;N次DB请求 转化为 N次Cache请求&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-v1kv64i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存每个用户的News Feeds&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-alo2gf2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;没有Cache News Feed的用户：归并N个用户最近的100条Tweets，取出结果前的100条&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bur0nd7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有Cache News Feed的用户：归并N个用户在某个时间戳之后的所有Tweets&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Push的缺陷&quot;&gt;Push的缺陷&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220615151122.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在用户发布一篇文章时，会向关注者的TimeLine中都插入一条Tweets。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-010p3ir&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会浪费更多的存储空间&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mks418k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个人那都会有一条Tweets数据&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gdzjazb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;存储相对内存便宜，可以接受&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xt9ld80&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不活跃用户的问题&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-p6icj5h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;导致每个人收到的时间不一样&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-90b00xs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;粉丝数量超级大，亿级&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xo6z20r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;插入的时长即使异步，也非常慢&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k1wtvlw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;切换回Pull模式，需要Trade Off ： Pull 和 Push成本&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;处理&quot;&gt;处理&lt;/h2&gt;
&lt;h3 id=&quot;最小改动&quot;&gt;最小改动&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1e2rq34&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展机器&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-sv642mz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Push的话，将需要插入的Tweets分布到多台机器上，并行插入&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w4z9v65&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Pull的话，增加Cache容量&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;增长预估&quot;&gt;增长预估&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对当前业务量的增长率进行一个预判，衡量是采用Pull还是Push，如果实在太大，考虑Push结合Pull进行优化&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jwtmaht&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;普通用户使用Push方案进行处理&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xet5oct&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;标记大V用户，采用Pull方式进行处理&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-az2g5hx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户查询，合并自己的TimeLine + 大V的TimeLine&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相对来说混用的模型实现上会比单纯的复杂。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[11.盛最多水的容器]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/11.盛最多水的容器</link><guid isPermaLink="false">/topic/LeetCode/双指针/11.盛最多水的容器</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><pubDate>Mon, 30 May 2022 05:09:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;11-盛最多水的容器&quot;&gt;11.盛最多水的容器&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode: &lt;a href=&quot;https://leetcode.cn/problems/container-with-most-water/&quot;&gt;https://leetcode.cn/problems/container-with-most-water/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;给定一个长度为 n 的整数数组 height 。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i]) 。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回容器可以储存的最大水量。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：[1,8,6,2,5,4,8,3,7]&lt;br /&gt;
输出：49&lt;br /&gt;
解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;决定一个容器容纳的水的大小，是由最短的那根木板决定。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，这道题目本质上寻找一个，底部长度和高度都相对较长的。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4uwxfzh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;声明左右指针，作为桶的左右边界&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-c10df1k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;按照双指针的思路向内部迭代&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4xiw00d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果左边的高度比右边小，则左边向右移；反之，右边向左移&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;若向内 移动短板 ，水槽的短板 min(h[i], h[j])min(h[i],h[j]) 可能变大，因此下个水槽的面积 可能增大&lt;br /&gt;
若向内 移动长板 ，水槽的短板 min(h[i], h[j])min(h[i],h[j]) 不变或变小，因此下个水槽的面积一定变小&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n6ekvyg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在迭代过程中，计算最大值，即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int maxArea(int[] height) {
    int left = 0;
    int right = height.length - 1;
    int max = -1;
    while (left &amp;lt; right){
        int leftHeight = height[left];
        int rightHeight = height[right];
        int cur = Math.min(leftHeight,rightHeight) * (right - left);
        max = Math.max(cur,max);
        if (leftHeight &amp;lt; rightHeight){
            left++;
        }else {
            right--;
        }

    }
    return max;
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[345.反转字符串中的元音字母]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/345.反转字符串中的元音字母</link><guid isPermaLink="false">/topic/LeetCode/双指针/345.反转字符串中的元音字母</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><pubDate>Mon, 30 May 2022 03:29:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;345-反转字符串中的元音字母&quot;&gt;345.反转字符串中的元音字母&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接:&lt;a href=&quot;https://leetcode.cn/problems/reverse-string/&quot;&gt; https://leetcode.cn/problems/reverse-string/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述: 反转字符串中的元音字母。元音字母包括 &lt;code&gt;&apos;a&apos;&lt;/code&gt;、&lt;code&gt;&apos;e&apos;&lt;/code&gt;、&lt;code&gt;&apos;i&apos;&lt;/code&gt;、&lt;code&gt;&apos;o&apos;&lt;/code&gt;、&lt;code&gt;&apos;u&apos;&lt;/code&gt;，且可能以大小写两种形式出现。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：s = &amp;quot;hello&amp;quot;&lt;br /&gt;
输出：&amp;quot;holle&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这道题的题型和&lt;a href=&quot;../125.验证回文串&quot;&gt;125.验证回文串&lt;/a&gt;类似，区别就是一个是反转另一个是比较。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zflvava&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;声明左右指针&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xu34r1x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将左右指针移动到有效的符号位置&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7khvrpy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;开始交换元素&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public String reverseVowels(String s) {
    char[] chars = s.toCharArray();
    int left = 0;
    int right = chars.length - 1;

    while (left &amp;lt; right){
        while (left &amp;lt; right &amp;amp;&amp;amp; !isV(chars[left])){
            left++;
        }
        while(left &amp;lt; right &amp;amp;&amp;amp; !isV(chars[right])){
            right--;
        }
        char t = chars[left];
        chars[left] = chars[right];
        chars[right] = t;
        left++;
        right--;
    }
    return new String(chars);
}
public boolean isV(char ch) {
    return &amp;quot;aeiouAEIOU&amp;quot;.indexOf(ch) &amp;gt;= 0;
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[125.验证回文串]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/125.验证回文串</link><guid isPermaLink="false">/topic/LeetCode/双指针/125.验证回文串</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><pubDate>Mon, 30 May 2022 03:01:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;125-验证回文串&quot;&gt;125.验证回文串&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode: &lt;a href=&quot;https://leetcode.cn/problems/valid-palindrome/&quot;&gt;https://leetcode.cn/problems/valid-palindrome/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述: 验证只考虑字母和数字字符的回文串&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入: &amp;quot;A man, a plan, a canal: Panama&amp;quot;&lt;br /&gt;
输出: true&lt;br /&gt;
解释：&amp;quot;amanaplanacanalpanama&amp;quot; 是回文串&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h3ek2yr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;声明左右指针&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gpp5j58&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将左右指针移动到有效的符号位置&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b2wdz05&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;开始比较&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public boolean isPalindrome(String s) {
    char[] chars = s.toLowerCase().toCharArray();
    int left = 0;
    int right = chars.length - 1;
    while (left &amp;lt; right){
        while (left &amp;lt; right &amp;amp;&amp;amp; !Character.isLetterOrDigit(chars[left])) {
            left++;
        }
        while (left &amp;lt; right  &amp;amp;&amp;amp; !Character.isLetterOrDigit(chars[right])) {
            right--;
        }
        if (chars[left] == chars[right]){
            left++;
            right--;
        }else {
            return false;
        }
    }
    return true;
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[80.删除有序数组中的重复项2]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/80.删除有序数组中的重复项2</link><guid isPermaLink="false">/topic/LeetCode/双指针/80.删除有序数组中的重复项2</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><pubDate>Fri, 27 May 2022 07:29:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;80-删除有序数组中的重复项2&quot;&gt;80.删除有序数组中的重复项2&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接: &lt;a href=&quot;https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/&quot;&gt;https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述：升序数组，删除重复元素（允许元素最多重复两次）&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：nums = [1,1,1,2,2,3]&lt;br /&gt;
输出：5, nums = [1,1,2,2,3]&lt;br /&gt;
解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3 。 不需要考虑数组中超出新长度后面的元素。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-9eg6qlh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果nums[fast] != nums[slow], 则slow++，将fast的值赋值于slow&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uyym8hq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;否则fast自顾自往前走即可&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zexgxua&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;a href=&quot;../26.删除有序数组中的重复项&quot;&gt;26题&lt;/a&gt;的基础上加上重复两次的限制&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rkok360&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;slow可以从1开始，fast从2开始&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-riv0ro4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;slow往前走的条件限制放宽&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在nums[fast] != nums[slow]的时候可以往前走&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;nums[fast-1] != nums[slow]的时候也可往前走&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int removeDuplicates(int[] nums) {
        int n = nums.length;
        int slow = 1;
        int fast = 2;
        while (fast &amp;lt; n){
            if (nums[slow] != nums[fast] || nums[slow-1] != nums[fast]){
                slow++;
                nums[slow] = nums[fast];
            }
            fast++;
        }
        return slow+1;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;复杂度分析&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-d4ulxhm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(n﻿)&quot;&gt;&lt;/span&gt;，其中 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 是数组的长度。快指针和慢指针最多各移动 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4zx4cx7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(1﻿)&quot;&gt;&lt;/span&gt;。只需要使用常数的额外空间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[283.移动零]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/283.移动零</link><guid isPermaLink="false">/topic/LeetCode/双指针/283.移动零</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><category><![CDATA[快慢指针]]></category><pubDate>Fri, 27 May 2022 07:02:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;283-移动零&quot;&gt;283.移动零&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接: &lt;a href=&quot;https://leetcode.cn/problems/move-zeroes/submissions/&quot;&gt;https://leetcode.cn/problems/move-zeroes/submissions/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述: 将数组中的零，移动到数组的最后，同时保持数组相对顺序不变&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入: nums = [0,1,0,3,12]&lt;br /&gt;
输出: [1,3,12,0,0]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用双指针，左指针指向当前已经处理好的序列的尾部，右指针指向待处理序列的头部。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;右指针不断向右移动，每次右指针指向非零数，则将左右指针对应的数交换，同时左指针右移。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此每次交换，都是将左指针的零与右指针的非零数交换，且非零数的相对顺序并未改变。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void moveZeroes(int[] nums) {
    int slow = 0;
    int fast = 0;
    while (fast &amp;lt; nums.length){
        if (nums[fast] != 0 ){
            nums[slow] = nums[fast];
            slow++;
        }
        fast++;
    }
    for (int i = slow;i&amp;lt;nums.length;i++){
        nums[i] = 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;复杂度分析&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-syno3v5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时间复杂度：O(n)&lt;strong&gt;O&lt;/strong&gt;(&lt;strong&gt;n&lt;/strong&gt;)，其中 n&lt;strong&gt;n&lt;/strong&gt; 为序列长度。每个位置至多被遍历两次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mfr8q3r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空间复杂度：O(1)&lt;strong&gt;O&lt;/strong&gt;(&lt;strong&gt;1&lt;/strong&gt;)。只需要常数的空间存放若干变量。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[并发请求去重]]></title><link>https://www.ztianzeng.com/posts/并发请求去重</link><guid isPermaLink="false">/posts/并发请求去重</guid><pubDate>Wed, 25 May 2022 12:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;并发请求去重&quot;&gt;并发请求去重&lt;/h1&gt;
&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一些请求在某种情况下，会导致重复请求，比如:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nay1h3e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Nginx反向代理下游服务器，下游服务器超时自动故障转移进行重试&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ha47e05&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前端按钮重复点击，没有做处理&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ajtmxv9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式环境下，请求出现错误进行重试&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vsu6cnv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;甚至于&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB&quot;&gt;重放攻击&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，对于后端来说需要统一去处理这种情况。&lt;/p&gt;
&lt;h1 id=&quot;利用唯一编号进行去重&quot;&gt;利用唯一编号进行去重&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在分布式环境下，我们可以借助Redis来进行数据去重,伪代码如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;fun 是否第一次访问(key){
    if (redis.setKey(key,key,超时时间)){
	return true
    }else {
	return false
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，目前的问题就是这个关键的key怎么生成&lt;/p&gt;
&lt;h2 id=&quot;提前下发&quot;&gt;提前下发&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以提供一个接口，提前下发一个key下去，在请求的时候带上这个key就可以完成重复接口的判断&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是这种方式会导致开发成本变大，不太适合用这个&lt;/p&gt;
&lt;h2 id=&quot;唯一索引&quot;&gt;唯一索引&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; 数据库处理就是设置唯一索引，可设联合唯一索引用来处理重复数据。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缺点：如果业务场景就是应该存储重复的数据，则该种方式不可用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;业务参数去重&quot;&gt;业务参数去重&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主流的方式都是采用业务参数进行去重&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以对请求的参数进行一个升序排序，拼接成一个字符串，然后字符串转成MD5来作为请求的key。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码如下：&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为用的是SpringMVC来做处理，参数都是用Bean来声明，所以加密的时候可以去掉排序这项，因为反序列化的顺序就是Bean中的顺序&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
public @interface RepeatableCommit {

    /**
     * 根据UserId限制重复提交
     * 取不到 ID 会报错
     */
    boolean userId() default true;

    /**
     * 用于定义区别重复提交的Key SPEl语法描述，就和CacheAble一样
     * &amp;lt;p&amp;gt;
     * 默认直接按照整个类去区分
     */
    String key() default &amp;quot;&amp;quot;;

    /**
     * 指定时间内不可重复提交,单位毫秒
     */
    long timeout() default 3000;
}

@Aspect
@Component
public class RepeatableCommitAspect {

    @Autowired
    private RedisConnectionFactory redisConnectionFactory;

    @Around(&amp;quot;@annotation(com.easysoft.puyao.config.RepeatableCommit)&amp;quot;)
    public Object around(ProceedingJoinPoint point) throws Throwable {
        MethodSignature signature = (MethodSignature) point.getSignature();
        Method method = signature.getMethod();
        RepeatableCommit commitAnnotation = method.getAnnotation(RepeatableCommit.class);
        String[] parameterNames = new LocalVariableTableParameterNameDiscoverer().getParameterNames(signature.getMethod());


        String className = method.getDeclaringClass().getName();
        String commitKey = handlerKey(commitAnnotation.key(), parameterNames, point.getArgs());

        String key;

        if (commitAnnotation.userId()) {
            String userId = BaseContextHandler.getUserId();
            if (userId == null) {
                throw new BizRuntimeException(API_REQUEST_LIMIT_ERROR, &amp;quot;请求失败，UserID不能为空&amp;quot;);
            }
            key = StrUtil.format(&amp;quot;{}_{}_{}&amp;quot;, className, commitKey, userId);
        } else {
            key = StrUtil.format(&amp;quot;{}_{}&amp;quot;, className, commitKey);
        }


        long timeout = commitAnnotation.timeout();
        RedisLockRegistry redisLockRegistry = new RedisLockRegistry(redisConnectionFactory, &amp;quot;new_king&amp;quot;, timeout);

        Lock lock = redisLockRegistry.obtain(&amp;quot;lock:&amp;quot; + key);
        if (!lock.tryLock()) {
            throw new BizRuntimeException(API_REQUEST_LIMIT_ERROR, &amp;quot;重复请求&amp;quot;);
        }
        //执行方法
        return point.proceed();
    }

    /**
     * 处理用于过滤重复请求的key
     */
    private String handlerKey(String key, String[] params, Object[] args) {
        if (StringUtils.isEmpty(key)) {
            return SecureUtil.md5(JSONObject.toJSONString(args));
        }
        Object request = getRequest(key, params, args);
        return SecureUtil.md5(JSONObject.toJSONString(request));
    }

    /**
     * 通过spring Spel 获取参数
     *
     * @param key            定义的key值 以#开头 例如:#user
     * @param parameterNames 形参
     * @param values         形参值
     * @return
     */
    public Object getRequest(String key, String[] parameterNames, Object[] values) {

        //spel解析器
        ExpressionParser parser = new SpelExpressionParser();
        //spel上下文
        EvaluationContext context = new StandardEvaluationContext();
        for (int i = 0; i &amp;lt; parameterNames.length; i++) {
            context.setVariable(parameterNames[i], values[i]);
        }
        return parser.parseExpression(key).getValue(context);
    }
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[27.移除元素]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/27.移除元素</link><guid isPermaLink="false">/topic/LeetCode/双指针/27.移除元素</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><category><![CDATA[快慢指针]]></category><pubDate>Wed, 25 May 2022 07:32:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;27-移除元素&quot;&gt;27.移除元素&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接: &lt;a href=&quot;https://leetcode.cn/problems/remove-element/&quot;&gt;https://leetcode.cn/problems/remove-element/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述: 移除指定元素&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：nums = [3,2,2,3], val = 3&lt;br /&gt;
输出：2, nums = [2,2]&lt;br /&gt;
解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这道题目和26题类似。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4myetqe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;声明slow和fast ，指向头部第一个元素&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-z7ln0we&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果fast向前走的过程中没有遇到val，则将fast值赋值给slow&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0fp90ma&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就能够确保，slow和slow之前的元素都是不包含val元素的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int removeElement(int[] nums, int val) {
        int n = nums.length;
        int slow = 0;
        int fast = 0;
        while (fast &amp;lt; n){
            if (nums[fast] != val){
                nums[slow] = nums[fast];
                slow++;
            }
            fast++;
        }
        return slow;
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[344.反转字符串]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/344.反转字符串</link><guid isPermaLink="false">/topic/LeetCode/双指针/344.反转字符串</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><category><![CDATA[左右指针]]></category><pubDate>Wed, 25 May 2022 03:30:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;344-反转字符串&quot;&gt;344.反转字符串&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接:&lt;a href=&quot;https://leetcode.cn/problems/reverse-string/&quot;&gt; https://leetcode.cn/problems/reverse-string/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述: 原地反转字符数组char[s]&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：s = [&amp;quot;h&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;o&amp;quot;]&lt;br /&gt;
输出：[&amp;quot;o&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;h&amp;quot;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-r6ciufd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;申明左右指针，左边代表首字母，右边代表位字母&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9fn70mv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首字母与倒数第一个字母交换&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ytx50un&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二个字母与倒数第二个字母交换&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mdc6e3l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重复以上过程，直到走到中间位置的字母为止&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void reverseString(char[] s) {
        int left = 0;
        int right = s.length - 1;
        while (left &amp;lt; right){
            char tmp = s[left];
            s[left] = s[right];
            s[right] = tmp;
            left++;
            right--;
        }
    }
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[167.两数之和 II - 输入有序数组]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/167.两数之和 II - 输入有序数组</link><guid isPermaLink="false">/topic/LeetCode/双指针/167.两数之和 II - 输入有序数组</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><category><![CDATA[左右指针]]></category><pubDate>Wed, 25 May 2022 02:23:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;167-两数之和-II---输入有序数组&quot;&gt;167.两数之和 II - 输入有序数组&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接: &lt;a href=&quot;https://leetcode.cn/problems/two-sum-ii-input-array-is-sorted/solution/yi-zhang-tu-gao-su-ni-on-de-shuang-zhi-zhen-jie-fa/&quot;&gt;https://leetcode.cn/problems/two-sum-ii-input-array-is-sorted/solution/yi-zhang-tu-gao-su-ni-on-de-shuang-zhi-zhen-jie-fa/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述：在有序数组中找出两个数，使它们的和为 target。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：numbers = [2,7,11,15], target = 9&lt;br /&gt;
输出：[1,2]&lt;br /&gt;
解释：2 与 7 之和等于目标数 9 。因此 index1 = 1, index2 = 2 。返回 [1, 2] 。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个指针指向值较小的元素，一个指针指向值较大的元素。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;指向较小元素的指针从头向尾遍历，指向较大元素的指针从尾向头遍历。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xdzf71v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果两个指针指向元素的和 sum == target，那么得到要求的结果；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-52l9pg8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 sum &amp;gt; target，移动较大的元素，使 sum 变小一些；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4xa84hn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 sum &amp;lt; target，移动较小的元素，使 sum 变大一些。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数组中的元素最多遍历一次，时间复杂度为 O(N)。只使用了两个额外变量，空间复杂度为 O(1)。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int[] twoSum(int[] numbers, int target) {
        int start = 0;
        int end = numbers.length - 1;
        while (start &amp;lt; end){
            if (numbers[start] + numbers[end] == target){
                return new int[]{start+1,end+1};
            }
            if (numbers[start] + numbers[end] &amp;lt; target){
                start ++;
            }else {
                end --;
            }
        }
        return new int[]{};
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;复杂度分析&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-p5332sw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(n)&quot;&gt;&lt;/span&gt;，其中 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 是数组的长度。两个指针移动的总次数最多为 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g1talho&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(1)﻿&quot;&gt;&lt;/span&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[26.删除有序数组中的重复项]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针/26.删除有序数组中的重复项</link><guid isPermaLink="false">/topic/LeetCode/双指针/26.删除有序数组中的重复项</guid><category><![CDATA[LeetCode]]></category><category><![CDATA[双指针]]></category><category><![CDATA[快慢指针]]></category><pubDate>Wed, 25 May 2022 02:20:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;26-删除有序数组中的重复项&quot;&gt;26.删除有序数组中的重复项&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LeetCode链接: &lt;a href=&quot;https://leetcode.cn/problems/remove-duplicates-from-sorted-array/&quot;&gt;https://leetcode.cn/problems/remove-duplicates-from-sorted-array/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;题目描述：升序数组，删除重复元素&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输入：nums = [1,1,2]&lt;br /&gt;
输出：2, nums = [1,2,_]&lt;br /&gt;
解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这道题可以采用快慢指针。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-u6iw5g4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果nums[fast] != nums[slow], 则slow++，将fast的值赋值于slow&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5k9zk1j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;否则fast自顾自往前走即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int removeDuplicates(int[] nums) {
        int n = nums.length;
        int slow = 0;
        int fast = 0;
        while (fast &amp;lt; n){
            if (nums[slow] != nums[fast]){
                slow++;
                nums[slow] = nums[fast];
            }
            fast++;
        }
        return slow+1;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;复杂度分析&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mjw28u2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(n﻿)&quot;&gt;&lt;/span&gt;，其中 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 是数组的长度。快指针和慢指针最多各移动 &lt;span data-subtype=&quot;math&quot; data-content=&quot;n&quot;&gt;&lt;/span&gt; 次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yvhmjdb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空间复杂度：&lt;span data-subtype=&quot;math&quot; data-content=&quot;O(1﻿)&quot;&gt;&lt;/span&gt;。只需要使用常数的额外空间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[每个程序员都应该知道的延迟数字]]></title><link>https://www.ztianzeng.com/topic/系统设计/每个程序员都应该知道的延迟数字</link><guid isPermaLink="false">/topic/系统设计/每个程序员都应该知道的延迟数字</guid><category><![CDATA[系统设计]]></category><pubDate>Tue, 24 May 2022 11:41:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;每个程序员都应该知道的延迟数字&quot;&gt;每个程序员都应该知道的延迟数字&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在一些情况下对系统设计的时候，需要做出对系统性能的保守估计。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Jeff Dean （谷歌的巨佬，分布式系统的奠基人）在&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf&quot;&gt;分布式系统的PPT&lt;/a&gt;中列出了&amp;quot;Latency Numbers Every Programmer Should Know&amp;quot;(每个程序员都应该了解的数字)，对计算机中的各类的操作的耗时做了大致的估计。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;操作&lt;/th&gt;
&lt;th&gt;延迟&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;执行一个指令&lt;/td&gt;
&lt;td&gt;1 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;L1 缓存查询&lt;/td&gt;
&lt;td&gt;0.5 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;分支预测错误（Branch mispredict）&lt;/td&gt;
&lt;td&gt;3 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;L2 缓存查询&lt;/td&gt;
&lt;td&gt;4 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;互斥锁/解锁&lt;/td&gt;
&lt;td&gt;17 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;在 1Gbps 的网络上发送 2KB&lt;/td&gt;
&lt;td&gt;44 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;主存访问&lt;/td&gt;
&lt;td&gt;100 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Zippy 压缩 1KB&lt;/td&gt;
&lt;td&gt;2,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;从内存顺序读取 1 MB&lt;/td&gt;
&lt;td&gt;3,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SSD 随机读&lt;/td&gt;
&lt;td&gt;16,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;从 SSD 顺序读取 1 MB&lt;/td&gt;
&lt;td&gt;49,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;同一个数据中心往返&lt;/td&gt;
&lt;td&gt;500,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;从磁盘顺序读取 1 MB&lt;/td&gt;
&lt;td&gt;825,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;磁盘寻址&lt;/td&gt;
&lt;td&gt;2,000,000 ns (2 ms)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;从美国发送到欧洲的数据包&lt;/td&gt;
&lt;td&gt;150,000,000 ns（150 ms）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于上述数字的指标：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-sskjcys&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从磁盘以 30 MB/s 的速度顺序读取&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rlse1kt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以 100 MB/s 从 1 Gbps 的以太网顺序读取&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2q3atgl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从 SSD 以 1 GB/s 的速度读取&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6nmj85r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以 4 GB/s 的速度从主存读取&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y250nhu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每秒能绕地球 6-7 圈&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wei98il&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据中心内每秒有 2,000 次往返&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Jeff Dean给出这些数字的重点是在于了解这些操作之间的数量级和比例，而不是具体的数字。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为计算机会随着科技的发展，变得越来越快。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;伯克利大学有个&lt;a href=&quot;https://colin-scott.github.io/personal_website/research/interactive_latency.html&quot;&gt;动态网页&lt;/a&gt;，可以查看每年各个操作耗时的变化&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220524195143.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[微博架构设计]]></title><link>https://www.ztianzeng.com/topic/系统设计/样例/微博架构设计</link><guid isPermaLink="false">/topic/系统设计/样例/微博架构设计</guid><category><![CDATA[系统设计]]></category><category><![CDATA[样例]]></category><pubDate>Tue, 24 May 2022 06:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;微博架构设计&quot;&gt;微博架构设计&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;微博日活跃用户1.6亿+，每日访问量达百亿级，面对庞大用户群的海量访问，需要有良好的架构设计来支撑微博这庞大的访问量。&lt;/p&gt;
&lt;h1 id=&quot;概述用例和约束&quot;&gt;概述用例和约束&lt;/h1&gt;
&lt;h2 id=&quot;用例&quot;&gt;用例&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-x11cdi1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt;发布了一条微博&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;服务&lt;/strong&gt;将微博推送给关注者，并且进行手机推送&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pqdsy25&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt;浏览自己的微博列表&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bqi25wp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt;浏览主页的微博列表（聚合关注的人的微博）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qhaa87d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt;可以通过关键词搜索&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ki8k6tk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;服务&lt;/strong&gt;应该具有高可用性&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;限制条件与假设&quot;&gt;限制条件与假设&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;普遍情况&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-stnxwsl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;网络流量不是均匀分布的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nf9ribn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发布微博的速度需要足够快速&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-sw26qpp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除非有上百万的关注者，否则将微博推送给粉丝的速度要足够快&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-c6oroyq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;1 亿个活跃用户&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ao5q3c3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每天新发布 5 亿条微博，每月新发布 150 亿条微博&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mi8wsoy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平均每条微博需要推送给 5 个人&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-stz7bsz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每天需要进行 50 亿次推送&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cvn4fbf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月需要进行 1500 亿次推送&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2qhvqc4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月需要处理 2500 亿次读取请求&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nxrd4ko&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月需要处理 100 亿次搜索&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;浏览功能&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7ihmnnt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;浏览的速度需要足够快&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j4drizs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读取的负载远大于写入的负载&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;搜索功能&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-b3tl0zk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;搜索的速度需要足够快&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3o1421s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;搜索是高负载的读取功能&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;计算用量&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ge3kayv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每条微博的大小：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1k9xm0h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;weibo_id&lt;/code&gt; - 8 字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-67wyvze&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;user_id&lt;/code&gt; - 32 字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ihhj09x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;text&lt;/code&gt; - 140 字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ft8a70q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;media&lt;/code&gt; - 平均 10 KB&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h6dpt0k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总计： 大约 10 KB&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pkviu0t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月产生新微博的内容为 150 TB&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nii2mp5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每条微博 10 KB * 每天 5 亿条微博* 每月 30 天&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2k66jgj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;3 年产生的内容为 5.4 PB&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-smjtjsd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每秒需要处理 10 万次读取请求&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-102nx8u&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个月需要处理 2500 亿次请求 * (每秒 400 次请求 / 每月 10 亿次请求)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5i6vq3d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每秒发布 6000 条微博&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-90nipsc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月发布 150 亿条微博 * (每秒 400 次请求 / 每月 10 次请求)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y52jecl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每秒推送 6 万条微博&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7a2ejfo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每月推送 1500 亿条微博 * (每秒 400 次请求 / 每月 10 亿次请求)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ag5hjnn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每秒 4000 次搜索请求&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;概要设计&quot;&gt;概要设计&lt;/h1&gt;
&lt;div data-content=&quot;graph TD;
	Client--&amp;amp;gt;WebServer;
	WebServer--&amp;amp;gt;WriteAPI;
	WebServer--&amp;amp;gt;ReadAPI;
	ReadAPI--&amp;amp;gt;TimeLineService;
	TimeLineService--&amp;amp;gt;WeiboInfoService;
	TimeLineService--&amp;amp;gt;UserInfoService;
	TimeLineService--&amp;amp;gt;MemoryCache;
	WriteAPI--&amp;amp;gt;FansService;
	FansService--&amp;amp;gt;MemoryCache;
	FansService--&amp;amp;gt;UserGraphService;
	FansService--&amp;amp;gt;SearchService;
	SearchAPI--&amp;amp;gt;SearchService;
	FansService--&amp;amp;gt;NotificationService;
	WebServer--&amp;amp;gt;SearchAPI;
	ReadAPI--&amp;amp;gt;MySQL;
	WriteAPI--&amp;amp;gt;MySQL;
	FansService--&amp;amp;gt;OSS;&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;设计核心组件&quot;&gt;设计核心组件&lt;/h1&gt;
&lt;h2 id=&quot;用例--用户发表了一篇微博&quot;&gt;用例: 用户发表了一篇微博&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以简单的先将数据存储到MySQL中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查看当前用户的关注的人发的微博以及推送数据是非常麻烦的事情。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据预估容量，每秒大概会产生6万条数据，这个操作一般的关系型数据库可能会支撑不住，因此可以通过NoSQL数据库或者内存数据库来对数据进行存储。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且对于微博架构这种，大V发送了微博远比普通的用户发送的微博带来的影响大，会造成数据的倾斜。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般情况下处理这种情况下会采用推拉结合的模式来进行处理:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ukjsh2w&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;推模式&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果用户被关注的人少，发送了微博，就直接将微博发送到各个人的收件箱中&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w0aingf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;拉模式&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果用户被关注的人多，发送了微博就存储在自己的发件箱里，关注的人拉取自己的关注的人时在对关注的人的发件箱和自己的收件箱进行一个聚合&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;处了数据模型，还需要对静态文件进行一个处理，可以借助于三方的对象存储来存储照片和视频之类的媒体文件。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ro3m6au&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt;向应用反向代理的&lt;strong&gt;Web 服务器&lt;/strong&gt;发送一条微博&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-41hhiq7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web 服务器&lt;/strong&gt;将请求转发给&lt;strong&gt;写 API&lt;/strong&gt;服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vz2xzw2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写 API&lt;/strong&gt;服务器将微博使用 &lt;strong&gt;SQL 数据库&lt;/strong&gt;存储于用户收件箱&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hz553ic&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写 API&lt;/strong&gt;调用 &lt;strong&gt;消息输出服务&lt;/strong&gt; ，进行以下操作：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-a76atvy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查询&lt;strong&gt;用户服务&lt;/strong&gt;找到存储于&lt;strong&gt;内存缓存&lt;/strong&gt;中的此用户的粉丝&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rk9s50c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将微博存储于&lt;strong&gt;内存缓存&lt;/strong&gt;中的&lt;strong&gt;此用户的粉丝的主页TimeLine&lt;/strong&gt;中&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mlvsfpm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;O(n) 复杂度操作： 1000 名粉丝 = 1000 次查找与插入&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pwq1z8c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将微博数据存储在&lt;strong&gt;搜索索引服务&lt;/strong&gt;中，以加快搜索&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-e5jymuy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将媒体存储于&lt;strong&gt;对象存储&lt;/strong&gt;中&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uruf6cn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用&lt;strong&gt;通知服务&lt;/strong&gt;向粉丝发送推送：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yvqnbcp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用&lt;strong&gt;队列&lt;/strong&gt;异步推送通知&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用例-用户浏览聚合主页时间轴&quot;&gt;用例：用户浏览聚合主页时间轴&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3jw9sr3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt;向 &lt;strong&gt;Web 服务器&lt;/strong&gt;发起一次读取主页的请求&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8hinrlm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web 服务器&lt;/strong&gt;将请求转发给&lt;strong&gt;读取 API&lt;/strong&gt;服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m5ahq0x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读取 API&lt;/strong&gt;服务器调用&lt;strong&gt;TimeLine服务&lt;/strong&gt;进行以下操作：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-02925xg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从&lt;strong&gt;内存缓存&lt;/strong&gt;读取时间轴数据，其中包括微博id 与用户 id - O(1)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-woqcn8e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过 &lt;a href=&quot;http://redis.io/commands/mget&quot;&gt;multiget&lt;/a&gt; 向&lt;strong&gt;微博信息服务&lt;/strong&gt;进行查询，以获取相关 id 微博的额外信息 - O(n)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cdv0ami&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过 muiltiget 向&lt;strong&gt;用户信息服务&lt;/strong&gt;进行查询，以获取相关 id 用户的额外信息 - O(n)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用例-用户浏览用户时间轴&quot;&gt;用例：用户浏览用户时间轴&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-50muszy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt;向&lt;strong&gt;Web 服务器&lt;/strong&gt;发起获得用户时间线的请求&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h3ntxr2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web 服务器&lt;/strong&gt;将请求转发给&lt;strong&gt;读取 API&lt;/strong&gt;服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7vrtpm9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读取 API&lt;/strong&gt;从 &lt;strong&gt;SQL 数据库&lt;/strong&gt;中取出用户的TimeLine&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用例-用户搜索关键词&quot;&gt;用例：用户搜索关键词&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-n9mzvq3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt;将搜索请求发给&lt;strong&gt;Web 服务器&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nlay1bm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web 服务器&lt;/strong&gt;将请求转发给&lt;strong&gt;搜索 API&lt;/strong&gt;服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-d8mcgok&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;搜索 API&lt;/strong&gt;调用&lt;strong&gt;搜索服务&lt;/strong&gt;进行以下操作：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dm2g4hk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对输入进行转换与分词，弄明白需要搜索什么东西&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ywcyp9m&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;移除标点等额外内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s209ksq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将文本打散为词组&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6iks5q7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修正拼写错误&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-39bq57t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;规范字母大小写&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-aadyhtk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将查询转换为布尔操作&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pgk515r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查询 &lt;strong&gt;搜索集群&lt;/strong&gt; （例如Lucene、ES）检索结果：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-cuh3ghn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对集群内的所有服务器进行查询，将有结果的查询进行聚合（Scatter gathers）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zlwp3as&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;合并取到的条目，进行评分与排序，最终返回结果&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;架构扩展&quot;&gt;架构扩展&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;消息发送服务&lt;/strong&gt;有可能成为性能瓶颈。那些有着百万数量关注着的用户可能发一条微博就需要好几分钟才能完成消息的发送进程。这有可能使 @回复 这种微博时出现竞争条件，因此需要根据服务时间进行重排序来降低影响。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们还可以避免从高关注量的用户输出。相反，我们可以通过搜索来找到高关注量用户的微博，并将搜索结果与用户的主页时间轴合并，再根据时间对其进行排序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，还可以通过以下内容进行优化：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h6ac8sf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;仅为每个主页时间轴在&lt;strong&gt;内存缓存&lt;/strong&gt;中存储数百条数据&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vferyin&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;仅在&lt;strong&gt;内存缓存&lt;/strong&gt;中存储活动用户的主页时间轴&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-i0fvj5r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果某个用户在过去 30 天都没有产生活动，那我们可以使用 &lt;strong&gt;SQL 数据库&lt;/strong&gt;重新构建他的时间轴&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vxvkukl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用&lt;strong&gt;用户服务&lt;/strong&gt;来查询并确定用户关注的人&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mst4pkj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从 &lt;strong&gt;SQL 数据库&lt;/strong&gt;中取出推特，并将它们存入&lt;strong&gt;内存缓存&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-owwsq62&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;仅在&lt;strong&gt;微博信息服务&lt;/strong&gt;中存储一个月的推特&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-eenrgsn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;仅在&lt;strong&gt;用户信息服务&lt;/strong&gt;中存储活动用户的信息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x8o7qob&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;搜索集群&lt;/strong&gt;需要将推特保留在内存中，以降低延迟&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们还可以考虑优化 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 来解决一些瓶颈问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;内存缓存&lt;/strong&gt;能减小一些数据库的负载，靠 &lt;strong&gt;SQL Read 副本&lt;/strong&gt;已经足够处理缓存未命中情况。我们还可以考虑使用一些额外的 SQL 性能拓展技术。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;高容量的写入将淹没单个的 &lt;strong&gt;SQL 写主从&lt;/strong&gt;模式，因此需要更多的拓展技术。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除此之外，还需要对热点事件造成的流量突增进行处理。可以采用容器化进行部署，流量或者负载达到一定程度就扩容。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[样例]]></title><link>https://www.ztianzeng.com/topic/系统设计/样例</link><guid isPermaLink="false">/topic/系统设计/样例</guid><category><![CDATA[系统设计]]></category><pubDate>Mon, 23 May 2022 08:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;样例&quot;&gt;样例&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[短链系统]]></title><link>https://www.ztianzeng.com/topic/系统设计/样例/短链系统</link><guid isPermaLink="false">/topic/系统设计/样例/短链系统</guid><category><![CDATA[系统设计]]></category><category><![CDATA[样例]]></category><pubDate>Mon, 23 May 2022 06:28:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;短链系统&quot;&gt;短链系统&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; a短链系统设计看起来简单，但是每个点都能展开很多知识点。短链是通过访问服务器上的链接，通过Http返回的302Code，对链接进行重定向，然后访问到对应的地址上。&lt;/p&gt;
&lt;div data-content=&quot;sequenceDiagram
    客户端-&amp;amp;gt;&amp;amp;gt;短链服务器: 访问A
    短链服务器-&amp;amp;gt;&amp;amp;gt;客户端: status code:302  location:B
    客户端 -&amp;amp;gt;&amp;amp;gt; B服务器: 访问B&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Http协议中重定向有两种code: 301 、302&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-v2q0gwl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;301: 代表永久&lt;strong&gt;重定向&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oe5i7sm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;302: 代表&lt;strong&gt;临时重定向&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;他们的区别就在于浏览器会对301做缓存的效果，如果返回的code是301，则浏览器缓存A到B的映射，在下次发起请求的时候不会再去请求A的服务器。&lt;/p&gt;
&lt;h1 id=&quot;概述用例和约束&quot;&gt;概述用例和约束&lt;/h1&gt;
&lt;h2 id=&quot;用例&quot;&gt;用例&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-j2z7tgb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt; 输入一段文本，然后得到一个随机生成的链接&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xbp5xm9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;过期设置&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jetvep2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;默认的设置是不会过期的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-93ia5go&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以选择设置一个过期的时间&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cus6hb6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt; 输入一个 paste 的 url 后，可以看到它存储的内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u641fh1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用户&lt;/strong&gt; 是匿名的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-i2dzcxp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Service&lt;/strong&gt; 跟踪页面分析&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3dhgqjh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个月的访问统计&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ht9pdga&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Service&lt;/strong&gt; 删除过期的 pastes&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5mceozk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Service&lt;/strong&gt; 需要高可用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;约束和假设&quot;&gt;约束和假设&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-stn89mo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;访问流量不是均匀分布的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-okbpcx2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;打开一个短链接应该是很快的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-15kkjgr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;pastes 只能是文本&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1rcmeyd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;页面访问分析数据可以不用实时&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-aoo2zo6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一千万的用户量&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-74pys8e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个月一千万的 paste 写入量&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h8e76yt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个月一亿的 paste 读取量&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3rgkbdg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读写比例在 10:1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;预估容量&quot;&gt;预估容量&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qmswvr0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个 paste 的大小&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-69p8eko&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每一个 paste 1 KB&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6t0r6ye&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;shortlink&lt;/code&gt; - 7 bytes&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vp8n9rc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;expiration_length_in_minutes&lt;/code&gt; - 4 bytes&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kpu3q07&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;created_at&lt;/code&gt; - 5 bytes&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uha9se9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总共 = ~1.27 KB&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pbaupdi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个月新的 paste 内容在 12.7GB&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-v6ewvxf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;(1.27 * 10000000)KB / 月的 paste&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uzr0j41&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;三年内将近 450GB 的新 paste 内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-svwc40c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;三年内 3.6 亿短链接&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7y42xkz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设大部分都是新的 paste，而不是需要更新已存在的 paste&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yn1zdei&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平均 4paste/s 的写入速度&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gp7m8dp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平均 40paste/s 的读取速度&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;创建一个高层次设计&quot;&gt;创建一个高层次设计&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用webServer作为请求的入口，然后调用API去访问SQL。最后采用Analytics对请求数据进行分析。&lt;/p&gt;
&lt;div data-content=&quot;graph TD;
    客户端--&amp;amp;gt;WebServer;
    WebServer--&amp;amp;gt;WriteAPI;
    WebServer--&amp;amp;gt;ReadAPI;
    ReadAPI--&amp;amp;gt;SQL;
    WriteAPI--&amp;amp;gt;SQL;
   Analytics --&amp;amp;gt;SQL;&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;设计核心组件&quot;&gt;设计核心组件&lt;/h1&gt;
&lt;h2 id=&quot;用例--用户输入一段文本-然后得到一个随机生成的链接&quot;&gt;用例: &lt;strong&gt;用户&lt;/strong&gt;输入一段文本，然后得到一个随机生成的链接&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用关系型数据库直接将生成的URL映射成用户的URL。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ixigvgd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt; 发送一个创建 paste 的请求到作为一个&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86web-%E6%9C%8D%E5%8A%A1%E5%99%A8&quot;&gt;反向代理&lt;/a&gt;启动的  &lt;strong&gt;Web 服务器&lt;/strong&gt; 。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j3kn0pi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web 服务器&lt;/strong&gt; 转发请求给 &lt;strong&gt;写接口&lt;/strong&gt; 服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s52wzex&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写接口&lt;/strong&gt; 服务器执行如下操作：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-40t06w9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生成一个唯一的 url&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1ugf17e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;检查这个 url 在 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 里面是否是唯一的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vi1oxrf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这个 url 不是唯一的，生成另外一个 url&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pmywsio&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们支持自定义 url，我们可以使用用户提供的 url（也需要检查是否重复）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0k6fl41&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;把生成的 url 和用户的url 存储到 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 的 &lt;code&gt;pastes&lt;/code&gt; 表里面&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lc2e2up&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回生成的 url&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;pastes&lt;/code&gt;结构如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;shortlink char(7) NOT NULL
expiration_length_in_minutes int NOT NULL
created_at datetime NOT NULL
paste varchar(2048) NOT NULL
PRIMARY KEY(shortlink)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;code&gt;shortlink&lt;/code&gt;上创建一个数据库索引，用来提高查询的速度。&lt;/p&gt;
&lt;h2 id=&quot;用例-用户输入一个-paste-的-url-后可以看到它存储的内容&quot;&gt;用例：用户输入一个 paste 的 url 后可以看到它存储的内容&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h2kqibq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;客户端&lt;/strong&gt; 发送一个获取 paste 请求到 &lt;strong&gt;Web Server&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zzmr7zd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Web Server&lt;/strong&gt; 转发请求给 &lt;strong&gt;读取接口&lt;/strong&gt; 服务器&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-q7n3twh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读取接口&lt;/strong&gt; 服务器执行如下操作：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qxwuhom&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 检查这个生成的 url&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1mcvfow&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这个 url 在 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 里面，则从返回这个 &lt;code&gt;paste&lt;/code&gt; 的内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p41gqhc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;否则，返回一个错误页面给用户&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用例--服务跟踪分析页面&quot;&gt;用例： 服务跟踪分析页面&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为实时分析不是必须的，所以我们可以简单的 &lt;strong&gt;MapReduce&lt;/strong&gt; &lt;strong&gt;Web Server&lt;/strong&gt; 的日志，用来生成点击次数。&lt;/p&gt;
&lt;h2 id=&quot;用例--服务删除过期的-pastes&quot;&gt;用例： 服务删除过期的 pastes&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了删除过期的 pastes，我们可以直接搜索 &lt;strong&gt;SQL 数据库&lt;/strong&gt; 中所有的过期时间比当前时间更早的记录， 所有过期的记录将从这张表里面删除（或者将其标记为过期）。&lt;/p&gt;
&lt;h1 id=&quot;扩展设计&quot;&gt;扩展设计&lt;/h1&gt;
&lt;div data-content=&quot;graph TD;
	Client--&amp;amp;gt;DNS负载;
        Client--&amp;amp;gt;CDN回源;
	DNS负载--&amp;amp;gt;LoadBalancer;
	LoadBalancer--&amp;amp;gt;WebServer;
	WebServer--&amp;amp;gt;WriteAPI;
	WebServer--&amp;amp;gt;ReadAPI;
	ReadAPI--&amp;amp;gt;MemoryCache;
	WriteAPI--&amp;amp;gt;SQLMaster-Slave;
	ReadAPI--&amp;amp;gt;SQLReadReplicas;
	SQLMaster-Slave --- SQLReadReplicas;
	Analytics--&amp;amp;gt;SQLAnalytics;
	SQLAnalytics--&amp;amp;gt;SQLMaster-Slave&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-c9xp47a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于请求量比较大的，应该将数据留在上游，这部分可以采用CDN来代理源站，将数据放在边缘&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4lpwugx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用LoadBalancer来代理我们具体的服务器，以便于可以对webServer进行水平扩展&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x2hdqpk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;处理每秒40的读请求，其内容应该交由给内存级别的缓存来处理。比如Redis这种&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vwkix7b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于单个关系型数据库，主从切分之后每秒4次的写入问题不大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果写入出现了瓶颈，需要额外采用别的方式。包括但不限于：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8atqr7v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;水平、垂直分片&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zylso6r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;非规范化&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u5s8qbg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SQL调优&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于短链系统，整体的系统的设计大概如此，从架构方面应该是满足要求了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其次，还有一些细节在我看来就是属于业务上的东西了，需要自行衡量,比如: 短链生成方法有好几种方式，Hash、Md5、UUID、redis、Snowflake、Mysql 自增主键。其选型并没有什么优劣之分，只有合适与否。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;整个系统的诞生是一个不断优化的过程，我们需要先解决有的问题，再持续进行优化。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mclsmtm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;继续对系统进行基准测试和监控，以在瓶颈出现时解决它们&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5ctl0g7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展是一个迭代的过程&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[系统设计]]></title><link>https://www.ztianzeng.com/topic/系统设计</link><guid isPermaLink="false">/topic/系统设计</guid><pubDate>Mon, 23 May 2022 06:28:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;系统设计&quot;&gt;系统设计&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220614171025.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; 在面试中遇到系统设计的问题，大多数的时候都会回答不全，或者回答的答案和面试官想要的大相径庭。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就比如，设计一个&lt;em&gt;1000QPS&lt;/em&gt;的秒杀系统啥Redis、MQ统统网上怼，系统都能扛得住数万QPS，明显看上去是背答案的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关于系统设计github上面有个非常好的repo: &lt;a href=&quot;https://github.com/donnemartin/system-design-primer&quot;&gt;https://github.com/donnemartin/system-design-primer&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面详细的提到了如何设计一个合理的系统 ,总共分为4个步骤:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这4个步骤也被称之为4s分析法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-gjz0suq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;描述使用场景，约束和假设（&lt;strong&gt;S&lt;/strong&gt;cenario）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;明确这个系统的使用场景以及预估所能承载的容量（QPS、DAU、Features）&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8wbwavo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;谁会使用它？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wguaq9e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;他们会怎样使用它？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hh83mlt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有多少用户？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t14gftz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统的作用是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-sf1wpre&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统的输入输出分别是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fiagsqt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们希望处理多少数据？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vg94pt7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们希望每秒钟处理多少请求？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3rnla5k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们希望的读写比率？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hlo51uq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;拆分不同的服务，并且对其进行设计（&lt;strong&gt;S&lt;/strong&gt;ervice）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用所有重要的组件来描绘出一个高层级的设计。（Split 、Application 、Module）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对每一个核心组件进行详细深入的分析。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-hjn4ehy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;画出主要的组件和连接&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jkm94b6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;证明你的想法&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-emj4xbt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;设计服务对应的存储逻辑（&lt;strong&gt;S&lt;/strong&gt;torage）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据最终需要进行持久化存储，需要选择不同的存储中间件，来衡量其不同的设计。（SQL、NoSQL、File System）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-up96b32&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩展设计（&lt;strong&gt;S&lt;/strong&gt;cala）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;确认和处理瓶颈以及一些限制。（Sharding、Optimize、Special Case）&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-diof4mf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;负载均衡&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-slmtzdf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;水平扩展&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1vqhvx6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过上面这4个步骤，就能大体设计出来一个相对完备的系统。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Gatsby4.0升级]]></title><link>https://www.ztianzeng.com/posts/Gatsby4.0升级</link><guid isPermaLink="false">/posts/Gatsby4.0升级</guid><pubDate>Fri, 20 May 2022 06:25:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Gatsby4-0升级&quot;&gt;Gatsby4.0升级&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Gastby发布了4.0的版本，引入了巨大的性能改进。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最大的特点是最多减少40%的构建时间和两个新的渲染选项:延迟静态生成和服务端渲染。&lt;/p&gt;
&lt;h1 id=&quot;处理旧的依赖&quot;&gt;处理旧的依赖&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在升级到V4版本之前，最好将所有的插件都升级到V3版本，这样可以竟可能避免出现问题。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以通过&lt;code&gt;npm outdated&lt;/code&gt; 或者 &lt;code&gt;yarn upgrade-interactive&lt;/code&gt;来自动升级到v3的版本&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;升级好之后，运行&lt;code&gt;yarn buld&lt;/code&gt;看看有没有什么问题，出现啥问题修复啥问题。&lt;/p&gt;
&lt;h1 id=&quot;安装最新的Gatsby版本&quot;&gt;安装最新的Gatsby版本&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接通过命令安装最快乐。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; yarn add gatsby@latest
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行玩之后，使用&lt;code&gt;yarn build&lt;/code&gt; 如果没有出现大问题的话，则升级成功&lt;/p&gt;
&lt;h1 id=&quot;更新插件&quot;&gt;更新插件&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在升级完成之后，启动时会出现很多warning比如下面这样:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;warn Plugin gatsby-plugin-react-helmet is not compatible with your gatsby version 4.14.1 - It requires gatsby@^3.0.0-next.0
warn Plugin gatsby-plugin-sitemap is not compatible with your gatsby version 4.14.1 - It requires gatsby@^3.0.0-next.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要根据warning挨个升级依赖。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果社区版的插件没有升级到最新，就没有办法了，只有等待社区更新。不过大部分情况下都不影响使用。&lt;/p&gt;
&lt;h2 id=&quot;遇到的问题&quot;&gt;遇到的问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前我的博客只遇到了一个问题，id冲突。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在调用&lt;code&gt;createNode&lt;/code&gt;的时候，之前的版本会将后创建id相同的话不会覆盖，新版本则会覆盖。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外一个问题是，如果删除了&lt;code&gt;yarn.lock&lt;/code&gt;会导致无法启动成功，因为对npm的依赖机制不是很了解，所以暂时先将&lt;code&gt;yarn.lock&lt;/code&gt;进行上传跳过这个问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它会抛出一个&lt;code&gt;@parcel/source-map not found&lt;/code&gt;的异常，是&lt;code&gt;@parcel/utils&lt;/code&gt;中引用的，大概是版本可能有所偏差。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[双指针]]></title><link>https://www.ztianzeng.com/topic/LeetCode/双指针</link><guid isPermaLink="false">/topic/LeetCode/双指针</guid><category><![CDATA[LeetCode]]></category><pubDate>Thu, 19 May 2022 03:31:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;双指针&quot;&gt;双指针&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;双指针主要用于遍历数组或者链表，两个指针指向不同的元素，从而协同完成任务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是双指针并不隶属于某一种数据结构，无论是数组、链表、字符串等元素都会运用到双指针，而且双指针的提醒在面对中小型的公司，也是笔试的常客。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;双指针主要分为两大类: 左右指针和快慢指针。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rh52yyu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;左右指针:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个指针相向而行 -&amp;gt;   &amp;lt;-&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ih109va&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;快慢指针:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个指针同向而行，一快一慢  -&amp;gt;   -&amp;gt;&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;快慢指针&lt;/strong&gt;也是双指针，但是两个指针从同一侧开始遍历数组，将这两个指针分别定义为&lt;code&gt;快指针（fast）&lt;/code&gt;和&lt;code&gt;慢指针（slow）&lt;/code&gt;，两个指针以不同的策略移动，直到两个指针的值相等（或其他特殊条件）为止，如fast每次增长两个，slow每次增长一个。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;伪代码如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;js&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;function fn(list) {
        var slow = 0;
        var fast = 0;
        while (fast &amp;lt; list.length){
	    slow++;
	    fas
        }
        return slow+1;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ugoty9r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;26.删除有序数组中的重复项&quot;&gt;26.删除有序数组的重复项&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x0x1szb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;80.删除有序数组中的重复项2&quot;&gt;80.删除有序数组中的重复项 II&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-df78qt6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;27.移除元素&quot;&gt;27.移除元素&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-98w7e4q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;283.移动零&quot;&gt;283.移动零&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;左右指针&lt;/strong&gt;是指在有序数组中，将指向最左侧的索引定义为&lt;code&gt;左指针(left)&lt;/code&gt;，最右侧的定义为&lt;code&gt;右指针(right)&lt;/code&gt;，然后从两头向中间进行数组遍历。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;左右对撞适用于有序数组，也就是说当你遇到题目给定有序数组时，应该第一时间想到用左右指针解题&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;js&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;function fn (list) {
  var left = 0;
  var right = list.length - 1;

  //遍历数组
  while (left &amp;lt;= right) {
    left++;
    // 一些条件判断 和处理
    ... ...
    right--;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-964ztrf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;167.两数之和%20II%20-%20输入有序数组&quot;&gt;167.两数之和 II - 输入有序数组&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rrlx5py&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;344.反转字符串&quot;&gt;344.反转字符串&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ejyarhj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;125.验证回文串&quot;&gt;125.验证回文串&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t3s9y63&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;345.反转字符串中的元音字母&quot;&gt;345.反转字符串中的元音字母&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g6mfgnb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;11.盛最多水的容器&quot;&gt;11.盛最多水的容器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[LeetCode]]></title><link>https://www.ztianzeng.com/topic/LeetCode</link><guid isPermaLink="false">/topic/LeetCode</guid><pubDate>Thu, 19 May 2022 03:12:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;LeetCode&quot;&gt;LeetCode&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Log Structured Merge Tree LSM原理]]></title><link>https://www.ztianzeng.com/posts/Log Structured Merge Tree LSM原理</link><guid isPermaLink="false">/posts/Log Structured Merge Tree LSM原理</guid><pubDate>Wed, 18 May 2022 03:01:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Log-Structured-Merge-Tree-LSM原理&quot;&gt;Log Structured Merge Tree LSM原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最近在看Google十年前发表的&lt;a href=&quot;/topic/分布式解决方案/分布式理论/三驾马车/BigTable中文翻译&quot;&gt;BigTable论文&lt;/a&gt;，BigTable这玩意，最骚的一点就是改变了大多数传统数据库所使用的文件组织方法,业界对这种新一代的文件组织方法进行了实现，叫做Log Structured Merge Tree，简称LSM，中文叫做&lt;em&gt;日志结构的合并树。&lt;/em&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LSM目前被用于多个面向大数据的数据库产品: HBase、Cassandra、LevelDB等。&lt;/p&gt;
&lt;h1 id=&quot;诞生背景&quot;&gt;诞生背景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无论B树和B+树在写入的时候，为了能处理数据库异常崩溃的场景，通常都会有额外的结构，学名叫做&lt;strong&gt;预写式日志&lt;/strong&gt;(WAL，write-ahead log)，在Mysql 中叫做 redo log。在写入数据之前，会将操作都写入这个redo log(这个文件在磁盘上)，然后再从这个redo log中将数据同步到具体的B树中。这样即使数据库发生崩溃，也能够通过这个日志文件，让B树恢复到一致的状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是B树难以应对并发操作的情况，在多个线程同时访问B树的时候需要加锁，需要保证树的结构是一致和完整的，否则不同的线程就会看到树处于不一致的状态。Msql会有各个隔离级别和各种锁，也是因为这个原因。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了加快写入的速度，就诞生了LSM这个算法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LSM的思想，在对于数据修改采用增量的方式保存在内存中，内存容量达到指定的限制时就将操作的数据批量写入到磁盘(SSTable，Sorted String Table)中，相比较于写入操作的高性能，读取操作需要合并内存中最近修改的操作和磁盘中的历史数据，需要先看内存，如果没有命中还要访问磁盘文件。将之前使用一个大的查找结构（造成随机读写，影响写性能），变换为将写操作顺序的保存到一些相似的有序文件（也就是sstable)中。所以每个文件包含短时间内的一些改动。因为文件是有序的，所以之后查找也会很快。文件是不可修改的，他们永远不会被更新，新的更新操作只会写到新的文件中。通过周期性的合并这些文件来减少文件个数。&lt;/p&gt;
&lt;h2 id=&quot;B树对比LSM树&quot;&gt;B树对比LSM树&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;B树在写入的时候至少会被写入两次，一次是WAL(redo log)，另一次是树结构本身。即使树只有几个字节的变化，也需要接受整个页面写入的开销。如果一张表存在多个索引树，那肯定会对硬盘造成多次写入。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一次数据库操作导入对磁盘上的文件多次写入，被称之为写放大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LSM树会有更低的写放大，因为磁盘上的SSTable是顺序且紧凑的而不是必须复写树结构。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且LSM树可以对文件进行压缩和排序，这是SSTable的特性所决定的，Stored String Table中的数据是可排序的，也就意味着可以用前缀树来进行排序。然后由于sstable文件是不可修改的，这让对他们的锁操作非常简单。一般来说，唯一的竞争资源就是memtable，相对来说需要相对复杂的锁机制来管理在不同的级别。&lt;/p&gt;
&lt;h1 id=&quot;LSM树&quot;&gt;LSM树&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LSM本质上并不是一种树，而是一种文件组织的形式，将数据进行一个分层以便于获得更好的性能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从结构上分为两类，一种是存储在内存中的Memtable，另一种则是存储在磁盘中的SSTable。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220518153629.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般简单的都会划分为两层，Level 0 是存储在内存上的Memtable，Level 0以上则是存在磁盘中的SSTable&lt;/p&gt;
&lt;h2 id=&quot;基本原理&quot;&gt;基本原理&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nqraezu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写入操作&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当一些更新操作到达时，他们会被写到内存缓存（也就是memtable）中，memtable使用树结构来保持key的有序.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在大部分的实现中，memtable会通过写WAL的方式备份到磁盘，用来恢复数据，防止数据丢失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当memtable数据达到一定规模时会被刷新到磁盘上的一个新文件，重要的是系统只做了顺序磁盘读写，因为没有文件被编辑，新的内容或者修改只用简单的生成新的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rn61n2n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;合并文件&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以越多的数据存储到系统中，就会有越多的不可修改的，顺序的sstable文件被创建，它们代表了小的，按时间顺序的修改。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为比较旧的文件不会被更新，重复的记录只会通过创建新的记录来覆盖，这也就产生了一些冗余的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以系统会周期的执行合并操作（compaction)。 合并操作选择一些文件，并把他们合并到一起，移除重复的更新或者删除记录，同时也会删除上述的冗余。更重要的是，通过减少文件个数的增长，保证读操作的性 能。因为sstable文件都是有序结构的，所以合并操作也是非常高效的。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8jr3qp4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读操作&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读操作优先判断key是否在MemTable, 如果不在的话，则把覆盖该key range的所有SSTable都查找一遍。简单，但是低效。因此，在工程实现上，一般会为SSTable加入索引。可以是一个key-offset索引（类似于kafka的index文件），也可以是布隆过滤器（Bloom Filter）。布隆过滤器有一个特性：如果bloom说一个key不存在，就一定不存在，而当bloom说一个key存在于这个文件，可能是不存在的。实现层面上，布隆过滤器就是&lt;code&gt;key--比特位&lt;/code&gt;的映射。理想情况下，当然是一个key对应一个比特实现全映射，但是太消耗内存。因此，一般通过控制假阳性概率来节约内存，代价是牺牲了一定的读性能。对于我们的应用场景，我们将该概率从0.99降低到0.8，布隆过滤器的内存消耗从2GB+下降到了300MB，数据读取速度有所降低，但在感知层面可忽略。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LSM Tree 思想是把随机写入转化成顺序写入，这样可以大幅度提升写入的性能，但是查询性能会有一部分牺牲。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在时序数据库运用这一特性非常合适。持续写入数据量大，数据和时间，将时间编码到 key 值中很容易使 key 值有序。读取操作通常是根据某个Key的值，去获取一段时间范围内的数据。这样就把 LSM Tree 读取性能差的劣势缩小了，反而因为数据在 SSTable 中是按照 key 值顺序排列，读取大块连续的数据时效率也很高。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[BigTable中文翻译]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/三驾马车/BigTable中文翻译</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/三驾马车/BigTable中文翻译</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><category><![CDATA[三驾马车]]></category><pubDate>Mon, 16 May 2022 08:05:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;BigTable中文翻译&quot;&gt;BigTable中文翻译&lt;/h1&gt;
&lt;h1 id=&quot;1-摘要&quot;&gt;1 摘要&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服 务器上的 PB 级的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Google 的很多项目使用 Bigtable 存储数据，包括 Web 索引、Google Earth、Google Finance。这些应用对 Bigtable 提出的要求差异非常大，无论是在数据量上（从 URL 到网页到卫星图像）还是在响应速度上（从后 端的批量处理到实时数据服务）。尽管应用需求差异很大，但是，针对 Google 的这些产品，Bigtable 还是成功 的提供了一个灵活的、高性能的解决方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本论文描述了 Bigtable 提供的简单的数据模型。利用这个模型，用户可以动态的控制数据的分布和格式。 我们还将描述 Bigtable 的设计和实现。&lt;/p&gt;
&lt;h1 id=&quot;2-介绍&quot;&gt;2 介绍&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在过去两年半时间里，我们设计、实现并部署了一个分布式的结构化数据存储系统 — 在 Google，我们 称之为 Bigtable。Bigtable 的设计目的是可靠的处理 PB 级别的数据，并且能够部署到上千台机器上。Bigtable 已经实现了下面的几个目标：适用性广泛、可扩展、高性能和高可用性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 已经在超过 60 个 Google 的产品和项目上得到了应用，包括 Google Analytics、Google Finance、 Orkut、Personalized Search、Writely 和 Google Earth。这些产品对 Bigtable 提出了迥异的需求，有的需要高吞 吐量的批处理，有的则需要及时响应，快速返回数据给最终用户。它们使用的 Bigtable 集群的配置也有很大 的差异，有的集群只有几台服务器，而有的则需要上千台服务器、存储几百 TB 的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在很多方面，Bigtable 和数据库很类似：&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它使用了很多数据库的实现策略。并行数据库和内存数 据库已经具备可扩展性和高性能，但是 Bigtable 提供了一个和这些系统完全不同的接口。Bigtable 不支持完整的关系数据模型；与之相反，Bigtable 为客户提供了简单的数据模型，利用这个模型，客户可以动态控 制数据的分布和格式 ，用户也可以自己推测 底层存储数据的位置相关性。数据的下标是行和列的名字，名字可以是任意的字符串。Bigtable 将存储的数据都视为字符串，但是 Bigtable 本身不去解析这些字符串，客户程序通常会在把各种结构化或者半结构化的数据串行化到这些字符串里。通过仔细选择数据的模式，客户可以控制数据的位置相关性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后，可以通过 BigTable 的模式参数来控制数据是存放在内存中、还是硬盘上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; 第 3 节描述关于数据模型更多细节方面的东西；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 4 节概要介绍了客户端 API；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 5 节简要介绍了 BigTable 底层使用的 Google 的基础框架；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 6 节描述了 BigTable 实现的关键部分；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 7 节描述了我们为了提高 BigTable 的性能采用的一些精细的调优方法；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 8 节提供了 BigTable 的性能数据；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 9 节讲述了几个 Google 内部使用 BigTable 的例子；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 10 节是我们在设计和后期支持过程中得到一些经验和教训；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后，在第 11 节列出我们的相关研究工作；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 12 节是我们的结论。&lt;/p&gt;
&lt;h1 id=&quot;3-数据模型&quot;&gt;3 数据模型&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序 Map。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Map 的索引是行关键字、列关键字 以及时间戳；Map 中的每个 value 都是一个未经解析的 byte 数组。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sql&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;(row:string, column:string,time:int64)-&amp;gt;string
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在仔细分析了一个类似 Bigtable 的系统的种种潜在用途之后，决定使用这个数据模型。我们先举个 具体的例子，这个例子促使我们做了很多设计决策；假设我们想要存储海量的网页及相关信息，这些数据可 以用于很多不同的项目，我们姑且称这个特殊的表为 Webtable。在 Webtable 里，我们使用 URL 作为行关键 字，使用网页的某些属性作为列名，网页的内容存在“contents:”列中，并用获取该网页的时间戳作为标识 ， 如图一所示。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516165015.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;行名是一个反向 URL。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;contents 列族存放的是网页的内容，anchor 列族存放引用该网页的锚链接文本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CNN 的主页被 Sports Illustrator 和 MY-look 的主页引用， 因此该行包含了名为“ anchor:cnnsi.com ”和 “anchhor:my.look.ca”的列。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个锚链接只有一个版本 ；而 contents 列则有三个版本，分别由时间戳 t3，t5和 t6 标识。&lt;/p&gt;
&lt;h2 id=&quot;3-1-行&quot;&gt;3.1 行&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;表中的行关键字可以是任意的字符串（目前支持最大 64KB 的字符串，但是对大多数用户，10-100 个字 节就足够了）。对同一个行关键字的读或者写操作都是原子的（不管读或者写这一行里多少个不同列），这个 设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 通过行关键字的字典顺序来组织数据。表中的每个行都可以动态分区。每个分区叫做一个”Tablet”， Tablet 是数据分布和负载均衡调整的最小单位。这样做的结果是，当操作只读取行中很少几列的数据时效率很 高，通常只需要很少几次机器间的通信即可完成。用户可以通过选择合适的行关键字，在数据访问时有效利 用数据的位置相关性，从而更好的利用这个特性。举例来说，在 Webtable 里，通过反转 URL 中主机名的方 式，可以把同一个域名下的网页聚集起来组织成连续的行。具体来说，我们可以把 maps.google.com/index.html 的数据存放在关键字 com.google.maps/index.html 下。把相同的域中的网页存储在连续的区域可以让基于主机 和域名的分析更加有效。&lt;/p&gt;
&lt;h2 id=&quot;3-2-列族&quot;&gt;3.2 列族&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;列关键字组成的集合叫做“列族“，列族是访问控制的基本单位。存放在同一列族下的所有数据通常都 属于同一个类型（我们可以把同一个列族下的数据压缩在一起）。列族在使用之前必须先创建，然后才能在列 族中任何的列关键字下存放数据；列族创建后，其中的任何一个列关键字下都可以存放数据。根据我们的设 计意图，一张表中的列族不能太多（最多几百个），并且列族在运行期间很少改变。与之相对应的，一张表可 以有无限多个列。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;列关键字的命名语法如下：列族：限定词。 列族的名字必须是可打印的字符串，而限定词的名字可以是 任意的字符串。比如，Webtable 有个列族 language，language 列族用来存放撰写网页的语言。我们在 language 列族中只使用一个列关键字，用来存放每个网页的语言标识 ID。Webtable 中另一个有用的列族是 anchor；这 个列族的每一个列关键字代表一个锚链接，如图一所示。Anchor 列族的限定词是引用该网页的站点名；Anchor 列族每列的数据项存放的是链接文本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;访问控制、磁盘和内存的使用统计都是在列族层面进行的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们的 Webtable 的例子中，上述的控制权 限能帮助我们管理不同类型的应用：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据 并创建继承的列族、一些应用则只允许浏览数据（甚至可能因为隐私的原因不能浏览所有数据）。&lt;/p&gt;
&lt;h2 id=&quot;3-3-时间戳&quot;&gt;3.3 时间戳&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Bigtable 中，表的每一个数据项都可以包含同一份数据的不同版本；不同版本的数据通过时间戳来索 引。Bigtable 时间戳的类型是 64 位整型。Bigtable 可以给时间戳赋值，用来表示精确到毫秒的“实时”时间； 用户程序也可以给时间戳赋值。如果应用程序需要避免数据版本冲突，那么它必须自己生成具有唯一性的时 间戳。数据项中，不同版本的数据按照时间戳倒序排序，即最新的数据排在最前面。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了减轻多个版本数据的管理负担，我们对每一个列族配有两个设置参数，Bigtable 通过这两个参数可以 对废弃版本的数据自动进行垃圾收集。用户可以指定只保存最后 n 个版本的数据，或者只保存“足够新”的 版本的数据（比如，只保存最近 7 天的内容写入的数据）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Webtable 的举例里，contents:列存储的时间戳信息是网络爬虫抓取一个页面的时间。上面提及的垃圾 收集机制可以让我们只保留最近三个版本的网页数据。&lt;/p&gt;
&lt;h1 id=&quot;4-API&quot;&gt;4 API&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 提供了建立和删除表以及列族的 API 函数。Bigtable 还提供了修改集群、表和列族的元数据的 API，比如修改访问权限。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// Open the table

Table *T = OpenOrDie(“/bigtable/web/webtable”);

// Write a new anchor and delete an old anchor

RowMutation r1(T, “com.cnn.www”);

r1.Set(“anchor:www.c-span.org”, “CNN”);

r1.Delete(“anchor:www.abc.com”);

Operation op;

Apply(&amp;amp;op, &amp;amp;r1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户程序可以对 Bigtable 进行如下的操作：写入或者删除 Bigtable 中的值、从每个行中查找值、或者遍 历表中的一个数据子集。图 2 中的Ｃ++代码使用 RowMutation 抽象对象进行了一系列的更新操作。（为了保持示例代码的简洁，我们忽略了一些细节相关代码）。调用 Apply 函数对Ｗebtable 进行了一个原子修改操作：它为 www.cnn.com 增加了一个锚点，同时删除了另外一个锚点。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Scanner scanner(T);

ScanStream *stream;

stream = scanner.FetchColumnFamily(“anchor”);

stream-&amp;gt;SetReturnAllVersions();

scanner.Lookup(“com.cnn.www”);

for (; !stream-&amp;gt;Done(); stream-&amp;gt;Next()) {

printf(“%s %s %lld %s\n”,

scanner.RowName(),

stream-&amp;gt;ColumnName(),

stream-&amp;gt;MicroTimestamp(),

stream-&amp;gt;Value());

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;C++代码使用 Scanner 抽象对象遍历一个行内的所有锚点。客户程序可以遍历多个列族，有几 种方法可以对扫描输出的行、列和时间戳进行限制。例如，我们可以限制上面的扫描，让它只输出那些匹配 正则表达式*.cnn.com 的锚点，或者那些时间戳在当前时间前 10 天的锚点。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 还支持一些其它的特性，利用这些特性，用户可以对数据进行更复杂的处理。首先，Bigtable 支 持单行上的事务处理，利用这个功能，用户可以对存储在一个行关键字下的数据进行原子性的读-更新-写操作。 虽然 Bigtable 提供了一个允许用户跨行批量写入数据的接口，但是，Bigtable 目前还不支持通用的跨行事务处 理。其次，Bigtable 允许把数据项用做整数计数器。最后，Bigtable 允许用户在服务器的地址空间内执行脚本 程序。脚本程序使用 Google 开发的 Sawzall数据处理语言。虽然目前我们基于的 Sawzall 语言的 API 函数还不允许客户的脚本程序写入数据到 Bigtable，但是它允许多种形式的数据转换、基于任意表达式的数据 过滤、以及使用多种操作符的进行数据汇总。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 可以和 MapReduce一起使用，MapReduce 是 Google 开发的大规模并行计算框架。我们已经开发了一些 Wrapper 类，通过使用这些 Wrapper 类，Bigtable 可以作为 MapReduce 框架的输入和输出。&lt;/p&gt;
&lt;h1 id=&quot;5-BigTable-构件&quot;&gt;5 BigTable 构件&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 是建立在其它的几个 Google 基础构件上的。BigTable 使用 Google 的分布式文件系统(GFS)存储日志文件和数据文件。BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable 的进程经常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来 调度任务、管理共享的机器上的资源、处理机器的故障、以及监视机器的状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BigTable 内部存储数据的文件是 Google SSTable 格式的。SSTable 是一个持久化的、排序的、不可更改的 Map 结构，而 Map 是一个 key-value 映射的数据结构，key 和 value 的值都是任意的 Byte 串。可以对 SSTable 进行如下的操作：查询与一个 key 值相关的 value，或者遍历某个 key 值范围内的所有的 key-value 对。从内 部看，SSTable 是一系列的数据块（通常每个块的大小是 64KB，这个大小是可以配置的）。SSTable 使用块索 引（通常存储在 SSTable 的最后）来定位数据块；在打开 SSTable 的时候，索引被加载到内存。每次查找都可 以通过一次磁盘搜索完成：首先使用二分查找法在内存中的索引里找到数据块的位置，然后再从硬盘读取相 应的数据块。也可以选择把整个 SSTable 都放在内存中，这样就不必访问硬盘了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BigTable 还依赖一个高可用的、序列化的分布式锁服务组件，叫做 Chubby。一个 Chubby 服务包括 了 5 个活动的副本，其中的一个副本被选为 Master，并且处理请求。只有在大多数副本都是正常运行的，并 且彼此之间能够互相通信的情况下，Chubby 服务才是可用的。当有副本失效的时候，Chubby 使用 Paxos 算法来保证副本的一致性。Chubby 提供了一个名字空间，里面包括了目录和小文件。每个目录或者文件 可以当成一个锁，读写文件的操作都是原子的。Chubby 客户程序库提供对 Chubby 文件的一致性缓存。每个 Chubby 客户程序都维护一个与 Chubby 服务的会话。如果客户程序不能在租约到期的时间内重新签订会话的 租约，这个会话就过期失效了。当一个会话失效时，它拥有的锁和打开的文件句柄都失效了。Chubby 客户 程序可以在文件和目录上注册回调函数，当文件或目录改变、或者会话过期时，回调函数会通知客户程序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 使用 Chubby 完成以下的几个任务：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bhlajcr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;确保在任何给定的时间内最多只有一个活动的 Master 副本；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-taisbht&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;存储 BigTable 数据的自引导指令的位置（参考 5.1 节）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-py1cemi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;查找 Tablet 服务器，以及在 Tablet 服务器失效时进行善后（5.2 节）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4mumu9d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;存储 BigTable 的模式信息（每张表的列族信息）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rwupzs3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以及存储访问控制列表。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 Chubby 长时间无法访问，BigTable 就会失效。最近我们在使用 11 个 Chubby 服务实例的 14 个 BigTable 集群上测量了这个影响。由于 Chubby 不可用而导致 BigTable 中的部分数据不能访问的平均比率是 0.0047% （Chubby 不能访问的原因可能是 Chubby 本身失效或者网络问题）。单个集群里，受 Chubby 失效影响最大的 百分比是 0.0326%&lt;sup&gt;10&lt;/sup&gt;。&lt;/p&gt;
&lt;h1 id=&quot;6-介绍&quot;&gt;6 介绍&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 包括了三个主要的组件：链接到客户程序中的库、一个 Master 服务器和多个 Tablet 服务器。针 对系统工作负载的变化情况，BigTable 可以动态的向集群中添加（或者删除）Tablet 服务器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器主要负责以下工作：为 Tablet 服务器分配 Tablets、检测新加入的或者过期失效的 Table 服 务器、对 Tablet 服务器进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。除此之外，它还处理对模 式的相关修改操作，例如建立表和列族。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个 Tablet 服务器都管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet 服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和很多 Single-Master 类型的分布式存储系统类似，客户端读取的数据都不经过 Master 服务器： 客户程序直接和 Tablet 服务器通信进行读写操作。由于 BigTable 的客户程序不必通过 Master 服务器来获取 Tablet 的位置信息，因此，大多数客户程序甚至完全不需要和 Master 服务器通信。在实际应用中，Master 服 务器的负载是很轻的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个 BigTable 集群存储了很多表，每个表包含了一个 Tablet 的集合，而每个 Tablet 包含了某个范围内的 行的所有相关数据。初始状态下，一个表只有一个 Tablet。随着表中数据的增长，它被自动分割成多个 Tablet， 缺省情况下，每个 Tablet 的尺寸大约是 100MB 到 200MB。&lt;/p&gt;
&lt;h2 id=&quot;6-1-Tablet-的位置&quot;&gt;6.1 Tablet 的位置&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们使用一个三层的、类似Ｂ+树的结构存储 Tablet 的位置信息(如图 4)。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516171916.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一层是一个存储在 Chubby 中的文件，它包含了 Root Tablet 的位置信息。Root Tablet 包含了一个特殊 的 METADATA 表里所有的 Tablet 的位置信息。METADATA 表的每个 Tablet 包含了一个用户 Tablet 的集合。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Root Tablet 实际上是 METADATA 表的第一个 Tablet，只不过对它的处理比较特殊 — Root Tablet 永远不会被分割。这就保证了 Tablet 的位置信息存储结构不会超过三层。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 METADATA 表里面，每个 Tablet 的位置信息都存放在一个行关键字下面，而这个行关键字是由 Tablet 所在的表的标识符和 Tablet 的最后一行编码而成的。METADATA 的每一行都存储了大约 1KB 的内存数据。 在一个大小适中的、容量限制为 128MB 的 METADATA Tablet 中，采用这种三层结构的存储模式，可以标识 2&lt;sup&gt;34&lt;/sup&gt; 个 Tablet 的地址（如果每个 Tablet 存储 128MB 数据，那么一共可以存储 2&lt;sup&gt;61&lt;/sup&gt;字节数据）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户程序使用的库会缓存 Tablet 的位置信息。如果客户程序没有缓存某个 Tablet 的地址信息，或者发现它缓存的地址信息不正确，客户程序就在树状的存储结构中递归的查询 Tablet 位置信息；如果客户端缓存是 空的，那么寻址算法需要通过三次网络来回通信寻址，这其中包括了一次 Chubby 读操作；如果客户端缓存的 地址信息过期了，那么寻址算法可能需要最多６次网络来回通信才能更新数据，因为只有在缓存中没有查到 数据的时候才能发现数据过期11 。尽管 Tablet 的地址信息是存放在内存里的，对它的操作不必访问 GFS 文件 系统，但是，通常我们会通过预取 Tablet 地址来进一步的减少访问的开销：每次需要从 METADATA 表中读 取一个 Tablet 的元数据的时候，它都会多读取几个 Tablet 的元数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 METADATA 表中还存储了次级信息 ，包括每个 Tablet 的事件日志（例如，什么时候一个服务器开始 为该 Tablet 提供服务）。这些信息有助于排查错误和性能分析。&lt;/p&gt;
&lt;h2 id=&quot;6-2-Tablet-分配&quot;&gt;6.2 Tablet 分配&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在任何一个时刻，一个 Tablet 只能分配给一个 Tablet 服务器。Master 服务器记录了当前有哪些活跃的 Tablet 服务器、哪些 Tablet 分配给了哪些 Tablet 服务器、哪些 Tablet 还没有被分配。当一个 Tablet 还没有被分配、 并且刚好有一个 Tablet 服务器有足够的空闲空间装载该 Tablet 时，Master 服务器会给这个 Tablet 服务器发送 一个装载请求，把 Tablet 分配给这个服务器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BigTable 使用 Chubby 跟踪记录 Tablet 服务器的状态。当一个 Tablet 服务器启动时，它在 Chubby 的一个 指定目录下建立一个有唯一性名字的文件，并且获取该文件的独占锁。Master 服务器实时监控着这个目录（服 务器目录），因此 Master 服务器能够知道有新的 Tablet 服务器加入了。如果 Tablet 服务器丢失了 Chubby 上的 独占锁 — 比如由于网络断开导致 Tablet 服务器和 Chubby 的会话丢失 — 它就停止对 Tablet 提供服务。 （Chubby 提供了一种高效的机制，利用这种机制，Tablet 服务器能够在不增加网络负担的情况下知道它是否 还持有锁）。只要文件还存在，Tablet 服务器就会试图重新获得对该文件的独占锁；如果文件不存在了，那么 Tablet 服务器就不能再提供服务了，它会自行退出 。当 Tablet 服务器终止时（比如，集群的管理系统将运行 该 Tablet 服务器的主机从集群中移除），它会尝试释放它持有的文件锁，这样一来，Master 服务器就能尽快把 Tablet 分配到其它的 Tablet 服务器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器负责检查一个 Tablet 服务器是否已经不再为它的 Tablet 提供服务了，并且要尽快重新分配 它加载的 Tablet。Master 服务器通过轮询 Tablet 服务器文件锁的状态来检测何时 Tablet 服务器不再为 Tablet 提供服务。如果一个 Tablet 服务器报告它丢失了文件锁，或者 Master 服务器最近几次尝试和它通信都没有得 到响应，Master 服务器就会尝试获取该 Tablet 服务器文件的独占锁；如果 Master 服务器成功获取了独占锁， 那么就说明 Chubby 是正常运行的，而 Tablet 服务器要么是宕机了、要么是不能和 Chubby 通信了，因此，Master 服务器就删除该 Tablet 服务器在 Chubby 上的服务器文件以确保它不再给 Tablet 提供服务。一旦 Tablet 服务器 在 Chubby 上的服务器文件被删除了，Master 服务器就把之前分配给它的所有的 Tablet 放入未分配的 Tablet 集合中。为了确保 Bigtable 集群在 Master 服务器和 Chubby 之间网络出现故障的时候仍然可以使用，Master 服务器在它的 Chubby 会话过期后主动退出。但是不管怎样，如同我们前面所描述的，Master 服务器的故障不 会改变现有 Tablet 在 Tablet 服务器上的分配状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当集群管理系统启动了一个 Master 服务器之后，Master 服务器首先要了解当前 Tablet 的分配状态，之后 才能够修改分配状态。Master 服务器在启动的时候执行以下步骤：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mihtdzc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器从 Chubby 获取一个唯一的 Master 锁，用来阻止创建其它的 Master 服务器实例；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jkvxua7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器扫描 Chubby 的服务器文件锁存储目录，获取当前正在运行的服务器列表；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0nd147e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器和所有的正在运行的 Tablet 表服务器通信，获取每个 Tablet 服务器上 Tablet 的分配信 息；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m51d929&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master 服务器扫描 METADATA 表获取所有的 Tablet 的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在扫描的过程中，当 Master 服务器发现了一个还没有分配的 Tablet，Master 服务器就将这个 Tablet 加入 未分配的 Tablet 集合等待合适的时机分配。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可能会遇到一种复杂的情况：在 METADATA 表的 Tablet 还没有被分配之前是不能够扫描它的。因此， 在开始扫描之前（步骤 4），如果在第三步的扫描过程中发现 Root Tablet 还没有分配，Master 服务器就把 Root Tablet 加入到未分配的 Tablet 集合。这个附加操作确保了 Root Tablet 会被分配。由于 Root Tablet 包括了所有 METADATA 的 Tablet 的名字，因此 Master 服务器扫描完 Root Tablet 以后，就得到了所有的 METADATA 表 的 Tablet 的名字了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;保存现有 Tablet 的集合只有在以下事件发生时才会改变：建立了一个新表或者删除了一个旧表、两个 Tablet 被合并了、或者一个 Tablet 被分割成两个小的 Tablet。Master 服务器可以跟踪记录所有这些事件，因为 除了最后一个事件外的两个事件都是由它启动的。Tablet 分割事件需要特殊处理，因为它是由 Tablet 服务器启 动。在分割操作完成之后，Tablet 服务器通过在 METADATA 表中记录新的 Tablet 的信息来提交这个操作；当 分割操作提交之后，Tablet 服务器会通知 Master 服务器。如果分割操作已提交的信息没有通知到 Master 服务 器（可能两个服务器中有一个宕机了），Master 服务器在要求 Tablet 服务器装载已经被分割的子表的时候会发现一个新的 Tablet。通过对比 METADATA 表中 Tablet 的信息，Tablet 服务器会发现 Master 服务器要求其装载 的 Tablet 并不完整，因此，Tablet 服务器会重新向 Master 服务器发送通知信息。&lt;/p&gt;
&lt;h2 id=&quot;6-3-Tablet服务&quot;&gt;6.3 Tablet服务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516191019.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如图 5 所示，Tablet 的持久化状态信息保存在 GFS 上。更新操作提交到 REDO 日志中。在这些更新操 作中，最近提交的那些存放在一个排序的缓存中，我们称这个缓存为 memtable；较早的更新存放在一系列 SSTable 中。为了恢复一个 Tablet，Tablet 服务器首先从 METADATA 表中读取它的元数据。Tablet 的元数据包 含了组成这个 Tablet 的 SSTable 的列表，以及一系列的 Redo Point15 ，这些 Redo Point 指向可能含有该 Tablet 数据的已提交的日志记录。Tablet 服务器把 SSTable 的索引读进内存，之后通过重复 Redo Point 之后提交的更 新来重建 memtable。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当对 Tablet 服务器进行写操作时，Tablet 服务器首先要检查这个操作格式是否正确、操作发起者是否有执行这个操作的权限。权限验证的方法是通过从一个 Chubby 文件里读取出来的具有写权限的操作者列表来进行 验证（这个文件几乎一定会存放在 Chubby 客户缓存里）。成功的修改操作会记录在提交日志里。可以采用批 量提交方式来提高包含大量小的修改操作的应用程序的吞吐量。当一个写操作提交后，写的内容插入到memtable里面。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当对 Tablet 服务器进行读操作时，Tablet 服务器会作类似的完整性和权限检查。一个有效的读操作在一个由一系列SSTable 和 memtable 合并的视图里执行。由于 SSTable 和 memtable 是按字典排序的数据结构，因此可以高效生成合并视图。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当进行 Tablet 的合并和分割时，正在进行的读写操作能够继续进行。&lt;/p&gt;
&lt;h2 id=&quot;6-4-空间收缩&quot;&gt;6.4 空间收缩&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随着写操作的执行，memtable 的大小不断增加。当 memtable 的尺寸到达一个门限值的时候，这个 memtable 就会被冻结，然后创建一个新的 memtable；被冻结住 memtable 会被转换成 SSTable，然后写入 GFS 。Minor Compaction 过程有两个目的：shrink Tablet 服务器使用的内存，以及在服务器灾难恢复过程中，减少必须从 提交日志里读取的数据量。在 Compaction 过程中，正在进行的读写操作仍能继续。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每一次 Minor Compaction 都会创建一个新的 SSTable。如果 Minor Compaction 过程不停滞的持续进行下 去，读操作可能需要合并来自多个 SSTable 的更新；否则，我们通过定期在后台执行 Merging Compaction 过 程合并文件，限制这类文件的数量。Merging Compaction 过程读取一些 SSTable 和 memtable 的内容，合并成 一个新的 SSTable。只要 Merging Compaction 过程完成了，输入的这些 SSTable 和 memtable 就可以删除了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;合并所有的 SSTable 并生成一个新的 SSTable 的 Merging Compaction 过程叫作 Major Compaction。由非 Major Compaction 产生的 SSTable 可能含有特殊的删除条目，这些删除条目能够隐藏在旧的、但是依然有效的 SSTable 中已经删除的数据 。而 Major Compaction 过程生成的 SSTable 不包含已经删除的信息或数据。Bigtable 循环扫描它所有的 Tablet，并且定期对它们执行 Major Compaction。Major Compaction 机制允许 Bigtable 回收 已经删除的数据占有的资源，并且确保 BigTable 能及时清除已经删除的数据 ，这对存放敏感数据的服务是非常重要。&lt;/p&gt;
&lt;h1 id=&quot;7-优化&quot;&gt;7 优化&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上一章我们描述了 Bigtable 的实现，我们还需要很多优化工作才能使 Bigtable 到达用户要求的高性能、 高可用性和高可靠性。本章描述了 Bigtable 实现的其它部分，为了更好的强调这些优化工作，我们将深入细节。&lt;/p&gt;
&lt;h2 id=&quot;7-1-局部性群组&quot;&gt;7.1 局部性群组&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户程序可以将多个列族组合成一个局部性群族。对 Tablet 中的每个局部性群组都会生成一个单独的SSTable。将通常不会一起访问的列族分割成不同的局部性群组可以提高读取操作的效率。例如，在 Webtable 表中，网页的元数据（比如语言和 Checksum）可以在一个局部性群组中，网页的内容可以在另外一个群组：&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当一个应用程序要读取网页的元数据的时候，它没有必要去读取所有的页面内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，可以以局部性群组为单位设定一些有用的调试参数。比如，可以把一个局部性群组设定为全部存 储在内存中。Tablet 服务器依照惰性加载的策略将设定为放入内存的局部性群组的 SSTable 装载进内存。加载完成之后，访问属于该局部性群组的列族的时候就不必读取硬盘了。这个特性对于需要频繁访问的小块数据 特别有用：在 Bigtable 内部，我们利用这个特性提高 METADATA 表中具有位置相关性的列族的访问速度。&lt;/p&gt;
&lt;h2 id=&quot;7-2-压缩&quot;&gt;7.2 压缩&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户程序可以控制一个局部性群组的 SSTable 是否需要压缩；如果需要压缩，那么以什么格式来压缩。 每个SSTable 的块（块的大小由局部性群组的优化参数指定）都使用用户指定的压缩格式来压缩。虽然分块 压缩浪费了少量空间 ，但是，我们在只读取 SSTable 的一小部分数据的时候就不必解压整个文件了。很多客户程序使用了“两遍”的、可定制的压缩方式。第一遍采用 Bentley and McIlroy’s 方式，这种方式在一个 很大的扫描窗口里对常见的长字符串进行压缩；第二遍是采用快速压缩算法，即在一个 16KB 的小扫描窗口 中寻找重复数据。两个压缩的算法都很快，在现在的机器上，压缩的速率达到 100-200MB/s，解压的速率达 到 400-1000MB/s。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虽然我们在选择压缩算法的时候重点考虑的是速度而不是压缩的空间，但是这种两遍的压缩方式在空间 压缩率上的表现也是令人惊叹。比如，在 Webtable 的例子里，我们使用这种压缩方式来存储网页内容。在一 次测试中，我们在一个压缩的局部性群组中存储了大量的网页。针对实验的目的，我们没有存储每个文档所 有版本的数据，我们仅仅存储了一个版本的数据。该模式的空间压缩比达到了 10:1。这比传统的 Gzip 在压缩 HTML 页面时 3:1 或者 4:1 的空间压缩比好的多；“两遍”的压缩模式如此高效的原因是由于 Webtable 的行的 存放方式：从同一个主机获取的页面都存在临近的地方。利用这个特性，Bentley-McIlroy 算法可以从来自同 一个主机的页面里找到大量的重复内容。不仅仅是 Webtable，其它的很多应用程序也通过选择合适的行名来 将相似的数据聚簇在一起，以获取较高的压缩率。当我们在 Bigtable 中存储同一份数据的多个版本的时候， 压缩效率会更高。&lt;/p&gt;
&lt;h2 id=&quot;7-3-通过缓存提高读操作的性能&quot;&gt;7.3 通过缓存提高读操作的性能&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了提高读操作的性能，Tablet 服务器使用二级缓存的策略。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扫描缓存是第一级缓存，主要缓存 Tablet 服务器通过 SSTable 接口获取的 Key-Value 对；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Block 缓存是二级缓存，缓存的是从 GFS 读取的 SSTable的Block。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于经常要重复读取相同数据的应用程序来说，扫描缓存非常有效；对于经常要读取刚刚读过的数据 附近的数据的应用程序来说，Block 缓存更有用（例如，顺序读，或者在一个热点的行的局部性群组中随机读取不同的列)。&lt;/p&gt;
&lt;h3 id=&quot;7-3-1-Bloom-过滤器&quot;&gt;7.3.1 Bloom 过滤器&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如 6.3 节所述，一个读操作必须读取构成 Tablet 状态的所有 SSTable 的数据。如果这些 SSTable 不在内存 中，那么就需要多次访问硬盘。我们通过允许客户程序对特定局部性群组的 SSTable 指定 Bloom 过滤器， 来减少硬盘访问的次数。我们可以使用 Bloom 过滤器查询一个 SSTable 是否包含了特定行和列的数据。对于 某些特定应用程序，我们只付出了少量的、用于存储 Bloom 过滤器的内存的代价，就换来了读操作显著减少 的磁盘访问的次数。使用 Bloom 过滤器也隐式的达到了当应用程序访问不存在的行或列时，大多数时候我们 都不需要访问硬盘的目的。&lt;/p&gt;
&lt;h3 id=&quot;7-3-2-Commit-日志的实现&quot;&gt;7.3.2 Commit 日志的实现&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们把对每个 Tablet 的操作的 Commit 日志都存在一个单独的文件的话，那么就会产生大量的文件， 并且这些文件会并行的写入 GFS。根据 GFS 服务器底层文件系统实现的方案，要把这些文件写入不同的磁盘 日志文件时24 ，会有大量的磁盘 Seek 操作。另外，由于批量提交25 中操作的数目一般比较少，因此，对每个 Tablet 设置单独的日志文件也会给批量提交本应具有的优化效果带来很大的负面影响。为了避免这些问题，我 们设置每个 Tablet 服务器一个 Commit 日志文件，把修改操作的日志以追加方式写入同一个日志文件，因此 一个实际的日志文件中混合了对多个 Tablet 修改的日志记录。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用单个日志显著提高了普通操作的性能，但是将恢复的工作复杂化了。当一个 Tablet 服务器宕机时， 它加载的 Tablet 将会被移到很多其它的 Tablet 服务器上：每个 Tablet 服务器都装载很少的几个原来的服务器 的 Tablet。当恢复一个 Tablet 的状态的时候，新的 Tablet 服务器要从原来的 Tablet 服务器写的日志中提取修改 操作的信息，并重新执行。然而，这些 Tablet 修改操作的日志记录都混合在同一个日志文件中的。一种方法 新的 Tablet 服务器读取完整的 Commit 日志文件，然后只重复执行它需要恢复的 Tablet 的相关修改操作。使 用这种方法，假如有 100 台 Tablet 服务器，每台都加载了失效的 Tablet 服务器上的一个 Tablet，那么，这个日 志文件就要被读取 100 次（每个服务器读取一次）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了避免多次读取日志文件，我们首先把日志按照关键字（table，row name，log sequence number）排序。 排序之后，对同一个 Tablet 的修改操作的日志记录就连续存放在了一起，因此，我们只要一次磁盘 Seek 操作之后顺序读取就可以了。为了并行排序，我们先将日志分割成 64MB 的段，之后在不同的 Tablet 服务器对段 进行并行排序。这个排序工作由 Master 服务器来协同处理，并且在一个 Tablet 服务器表明自己需要从 Commit 日志文件恢复 Tablet 时开始执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在向 GFS 中写 Commit 日志的时候可能会引起系统颠簸，原因是多种多样的（比如，写操作正在进行的 时候，一个 GFS 服务器宕机了；或者连接三个 GFS 副本所在的服务器的网络拥塞或者过载了）。为了确保在 GFS 负载高峰时修改操作还能顺利进行，每个 Tablet 服务器实际上有两个日志写入线程，每个线程都写自己 的日志文件，并且在任何时刻，只有一个线程是工作的。如果一个线程的在写入的时候效率很低，Tablet 服务 器就切换到另外一个线程，修改操作的日志记录就写入到这个线程对应的日志文件中。每个日志记录都有一 个序列号，因此，在恢复的时候，Tablet 服务器能够检测出并忽略掉那些由于线程切换而导致的重复的记录。&lt;/p&gt;
&lt;h3 id=&quot;7-3-3-Tablet-恢复提速&quot;&gt;7.3.3 Tablet 恢复提速&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当 Master 服务器将一个 Tablet 从一个 Tablet 服务器移到另外一个 Tablet 服务器时，源 Tablet 服务器会对 这个 Tablet 做一次 Minor Compaction。这个 Compaction 操作减少了 Tablet 服务器的日志文件中没有归并的记 录，从而减少了恢复的时间。Compaction 完成之后，该服务器就停止为该 Tablet 提供服务。在卸载 Tablet 之 前，源 Tablet 服务器还会再做一次（通常会很快）Minor Compaction，以消除前面在一次压缩过程中又产生的 未归并的记录。第二次 Minor Compaction 完成以后，Tablet 就可以被装载到新的 Tablet 服务器上了，并且不 需要从日志中进行恢复。&lt;/p&gt;
&lt;h3 id=&quot;7-3-4-利用不变性&quot;&gt;7.3.4 利用不变性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在使用 Bigtable 时，除了 SSTable 缓存之外的其它部分产生的 SSTable 都是不变的，我们可以利用这 一点对系统进行简化。例如，当从 SSTable 读取数据的时候，我们不必对文件系统访问操作进行同步。这样 一来，就可以非常高效的实现对行的并行操作。memtable 是唯一一个能被读和写操作同时访问的可变数据结 构。为了减少在读操作时的竞争，我们对内存表采用 COW(Copy-on-write)机制，这样就允许读写操作并行执 行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为 SSTable 是不变的，因此，我们可以把永久删除被标记为“删除”的数据的问题，转换成对废弃的 SSTable 进行垃圾收集的问题了。每个 Tablet 的 SSTable 都在 METADATA 表中注册了。Master 服务器采用“标 记-删除”的垃圾回收方式删除 SSTable 集合中废弃的 SSTable，METADATA 表则保存了 Root SSTable 的集合。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后，SSTable 的不变性使得分割 Tablet 的操作非常快捷。我们不必为每个分割出来的 Tablet 建立新的 SSTable 集合，而是共享原来的 Tablet 的 SSTable 集合。&lt;/p&gt;
&lt;h1 id=&quot;8-性能评估&quot;&gt;8 性能评估&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了测试 Bigtable 的性能和可扩展性，我们建立了一个包括 N 台 Tablet 服务器的 Bigtable 集群，这里 N 是可变的。每台 Tablet 服务器配置了 1GB 的内存，数据写入到一个包括 1786 台机器、每台机器有 2 个 IDE 硬盘的 GFS 集群上。我们使用 N 台客户机生成工作负载测试 Bigtable。（我们使用和 Tablet 服务器相同数目的 客户机以确保客户机不会成为瓶颈。） 每台客户机配置 2GZ 双核 Opteron 处理器，配置了足以容纳所有进程 工作数据集的物理内存，以及一张 Gigabit 的以太网卡。这些机器都连入一个两层的、树状的交换网络里，在 根节点上的带宽加起来有大约 100-200Gbps。所有的机器采用相同的设备，因此，任何两台机器间网络来回一 次的时间都小于 1ms。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Tablet 服务器、Master 服务器、测试机、以及 GFS 服务器都运行在同一组机器上。每台机器都运行一个 GFS 的服务器。其它的机器要么运行 Tablet 服务器、要么运行客户程序、要么运行在测试过程中，使用这组 机器的其它的任务启动的进程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;R 是测试过程中，Bigtable 包含的不同的列关键字的数量。我们精心选择 R 的值，保证每次基准测试对每 台 Tablet 服务器读/写的数据量都在 1GB 左右。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在序列写的基准测试中，我们使用的列关键字的范围是 0 到 R-1。这个范围又被划分为 10N 个大小相同 的区间。核心调度程序把这些区间分配给 N 个客户端，分配方式是：只要客户程序处理完上一个区间的数据， 调度程序就把后续的、尚未处理的区间分配给它。这种动态分配的方式有助于减少客户机上同时运行的其它 进程对性能的影响。我们在每个列关键字下写入一个单独的字符串。每个字符串都是随机生成的、因此也没 有被压缩26 。另外，不同列关键字下的字符串也是不同的，因此也就不存在跨行的压缩。随机写入基准测试采 用类似的方法，除了行关键字在写入前先做 Hash，Hash 采用按 R 取模的方式，这样就保证了在整个基准测 试持续的时间内，写入的工作负载均匀的分布在列存储空间内。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;序列读的基准测试生成列关键字的方式与序列写相同，不同于序列写在列关键字下写入字符串的是，序 列读是读取列关键字下的字符串（这些字符串由之前序列写基准测试程序写入）。同样的，随机读的基准测试 和随机写是类似的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扫描基准测试和序列读类似，但是使用的是 BigTable 提供的、从一个列范围内扫描所有的 value 值的 API。 由于一次 RPC 调用就从一个 Tablet 服务器取回了大量的 Value 值，因此，使用扫描方式的基准测试程序可以 减少 RPC 调用的次数。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随机读（内存）基准测试和随机读类似，除了包含基准测试数据的局部性群组被设置为“in-memory”， 因此，读操作直接从 Tablet 服务器的内存中读取数据，不需要从 GFS 读取数据。针对这个测试，我们把每台Tablet 服务器存储的数据从 1GB 减少到 100MB，这样就可以把数据全部加载到 Tablet 服务器的内存中了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516193008.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;图 6 中有两个视图，显示了我们的基准测试的性能；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;图中的数据和曲线是读/写 1000-byte value 值时取得 的。图中的表格显示了每个 Tablet 服务器每秒钟进行的操作的次数；图中的曲线显示了每秒种所有的 Tablet&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;服务器上操作次数的总和。&lt;/p&gt;
&lt;h2 id=&quot;8-1-单个-Tablet-服务器的性能&quot;&gt;8.1 单个 Tablet 服务器的性能&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们首先分析下单个 Tablet 服务器的性能。随机读的性能比其它操作慢一个数量级或以上27 。 每个随机 读操作都要通过网络从 GFS 传输 64KB 的 SSTable 到 Tablet 服务器，而我们只使用其中大小是 1000 byte 的一 个 value 值。Tablet 服务器每秒大约执行 1200 次读操作，也就是每秒大约从 GFS 读取 75MB 的数据。这个传 输带宽足以占满 Tablet 服务器的 CPU 时间，因为其中包括了网络协议栈的消耗、SSTable 解析、以及 BigTable 代码执行；这个带宽也足以占满我们系统中网络的链接带宽。大多数采用这种访问模式 BigTable 应用程序会 减小 Block 的大小，通常会减到 8KB。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内存中的随机读操作速度快很多，原因是，所有 1000-byte 的读操作都是从 Tablet 服务器的本地内存中读 取数据，不需要从 GFS 读取 64KB 的 Block。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随机和序列写操作的性能比随机读要好些，原因是每个 Tablet 服务器直接把写入操作的内容追加到一个 Commit 日志文件的尾部，并且采用批量提交的方式，通过把数据以流的方式写入到 GFS 来提高性能。随机 写和序列写在性能上没有太大的差异，这两种方式的写操作实际上都是把操作内容记录到同一个 Tablet 服务 器的 Commit 日志文件中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;序列读的性能好于随机读，因为每取出 64KB 的 SSTable 的 Block 后，这些数据会缓存到 Block 缓存中， 后续的 64 次读操作直接从缓存读取数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扫描的性能更高，这是由于客户程序每一次 RPC 调用都会返回大量的 value 的数据，所以，RPC 调用的 消耗基本抵消了。&lt;/p&gt;
&lt;h2 id=&quot;8-2-性能提升&quot;&gt;8.2 性能提升&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随着我们将系统中的 Tablet 服务器从 1 台增加到 500 台，系统的整体吞吐量有了梦幻般的增长，增长的 倍率超过了 100。比如，随着 Tablet 服务器的数量增加了 500 倍，内存中的随机读操作的性能增加了 300 倍。 之所以会有这样的性能提升，主要是因为这个基准测试的瓶颈是单台 Tablet 服务器的 CPU。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管如此，性能的提升还不是线性的。在大多数的基准测试中我们看到，当 Tablet 服务器的数量从 1 台 增加到 50 台时，每台服务器的吞吐量会有一个明显的下降。这是由于多台服务器间的负载不均衡造成的，大 多数情况下是由于其它的程序抢占了 CPU。 我们负载均衡的算法会尽量避免这种不均衡，但是基于两个主要 原因，这个算法并不能完美的工作：一个是尽量减少 Tablet 的移动导致重新负载均衡能力受限（如果 Tablet 被移动了，那么在短时间内 — 一般是 1 秒内 — 这个 Tablet 是不可用的），另一个是我们的基准测试程序产生的负载会有波动。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随机读基准测试的测试结果显示，随机读的性能随 Tablet 服务器数量增加的提升幅度最小（整体吞吐量 只提升了 100 倍，而服务器的数量却增加了 500 倍）。这是因为每个 1000-byte 的读操作都会导致一个 64KB 大的 Block 在网络上传输。这样的网络传输量消耗了我们网络中各种共享的 1GB 的链路，结果导致随着我们 增加服务器的数量，每台服务器上的吞吐量急剧下降。&lt;/p&gt;
&lt;h1 id=&quot;9-实际应用&quot;&gt;9 实际应用&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516193453.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;截止到 2006 年 8 月，Google 内部一共有 388 个非测试用的 Bigtable 集群运行在各种各样的服务器集群上， 合计大约有 24500 个 Tablet 服务器。表 1 显示了每个集群上 Tablet 服务器的大致分布情况。这些集群中，许 多用于开发目的，因此会有一段时期比较空闲。通过观察一个由 14 个集群、8069 个 Tablet 服务器组成的集群 组，我们看到整体的吞吐量超过了每秒 1200000 次请求，发送到系统的 RPC 请求导致的网络负载达到了 741MB/s，系统发出的 RPC 请求网络负载大约是 16GB/s。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220516193546.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;表 2 提供了一些目前正在使用的表的相关数据。一些表存储的是用户相关的数据，另外一些存储的则是 用于批处理的数据；这些表在总的大小、 每个数据项的平均大小、从内存中读取的数据的比例、表的 Schema 的复杂程度上都有很大的差别。本节的其余部分，我们将主要描述三个产品研发团队如何使用 Bigtable 的。&lt;/p&gt;
&lt;h2 id=&quot;9-1-Google-Analytics&quot;&gt;9.1 Google Analytics&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Google Analytics 是用来帮助 Web 站点的管理员分析他们网站的流量模式的服务。它提供了整体状况的统 计数据，比如每天的独立访问的用户数量、每天每个 URL 的浏览次数；它还提供了用户使用网站的行为报告， 比如根据用户之前访问的某些页面，统计出几成的用户购买了商品。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了使用这个服务，Web 站点的管理员只需要在他们的 Web 页面中嵌入一小段 JavaScript 脚本就可以了。 这个 Javascript 程序在页面被访问的时候调用。它记录了各种 Google Analytics 需要使用的信息，比如用户的 标识、获取的网页的相关信息。Google Analytics 汇总这些数据，之后提供给 Web 站点的管理员。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们粗略的描述一下 Google Analytics 使用的两个表。Row Click 表（大约有 200TB 数据）的每一行存放 了一个最终用户的会话。行的名字是一个包含 Web 站点名字以及用户会话创建时间的元组。这种模式保证了 对同一个 Web 站点的访问会话是顺序的，会话按时间顺序存储。这个表可以压缩到原来尺寸的 14%。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Summary 表（大约有 20TB 的数据）包含了关于每个 Web 站点的、各种类型的预定义汇总信息。一个周 期性运行的 MapReduce 任务根据 Raw Click 表的数据生成 Summary 表的数据。每个 MapReduce 工作进程都 从 Raw Click 表中提取最新的会话数据。系统的整体吞吐量受限于 GFS 的吞吐量。这个表的能够压缩到原有尺寸的 29%。&lt;/p&gt;
&lt;h2 id=&quot;9-2-Google-Earth&quot;&gt;9.2 Google Earth&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Google 通过一组服务为用户提供了高分辨率的地球表面卫星图像，访问的方式可以使通过基于 Web 的 Google Maps 访问接口（maps.google.com），也可以通过 Google Earth 定制的客户端软件访问。这些软件产品 允许用户浏览地球表面的图像：用户可以在不同的分辨率下平移、查看和注释这些卫星图像。这个系统使用一个表存储预处理数据，使用另外一组表存储用户数据。 数据预处理流水线使用一个表存储原始图像。在预处理过程中，图像被清除，图像数据合并到最终的服 务数据中。这个表包含了大约 70TB 的数据，所以需要从磁盘读取数据。图像已经被高效压缩过了，因此存 储在 Bigtable 后不需要再压缩了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Imagery 表的每一行都代表了一个单独的地理区域。 行都有名称， 以确保毗邻的区域存储在了一起。 Imagery 表中有一个列族用来记录每个区域的数据源。这个列族包含了大量的列：基本上市每个列对应一个原 始图片的数据。由于每个地理区域都是由很少的几张图片构成的，因此这个列族是非常稀疏的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据预处理流水线高度依赖运行在 Bigtable 上的 MapReduce 任务传输数据。在运行某些 MapReduce 任务 的时候，整个系统中每台 Tablet 服务器的数据处理速度是 1MB/s。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个服务系统使用一个表来索引 GFS 中的数据。这个表相对较小（大约是 500GB），但是这个表必须在 保证较低的响应延时的前提下，针对每个数据中心，每秒处理几万个查询请求。 因此，这个表必须在上百个 Tablet 服务器上存储数据，并且使用 in-memory 的列族。&lt;/p&gt;
&lt;h2 id=&quot;9-3-个性化查询&quot;&gt;9.3 个性化查询&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;个性化查询（www.google.com/psearch）是一个双向服务；这个服务记录用户的查询和点击，涉及到各种 Google 的服务，比如 Web 查询、图像和新闻。用户可以浏览他们查询的历史，重复他们之前的查询和点击； 用户也可以定制基于 Google 历史使用习惯模式的个性化查询结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;个性化查询使用 Bigtable 存储每个用户的数据。每个用户都有一个唯一的用户 id，每个用户 id 和一个列 名绑定。一个单独的列族被用来存储各种类型的行为（比如，有个列族可能是用来存储所有的 Web 查询的）。 每个数据项都被用作 Bigtable 的时间戳，记录了相应的用户行为发生的时间。个性化查询使用以 Bigtable 为 存储的 MapReduce 任务生成用户的数据图表。这些用户数据图表用来个性化当前的查询结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;个性化查询的数据会复制到几个 Bigtable 的集群上，这样就增强了数据可用性，同时减少了由客户端和 Bigtable 集群间的“距离”造成的延时。个性化查询的开发团队最初建立了一个基于 Bigtable 的、“客户侧” 的复制机制为所有的复制节点提供一致性保障。现在的系统则使用了内建的复制子系统。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;个性化查询存储系统的设计允许其它的团队在它们自己的列中加入新的用户数据，因此，很多 Google 服 务使用个性化查询存储系统保存用户级的配置参数和设置。在多个团队之间分享数据的结果是产生了大量的 列族。为了更好的支持数据共享，我们加入了一个简单的配额机制限制用户在共享表中使用的空间；配额也 为使用个性化查询系统存储用户级信息的产品团体提供了隔离机制。&lt;/p&gt;
&lt;h1 id=&quot;10-经验教训&quot;&gt;10 经验教训&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在设计、实现、维护和支持 Bigtable 的过程中，我们得到了很多有用的经验和一些有趣的教训。 一个教训是，我们发现，很多类型的错误都会导致大型分布式系统受损，这些错误不仅仅是通常的网络 中断、或者很多分布式协议中设想的 fail-stop 类型的错误。比如，我们遇到过下面这些类型的错误导致的问 题：内存数据损坏、网络中断、时钟偏差、机器挂起、扩展的和非对称的网络分区、我们使用的其它系统的 Bug（比如 Chubby）、GFS 配额溢出、计划内和计划外的硬件维护。我们在解决这些问题的过程中学到了很多 经验，我们通过修改协议来解决这些问题。比如，我们在我们的 RPC 机制中加入了 Checksum。我们在设计 系统的部分功能时，不对其它部分功能做任何的假设，这样的做法解决了其它的一些问题。比如，我们不再 假设一个特定的 Chubby 操作只返回错误码集合中的一个值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外一个教训是，我们明白了在彻底了解一个新特性会被如何使用之后，再决定是否添加这个新特性是 非常重要的。比如，我们开始计划在我们的 API 中支持通常方式的事务处理。但是由于我们还不会马上用到 这个功能，因此，我们并没有去实现它。现在，Bigtable 上已经有了很多的实际应用，我们可以检查它们真实 的需求；我们发现，大多是应用程序都只是需要单个行上的事务功能。有些应用需要分布式的事务功能，分 布式事务大多数情况下用于维护二级索引，因此我们增加了一个特殊的机制去满足这个需求。新的机制在通 用性上比分布式事务差很多，但是它更有效（特别是在更新操作的涉及上百行数据的时候），而且非常符合我 们的“跨数据中心”复制方案的优化策略。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有一个具有实践意义的经验：我们发现系统级的监控对 Bigtable 非常重要（比如，监控 Bigtable 自身 以及使用 Bigtable 的客户程序）。比如，我们扩展了我们的 RPC 系统，因此对于一个 RPC 调用的例子，它可 以详细记录代表了 RPC 调用的很多重要操作。这个特性允许我们检测和修正很多的问题，比如 Tablet 数据结 构上的锁的内容、在修改操作提交时对 GFS 的写入非常慢的问题、以及在 METADATA 表的 Tablet 不可用时， 对 METADATA 表的访问挂起的问题。关于监控的用途的另外一个例子是，每个 Bigtable 集群都在 Chubby 中 注册了。这可以帮助我们跟踪所有的集群状态、监控它们的大小、检查集群运行的我们软件的版本、监控集 群流入数据的流量，以及检查是否有引发集群高延时的潜在因素。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对我们来说，最宝贵的经验是简单设计的价值。考虑到我们系统的代码量（大约 100000 行生产代码 ）， 以及随着时间的推移，新的代码以各种难以预料的方式加入系统，我们发现简洁的设计和编码给维护和调试 带来的巨大好处。这方面的一个例子是我们的 Tablet 服务器成员协议。我们第一版的协议很简单：Master 服务器周期性的和 Tablet 服务器签订租约，Tablet 服务器在租约过期的时候 Kill 掉自己的进程。不幸的是，这个协议在遇到网络问题时会大大降低系统的可用性，也会大大增加 Master 服务器恢复的时间。我们多次重新设计这个协议，直到它能够很好的处理上述问题。但是，更不幸的是，最终的协议过于复杂了，并且依赖一些 Chubby 很少被用到的特性。我们发现我们浪费了大量的时间在调试一些古怪的问题 ，有些是 Bigtable 代码的问题，有些是 Chubby 代码的问题。最后，我们只好废弃了这个协议，重新制订了一个新的、更简单、只使用 Chubby 最广泛使用的特性的协议。&lt;/p&gt;
&lt;h1 id=&quot;11-相关工作&quot;&gt;11 相关工作&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Boxwood 项目的有些组件在某些方面和 Chubby、GFS 以及 Bigtable 类似，因为它也提供了诸如分布式协议、锁、分布式 Chunk 存储以及分布式 B-tree 存储。Boxwood 与 Google 的某些组件尽管功能类似，&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是 Boxwood 的组件提供更底层的服务。Boxwood 项目的目的是提供创建类似文件系统、数据库等高级服务 的基础构件，而 Bigtable 的目的是直接为客户程序的数据存储需求提供支持。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在有不少项目已经攻克了很多难题， 实现了在广域网上的分布式数据存储或者高级服务， 通常是 “Internet 规模”的。这其中包括了分布式的 Hash 表，这项工作由一些类似 CAN 、Chord 、Tapestry 和 Pastry 的项目率先发起。这些系统的主要关注点和 Bigtable 不同，比如应对各种不同的传输带 宽、不可信的协作者、频繁的更改配置等；另外，去中心化和 Byzantine 灾难冗余也不是 Bigtable的目的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就提供给应用程序开发者的分布式数据存储模型而言，我们相信，分布式 B-Tree 或者分布式 Hash 表提 供的 Key-value pair 方式的模型有很大的局限性。Key-value pair 模型是很有用的组件，但是它们不应该是提供 给开发者唯一的组件。我们选择的模型提供的组件比简单的 Key-value pair 丰富的多，它支持稀疏的、半结构 化的数据。另外，它也足够简单，能够高效的处理平面文件；它也是透明的（通过局部性群组），允许我们的 使用者对系统的重要行为进行调整。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有些数据库厂商已经开发出了并行的数据库系统，能够存储海量的数据。Oracle 的 RAC使用共享 磁盘存储数据（Bigtable 使用 GFS），并且有一个分布式的锁管理系统（Bigtable 使用 Chubby）。IBM 并行版 本的 DB2基于一种类似于 Bigtable 的、不共享任何东西的架构。每个 DB2 的服务器都负责处理 存储在一个关系型数据库中的表中的行的一个子集。这些产品都提供了一个带有事务功能的完整的关系模型。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 的局部性群组提供了类似于基于列的存储方案在压缩和磁盘读取方面具有的性能；这些以列而不 是行的方式组织数据的方案包括 C-Store 、商业产品 Sybase IQ 、SenSage 、KDB+ ， 以及 MonetDB/X100 的 ColumnDM 存储层。另外一种在平面文件中提供垂直和水平数据分区、并且提 供很好的数据压缩率的系统是 AT&amp;amp;T 的 Daytona 数据库。局部性群组不支持 Ailamaki 系统中描述的 CPU 缓存级别的优化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 采用 memtable 和 SSTable 存储对表的更新的方法与 Log-Structured Merge Tree存储索引数 据更新的方法类似。这两个系统中，排序的数据在写入到磁盘前都先存放在内存中，读取操作必须从内存和 磁盘中合并数据产生最终的结果集。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;C-Store 和 Bigtable 有很多相似点：两个系统都采用 Shared-nothing 架构，都有两种不同的数据结构，一 种用于当前的写操作，另外一种存放“长时间使用”的数据，并且提供一种机制在两个存储结构间搬运数据。 两个系统在 API 接口函数上有很大的不同：C-Store 操作更像关系型数据库，而 Bigtable 提供了低层次的读写 操作接口，并且设计的目标是能够支持每台服务器每秒数千次操作。C-Store 同时也是个“读性能优化的关系 型数据库”，而 Bigtable 对读和写密集型应用都提供了很好的性能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Bigtable 也必须解决所有的 Shared-nothing 数据库需要面对的、类型相似的一些负载和内存均衡方面的难题。我们的问题在某种程度上简单一些：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-przp1mw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们不需要考虑同一份数据可能有多个拷贝的问题，同一份数据可能由于视图或索引的原因以不同 的形式表现出来；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pllrfqz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们让用户决定哪些数据应该放在内存里、哪些放在磁盘上，而不是由系统动态的判断；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t1e6bpl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的系统中没有复杂的查询执行或优化工作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;12-结论&quot;&gt;12 结论&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们已经讲述完了 Bigtable，Google 的一个分布式的结构化数据存储系统。Bigtable 的集群从 2005 年 4 月开始已经投入使用了，在此之前，我们花了大约 7 人年设计和实现这个系统。截止到 2006 年 4 月，已经有 超过 60 个项目使用 Bigtable 了。我们的用户对 Bigtable 提供的高性能和高可用性很满意，随着时间的推移， 他们可以根据自己的系统对资源的需求增加情况，通过简单的增加机器，扩展系统的承载能力。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于 Bigtable 提供的编程接口并不常见，一个有趣的问题是：我们的用户适应新的接口有多难？新的使用者有时不太确定使用 Bigtable 接口的最佳方法，特别是在他们已经习惯于使用支持通用事务的关系型数据 库的接口的情况下。但是，Google 内部很多产品都成功的使用了 Bigtable 的事实证明了，我们的设计在实践 中行之有效。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们现在正在对 Bigtable 加入一些新的特性，比如支持二级索引，以及支持多 Master 节点的、跨数据中心复制的 Bigtable 的基础构件。我们现在已经开始将 Bigtable 部署为服务供其它的产品团队使用，这样不同 的产品团队就不需要维护他们自己的 Bigtable 集群了。随着服务集群的扩展，我们需要在 Bigtable 系统内部 处理更多的关于资源共享的问题了。 最后，我们发现，建设 Google 自己的存储解决方案带来了很多优势。通过为 Bigtable 设计我们自己的数 据模型，是我们的系统极具灵活性。另外，由于我们全面控制着 Bigtable 的实现过程，以及 Bigtable 使用到的其它的 Google 的基础构件，这就意味着我们在系统出现瓶颈或效率低下的情况时，能够快速的解决这些问题。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[从CPU亲缘性探究Thread.currentThread]]></title><link>https://www.ztianzeng.com/posts/从CPU亲缘性探究Thread.currentThread</link><guid isPermaLink="false">/posts/从CPU亲缘性探究Thread.currentThread</guid><pubDate>Thu, 12 May 2022 12:47:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;从CPU亲缘性探究Thread-currentThread&quot;&gt;从CPU亲缘性探究Thread.currentThread&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在美团这篇文章: &lt;a href=&quot;https://tech.meituan.com/2018/03/16/redis-high-concurrency-optimization.html&quot;&gt;《Redis 高负载下的中断优化》&lt;/a&gt;看到了一个叫做CPU亲缘性的东西&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果某个&lt;code&gt;CPU Core&lt;/code&gt;正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交给其他core继续运行，必须等处理完中断后才能继续运行。Redis本身定位就是高速缓存，线上的平均端到端响应时间小于1ms，如果频繁被中断，那么响应时间必然受到极大影响。容易想到，由最初的&lt;code&gt;CPU 0&lt;/code&gt;单核处理中断，改进到多核处理中断，Redis进程被中断影响的几率增大了，因此我们需要对Redis进程也设置CPU亲缘性，使其与处理中断的Core互相错开，避免受到影响。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在网卡收集到数据包的时候，需要CPU进行一个软中断，告诉操作系统内核有数据进来了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，在大量的网络请求过来之后，可能Redis处理数据的CPU的核心、和响应中断的CPU的核心是同一个核心。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那就意味着，一旦CPU中断了（即使速度很快），也会影响Redis的处理速度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作者还提到:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于&lt;code&gt;Linux wake affinity&lt;/code&gt;特性，如果两个进程频繁互动，调度系统会觉得它们很有可能共享同样的数据，把它们放到同一CPU核心或&lt;code&gt;NUMA Node&lt;/code&gt;有助于提高缓存和内存的访问性能，所以当一个进程唤醒另一个的时候，被唤醒的进程可能会被放到相同的&lt;code&gt;CPU core&lt;/code&gt;或者相同的NUMA节点上。此特性对中断唤醒进程时也起作用，在上一节所述的现象中，所有的网络中断都分配给&lt;code&gt;CPU 0&lt;/code&gt;去处理，当中断处理完成时，由于&lt;code&gt;wakeup affinity&lt;/code&gt;特性的作用，所唤醒的用户进程也被安排给&lt;code&gt;CPU 0&lt;/code&gt;或其所在的numa节点上其他core。而当两个&lt;code&gt;NUMA node&lt;/code&gt;处理中断时，这种调度特性有可能导致Redis进程在&lt;code&gt;CPU core&lt;/code&gt;之间频繁迁移，造成性能损失。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也就是说，如果CPU核心一直在交替处理Redis和网络请求，那么就会导致没有办法进行有效缓存，进而影响性能。&lt;/p&gt;
&lt;h1 id=&quot;探究&quot;&gt;探究&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以从美团的这篇文章上来看，我觉得JVM实际上也会有这样的问题，就突发奇想了一下，如果JVM的线程调度归个类，让相似的线程使用同一个CPU核心处理，这样不就能够进一步加强并发效率么？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后就查询了各种资料，最后发现有个叫做&lt;code&gt;Java Thread Affinity&lt;/code&gt;的东西。&lt;/p&gt;
&lt;h1 id=&quot;Java-Thread-Affinity简介&quot;&gt;Java Thread Affinity简介&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;git地址: &lt;a href=&quot;https://github.com/OpenHFT/Java-Thread-Affinity&quot;&gt;https://github.com/OpenHFT/Java-Thread-Affinity&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Java Thread Affinity&lt;/code&gt;是将Java代码中的线程绑定到&lt;code&gt;CPU&lt;/code&gt;特定的核上，用来提升程序的性能。底层使用了&lt;code&gt;JNA技术&lt;/code&gt;来提供对底层线程的访问能力&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JNA（Java Native Access ）提供封装好的java函数用JNI来调用本地共享文件.dll/.so中的函数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在双核的服务器上使用&lt;code&gt;lscpu&lt;/code&gt;命令来查看系统的CPU情况，如下所示&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;python&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                2
On-line CPU(s) list:   0,1
Thread(s) per core:    2
Core(s) per socket:    1
座：                 1
NUMA 节点：         1
厂商 ID：           GenuineIntel
CPU 系列：          6
型号：              79
型号名称：        Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz
步进：              1
CPU MHz：             2494.220
BogoMIPS：            4988.44
超管理器厂商：  KVM
虚拟化类型：     完全
L1d 缓存：          32K
L1i 缓存：          32K
L2 缓存：           256K
L3 缓存：           40960K
NUMA 节点0 CPU：    0,1
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从上面的输出我们可以看到，这个服务器有两个socket，每个socket有一个core，每个&lt;em&gt;core&lt;/em&gt;可以同时处理2个线程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完整的信息在&lt;code&gt;/proc/cpuinfo&lt;/code&gt;中：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;python&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;processor	: 0
vendor_id	: GenuineIntel
cpu family	: 6
model		: 79
model name	: Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz
stepping	: 1
microcode	: 0x1
cpu MHz		: 2494.220
cache size	: 40960 KB
physical id	: 0
siblings	: 2
core id		: 0
cpu cores	: 1
apicid		: 0
initial apicid	: 0
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt
bogomips	: 4988.44
clflush size	: 64
cache_alignment	: 64
address sizes	: 46 bits physical, 48 bits virtual
power management:

processor	: 1
vendor_id	: GenuineIntel
cpu family	: 6
model		: 79
model name	: Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz
stepping	: 1
microcode	: 0x1
cpu MHz		: 2494.220
cache size	: 40960 KB
physical id	: 0
siblings	: 2
core id		: 0
cpu cores	: 1
apicid		: 1
initial apicid	: 1
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt
bogomips	: 4988.44
clflush size	: 64
cache_alignment	: 64
address sizes	: 46 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Java Thread Affinity&lt;/code&gt;会读取&lt;code&gt;/proc/cpuinfo&lt;/code&gt;来确定CPU的&lt;code&gt;layout&lt;/code&gt;信息，代码中有个CpuLayout与之对应：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220513103640.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据&lt;code&gt;CPU layout&lt;/code&gt;的信息， &lt;code&gt;AffinityStrategies&lt;/code&gt;提供了一些基本的Affinity策略，用来安排不同的&lt;code&gt;thread&lt;/code&gt;之间的分布关系：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;python&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public enum AffinityStrategies implements AffinityStrategy {

    /**
     * 任何CPU都行.
     */
    ANY {
        @Override
        public boolean matches(int cpuId, int cpuId2) {
            return true;
        }
    },
    /**
     * 运行在同一个core中.
     */
    SAME_CORE {
        @Override
        public boolean matches(int cpuId, int cpuId2) {
            CpuLayout cpuLayout = AffinityLock.cpuLayout();
            return cpuLayout.socketId(cpuId) == cpuLayout.socketId(cpuId2) &amp;amp;&amp;amp;
                    cpuLayout.coreId(cpuId) == cpuLayout.coreId(cpuId2);
        }
    },
    /**
     * 运行在同一个socket中，但是不在同一个core上。.
     */
    SAME_SOCKET {
        @Override
        public boolean matches(int cpuId, int cpuId2) {
            CpuLayout cpuLayout = AffinityLock.cpuLayout();
            return cpuLayout.socketId(cpuId) == cpuLayout.socketId(cpuId2) &amp;amp;&amp;amp;
                    cpuLayout.coreId(cpuId) != cpuLayout.coreId(cpuId2);
        }
    },
    /**
     * 运行在不同的socket中
     */
    DIFFERENT_CORE {
        @Override
        public boolean matches(int cpuId, int cpuId2) {
            CpuLayout cpuLayout = AffinityLock.cpuLayout();
            return cpuLayout.socketId(cpuId) != cpuLayout.socketId(cpuId2) ||
                    cpuLayout.coreId(cpuId) != cpuLayout.coreId(cpuId2);
        }
    },
    /**
     * 运行在不同的core上
     */
    DIFFERENT_SOCKET {
        @Override
        public boolean matches(int cpuId, int cpuId2) {
            CpuLayout cpuLayout = AffinityLock.cpuLayout();
            return cpuLayout.socketId(cpuId) != cpuLayout.socketId(cpuId2);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于MacOS系统的局限性，没有办法通过&lt;code&gt;/proc/cpuinfo&lt;/code&gt;获取到CPU信息，全部都是走的默认&lt;code&gt;NoCpuLayout&lt;/code&gt;来进行处理，我的Mac是16核，默认16核全部参与工作。&lt;/p&gt;
&lt;h2 id=&quot;使用方式&quot;&gt;使用方式&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-aumd8qb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;限制线程在单个CPU核心上运行&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;try (AffinityLock al = AffinityLock.acquireLock()) {
    // do some work while locked to a CPU.
    System.out.println(al.cpuId());
    while(true) {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-47fxc4q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;指定CPU运行&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;try (AffinityLock al = AffinityLock.acquireLock(5)) {
    // do some work while locked to a CPU.
    System.out.println(al.cpuId());
    while(true) {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jg3luq6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池指定&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Affinity&lt;/code&gt;提供了线程工厂方法，可以构造自己的线程池的亲缘策略&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;ExecutorService ES = Executors.newFixedThreadPool(4,new AffinityThreadFactory(&amp;quot;bg&amp;quot;, SAME_CORE, DIFFERENT_SOCKET, ANY));
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般服务器都是Linux的，所以只看Linux下的实现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Java Thread Affinity&lt;/code&gt;有个&lt;code&gt;CLibrary&lt;/code&gt;的匿名内部类，用来封装操作系统提供的API&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; interface CLibrary extends Library {
        CLibrary INSTANCE = (CLibrary) Native.loadLibrary(LIBRARY_NAME, CLibrary.class);

        int sched_setaffinity(final int pid,
                              final int cpusetsize,
                              final cpu_set_t cpuset) throws LastErrorException;

        int sched_getaffinity(final int pid,
                              final int cpusetsize,
                              final cpu_set_t cpuset) throws LastErrorException;

        int getpid() throws LastErrorException;

        int sched_getcpu() throws LastErrorException;

        int uname(final utsname name) throws LastErrorException;

        int syscall(int number, Object... args) throws LastErrorException;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;sched_setaffinity可以将某个进程绑定到一个特定的CPU，这是Linux提供了设置CPU亲和力的方法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过调用这个方法，将cpu的掩码绑定到对应的pid上面，就能够形成亲和。&lt;/p&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Java Thread Affinity&lt;/code&gt;可以从JAVA代码中对程序中Thread使用的CPU进行控制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;能够通过自行设置亲和力的方式，来避免操作系统本身的调度。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[人菜瘾大，用python监控羽毛球场余票]]></title><link>https://www.ztianzeng.com/posts/人菜瘾大，用python监控羽毛球场余票</link><guid isPermaLink="false">/posts/人菜瘾大，用python监控羽毛球场余票</guid><pubDate>Thu, 12 May 2022 03:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;人菜瘾大-用python监控羽毛球场余票&quot;&gt;人菜瘾大，用python监控羽毛球场余票&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;display: block;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220512111453.png&quot; alt=&quot;&quot; parent-style=&quot;display: block;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;人到中年，迷上了羽毛球，苦于所住的地方周边球场着实火爆，票出秒没。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有必要通过一些技术手段，扒拉出余票数，将有票的场地给提取出来，发送通知到手机上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为球场都是下单减库存的，所以为了尽快实现这套逻辑则不去对接支付相关的东西，通过及时通知到手机上手动下单。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码是这样：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;python&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import time
from threading import Timer

import requests

productDetail = &amp;quot;&amp;quot;

id1 = 7



def getDay(id, date):
    # 先转换为时间数组
    timeArray = time.strptime(date, &amp;quot;%Y-%m-%d %H:%M:%S&amp;quot;)
    # 转换为时间戳
    timeStamp = int(time.mktime(timeArray))
    href = productDetail % (id, timeStamp)
    response = requests.get(href)
    return parseDayJSON(response.json())


def parseDayJSON(dayJson):
    table_data = dayJson[&apos;data&apos;][&apos;table_data&apos;]
    playground = {}
    for x in table_data:
        for y in x:
            if y[&apos;hall_name&apos;] not in playground:
                playground[y[&apos;hall_name&apos;]] = []
            if y[&apos;used&apos;] == 0:
                playground[y[&apos;hall_name&apos;]].append(
                    {
                        &apos;start&apos;: y[&apos;start&apos;],
                        &apos;end&apos;: y[&apos;end&apos;],
                        &apos;price&apos;: y[&apos;price&apos;],

                    }
                )
    playgroundNew = {}
    for site in playground:
        if site not in playgroundNew:
            playgroundNew[site] = []
        siteTime = playground[site]
        if len(siteTime) &amp;gt; 0:
            playgroundNew[site] = merge(siteTime)
    return analyze(playgroundNew)


def analyze(playground):
    count = 0
    consumingDict = {}
    oneHour = 0
    twoHour = 0
    for site in playground:
        if len(playground[site]) &amp;gt; 0:
            count = count + 1
        consuming = 0
        price = 0
        for siteTime in playground[site]:
            price += siteTime[&apos;price&apos;]
            consuming = int(siteTime[&apos;end&apos;].split(&apos;:&apos;)[0]) - int(siteTime[&apos;start&apos;].split(&apos;:&apos;)[0])
            if siteTime[&apos;price&apos;] &amp;gt;= 200:
                consuming = 0
        consumingDict[consuming] = consumingDict.get(consuming, 0) + 1
        if consuming == 1:
            oneHour = oneHour + 1
        if consuming &amp;gt; 1:
            twoHour = twoHour + 1
    print(f&apos;发现 {count} 片场地，一小时: {oneHour} 片 一小时以上: {twoHour} 片  晚上有 {count - oneHour - twoHour} 片&apos;)
    night = count - oneHour - twoHour
    return {
        &apos;count&apos;: count,
        &apos;oneHour&apos;: oneHour,
        &apos;twoHour&apos;: twoHour,
        &apos;night&apos;: night,
        &apos;playground&apos;: playground
    }


def merge(intervals):
    # 目标区间索引值
    target_idx = 0
    # 开始选取候选区间，和目标区间进行对比
    for i in range(1, len(intervals)):
        # 候选区间的开始值小于等于目标区间的结束值，则说明两区间有重合部分
        if intervals[i][&apos;start&apos;] == intervals[target_idx][&apos;end&apos;]:
            intervals[target_idx][&apos;end&apos;] = intervals[i][&apos;end&apos;]
            intervals[target_idx][&apos;occupy&apos;] = intervals[target_idx].get(&apos;occupy&apos;, 1) + 1
            intervals[i] = []
        # 否则，两区间不重合
        else:
            # 更新目标区间索引值（设置新的目标区间为当前的候选区间）
            intervals[target_idx][&apos;occupy&apos;] = intervals[target_idx].get(&apos;occupy&apos;, 1)
            target_idx = i
    # 返回原数组集合中不为空数组的集合
    return [interval for interval in intervals if interval]


def notify(content):
    if content:
        requests.get(f&apos;https://api.day.app/xxxxxxxxxxxx/{content}&apos;)


def getNotifyContent(name, data):
    count = data[&apos;count&apos;]
    oneHour = data[&apos;oneHour&apos;]
    twoHour = data[&apos;twoHour&apos;]
    night = data[&apos;night&apos;],
    playground = data[&apos;playground&apos;]
    if twoHour == 0:
        return None
    return f&apos;{name} \n &apos; \
           f&apos;发现 {count} 片场地 \n &apos; \
           f&apos;一小时: {oneHour} 片 &apos; \
           f&apos;一小时以上: {twoHour} 片 &apos; \
           f&apos;晚上有 {night} 片&apos;


def monitor():
    day = &apos;2022-05-15 00:00:00&apos;
    场地 = getDay(id1, day)
    content = getNotifyContent(&apos;场地&apos;, 场地)
    notify(content)
    print(&apos;--------------------------------------------------------------\n&apos;)

    Timer(600, monitor).start()


if __name__ == &apos;__main__&apos;:
    sTimer = Timer(600, monitor)
    sTimer.start()
    # monitor()
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每间隔10分钟，启动一次。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发现2小时以上的连续场地，就发送通知。。。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前已经抢到了周日的票，完美&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[RocketMQ Rebalance流程]]></title><link>https://www.ztianzeng.com/posts/RocketMQ Rebalance流程</link><guid isPermaLink="false">/posts/RocketMQ Rebalance流程</guid><category><![CDATA[RocketMQ]]></category><pubDate>Wed, 11 May 2022 09:06:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;RocketMQ-Rebalance流程&quot;&gt;RocketMQ Rebalance流程&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ存在Rebalance机制，这个机制的作用是将一个Topic下的多个队列，在同一个消费者组下的多个consumer之间重新进行分配。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Rebalance机制目的是为了提升消息的并行处理能力。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设不存在Rebalance机制，那就意味着原本有一个Consumer承载着Topic的8个队列，由于业务的增长无法用单个Consumer可以及时消费，这个时候没有Rebalance机制的存在导致即使增加了Consumer，也不会有任何改变。&lt;/p&gt;
&lt;h1 id=&quot;Rebalance局限性&quot;&gt;Rebalance局限性&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-09ir4b5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于一个队列最多分配给一个消费者，因此当某个消费者组下的消费者实例大于队列数量时，多余的消费者将分配不到任何队列。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dc8ddmu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消费暂停&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;考虑在只有&lt;em&gt;Consumer 1&lt;/em&gt;的情况下，其负责消费所有4个队列;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在新增&lt;em&gt;Consumer 2&lt;/em&gt;，触发&lt;code&gt;Rebalance&lt;/code&gt;时，需要分配2个队列给其消费。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么&lt;em&gt;Consumer 1&lt;/em&gt;就需要停止这2个队列的消费，等到这两个队列分配给&lt;em&gt;Consumer 2&lt;/em&gt;后，这两个队列才能继续被消费。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-666yewz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重复消费&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;em&gt;Consumer 2&lt;/em&gt; 在消费分配给自己的2个队列时，必须接着从&lt;em&gt;Consumer 1&lt;/em&gt;之前已经消费到的offset继续开始消费。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然而默认情况下，offset是异步提交的，如&lt;em&gt;Consumer 1&lt;/em&gt;当前消费到offset为10，但是异步提交给broker的offset为8；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么如果&lt;em&gt;Consumer 2&lt;/em&gt;从8的offset开始消费，那么就会有2条消息重复。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也就是说，&lt;em&gt;Consumer 2&lt;/em&gt; 并不会等待&lt;em&gt;Consumer1&lt;/em&gt;提交完offset后，再进行&lt;code&gt;Rebalance&lt;/code&gt;，因此提交间隔越长，可能造成的重复消费就越多。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1pewwd7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消费突刺&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于&lt;code&gt;Rebalance&lt;/code&gt;可能导致重复消费，如果需要重复消费的消息过多；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者因为&lt;code&gt;Rebalance&lt;/code&gt;暂停时间过长，导致积压了部分消息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么都有可能导致在&lt;code&gt;Rebalance&lt;/code&gt;结束之后瞬间可能需要消费很多消息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;Rebalance分配规则&quot;&gt;Rebalance分配规则&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Rebalance&lt;/code&gt;是没有做统一分配的，而是消费者通过自己再整体消费者中的偏移量来计算出自己应该获得哪些队列&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分配算法需要实现下面这个接口:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * Strategy Algorithm for message allocating between consumers
 */
public interface AllocateMessageQueueStrategy {

    /**
     * Allocating by consumer id
     *
     * @param consumerGroup current consumer group
     * @param currentCID current consumer id
     * @param mqAll message queue set in current topic
     * @param cidAll consumer set in current consumer group
     * @return The allocate result of given strategy
     */
    List&amp;lt;MessageQueue&amp;gt; allocate(
        final String consumerGroup,
        final String currentCID,
        final List&amp;lt;MessageQueue&amp;gt; mqAll,
        final List&amp;lt;String&amp;gt; cidAll
    );

    /**
     * Algorithm name
     *
     * @return The strategy name
     */
    String getName();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个接口的 getName() 只是一个唯一标识，用以标识该消费者实例是用什么负载均衡算法去分配队列。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关键在于&lt;code&gt;allocate&lt;/code&gt;这个方法，这个方法的出参就是这次Rebalace的结果 —— 本消费者实例应该去获取的队列列表。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其余四个入参分别是：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-s3r5g4o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消费者组名&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ys2m0zb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前的消费者实例的唯一ID，实际上就是client 的ip@instanceName。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5c1gep8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;全局这个消费者组可以分配的队列集合&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ozzwswg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前这个消费者组消费者集合（值是消费者实例的唯一id）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;试想下，假设要你去做一个分配队列的算法，实际上最关键的就是两个视图：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m6stthk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个topic下全局当前在线的消费者列表&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-a45s9x2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;topic在全局下有哪些队列。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;例如，你知道当前有4个消费者 c1 c2 c3 c4在线，也知道topic 下有 8个队列 q0,q1,q2,q3,q4,…q6，那么8/4=2，你就能知道每个消费者应该获取两个队列。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;例如： c1–&amp;gt;q0,q1, c2–&amp;gt;q2,q3, c3–&amp;gt;q4,q5, c4–&amp;gt;q5,q6。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实际上，这就是rocketmq默认的分配方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但现在唯一的问题在于，我们刚刚说的，我们没有一个中心节点统一地做分配，所以RocketMQ需要做一定的修改。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rh64a67&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如对于C1：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;“我是C1，我知道当前有4个消费者 c1 c2 c3 c4在线，也知道topic 下有 8个队列 q0,q1,q2,q3,q4,…q6，那么8/4=2，我就能知道每个消费者应该获取两个队列，而我算出来我要的队列是c1–&amp;gt;q0,q1”。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k6idwtu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于C2：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;“我是C2，我知道当前有4个消费者 c1 c2 c3 c4在线，也知道topic 下有 8个队列 q0,q1,q2,q3,q4,…q6，那么8/4=2，我就能知道每个消费者应该获取两个队列，而我算出来我要的队列是c2–&amp;gt;q2,q3。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;要做到无中心的完成这个目标，唯一需要增加的输入项就是“我是C1”，”我是C2”这样的入参，所以上文提到的&lt;code&gt;allocate&lt;/code&gt;方法下面&lt;code&gt;当前的消费者实例&lt;/code&gt;的唯一ID就是干这个事用的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面的代码就是RocketMQ的默认分配代码:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public List&amp;lt;MessageQueue&amp;gt; allocate(String consumerGroup, String currentCID, List&amp;lt;MessageQueue&amp;gt; mqAll,
        List&amp;lt;String&amp;gt; cidAll) {

        List&amp;lt;MessageQueue&amp;gt; result = new ArrayList&amp;lt;MessageQueue&amp;gt;();
        if (!check(consumerGroup, currentCID, mqAll, cidAll)) {
            return result;
        }
        int index = cidAll.indexOf(currentCID);
        int mod = mqAll.size() % cidAll.size();
        // 求最大可分配个数
        // q数量不超过客户端的数量，则每个客户端最多分配一个queue
        // 否则，每个客户端平分，当不够整除时，位置在mod内的按平均值多加1个，mod外的按平均值分
        int averageSize =
            mqAll.size() &amp;lt;= cidAll.size() ? 1 : (mod &amp;gt; 0 &amp;amp;&amp;amp; index &amp;lt; mod ? mqAll.size() / cidAll.size()
                + 1 : mqAll.size() / cidAll.size());
        // 计算当前客户端在queue列表的起始位置
        // 如果能够整除，或者不够整除时位置在mod内，则直接移动分配到的最大个数移动自己索引的倍数，给其他的客户端留位置
        // 如果不能整除且在mod外，则移动倍数之后加上mod数
        int startIndex = (mod &amp;gt; 0 &amp;amp;&amp;amp; index &amp;lt; mod) ? index * averageSize : index * averageSize + mod;
        // 计算分配Q的个数，最后一组不足averageSize的只分配能分配到的个数
        int range = Math.min(averageSize, mqAll.size() - startIndex);
        // 按照挪过的位置，计算所属Q的下标
        for (int i = 0; i &amp;lt; range; i++) {
            result.add(mqAll.get((startIndex + i) % mqAll.size()));
        }
        return result;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;RocketMQ按照Topic维度进行Rebalance，会导致一个很严重的结果：如果一个消费者组订阅多个Topic，可能会出现分配不均，部分处于排序前列的分配更多的队列，部分消费者处于空闲状态。&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;由于订阅多个Topic时可能会出现分配不均，这是在RocketMQ中我们为什么不建议同一个消费者组订阅多个Topic的重要原因。在这一点上，Kafka与不RocketMQ同，其是将所有Topic下的所有队列合并在一起，进行Rebalance，因此相对会更加平均。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;触发时机&quot;&gt;触发时机&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ有三个时机会触发：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-on1egk9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;启动的时候，会立即触发&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u27qn74&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有消费实例数量的变更的时候。broker在接受到消费者的心跳包的时候如果发现这个实例是新的实例的时候，会广播一个消费者数量变更的事件给所有消费者实例；同理，当发现一个消费者实例的连接断了，也会广播这样的一个事件&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ysufg68&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;定时触发（默认20秒）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于Broker只会通知一次，不保证client一定会收到变更事件通知，需要通过定时触发避免&lt;code&gt;Rebalance&lt;/code&gt;通知丢失&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[RocketMQ顺序消息]]></title><link>https://www.ztianzeng.com/posts/RocketMQ顺序消息</link><guid isPermaLink="false">/posts/RocketMQ顺序消息</guid><category><![CDATA[RocketMQ]]></category><pubDate>Mon, 09 May 2022 09:23:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;RocketMQ顺序消息&quot;&gt;RocketMQ顺序消息&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;电商的订单创建，以订单ID作为Sharding Key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照发布的先后顺序来消费。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;基本原理&quot;&gt;基本原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220509173821.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220509173700.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220509173907.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面用订单进行分区有序的示例:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Producer {
   public static void main(String[] args) throws Exception {
       DefaultMQProducer producer = new DefaultMQProducer(&amp;quot;please_rename_unique_group_name&amp;quot;);
       producer.setNamesrvAddr(&amp;quot;127.0.0.1:9876&amp;quot;);
       producer.start();
       String[] tags = new String[]{&amp;quot;TagA&amp;quot;, &amp;quot;TagC&amp;quot;, &amp;quot;TagD&amp;quot;};
       // 订单列表
       List&amp;lt;OrderStep&amp;gt; orderList = new Producer().buildOrders();
       Date date = new Date();
       SimpleDateFormat sdf = new SimpleDateFormat(&amp;quot;yyyy-MM-dd HH:mm:ss&amp;quot;);
       String dateStr = sdf.format(date);
       for (int i = 0; i &amp;lt; 10; i++) {
           // 加个时间前缀
           String body = dateStr + &amp;quot; Hello RocketMQ &amp;quot; + orderList.get(i);
           Message msg = new Message(&amp;quot;TopicTest&amp;quot;, tags[i % tags.length], &amp;quot;KEY&amp;quot; + i, body.getBytes());

           SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
               @Override
               public MessageQueue select(List&amp;lt;MessageQueue&amp;gt; mqs, Message msg, Object arg) {
                   Long id = (Long) arg;  //根据订单id选择发送queue
                   long index = id % mqs.size();
                   return mqs.get((int) index);
               }
           }, orderList.get(i).getOrderId());//订单id

           System.out.printf(&amp;quot;SendResult status:%s, queueId:%d, body:%s%n&amp;quot;,
               sendResult.getSendStatus(),
               sendResult.getMessageQueue().getQueueId(),
               body);
       }
       producer.shutdown();
   }

   /**
    * 订单的步骤
    */
   @Data
   private static class OrderStep {
       private long orderId;
       private String desc;
   }

   /**
    * 生成模拟订单数据
    */
   private List&amp;lt;OrderStep&amp;gt; buildOrders() {
       List&amp;lt;OrderStep&amp;gt; orderList = new ArrayList&amp;lt;OrderStep&amp;gt;();
       OrderStep orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111039L);
       orderDemo.setDesc(&amp;quot;创建&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111065L);
       orderDemo.setDesc(&amp;quot;创建&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111039L);
       orderDemo.setDesc(&amp;quot;付款&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103117235L);
       orderDemo.setDesc(&amp;quot;创建&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111065L);
       orderDemo.setDesc(&amp;quot;付款&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103117235L);
       orderDemo.setDesc(&amp;quot;付款&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111065L);
       orderDemo.setDesc(&amp;quot;完成&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111039L);
       orderDemo.setDesc(&amp;quot;推送&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103117235L);
       orderDemo.setDesc(&amp;quot;完成&amp;quot;);
       orderList.add(orderDemo);
       orderDemo = new OrderStep();
       orderDemo.setOrderId(15103111039L);
       orderDemo.setDesc(&amp;quot;完成&amp;quot;);
       orderList.add(orderDemo);
       return orderList;
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这是消费者的代码:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ConsumerInOrder {
   public static void main(String[] args) throws Exception {
       DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&amp;quot;please_rename_unique_group_name_3&amp;quot;);
       consumer.setNamesrvAddr(&amp;quot;127.0.0.1:9876&amp;quot;);
       /**
        * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&amp;lt;br&amp;gt;
        * 如果非第一次启动，那么按照上次消费的位置继续消费
        */
       consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
       consumer.subscribe(&amp;quot;TopicTest&amp;quot;, &amp;quot;TagA || TagC || TagD&amp;quot;);
       consumer.registerMessageListener(new MessageListenerOrderly() {
           Random random = new Random();

           @Override
           public ConsumeOrderlyStatus consumeMessage(List&amp;lt;MessageExt&amp;gt; msgs, ConsumeOrderlyContext context) {
               context.setAutoCommit(true);
               for (MessageExt msg : msgs) {
                   // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序
                   System.out.println(&amp;quot;consumeThread=&amp;quot; + Thread.currentThread().getName() + &amp;quot;queueId=&amp;quot; + msg.getQueueId() + &amp;quot;, content:&amp;quot; + new String(msg.getBody()));
               }
               try {
                   //模拟业务逻辑处理中...
                   TimeUnit.SECONDS.sleep(random.nextInt(10));
               } catch (Exception e) {
                   e.printStackTrace();
               }
               return ConsumeOrderlyStatus.SUCCESS;
           }
       });
       consumer.start();
       System.out.println(&amp;quot;Consumer Started.&amp;quot;);
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看出来，生产者那边需要实现&lt;code&gt;MessageQueueSelector&lt;/code&gt;完成队列的选举，而消费者需要实现&lt;code&gt;MessageListenerOrderly&lt;/code&gt;以完成消息的顺序消费&lt;/p&gt;
&lt;h1 id=&quot;问题&quot;&gt;问题&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们整个RocketMQ搭建的环境是，单个NameServer当个Broker的话，初始MessageQueue的队列为4。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有ID为13, 整个时候Hash情况如下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220510133921.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们由于业务的增长，新增了一个Broker，Broker非成倍数扩容，导致逻辑队列的QueueId无法路由到原有队列中，就变成了这样&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220510141046.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;解决方案&quot;&gt;解决方案&lt;/h1&gt;
&lt;h2 id=&quot;成倍扩容&quot;&gt;成倍扩容&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;成倍扩容，实现扩容前后，同样的 key，hash 到原队列，或者 hash 到新扩容的队列。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为可以参考HashMap的成倍扩容原理，消息要么在原队列上，要么在原有队列上+扩容的长度，由于RocketMQ的特性，他们的QueueId是一致的，所以可以顺序消费&lt;/p&gt;
&lt;h2 id=&quot;一致性Hash&quot;&gt;一致性Hash&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用一致性Hash来计算需要放置的MessageQueue队列&lt;/p&gt;
&lt;h2 id=&quot;自定义负载算法&quot;&gt;自定义负载算法&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现一个自定义的队列负载算法，需要传入一个队列的总队列个数，在负载均衡过程中如果发现数量不对时将消息先暂存到数据库，并将这些失败的队列信息存储到redis中，在发送新消息时，如果计算的负载队列是失败的队列，并且当前的队列信息已经恢复到当前初始值，则先判断数据库中是否有待发送到消息，如果有，则继续将消息发送到数据库，并开启一个线程，将数据库中的消息发送到mq中，这样后续的消息就会继续进入到MQ&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[RocketMQ持久化原理]]></title><link>https://www.ztianzeng.com/posts/RocketMQ持久化原理</link><guid isPermaLink="false">/posts/RocketMQ持久化原理</guid><category><![CDATA[RocketMQ]]></category><pubDate>Sat, 07 May 2022 02:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;RocketMQ持久化原理&quot;&gt;RocketMQ持久化原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息的持久化是RocketMQ中最为复杂和重要的一部分，由于持久化机制的存在才能够实现RocketMQ的高可靠性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图1&lt;/strong&gt;展示了RocketMQ的整体的工作逻辑&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;max-width: 1151px;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220507104147.png&quot; alt=&quot;&quot; title=&quot;图1 整体工作流程&quot; parent-style=&quot;max-width: 1151px;&quot; /&gt;&lt;span class=&quot;protyle-action__title&quot;&gt;图1 整体工作流程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yma10vc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Productor按照顺序写入&lt;code&gt;CommitLog&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ne9ca9t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Consumer顺序读取&lt;code&gt;ConsumeQueue&lt;/code&gt;进行消费, &lt;code&gt;ConsumeQueue&lt;/code&gt;是&lt;code&gt;CommitLog&lt;/code&gt;基于&lt;code&gt;Topic&lt;/code&gt;的索引文件&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ通过文件来作为中介，来衔接Productor和Consumer之间的消息传递，其流程还是比较简单的。&lt;/p&gt;
&lt;h1 id=&quot;ComitLog&quot;&gt;ComitLog&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;comitLog是RocketMQ存储消息的地方，Productor的发送消息都会写入到这个文件里面。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对应的实现类就叫做CommitLog。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CommitLog是通过MMAP的方式来操作文件，以加快文件处理速度，代码在&lt;code&gt;asyncPutMessages&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// CommitLog.java
public CompletableFuture&amp;lt;PutMessageResult&amp;gt; asyncPutMessages(final MessageExtBatch messageExtBatch) {
        	// .....
            MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

		// 如果文件为空，或者文件已经满了，则整一个新的文件出来
            if (null == mappedFile || mappedFile.isFull()) {
                mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
            }
		// 创建出来的文件为空，就返回异常
            if (null == mappedFile) {
                log.error(&amp;quot;Create mapped file1 error, topic: {} clientAddr: {}&amp;quot;, messageExtBatch.getTopic(), messageExtBatch.getBornHostString());
                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null));
            }
            // 向文件中追加消息信息
            result = mappedFile.appendMessages(messageExtBatch, this.appendMessageCallback, putMessageContext);

            switch (result.getStatus()) {
		// 如果正常处理，则相安无事
                case PUT_OK:
                    break;
		// 如果正好到了文件的末尾，则新建一个文件追加到新的文件中去
                case END_OF_FILE:
                    unlockMappedFile = mappedFile;
                    // Create a new file, re-write the message
                    mappedFile = this.mappedFileQueue.getLastMappedFile(0);
                    if (null == mappedFile) {
                        // XXX: warn and notify me
                        log.error(&amp;quot;Create mapped file2 error, topic: {} clientAddr: {}&amp;quot;, messageExtBatch.getTopic(), messageExtBatch.getBornHostString());
                        return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result));
                    }
                    result = mappedFile.appendMessages(messageExtBatch, this.appendMessageCallback, putMessageContext);
                    break;
                case MESSAGE_SIZE_EXCEEDED:
                case PROPERTIES_SIZE_EXCEEDED:
                    return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result));
                case UNKNOWN_ERROR:
                default:
                    return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
            }
	// .....
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;asyncPutMessages&lt;/code&gt; 追加msg信息还是比较好理解的，会调用到一个自己封装的&lt;code&gt;MappedFile&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;code&gt;MappedFile&lt;/code&gt;的构造函数中，通过JDK提供的文件NIO，初始化了&lt;code&gt;mappedByteBuffer&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// MappedFile.java
private void init(final String fileName, final int fileSize) throws IOException {
        // .... 
            this.fileChannel = new RandomAccessFile(this.file, &amp;quot;rw&amp;quot;).getChannel();
	    // 用mmap的技术来获取文件的句柄
            this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);
            TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);
            TOTAL_MAPPED_FILES.incrementAndGet();
            ok = true;
   // .....
    
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后调用&lt;code&gt;MappedFile&lt;/code&gt;的&lt;code&gt;appendMessagesInner&lt;/code&gt;来进行文件的追加，最终又会回到&lt;code&gt;CommitLog&lt;/code&gt;中的内部类&lt;code&gt;DefaultAppendMessageCallback&lt;/code&gt;完成文件的写入。&lt;/p&gt;
&lt;h1 id=&quot;ComitLog结构&quot;&gt;ComitLog结构&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;启动一个Productor，向着Broker中发送一条msg，msg结构如下&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Message msg = new Message(&amp;quot;TopicTest&amp;quot;,
                    &amp;quot;TagA&amp;quot;,
                    &amp;quot;OrderID188&amp;quot;,
                    &amp;quot;Hello world&amp;quot;.getBytes(RemotingHelper.DEFAULT_CHARSET));
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后我们用UltraEdit查看一下位于&lt;code&gt;${home}/store/commitlog&lt;/code&gt;下的&lt;code&gt;00000000000000000000&lt;/code&gt; 文件&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220507160040.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以明显的看到这个CommitLog文件里面明显有我们上传的msg信息。它具体的写入逻辑在&lt;code&gt;CommitLog&lt;/code&gt;中的内部类&lt;code&gt;DefaultAppendMessageCallback#doAppend&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个代码非常的长，主要盯住&lt;code&gt;byteBuffer&lt;/code&gt; 这个对象，看看往里面&lt;code&gt;put&lt;/code&gt;了什么东西&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
* 追加逻辑
* @param fileFromOffset 文件偏移量，也就是具体的文件
* @param byteBuffer 字节缓冲区，需要通过这个对象，完成文件的追加
* @param maxBlank  可以写入的文件的所剩空间
* @param msgInner 内部消息，就是msg对象
* @param putMessageContext 写入消息的上下文
* @return
*/
public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank,
	// ...先省略        
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;第一个put&quot;&gt;第一个put&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过IDEA工具，可以看到第一个&lt;code&gt;byteBuffer&lt;/code&gt;的&lt;code&gt;put&lt;/code&gt;处理，是用于判断文件是否结束的&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// 如果消息的长度+用于控制文件结束的8个空白字符 &amp;gt; 剩余胡亮
if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &amp;gt; maxBlank) {
                this.msgStoreItemMemory.clear();
                // 1 TOTALSIZE
                this.msgStoreItemMemory.putInt(maxBlank);
                // 2 MAGICCODE
                this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);
                // 3 The remaining space may be any value
                // Here the length of the specially set maxBlank
                final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
		// 加入最后8个空白字符，并且返回文件已经写满的标记
                byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8);
                return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset,
                        maxBlank, /* only wrote 8 bytes, but declare wrote maxBlank for compute write position */
                        msgIdSupplier, msgInner.getStoreTimestamp(),
                        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;第二个put&quot;&gt;第二个put&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二个Put的时候，&lt;code&gt;put&lt;/code&gt;了一个&lt;code&gt;preEncodeBuffer&lt;/code&gt; 进去&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;byteBuffer.put(preEncodeBuffer);
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，重点就回到了&lt;code&gt;preEncodeBuffer&lt;/code&gt;是怎么构造出来的&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// CommitLog.java
// 发现就一行代码，通过内部msgInner获取到byteBuffer
ByteBuffer preEncodeBuffer = msgInner.getEncodedBuff();
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;继续倒过来看，可以看到&lt;code&gt;MessageExtEncoder&lt;/code&gt;中设置有&lt;code&gt;encode&lt;/code&gt;方法来对进来的消息体进行设置&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// 1 TOTALSIZE
this.encoderBuffer.putInt(msgLen);
// 2 MAGICCODE
this.encoderBuffer.putInt(CommitLog.MESSAGE_MAGIC_CODE);
// 3 BODYCRC
this.encoderBuffer.putInt(msgInner.getBodyCRC());
// 4 QUEUEID
this.encoderBuffer.putInt(msgInner.getQueueId());
// 5 FLAG
this.encoderBuffer.putInt(msgInner.getFlag());
// 6 QUEUEOFFSET, need update later
this.encoderBuffer.putLong(0);
{
   // DefaultAppendMessageCallback.class 中
   preEncodeBuffer.putLong(pos, queueOffset);
}
// 7 PHYSICALOFFSET, need update later
this.encoderBuffer.putLong(0);
{
   // DefaultAppendMessageCallback.class 中
    preEncodeBuffer.putLong(pos, fileFromOffset + byteBuffer.position());

}

// 8 SYSFLAG
this.encoderBuffer.putInt(msgInner.getSysFlag());
// 9 BORNTIMESTAMP
this.encoderBuffer.putLong(msgInner.getBornTimestamp());
// 10 BORNHOST
socketAddress2ByteBuffer(msgInner.getBornHost() ,this.encoderBuffer);
// 11 STORETIMESTAMP
this.encoderBuffer.putLong(msgInner.getStoreTimestamp());
// 12 STOREHOSTADDRESS
socketAddress2ByteBuffer(msgInner.getStoreHost() ,this.encoderBuffer);
// 13 RECONSUMETIMES
this.encoderBuffer.putInt(msgInner.getReconsumeTimes());
// 14 Prepared Transaction Offset
this.encoderBuffer.putLong(msgInner.getPreparedTransactionOffset());
// 15 BODY
this.encoderBuffer.putInt(bodyLength);
if (bodyLength &amp;gt; 0)
    this.encoderBuffer.put(msgInner.getBody());
// 16 TOPIC
this.encoderBuffer.put((byte) topicLength);
this.encoderBuffer.put(topicData);
// 17 PROPERTIES
this.encoderBuffer.putShort((short) propertiesLength);
if (propertiesLength &amp;gt; 0)
    this.encoderBuffer.put(propertiesData);
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220507163411.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ng3l85r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TOTALSIZE: 该消息条目总长度，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6wrv4y6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MAGICCODE: 魔法值，固定0xdaa320a7，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-owprpmb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BODYCRC: 消息体crc校验码，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yzv1rb5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QUEUEID: ComsumeQueue消息消费队列ID，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0q0r1su&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;FLAG: 消息FLAG，预留给消费者的标识位，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8m7pwo2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QUEUEOFFSET: 消息在ComsumeQueue的偏移量，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oc2sn68&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;PHYSICALOFFSET: 消息在CommitLog文件中的偏移量，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-swzyukn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SYSFLAG: 消息系统FLAG，例如是否压缩、是否有事务消息，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-boc4j0h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BORNTIMESTAMP: 消息产生者调用消息发送API的时间戳，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qb1hzxs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BORNHOST: 消息发送者IP、端口号，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p5qkph7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;STORETIMESTAMP: 消息存储时间戳，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1yxks13&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;STOREHOSPTADDRESS: Broker服务器IP+端口号，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gc2wnk8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RECONSUMETIMES: 消息重试次数，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-75zotkh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Prepare Transaction Offset: 事务消息物理偏移量，8字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t2iqx7l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BodyLength: 消息体长度，4字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1ib1lac&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Body: 消息体内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rzk5y4y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TopicLength: 主题存储长度，主题名称不能超过255个字符，1字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bmjt99y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Topic: 主题内容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9xa1726&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;PropertiesLength: 消息属性长度，表示消息属性长度不能超过65536个字符，2字节&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7pv8q5n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Properties: 消息属性&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后把这个消息体给put到byteBuffer中去，就完成了文件的写入。&lt;/p&gt;
&lt;h1 id=&quot;消息丢失&quot;&gt;消息丢失&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了加快读写速度，RocketMQ采用了MMAP来进行写入&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xyndcx0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将数据文件通过MMAP技术，映射文件到OS的虚拟内存中&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lsrqclv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MMAP技术在写入消息时，会写入到PageCache中，然后异步刷盘到实际的磁盘中&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写入PageCache的时候，假如说这个时候发生了断电，导致数据没有及时刷到磁盘中就会发生消息丢失&lt;/p&gt;
&lt;h2 id=&quot;解决方案&quot;&gt;解决方案&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rpqvlyv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改配置&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改 Broker 端配置，默认刷盘方式是通过异步刷盘，修改为同步刷盘&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;## 默认情况为 ASYNC_FLUSH 
flushDiskType = SYNC_FLUSH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-etklp8e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;集群部署&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证可用性，Broker 通常采用一主（ &lt;code&gt;master&lt;/code&gt; ）多从（ &lt;code&gt;slave&lt;/code&gt; ）部署方式。为了保证消息不丢失，消息还需要复制到 slave 节点。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;默认方式下，消息写入 &lt;code&gt;master&lt;/code&gt; 成功，就可以返回确认响应给生产者，接着消息将会异步复制到 &lt;code&gt;slave&lt;/code&gt; 节点。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注：master 配置：flushDiskType = SYNC_FLUSH&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时若 master 突然&lt;code&gt; 宕机且不可恢复&lt;/code&gt; ，那么还未复制到 &lt;code&gt;slave&lt;/code&gt; 的消息将会丢失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了进一步提高消息的可靠性，我们可以采用同步的复制方式，&lt;code&gt;master&lt;/code&gt; 节点将会同步等待 &lt;code&gt;slave&lt;/code&gt; 节点复制完成，才会返回确认响应&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虽然上述配置提高消息的高可靠性，但是会降低性能 ，生产实践中需要综合选择。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[RocketMQ延迟消息原理]]></title><link>https://www.ztianzeng.com/posts/RocketMQ延迟消息原理</link><guid isPermaLink="false">/posts/RocketMQ延迟消息原理</guid><category><![CDATA[RocketMQ]]></category><pubDate>Fri, 06 May 2022 09:05:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;RocketMQ延迟消息原理&quot;&gt;RocketMQ延迟消息原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ提供了延迟消息的功能，消息在发送到RocketMQ服务端之后不会马上投递，而是根据消息中的属性延迟固定时间之后才会投递到消费者那。&lt;/p&gt;
&lt;h1 id=&quot;使用场景&quot;&gt;使用场景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。&lt;/p&gt;
&lt;h2 id=&quot;启动消费者等待传入订阅消息&quot;&gt;启动消费者等待传入订阅消息&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ScheduledMessageConsumer {
   public static void main(String[] args) throws Exception {
      // 实例化消费者
      DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&amp;quot;ExampleConsumer&amp;quot;);
      // 订阅Topics
      consumer.subscribe(&amp;quot;TestTopic&amp;quot;, &amp;quot;*&amp;quot;);
      // 注册消息监听者
      consumer.registerMessageListener(new MessageListenerConcurrently() {
          @Override
          public ConsumeConcurrentlyStatus consumeMessage(List&amp;lt;MessageExt&amp;gt; messages, ConsumeConcurrentlyContext context) {
              for (MessageExt message : messages) {
                  // Print approximate delay time period
                  System.out.println(&amp;quot;Receive message[msgId=&amp;quot; + message.getMsgId() + &amp;quot;] &amp;quot; + (System.currentTimeMillis() - message.getBornTimestamp()) + &amp;quot;ms later&amp;quot;);
              }
              return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
          }
      });
      // 启动消费者
      consumer.start();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;发送延迟消息&quot;&gt;发送延迟消息&lt;/h2&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18 消息消费失败会进入延时消息队列，消息发送时间与设置的延时等级和重试次数有关&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ScheduledMessageProducer {
   public static void main(String[] args) throws Exception {
      // 实例化一个生产者来产生延时消息
      DefaultMQProducer producer = new DefaultMQProducer(&amp;quot;ExampleProducerGroup&amp;quot;);
      // 启动生产者
      producer.start();
      int totalMessagesToSend = 100;
      for (int i = 0; i &amp;lt; totalMessagesToSend; i++) {
          Message message = new Message(&amp;quot;TestTopic&amp;quot;, (&amp;quot;Hello scheduled message &amp;quot; + i).getBytes());
          // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)
          message.setDelayTimeLevel(3);
          // 发送消息
          producer.send(message);
      }
       // 关闭生产者
      producer.shutdown();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;原理分析&quot;&gt;原理分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Productor发送没啥好说的，与事务消息队列相比简单太多，与正常发送相比仅仅设置了一个&lt;code&gt;DelayTimeLevel&lt;/code&gt;的属性。&lt;/p&gt;
&lt;h2 id=&quot;broker接收流程&quot;&gt;broker接收流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息从&lt;code&gt;SendMessageProcessor#asyncProcessRequest&lt;/code&gt; 进来之后，会一步步向下执行&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// SendMessageProcessor.java
 private CompletableFuture&amp;lt;RemotingCommand&amp;gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request,
                                                                SendMessageContext mqtraceContext,
                                                                SendMessageRequestHeader requestHeader) {
        // ......
        CompletableFuture&amp;lt;PutMessageResult&amp;gt; putMessageResult = null;
        String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED);
        if (transFlag != null &amp;amp;&amp;amp; Boolean.parseBoolean(transFlag)) {
            if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) {
                response.setCode(ResponseCode.NO_PERMISSION);
                response.setRemark(
                        &amp;quot;the broker[&amp;quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
                                + &amp;quot;] sending transaction message is forbidden&amp;quot;);
                return CompletableFuture.completedFuture(response);
            }
            //存储事务消息
            putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner);
        } else {
            //存储普通消息
            putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner);
        }
        return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt);
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后会调用到&lt;code&gt;DefaultMessageStore#asyncPutMessage&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// DefaultMessageStore#asyncPutMessage.java
public CompletableFuture&amp;lt;PutMessageResult&amp;gt; asyncPutMessage(MessageExtBrokerInner msg) {
 	// 检查存储状态：是否关闭、是否slave、是否不可写、写入是否频繁
        PutMessageStatus checkStoreStatus = this.checkStoreStatus();
        if (checkStoreStatus != PutMessageStatus.PUT_OK) {
            return CompletableFuture.completedFuture(new PutMessageResult(checkStoreStatus, null));
        }
	// 检查msg长度是否合法：topic是否超过127、body长度是否超过限定值
        PutMessageStatus msgCheckStatus = this.checkMessage(msg);
        if (msgCheckStatus == PutMessageStatus.MESSAGE_ILLEGAL) {
            return CompletableFuture.completedFuture(new PutMessageResult(msgCheckStatus, null));
        }

        PutMessageStatus lmqMsgCheckStatus = this.checkLmqMessage(msg);
        if (msgCheckStatus == PutMessageStatus.LMQ_CONSUME_QUEUE_NUM_EXCEEDED) {
            return CompletableFuture.completedFuture(new PutMessageResult(lmqMsgCheckStatus, null));
        }


        long beginTime = this.getSystemClock().now();
	// 往commitLog中塞入消息（核心！！）
        CompletableFuture&amp;lt;PutMessageResult&amp;gt; putResultFuture = this.commitLog.asyncPutMessage(msg);

        putResultFuture.thenAccept((result) -&amp;gt; {
            long elapsedTime = this.getSystemClock().now() - beginTime;
            if (elapsedTime &amp;gt; 500) {
                log.warn(&amp;quot;putMessage not in lock elapsed time(ms)={}, bodyLength={}&amp;quot;, elapsedTime, msg.getBody().length);
            }
            this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime);

            if (null == result || !result.isOk()) {
                this.storeStatsService.getPutMessageFailedTimes().add(1);
            }
        });

        return putResultFuture;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后通过RocketMQ的&lt;code&gt;CommitLog&lt;/code&gt;将消息存储起来，延迟消息的秘密也在这里将会得到解答&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public CompletableFuture&amp;lt;PutMessageResult&amp;gt; asyncPutMessage(final MessageExtBrokerInner msg) {
	// .... 省略一些代码
        if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE
                || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) {
            // 如果设置的延迟等级&amp;gt;0,则表示需要延迟进行推送
            if (msg.getDelayTimeLevel() &amp;gt; 0) {
                if (msg.getDelayTimeLevel() &amp;gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) {
                    msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel());
                }

                topic = TopicValidator.RMQ_SYS_SCHEDULE_TOPIC;
                int queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel());

                // 保存真实的Topic和QueueId
                MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic());
                MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId()));
                msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties()));
		// 将topic修改成延迟队列的topic
                msg.setTopic(topic);
                msg.setQueueId(queueId);
            }
        }
	// ... 省略一些代码
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ实现延迟队列的方式大致和事务消息类似，让消息重写到一个&lt;code&gt;Consumer&lt;/code&gt;无法监听的&lt;code&gt;Topic&lt;/code&gt;中，这样就能够将延迟消息给保存下来&lt;/p&gt;
&lt;h2 id=&quot;延迟投递原理&quot;&gt;延迟投递原理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过IDEA 查看 &lt;code&gt;TopicValidator#RMQ_SYS_SCHEDULE_TOPIC&lt;/code&gt;,可以发现在&lt;code&gt;ScheduleMessageService&lt;/code&gt;中有去扫描这个Topic，看这个类名大概也能够猜出，是延迟投递的核心实现类。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// ScheduleMessageService.java
public void start() {
        if (started.compareAndSet(false, true)) {
            this.load();
            this.deliverExecutorService = new ScheduledThreadPoolExecutor(this.maxDelayLevel, new ThreadFactoryImpl(&amp;quot;ScheduleMessageTimerThread_&amp;quot;));
            if (this.enableAsyncDeliver) {
                this.handleExecutorService = new ScheduledThreadPoolExecutor(this.maxDelayLevel, new ThreadFactoryImpl(&amp;quot;ScheduleMessageExecutorHandleThread_&amp;quot;));
            }
            for (Map.Entry&amp;lt;Integer, Long&amp;gt; entry : this.delayLevelTable.entrySet()) {
                Integer level = entry.getKey();
                Long timeDelay = entry.getValue();
                Long offset = this.offsetTable.get(level);
                if (null == offset) {
                    offset = 0L;
                }

                if (timeDelay != null) {
                    if (this.enableAsyncDeliver) {
                        this.handleExecutorService.schedule(new HandlePutResultTask(level), FIRST_DELAY_TIME, TimeUnit.MILLISECONDS);
                    }
		    // 启动延迟队列，调度任务
                    this.deliverExecutorService.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME, TimeUnit.MILLISECONDS);
                }
            }

            this.deliverExecutorService.scheduleAtFixedRate(new Runnable() {

                @Override
                public void run() {
                    try {
                        if (started.get()) {
			// 将任务持久化到文件中去
                            ScheduleMessageService.this.persist();
                        }
                    } catch (Throwable e) {
                        log.error(&amp;quot;scheduleAtFixedRate flush exception&amp;quot;, e);
                    }
                }
            }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval(), TimeUnit.MILLISECONDS);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过线程启动了一个&lt;code&gt;DeliverDelayedMessageTimerTask&lt;/code&gt;来调度延迟消息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就是通过Java自带的延迟队列，来掉队队列中的消息，满足时间了则进行投递，将定时任务的Topic中移除，放入它原本的Topic中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样客户端就能够接收到消息的信息。&lt;/p&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-d0x9su7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;producer端设置消息delayLevel延迟级别，消息属性DELAY中存储了对应了延时级别&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hgv4vgr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;broker端收到消息后，判断延时消息延迟级别，如果大于0，则备份消息原始topic，queueId，并将消息topic改为延时消息队列特定topic(SCHEDULE_TOPIC)，queueId改为延时级别-1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mrr34ii&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;mq服务端ScheduleMessageService中，为每一个延迟级别单独设置一个定时器，定时(每隔1秒)拉取对应延迟级别的消费队列&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k3scp16&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据消费偏移量offset从commitLog中解析出对应消息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5kbuiaz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从消息tagsCode中解析出消息应当被投递的时间，与当前时间做比较，判断是否应该进行投递&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fkpyvne&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;若到达了投递时间，则构建一个新的消息，并从消息属性中恢复出原始的topic，queueId，并清除消息延迟属性，从新进行消息投递&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[RocketMQ事务消息实现原理]]></title><link>https://www.ztianzeng.com/posts/RocketMQ事务消息实现原理</link><guid isPermaLink="false">/posts/RocketMQ事务消息实现原理</guid><category><![CDATA[RocketMQ]]></category><pubDate>Thu, 05 May 2022 12:27:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;RocketMQ事务消息实现原理&quot;&gt;RocketMQ事务消息实现原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ提供了事务消息的功能，采用了2PC+事务回查来实现事务，最终能通过RocketMQ提供的事务消息，能够简单方便的实现分布式事务。&lt;/p&gt;
&lt;h1 id=&quot;概念介绍&quot;&gt;概念介绍&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ai7ve1d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ提供类似XA或Open XA的分布式事务功能，通过RocketMQ事务消息能达到分布式事务的最终一致。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8he16to&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;半事务消息&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;暂不能投递的消息，生产者已经成功地将消息发送到了RocketMQ服务端，但是RocketMQ服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半事务消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m3nsmdz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息回查&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，RocketMQ服务端通过扫描发现某条消息长期处于“半事务消息”时，需要主动向消息生产者询问该消息的最终状态（Commit或是Rollback），该询问过程即消息回查。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;交互流程&quot;&gt;交互流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息交互流程如下图所示。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/RSb0i0.jpg&quot; alt=&quot;RSb0i0&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息发送步骤如下：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-pr4vky6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者将半事务消息发送至RocketMQ服务端。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-l4rtkbh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息为半事务消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3rpqav6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者开始执行本地事务逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t5adgox&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wan00ag&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-z13an16&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pyziydt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息回查步骤如下：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yb2ic4n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-voybdcy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;使用限制&quot;&gt;使用限制&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zzteq2b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息不支持延时消息和批量消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4oj5tga&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 &lt;code&gt;transactionCheckMax&lt;/code&gt;参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = &lt;code&gt;transactionCheckMax&lt;/code&gt; ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 &lt;code&gt;AbstractTransactionalMessageCheckListener&lt;/code&gt; 类来修改这个行为。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pwd54ew&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息将在 Broker 配置文件中的参数 &lt;code&gt;transactionTimeout&lt;/code&gt; 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 &lt;code&gt;CHECK_IMMUNITY_TIME_IN_SECONDS&lt;/code&gt; 来改变这个限制，该参数优先于 &lt;code&gt;transactionTimeout&lt;/code&gt; 参数。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k35wi2g&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务性消息可能不止一次被检查或消费。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gxb5kdb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vqkt3zt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;原理分析&quot;&gt;原理分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;整个事务消息，分为两大块，发送流程和回查流程:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-suycwud&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送流程：发送half message(半消息)，执行本地事务，发送事务执行结果&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3jx2j65&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;定时任务回查流程：MQ定时任务扫描半消息，回查本地事务，发送事务执行结果&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Productor发送消息&quot;&gt;Productor发送消息&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送端的代码:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class TransactionProducer {
   public static void main(String[] args) throws MQClientException, InterruptedException {
       TransactionListener transactionListener = new TransactionListenerImpl();
       TransactionMQProducer producer = new TransactionMQProducer(&amp;quot;please_rename_unique_group_name&amp;quot;);
       ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&amp;lt;Runnable&amp;gt;(2000), new ThreadFactory() {
           @Override
           public Thread newThread(Runnable r) {
               Thread thread = new Thread(r);
               thread.setName(&amp;quot;client-transaction-msg-check-thread&amp;quot;);
               return thread;
           }
       });
       producer.setExecutorService(executorService);
       producer.setTransactionListener(transactionListener);
       producer.start();
       String[] tags = new String[] {&amp;quot;TagA&amp;quot;, &amp;quot;TagB&amp;quot;, &amp;quot;TagC&amp;quot;, &amp;quot;TagD&amp;quot;, &amp;quot;TagE&amp;quot;};
       for (int i = 0; i &amp;lt; 10; i++) {
           try {
               Message msg =
                   new Message(&amp;quot;TopicTest1234&amp;quot;, tags[i % tags.length], &amp;quot;KEY&amp;quot; + i,
                       (&amp;quot;Hello RocketMQ &amp;quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
               SendResult sendResult = producer.sendMessageInTransaction(msg, null);
               System.out.printf(&amp;quot;%s%n&amp;quot;, sendResult);
               Thread.sleep(10);
           } catch (MQClientException | UnsupportedEncodingException e) {
               e.printStackTrace();
           }
       }
       for (int i = 0; i &amp;lt; 100000; i++) {
           Thread.sleep(1000);
       }
       producer.shutdown();
   }

	public class TransactionListenerImpl implements TransactionListener {
	  private AtomicInteger transactionIndex = new AtomicInteger(0);
	  private ConcurrentHashMap&amp;lt;String, Integer&amp;gt; localTrans = new ConcurrentHashMap&amp;lt;&amp;gt;();
	  @Override
	  public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
	      int value = transactionIndex.getAndIncrement();
	      int status = value % 3;
	      localTrans.put(msg.getTransactionId(), status);
	      return LocalTransactionState.UNKNOW;
	  }
	  @Override
	  public LocalTransactionState checkLocalTransaction(MessageExt msg) {
	      Integer status = localTrans.get(msg.getTransactionId());
	      if (null != status) {
	          switch (status) {
	              case 0:
	                  return LocalTransactionState.UNKNOW;
	              case 1:
	                  return LocalTransactionState.COMMIT_MESSAGE;
	              case 2:
	                  return LocalTransactionState.ROLLBACK_MESSAGE;
	          }
	      }
	      return LocalTransactionState.COMMIT_MESSAGE;
	  }
	}
	
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从代码中可以看出，发送半消息是通过&lt;code&gt;TransactionMQProducer&lt;/code&gt;的&lt;code&gt;sendMessageInTransaction&lt;/code&gt;来进行发送&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public TransactionSendResult sendMessageInTransaction(final Message msg,
        final Object arg) throws MQClientException {
        //判断transactionListener是否存在
        if (null == this.transactionListener) {
            throw new MQClientException(&amp;quot;TransactionListener is null&amp;quot;, null);
        }

        msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic()));
        //发送事务消息
        return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;transactionListener&lt;/code&gt; 是消息回查的类，它提供了两个方法&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-d9hp0d0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;executeLocalTransaction: 执行本地事务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iplp1ze&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;checkLocalTransaction: 回查本地事务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;TransactionMQProducer&lt;/code&gt;的&lt;code&gt;sendMessageInTransaction&lt;/code&gt;最终会进入到&lt;code&gt;DefaultMQProducerImpl.sendMessageInTransaction&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public TransactionSendResult sendMessageInTransaction(final Message msg,
        final LocalTransactionExecuter localTransactionExecuter, final Object arg)
        throws MQClientException {
        //判断检查本地事务的listener是否存在
        TransactionListener transactionListener = getCheckListener();
        if (null == localTransactionExecuter &amp;amp;&amp;amp; null == transactionListener) {
            throw new MQClientException(&amp;quot;tranExecutor is null&amp;quot;, null);
        }
        // ignore DelayTimeLevel parameter
        if (msg.getDelayTimeLevel() != 0) {
            MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_DELAY_TIME_LEVEL);
        }

        Validators.checkMessage(msg, this.defaultMQProducer);

        SendResult sendResult = null;
        MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &amp;quot;true&amp;quot;);
        MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup());
        try {
            //发送半消息
            sendResult = this.send(msg);
        } catch (Exception e) {
            throw new MQClientException(&amp;quot;send message Exception&amp;quot;, e);
        }

        LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;
        Throwable localException = null;
        switch (sendResult.getSendStatus()) {
            case SEND_OK: {
                try {
                    if (sendResult.getTransactionId() != null) {
                        msg.putUserProperty(&amp;quot;__transactionId__&amp;quot;, sendResult.getTransactionId());
                    }
                    String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
                    if (null != transactionId &amp;amp;&amp;amp; !&amp;quot;&amp;quot;.equals(transactionId)) {
                        msg.setTransactionId(transactionId);
                    }
                    if (null != localTransactionExecuter) {
                        localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg);
                    } else if (transactionListener != null) {
                        //发送消息成功，执行本地事务
                        log.debug(&amp;quot;Used new transaction API&amp;quot;);
                        localTransactionState = transactionListener.executeLocalTransaction(msg, arg);
                    }
                    if (null == localTransactionState) {
                        localTransactionState = LocalTransactionState.UNKNOW;
                    }

                    if (localTransactionState != LocalTransactionState.COMMIT_MESSAGE) {
                        log.info(&amp;quot;executeLocalTransactionBranch return {}&amp;quot;, localTransactionState);
                        log.info(msg.toString());
                    }
                } catch (Throwable e) {
                    log.info(&amp;quot;executeLocalTransactionBranch exception&amp;quot;, e);
                    log.info(msg.toString());
                    localException = e;
                }
            }
            break;
            case FLUSH_DISK_TIMEOUT:
            case FLUSH_SLAVE_TIMEOUT:
            case SLAVE_NOT_AVAILABLE:
                localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;
                break;
            default:
                break;
        }

        try {
            //执行endTransaction方法
            // 如果半消息发送失败或本地事务执行失败告诉服务端是删除半消息
            // 半消息发送成功且本地事务执行成功则告诉服务端生效半消息
            this.endTransaction(msg, sendResult, localTransactionState, localException);
        } catch (Exception e) {
            log.warn(&amp;quot;local transaction execute &amp;quot; + localTransactionState + &amp;quot;, but end broker transaction failed&amp;quot;, e);
        }

        TransactionSendResult transactionSendResult = new TransactionSendResult();
        transactionSendResult.setSendStatus(sendResult.getSendStatus());
        transactionSendResult.setMessageQueue(sendResult.getMessageQueue());
        transactionSendResult.setMsgId(sendResult.getMsgId());
        transactionSendResult.setQueueOffset(sendResult.getQueueOffset());
        transactionSendResult.setTransactionId(sendResult.getTransactionId());
        transactionSendResult.setLocalTransactionState(localTransactionState);
        return transactionSendResult;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法的功能:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-q3t4qkp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;给消息追加上事务消息相关的&lt;code&gt;tag&lt;/code&gt;,用于broker区分普通消息和事务消息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-11koewz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;调用&lt;code&gt;this.send(msg)&lt;/code&gt;发送半消息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-90pfmas&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送成功由用户自己编写的&lt;code&gt;transactionListener&lt;/code&gt;，执行本地事务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8rjyg0b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务结束之后，执行&lt;code&gt;endTransaction&lt;/code&gt;，告诉&lt;code&gt;broker&lt;/code&gt;执行&lt;code&gt;commit/rollback&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;code&gt;transactionListener&lt;/code&gt;执行完之后有三种情况: &lt;code&gt;UNKNOW&lt;/code&gt;、&lt;code&gt;COMMIT&lt;/code&gt;、&lt;code&gt;RollBack&lt;/code&gt;，然后调用&lt;code&gt;endTransaction&lt;/code&gt;来结束事务&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void endTransaction(
        final Message msg,
        final SendResult sendResult,
        final LocalTransactionState localTransactionState,
        final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException {
        final MessageId id;
        if (sendResult.getOffsetMsgId() != null) {
            id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId());
        } else {
            id = MessageDecoder.decodeMessageId(sendResult.getMsgId());
        }
        String transactionId = sendResult.getTransactionId();
        final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName());
        EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader();
        requestHeader.setTransactionId(transactionId);
        requestHeader.setCommitLogOffset(id.getOffset());
	// 根据事务执行的结果，来设置提交给broker的状态
        switch (localTransactionState) {
		// 提交事务
            case COMMIT_MESSAGE:
                requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE);
                break;
		// 回滚
            case ROLLBACK_MESSAGE:
                requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE);
                break;
            case UNKNOW:
                requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE);
                break;
            default:
                break;
        }

        doExecuteEndTransactionHook(msg, sendResult.getMsgId(), brokerAddr, localTransactionState, false);
        requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());
        requestHeader.setTranStateTableOffset(sendResult.getQueueOffset());
        requestHeader.setMsgId(sendResult.getMsgId());
        String remark = localException != null ? (&amp;quot;executeLocalTransactionBranch exception: &amp;quot; + localException.toString()) : null;
        this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark,
            this.defaultMQProducer.getSendMsgTimeout());
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;Broker处理半消息-第一次send-&quot;&gt;Broker处理半消息（第一次send）&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Broker端通过&lt;code&gt;SendMessageProcessor.processRequest()&lt;/code&gt;方法接收处理 Producer 发送的半消息&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后会调用到&lt;code&gt;SendMessageProcessor.asyncSendMessage()&lt;/code&gt;，判断消息类型，进行消息存储。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private CompletableFuture&amp;lt;RemotingCommand&amp;gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request,
                                                                SendMessageContext mqtraceContext,
                                                                SendMessageRequestHeader requestHeader) {
        // 。。。没必要看，都是set一些属性
        String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED);
	// 如果是事务消息
        if (transFlag != null &amp;amp;&amp;amp; Boolean.parseBoolean(transFlag)) {
            if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) {
                response.setCode(ResponseCode.NO_PERMISSION);
                response.setRemark(
                        &amp;quot;the broker[&amp;quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
                                + &amp;quot;] sending transaction message is forbidden&amp;quot;);
                return CompletableFuture.completedFuture(response);
            }
            //存储半消息
            putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner);
        } else {
            //存储普通消息
            putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner);
        }
        return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;存储半消息的核心代码:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public CompletableFuture&amp;lt;PutMessageResult&amp;gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) {
        return store.asyncPutMessage(parseHalfMessageInner(messageInner));
    }

    private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) {
        //备份消息的原主题名称与原队列ID
        MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic());
        MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID,
            String.valueOf(msgInner.getQueueId()));
        msgInner.setSysFlag(
            MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE));
        //事务消息的topic和queueID是写死固定的
        msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic());
        msgInner.setQueueId(0);
        msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));
        return msgInner;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这一步，备份消息的原主题名称与原队列ID，然后取消事务消息的消息标签，重新设置消息的主题为：RMQ_SYS_TRANS_HALF_TOPIC，队列ID固定为0。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与其他普通消息区分开，然后完成消息持久化。到这里，Broker 就初步处理完了 Producer 发送的事务半消息。&lt;/p&gt;
&lt;h2 id=&quot;Broker处理事务消息的二次提交&quot;&gt;Broker处理事务消息的二次提交&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws
        RemotingCommandException {
        final RemotingCommand response = RemotingCommand.createResponseCommand(null);
        final EndTransactionRequestHeader requestHeader =
            (EndTransactionRequestHeader)request.decodeCommandCustomHeader(EndTransactionRequestHeader.class);
        LOGGER.debug(&amp;quot;Transaction request:{}&amp;quot;, requestHeader);
        //从节点不处理
        if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) {
            response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE);
            LOGGER.warn(&amp;quot;Message store is slave mode, so end transaction is forbidden. &amp;quot;);
            return response;
        }
        // .....一堆没啥太大影响的代码
        OperationResult result = new OperationResult();
	// 核心流程
        if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) {
            //根据commitLogOffset从commitlog文件中查找消息
            result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader);
            if (result.getResponseCode() == ResponseCode.SUCCESS) {
		// 如果是提交动作，就恢复原消息的主题与队列，再次存入commitlog文件进而转到消息消费队列，供消费者消费，
            	// 然后将原预处理消息存入一个新的主题RMQ_SYS_TRANS_OP_HALF_TOPIC，代表该消息已被处理
                RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader);
                if (res.getCode() == ResponseCode.SUCCESS) {
                    MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage());
                    msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback()));
                    msgInner.setQueueOffset(requestHeader.getTranStateTableOffset());
                    msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset());
                    msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp());
                    MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED);
                    RemotingCommand sendResult = sendFinalMessage(msgInner);
                    if (sendResult.getCode() == ResponseCode.SUCCESS) {
                        //其实是将消息存储在主题为：RMQ_SYS_TRANS_OP_HALF_TOPIC的主题中，代表这些消息已经被处理（提交或回滚）。
                        this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage());
                    }
                    return sendResult;
                }
                return res;
            }
        } else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) {
            //根据commitlogOffset查找消息
            result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader);
            if (result.getResponseCode() == ResponseCode.SUCCESS) {
                RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader);
                if (res.getCode() == ResponseCode.SUCCESS) {
                    //删除预处理消息(prepare)
                    //其实是将消息存储在主题为：RMQ_SYS_TRANS_OP_HALF_TOPIC的主题中，代表这些消息已经被处理（提交或回滚）。
                    this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage());
                }
                return res;
            }
        }
        response.setCode(result.getResponseCode());
        response.setRemark(result.getResponseRemark());
        return response;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其流程大概如下:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8kj1r43&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据commitlogOffset找到消息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zor7zfv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果是提交动作，就恢复原消息的主题与队列，再次存入commitlog文件进而转到消息消费队列，供消费者消费，然后将原预处理消息存入一个新的主题RMQ_SYS_TRANS_OP_HALF_TOPIC，代表该消息已被处理&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yigg7wv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;回滚消息，则直接将原预处理消息存入一个新的主题RMQ_SYS_TRANS_OP_HALF_TOPIC，代表该消息已被处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;半消息事务回查&quot;&gt;半消息事务回查&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两段式协议发送与提交回滚消息，执行完本地事务消息的状态为&lt;code&gt;UNKNOW&lt;/code&gt;时，结束事务不做任何操作。通过事务状态定时回查得到发送端的事务状态是&lt;code&gt;rollback&lt;/code&gt;或&lt;code&gt;commit&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过&lt;code&gt;TransactionalMessageCheckService&lt;/code&gt;线程定时去检测&lt;code&gt;RMQ_SYS_TRANS_HALF_TOPIC&lt;/code&gt;主题中的消息，回查消息的事务状态。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-lcy2qs1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RMQ_SYS_TRANS_HALF_TOPIC&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;prepare消息的主题，事务消息首先先进入到该主题。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-670grpi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RMQ_SYS_TRANS_OP_HALF_TOPIC&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当消息服务器收到事务消息的提交或回滚请求后，会将消息存储在该主题下。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// TransactionalMessageCheckService   
@Override
    public void run() {
        log.info(&amp;quot;Start transaction check service thread!&amp;quot;);
        long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval();
        while (!this.isStopped()) {
            this.waitForRunning(checkInterval);
        }
        log.info(&amp;quot;End transaction check service thread!&amp;quot;);
    }

    @Override
    protected void onWaitEnd() {
        //事务过期时间
        long timeout = brokerController.getBrokerConfig().getTransactionTimeOut();
        int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax();
        long begin = System.currentTimeMillis();
        log.info(&amp;quot;Begin to check prepare message, begin time:{}&amp;quot;, begin);
        //检查本地事务
        this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener());
        log.info(&amp;quot;End to check prepare message, consumed time:{}&amp;quot;, System.currentTimeMillis() - begin);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;时序图如下:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220506195258.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;异常情况&quot;&gt;异常情况&lt;/h1&gt;
&lt;h2 id=&quot;Producer发送半消息失败&quot;&gt;Producer发送半消息失败&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在发送成功之后才会执行本地事务，所以半消息发送失败之后就直接退出发送流程了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送失败会抛出异常信息，可以自己针对异常信息再做进一步处理，是重试还是回滚上一步操作。&lt;/p&gt;
&lt;h2 id=&quot;半消息发送成功-没收到MQ返回的响应&quot;&gt;半消息发送成功，没收到MQ返回的响应&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本地事务执行失败，本地事务会进行回滚。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后，发送rollback给MQ，MQ会删除之前发送的半消息，也就不会继续调用下游服务了。&lt;/p&gt;
&lt;h2 id=&quot;半消息发送成功-没收到MQ返回的响应-&quot;&gt;半消息发送成功，没收到MQ返回的响应&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送半消息成功，但是没有收到MQ返回的响应，让我们系统误以为MQ消息发送失败，执行回滚逻辑。但是实际上MQ这个时候已经保存成功了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种情况下，就需要通过MQ的回查逻辑&lt;code&gt;TransactionalMessageCheckService&lt;/code&gt;定时扫描半消息队列，然后回查本地事务的状态&lt;/p&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RocketMQ实现事务消息的原理是通过改写&lt;code&gt;Topic&lt;/code&gt;和&lt;code&gt;queueId&lt;/code&gt;，将消息重写到对Consumer不可见的队列中，然后在Productor执行完本地事务之后，提交事务状态再决定将半事务消息&lt;code&gt;Commit&lt;/code&gt;或者&lt;code&gt;Rollback&lt;/code&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果由于某种情况，服务宕机或者网络抖动等原因，Broker没有收到Productor的事务状态请求，则会进入到补偿阶段，通过定时任务扫描半事务消息进行事务回查。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[高并发架构]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/高并发架构</link><guid isPermaLink="false">/topic/分布式解决方案/高并发架构</guid><category><![CDATA[分布式解决方案]]></category><pubDate>Thu, 05 May 2022 11:22:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;高并发架构&quot;&gt;高并发架构&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[The Google File System]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/三驾马车/The Google File System</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/三驾马车/The Google File System</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><category><![CDATA[三驾马车]]></category><pubDate>Thu, 05 May 2022 02:38:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;The-Google-File-System&quot;&gt;The Google File System&lt;/h1&gt;
&lt;h1 id=&quot;摘要&quot;&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS（Google File System）是由我们设计并实现的为大规模分布式数据密集型应用程序设计的可伸缩（scalable）的分布式文件系统。GFS为在廉价商用设备上运行提供了容错能力，并可以在有大量客户端的情况下提供较高的整体性能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS的设计来自于我们对我们的应用负载与技术环境的观察。虽然GFS与过去的分布式文件系统有着共同的目标，但是根据我们的观察，我们的应用负载和技术环境与过去的分布式系统所做的假设有明显的不同。这让我们重新审视了传统的选择并去探索完全不同的设计。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS很好地满足了我们的存储需求。GFS在Google被广泛地作为存储平台部署，用于生成、处理我们服务所使用的数据或用于需要大规模数据集的研发工作。到目前为止，最大的GFS集群有上千台机器、上千块磁盘，并提供了上百TB的存储能力。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在本文中，我们介绍了为支持分布式应用程序而设计的文件系统接口的扩展，还从多方面讨论了我们的设计，并给出了小批量的benchmark与在现实场景中的使用表现。&lt;/p&gt;
&lt;h1 id=&quot;1--引言&quot;&gt;1. 引言&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了满足Google快速增长的数据处理需求，我们设计并实现了GFS。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS与过去的分布式系统有着很多相同的目标，如性能（performance）、可伸缩性（scalability）、可靠性（reliability）和可用性（availability）。但是我们的设计来自于我们对我们的应用负载与技术环境的观察。这些观察反映了与过去的分布式系统所做的假设明显不同的结果。因此，我们重新审视的传统的选择并探索了完全不同的设计。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-tzwcule&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一，我们认为设备故常经常发生。GFS由成百上千台由廉价设备组成的存储节点组成，并被与其数量相当的客户端访问。设备的数量和质量决定了几乎在任何时间都会有部分设备无法正常工作，甚至部分设备无法从当前故障中分恢复。我们遇到过的问题包括：应用程序bug、操作系统bug、人为错误和硬盘、内存、插头、网络、电源等设备故障。因此，系统必须具有持续监控、错误检测、容错与自动恢复的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nq9uuai&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二，文件比传统标准更大。数GB大小的文件是十分常见的。每个文件一般包含很多引用程序使用的对象，如Web文档等。因为我们的数据集由数十亿个总计数TB的对象组成，且这个数字还在快速增长，所以管理数十亿个几KG大小的文件是非常不明智的，即使操作系统支持这种操作。因此，我们需要重新考虑像I/O操作和chunk大小等设计和参数。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ozwfdi7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第三，大部分文件会以“追加”（append）的方式变更（mutate），而非“覆写”（overwrite）。在实际场景中，几乎不存在对文件的随机写入。文件一旦被写入，即为只读的，且通常仅被顺序读取。很多数据都有这样的特征。如数据分析程序扫描的大型数据集、流式程序持续生成的数据、归档数据、由一台机器生产并同时或稍后在另一台机器上处理的数据等。鉴于这种对大文件的访问模式，追加成了为了性能优化和原子性保证的重点关注目标，而客户端中对chunk数据的缓存则不再重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ds6kyf8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第四，同时设计应用程序和文件系统API便于提高整个系统的灵活性。例如，我们放宽了GFS的一致性协议，从而大幅简化了系统，减少了应用程序的负担。我们还引入了一种在不需要额外同步操作的条件下允许多个客户端并发将数据追加到同一个文件的原子性操作。我们将在后文中讨论更多的细节。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前，我们部署了多个GFS集群并用于不同的目的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中最大的集群有超过1000个存储节点、超过300TB的磁盘存储，并被数百台客户端连续不断地访问。&lt;/p&gt;
&lt;h1 id=&quot;2--设计概述&quot;&gt;2. 设计概述&lt;/h1&gt;
&lt;h2 id=&quot;2-1-假设&quot;&gt;2.1 假设&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在设计能够满足我们需求的文件系统时，我们提出并遵循了一些挑战与机遇并存的假设。之前我们已经提到了一些，现在我们将更详细地阐述我们的假设。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mv5dudj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统有许多可能经常发生故障的廉价的商用设备组成。它必须具有持续监控自身并检测故障、容错、及时从设备故障中恢复的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ca1lolw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统存储一定数量的大文件。我们的期望是能够存储几百万个大小为100MB左右或更大的文件。系统中经常有几GB的文件，且这些文件需要被高效管理。系统同样必须支持小文件，但是不需要对其进行优化。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2908ufu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统负载主要来自两种读操作：大规模的流式读取和小规模的随机读取。在大规模的流式读取中，每次读取通常会读几百KB、1MB或更多。来自同一个客户端的连续的读操作通常会连续读文件的一个区域。小规模的随机读取通常会在文件的某个任意偏移位置读几KB。性能敏感的应用程序通常会将排序并批量进行小规模的随机读取，这样可以顺序遍历文件而不是来回遍历。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cir4w18&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统负载还来自很多对文件的大规模追加写入。一般来说，写入的规模与读取的规模相似。文件一旦被写入就几乎不会被再次修改。系统同样支持小规模随机写入，但并不需要高效执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tn4p95n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统必须良好地定义并实现多个客户端并发向同一个文件追加数据的语义。我们的文件通常在生产者-消费者队列中或多路归并中使用。来自不同机器的数百个生产者会并发地向同一个文件追加写入数据。因此，最小化原子性需要的同步开销是非常重要的。文件在被生产后可能同时或稍后被消费者读取。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-avdhjbw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;持续的高吞吐比低延迟更重要。我们的大多数应用程序更重视告诉处理大量数据，而很少有应用程序对单个读写操作有严格的响应时间的需求。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;2-2-接口&quot;&gt;2.2 接口&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管GFS没有实现像POSIX那样的标准API，但还是提供了大家较为熟悉的文件接口。文件被路径名唯一标识，并在目录中被分层组织。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS支持如:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ar1c3f8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;创建（create）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6tclx9l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;删除（delete）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jkvfknd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;打开（open）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iiuny4h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关闭（close）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p1lakfi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读（read）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jpf0jjw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写（write）文件。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，GFS还支持快照（snapshot）和追加记录（record append）操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;快照操作会以最小代价创建一个文件或一个目录树的拷贝。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;追加记录操作允许多个客户端在保证每个独立的客户端追加操作原子性的同时能够并发地向同一个文件追加数据。这对实现如多路归并、生产者-消费者队列等多个客户端不需要额外的锁即可同时向同一文件追加数据非常有益。我们发现这类文件对于构建大型分布式应用程序有极高的价值。快照和追加记录的操作将分别在章节3.4和章节3.3讨论。&lt;/p&gt;
&lt;h2 id=&quot;2-3-架构&quot;&gt;2.3 架构&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如&lt;strong&gt;图1&lt;/strong&gt;所示，一个GFS集群包括单个master（主服务器）和多个chunkserver（块服务器），并被多个client（客户端）访问。每个节点通常为一个运行着用户级服务进程的Linux主机。如果资源允许且可以接受不稳定的应用程序代码所带来的低可靠性，那么可以轻松地在一台机器上同时运行chunkserver和client。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;max-width: 1186px;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220505153537.png&quot; alt=&quot;&quot; title=&quot;图1 GFS架构图&quot; parent-style=&quot;max-width: 1186px;&quot; /&gt;&lt;span class=&quot;protyle-action__title&quot;&gt;图1 GFS架构图&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;文件被划分为若干个固定大小的chunk（块）。每个chunk被一个不可变的全局唯一的64位chunk handle（块标识符）唯一标识，chunk handle在chunk被创建时由主节点分配。chunkserver将chunk作为Linux文件存储到本地磁盘中，通过chunk handle和byte range（字节范围）来确定需要被读写的chunk和chunk中的数据。为了可靠性考虑，每个chunk会在多个chunkserver中有副本。我们默认存储三份副本，用户也可以为不同的命名空间的域指定不同的副本级别。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master维护系统所有的元数据。元数据包括命名空间（namespace）、访问控制（access control）信息、文件到chunk的映射和chunk当前的位置。master还控制系统级活动如chunk租约（chunk lease）管理、孤儿chunk垃圾回收（garbage collection of orphaned chunks）和chunkserver间的chunk迁移（migration）。master周期性地通过心跳（HeartBeat）消息与每个chunkserver通信，向其下达指令并采集其状态信息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;被链接到应用程序中的GFS client的代码实现了文件系统API并与master和chunkserver通信，代表应用程序来读写数据。进行元数据操作时，client与master交互。而所有的数据交互直接由client与chunkserver间进行。因为GFS不提供POXIS API，因此不会陷入到Linux vnode层。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无论client还是chunkserver都不需要缓存文件数据。在client中，因为大部分应用程序需要流式地处理大文件或者数据集过大以至于无法缓存，所以缓存几乎无用武之地。不使用缓存就消除了缓存一致性问题，简化了client和整个系统。（当然，client需要缓存元数据。）chunkserver中的chunk被作为本地文件存储，Linux系统已经在内存中对经常访问的数据在缓冲区缓存，因此也不需要额外地缓存文件数据。&lt;/p&gt;
&lt;h2 id=&quot;2-4-单master&quot;&gt;2.4 单master&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;采用单master节点大大简化了我们的设计，且让master可以通过全局的信息做复杂的chunk分配（chunk placement）和副本相关的决策。然而，我们必须最小化master节点在读写中的参与，以避免其成为系统瓶颈。client不会直接从master读取文件数据，而是询问master它需要与哪个chunkserver通信。client会在一定时间内缓存信息，并直接与对应的chunkserver通信以完成后续操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;让我们结合&lt;strong&gt;图1&lt;/strong&gt;来解释一个简单地“读”操作。首先，通过固定的chunk大小，client将应用程序指定的文件名和chunk偏移量翻译为该文件中的chunk index（块序号）。然后，client想master发送一个包含了文件名和chunk index的请求。master会返回其相应的chunk handle和副本所在的位置。client将这个信息以文件名和chunk index为键进行缓存。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;client接着向最有可能为最近的副本所在的chunkserver发送请求。请求中指定了chunk handle和byte range。之后，client再次读取相同的chunk时不再需要与master交互，直到缓存过期或文件被重新打开。事实上，client通常会在同一个请求中请求多个chunk，master也可以返回包含多个chunk的响应。这种方式避免了client与master进一步的通信，在几乎不需要额外开销的情况下得到更多的信息。&lt;/p&gt;
&lt;h2 id=&quot;2-5-chunk大小&quot;&gt;2.5 chunk大小&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;chunk大小是关键的设计参数之一。我们选择了64MB，其远大于通常的文件系统的块大小。每个chunk的副本被作为普通的Linux文件存储在chunkserver上，其仅在需要时扩展。懒式空间分配（lazy space allocation）避免了内部碎片（internal fragmentation）带来的空间浪费，而内部碎片可能是选择较大的chunk大小所带来的最大的不利因素。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;选择较大的chunk大小提供了很多重要的优势。第一，减少了client与master交互的次数，因为对一个chunk的读写仅需要与master通信一次以请求其位置信息。因为我们的应用程序通常连续地读写大文件，所以减少了client与master交互的次数是尤为重要的。即使对于小规模的随机读取的情况，client也可以轻松地缓存一个数TB的数据集所有的chunk位置信息。第二，因为chunk较大，client更有可能在一个chunk上执行更多的操作，这可以通过与chunkserver保持更长时间的TCP连接来减少网络开销。第三，减少了master中保存的元数据大小。我们可以将元数据保存在master的内存中，这样做提供了更多的优势，这些优势将在章节2.6.1中讨论。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然而，即使有懒式空间分配，较大的chunk大小也存在着缺点。管理仅有几个chunk的小文件就是其中之一。如果多个client访问同一个文件，那么存储这这些文件的chunkserver会成为hot spot（热点）。在实际情况相爱，因为应用程序大部分都顺序地读取包含很多chunk的大文件，所以hot spot不是主要问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然而在GFS首次被批处理队列（batch-queue）系统使用时，确实出现了hot spot问题：一个可执行文件被以单个chunk文件的形式写入了GFS，然后在数百台机器上启动。存储这个可执行程序的几台chunkserver因几百个并发的请求超载。我们通过提高这种可执行文件的副本数（replication factor）并让批处理队列系统错开应用程序启动时间的方式修复了这个问题。一个潜在的长期解决方案是在让client在这种场景下从其他client读取数据。&lt;/p&gt;
&lt;h2 id=&quot;2-6-元数据&quot;&gt;2.6 元数据&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master主要存储三种元数据：文件和chunk的命名空间（namespace）、文件到chunk的映射和chunk的每个副本的位置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有元数据被存储在master的内存中。前两种类型（文件和快的命名空间、文件到chunk的映射）还通过将变更（mutation）记录到一个操作日志（operation log）的方式持久化存储在master的磁盘上，并在远程机器上备份。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过日志，我们可以简单、可靠地更新master的状态，即使master故障也没有数据不一致的风险。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master不会持久化存储chunk的位置信息，而是在启动时和当chunkserver加入集群时向chunkserver询问其存储的chunk信息。&lt;/p&gt;
&lt;h3 id=&quot;2-6-1-内存数据结构&quot;&gt;2.6.1 内存数据结构&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为元数据被存储在内存中，master可以快速地对其进行操作。此外，在内存中存储元数据可以使master周期性扫描整个的状态变得简单高效。这种周期性的扫描被用作实现垃圾回收、chunkserver故障时重做副本、chunkserver间为了负载均衡和磁盘空间平衡的chunk迁移。章节4.3和章节4.4会进一步讨论这些活动。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种仅使用内存的方法的一个潜在问题是chunk的数量及整个系统的容量受master的内存大小限制。在实际情况中，这并不会成为一个严重的限制。master为每个64MB的chunk维护少于64字节的元数据。因为大多数文件包含多个chunk，所以大部分chunk是满的，仅最后一个chunk被部分填充。并且因为采用了前缀压缩的方式紧凑地存储文件名，每个文件的命名空间数据通常需要少于64字节。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;即使当有必要支持更大型的文件系统时，增加额外的内存的成本，远远低于通过内存存储元数据所带来的简单性、可靠性、性能和灵活性。&lt;/p&gt;
&lt;h3 id=&quot;2-6-2-chunk位置&quot;&gt;2.6.2 chunk位置&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master不会持久化保存哪台chunkserver含有给定的chunk的副本的记录，而是简单地在启动时从chunkserver获取信息。随后，master就可以保证自己的记录是最新的，因为master控制着所有chunk的分配并通过周期性的心跳消息监控chunkserver状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最初我们试图让master持久化保存chunk位置信息，但是后来我们意识到在chunkserver启动时和启动后周期性请求数据要简单的多。这样做消除了当chunkserver加入或离开集群、更改名称、故障、重启等问题时，保持master和chunkserver同步的问题。在有着数百台服务器的集群中，这些事件都会经常发生。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另一种理解这种设计的方法是，chunkserver对其磁盘上有或没有哪些chunk有着最终决定权。因为chunkserver中的错误会导致chunk消失（例如磁盘可能损坏或被禁用）或一个操作者可能重命名一个chunkserver。因此，试图在master上维护一个持久化的快位置信息视图是没有以意义的。&lt;/p&gt;
&lt;h3 id=&quot;2-6-3-操作日志&quot;&gt;2.6.3 操作日志&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;操作日志包含重要的元数据变更的历史记录。这是GFS的核心。它不仅是元数据中唯一被持久化的记录，还充当了定义并发操作顺序的逻辑时间线。带有版本号的文件和chunk都在他们被创建时由逻辑时间唯一、永久地确定。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;操作日志是GFS至关重要的部分，其必须被可靠存储，且在元数据的变更被持久化前不能让client对变更可见。否则当故障发生时，即使chunk本身没有故障，但是整个文件系统或者client最近的操作会损坏。我们将操作日志备份到多台远程主机上，且只有当当前操作记录条目被本地和远程主机均写入到了磁盘后才能向客户端发出响应。master会在操作记录被写入前批量合并一些操作记录来减少写入和备份操作对整个系统吞吐量的影响。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master通过重放（replay）操作日志来恢复其文件系统的状态。操作日志要尽可能小以减少启动时间。当日志超过一定大小时，master会对其状态创建一个检查点（checkpoint），这样master就可以从磁盘加载最后一个检查点并重放该检查点后的日志来恢复状态。检查点的结构为一个紧凑的B树（B-tree）这样它就可以在内存中被直接映射，且在查找命名空间时不需要进行额外的解析。这进一步提高了恢复速度，并增强了系统的可用性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为创建一个检查点需要一段时间，所以master被设计为可以在不推迟新到来的变更的情况下创建检查点。创建检查点时，master会切换到一个新的日志文件并在一个独立的线程中创建检查点。这个新的检查点包含了在切换前的所有变更。一个有着几百万个文件的集群可以再一分钟左右创建一个检查点。当检查点被创建完成后，它会被写入master本地和远程主机的磁盘中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;恢复仅需要最后一个完整的检查点和后续的日志文件。旧的检查点和日志文件可以随意删除，不过我们会不保留一段时间以容灾。创建检查点时发生错误不会影响日志的正确性，因为恢复代码会检测并跳过不完整的检查点。&lt;/p&gt;
&lt;h2 id=&quot;2-7-一致性模型&quot;&gt;2.7 一致性模型&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS宽松的一致性模型可以很好地支持我们的高度分布式应用程序，且实现起来简单高效。我们将讨论GFS提供的保证和其对应用程序的意义。我们也会重点讨论GFS如何维持这些保证，但会将细节留给本论文的其他部分。&lt;/p&gt;
&lt;h3 id=&quot;2-7-1-GFS提供的保证&quot;&gt;2.7.1 GFS提供的保证&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;文件命名空间的变更（例如创建文件）操作时原子性的。它们仅由master处理。命名空间锁保证了原子性和正确性（章节4.1）；master的操作日志定义了这些操作的全局总顺序（章节2.6.3）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在数据变更后，无论变更的成功与否，一个文件区域（file region）的状态都取决于变更类型。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;表1总结了变更后文件区域的状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个文件区域的任意一个副本被任何client读取总能得到相同的数据，那么这个文件区域状态为consistent（一致的）。在一个文件区域的数据变更后，如果它是一致的，且client总能看到其写入的内容，那么这个文件区域的状态为defined（确定的）（defined状态包含了consistent状态）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;文件区域在并发变更执行后的状态为consistent but undefined（一致的但非确定的）：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有客户端能考到同样的数据，但数据可能并不反映任何一个变更写入的数据。通常，数据融合了多个变更的内容。文件区域在一个失败的变更后状态会变为inconsistent（不一致的）（且undefined）：不同client在不同时刻可能看到不同的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我将描述我们的应用程序如何区分defined和undefined的区域。应用程序不需要进一步区分不同种的undefined状态。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;表1 变更后文件区域状态&lt;br /&gt;Table 1: File Region State After Mutation&lt;br /&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;write(写入)&lt;/td&gt;
&lt;td&gt;Record Append（记录追加）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;串行成功&lt;br /&gt;（Secrial success）&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;defined&lt;br /&gt;（确定的）&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;defined interspersed with inconsistent&lt;br /&gt;（确定的，但部分不一致）&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;并发成功&lt;br /&gt;（Secrial success）&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;consistent but undefined&lt;br /&gt;（一致的但非确定的）&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;失败&lt;br /&gt;（Failure）&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;inconsistent&lt;br /&gt; (不一致的)&lt;br /&gt;&lt;/td&gt;
&lt;td&gt;inconsistent（不一致的）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据变更操作可能为write或record append。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;write操作会在应用程序指定的文件与偏移处写入数据。record append会将数据至少一次（at least once）地原子性地写入文件，即使在record append的同时可能存在并发的变更，但是record append写入位置是由GFS选择的偏移量（章节3.3）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;record append的偏移量会被返回到client，这个偏移量为record append写入的数据的起始位置。除此之外，GFS可能会在记录的中间插入填充（padding）和或重复的记录。它们占用的区域状态为inconsistent的，通常情况下，它们的数量远少于用户数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在一系列变更执行成功后，被变更的文件区域状态为defined的，且该区域中包含最后一次变更写入的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这一点是GFS通过以下方式实现的：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-956fibc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对chunk执行变更时，其所有副本按照相同的顺序应用变更（章节3.1）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u8t8c2r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用chunk版本号（chunk version）来检测因chunkserver宕机而错过了变更的陈旧的chunk副本（章节4.5）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;陈旧的chunk副本永远不会在执行变更时被使用，也不会在master返回client请求的chunk的位置时被使用。它们会尽早地被作为垃圾回收。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于client会缓存chunk的位置，在缓存信息刷新前，client可能会访问陈旧的副本。这个时间窗口会受缓存过期时间和下一次打开文件限制（下一次打开文件会清除文件的所有chunk位置信息）。除此之外，由于我们大多数文件是仅追加的，陈旧的副本的通常会返回一个版本较早的结束位置处的数据，而不是陈旧的数据。当reader重试并与master通信时，它将立刻获取目前的chunk位置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;即使在变更被成功应用的很长时间后，设备故障仍然可以损坏（corrupt）会销毁（destroy）数据。GFS通过master和所有chunkserver周期性握手的方式来确定故障的chunkserver，并通过校验和（checksunmming）的方式检测数据损坏（章节5.2）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一旦出现问题，数据会尽快地从一个合法的副本恢复章节4.3）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个chunk只有在GFS作出反应前（通常在几分钟内）失去了所有的副本，chunk才会不可逆地丢失。即使在这种情况下，chunk也仅变得不可用而非损坏，因为应用程序可以收到明确的错误而非损坏的数据。&lt;/p&gt;
&lt;h3 id=&quot;2-7-2-对应用程序的影响&quot;&gt;2.7.2 对应用程序的影响&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS应用程序可以通过一些简单的技术来使用其宽松的一致性模型，且这些技术已经因其他目标而被使用，如：依赖append而不是overwrite、检查点、自验证写入（writing self-validating）、自标识记录（self-identifying records）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在实际使用中，我们所有的应用程序都通过append而不是overwrite的方式对文件进行变更。其中一个典型的引用场景是：一个write从头到尾地生成一个文件。它会周期性地为已经写入的文件数据创建检查点，并在所有数据都被写入文件后自动将其重命名为一个永久的文件名。检查点可能包含应用程序级别的校验和。reader会验证文件仅处理跟上最新的检查点的文件区域，这些区域的状态一定的“defined”的。尽管这种方法有一致性和并发问题，它仍很好地满足了我们的需求。append的效率远高于随机写入，且在应用程序故障时更容易恢复。检查点机制允许writer在重启时增量写入，并能够防止reader处理那些虽然已经被成功写入文件但是从应用程序的角度看仍然不完整的文件数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另一种典型的用途是，许多write并发地向同一个文件append数据以获得合并后的结果或文件作为生产者-消费者队列使用。record append的“至少一次追加（append-at-least-once）”语义保证了每个write的输出。而reader偶尔需要处理填充和重复的数据，如下文所述。每条被writer准备好的记录包含如校验和的额外信息，这样，记录的合法性就可被校验。一个reader通过校验和来识别并丢弃额外的填充和记录。如果rearder无法容忍偶尔发生的重复（如果重复的记录可能触发非幂等（non-idempotent）运算），它可以使用记录中的唯一标识符来对齐进行过滤。通常，在命名应用程序相关的实体时（如web文档），总会使用唯一的标识符。数据记录的I/O的充能都在库代码中（除了去重），可以被我们的应用程序使用，且其还适应于Google实现的其他文件接口。通过这些库，带有极少的重复的记录，总会被以相同顺序交付给reader。&lt;/p&gt;
&lt;h2 id=&quot;3--系统交互&quot;&gt;3. 系统交互&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们设计系统时，我们让master尽可能少地参与所有操作。在此背景下，我们将描述client、master和chunkserver如何交互来实现数据变更、原子地record append和快照操作。&lt;/p&gt;
&lt;h3 id=&quot;3-1-租约和变更顺序&quot;&gt;3.1 租约和变更顺序&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;改变chunk或元数据的操作被称为“变更”，如write或append。chunk变更时，其每个副本都会应用变更。我们使用租约（lease）来维护副本间变更顺序的一致性。master向其中一份副本授权一个变更的租约，我们称这个副本为primary。primary为应用于该chunk的所有变更选取顺序。所有副本都会按照这个顺序来应用变更。因此，全局的变更顺序首先由master选取的租约授权顺序定义，接着在租约内由primary选取的顺序编号定义。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种租约机制是为了最小化master管理负载而设计的。租约的初始超时时间为60秒。然而，一旦chunk被变更，primary就可以向master请求延长租约时间，或者（通常为）接受来自master的租约时间延长操作。这些租约延长请求和租约授权请求依赖master与chunkserver间周期性地心跳消息来实现。有时master可能会在租约过期前视图撤销租约（例如，当master想禁止对正在被重命名的文件进行变更时）。即使master与一个primary的通信丢失，master仍可以在旧租约过期后安全地向另一个副本授权新的租约。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 图2 中，我们将通过带编号的控制流来讲解一次write的流程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220505163116.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rx67xjx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;client向master询问哪个chunkserver持有指定chunk的租约及该chunk的其他副本的位置。如果没有chunkserver持有租约，那么master会选择一个副本对其授权（这一步在图中没有展示）。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9bxfijf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master回复primary副本的标识符和其他副本（也称secondary）的位置。client为后续的变更缓存这些信息。client只有当primary不可访问或primary向client回复其不再持有租约时才需要再次与master通信。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xgf4ehi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;client将数据推送到所有副本。client可以按任意顺序推送。每个chunkserver都会将数据在内部的LRU中缓存，直到数据被使用或缓存老化失效（age out）。通过将数据流和控制流解耦，我们可以使用基于网络拓扑的技术来提高开销高昂的数据流的性能，且与哪台chunkserver是primary无关。章节3.2将对此进一步讨论。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4b4hd8n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一旦所有副本都确认收到了数据，client会向primary发送一个write请求。这个请求标识了之前推送到所有副本的数据的作用。primary会为其收到的所有的变更（可能来自多个client）分配连续的编号，这一步提供了重要的顺序。primary对在本地按照该顺序应用变更。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4ipe8t6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;primary将write请求继续传递给其他secondary副本。每个secondary副本都按照primary分配的顺序来应用变更。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ib9ju42&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有的secondary副本通知primary其完成了变更操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rslial3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;primary回复client。任意副本遇到的任何错误都会被报告给client。即使错误发生，write操作可能已经在primary或secondary的任意子集中被成功执行。（如果错误在primary中发生，那么操作将不会被分配顺序，也不会被继续下发到其他副本。）只要错误发生，该请求都会被认为是失败的，且被修改的区域的状态为inconsistent。client中的代码会通过重试失败的变更来处理这种错误。首先它会重试几次步骤（3）到步骤（7），如果还没有成功，再从write请求的初始操作开始重试。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果应用程序发出的一次write请求过大或跨多个chunk，GFS的client代码会将其拆分成多个write操作。拆分后的write请求都按照上文中的控制流执行，但是可能存在与其他client的并发的请求交叉或被其他client的并发请求覆盖的情况。因此，共享的文件区域最终可能包含来自不同client的片段。但共享的文件区域中的内容最终是相同的，因为每个操作在所有副本上都会以相同的顺序被成功执行。正如章节2.7中所述，这会使文件区域变为consistent but undefined状态。&lt;/p&gt;
&lt;h2 id=&quot;3-2-数据流&quot;&gt;3.2 数据流&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了高效地利用网络，我们对数据流与控制流进行了解耦。在控制流从client向primary再向所有secondary推送的同时，数据流沿着一条精心挑选的chunkserver链以流水线的方式线性推送。我们的目标是充分利用每台机器的网络带宽，避免网络瓶颈和高延迟的链路，并最小化推送完所有数据的时延。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了充分利用机器的网络带宽，数据会沿着chunkserver链线性地推送，而不是通过其他拓扑结构（如树等）分配发送。因此，每台机器全部的出口带宽都被用来尽可能快地传输数据，而不是非给多个接受者。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了尽可能地避免网络瓶颈和高延迟的数据链路（例如，交换机间链路（inter-switch）经常同时成为网络瓶颈和高延迟链路），每台机器会将数据传递给在网络拓扑中最近的的且还没有收到数据的机器。假设client正准备将数据推送给S1 ~~ S4。client会将数据发送给最近的chunkserver，比如S1。S1会将数据传递给S2S4中离它最近的chunkserver，比如S2。同样，S2会将数据传递给S3~S4中离它最近的chunkserver，以此类推。由于我们的网络拓扑非常简单，所以可以通过IP地址来准确地估算出网络拓扑中的“距离”。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后，我们通过流水线的方式通过TCP连接传输数据，以最小化时延。当chunkserver收到一部分数据时，它会立刻开始将数据传递给其他chunkserver。因为我们使用全双工的交换网络，所以流水线可以大幅减少时延。发送数据不会减少接受数据的速度。如果没有网络拥塞，理论上将B个字节传输给R个副本所需的时间为B/T+RL，其中T是网络的吞吐量，L是两台机器间的传输时延。通常，我们的网络连接吐吞量T为100Mbps，传输时延L远小于1ms。&lt;/p&gt;
&lt;h2 id=&quot;3-3-原子性record-append&quot;&gt;3.3 原子性record append&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS提供了一种叫做record append的原子性append操作。在传统的write操作中，client会指定数据写入的偏移量。对同一个文件区域的并发write操作不是串行的，可能会导致该区域中不同段的数据来自多个cllient。然而在record append中，client仅需指定待追加的数据。GFS会为其选择一个偏移量，在该偏移量处至少一次地原子性地将数据作为一个连续的字节序列追加到文件，并将该偏移量返回给client。这很像Unix系统中，在不存在多writer并发写入带来的竞态条件下，写入以O_APPEND模式打开的文件的情况。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;record append被大量应用在我们的有多个来自不同机器的client向同一个文件并发append数据的分布式应用程序中。如果通过传统的write操作，那么client还需要额外的复杂且开销很高的同步操作（例如分布式锁管理）。这种文件在我们的工作环境下常被作为MPSC（multiple-producer/single-consumer，多生产者单消费者）队列使用，或是作为包含了来自多个client的数据合并后的结果被使用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;record append是变更的一种，也遵循章节3.1中的控制流，仅在primary端稍有点额外的逻辑。在client将数据推送到所有副本的最后一个chunk之后，client会向primary发送一个请求。primary会检查当新记录追加到该chunk之后，是否会导致该chunk超过最大的chunk大小限制（64MB）。如果会超出chunk大小限制，primary会将该chunk填充到最大的大小，并通知secondary也做相同的操作，再回复客户端，使其在下一个chunk上重试该操作。record append操作限制了每次最多写入最大chunk大小的四分之一的数据，以保证在最坏的情况下产生的碎片在可接受的范围内。在一般情况下，记录大小都在最大限制以内，这样primary会向数据追加到它的副本中，并通知secondary在与其追加的偏移量相同的位置处写入数据，并将最终成功操作的结果返回给client。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果record append操作在任何一个副本中失败，那么client会重试操作。这样会导致同一个chunk的不同副本中可能包含不同的数据，这些数据可能是同一条记录的部分或完整的副本。GFS不保证所有副本在字节级别一致，其只保证record append的数据作为一个单元被原子性地至少写入一次。这一点很容易证明，因为数据必须在某个chunk的所有副本的相同偏移位置处写入。此外，在record append之后，每个副本都至少与最后一条记录一样长。这样，任何未来的新记录都会被分配到一个更高的偏移位置或者一个新chunk，即使另一个副本成为了primary也能保证这个性质。这样，被record append操作成功写入的区域在一致性方面都将是defined状态（因此也是consistent的），而这些defined区域间的文件区域是inconsistent的（因此也是undefined的）。我们应用程序会通过章节2.7.2中讨论的方式处理inconsistent的区域。&lt;/p&gt;
&lt;h2 id=&quot;3-4-快照&quot;&gt;3.4 快照&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;快照操作几乎会在瞬间对一个文件或一个目录树（被称为源）完成拷贝，同时能够尽可能少地打断正在执行的变更。我们的用户使用快照操作来快速地对一个庞大的数据集的一个分支进行拷贝（或对其拷贝再进行拷贝等等），或者在实验前对当前状态创建检查点，这样就可以在试验后轻松地提交或回滚变更。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们使用类似AFS 的标准的写入时复制技术来实现快照。当master收到快照请求的时候，它首先会撤销快照涉及到的文件的chunk上所有未完成的租约。这确保了对这些chunk在后续的写入时都需要与master交互以查找租约的持有者。这会给master优先拷贝这些chunk的机会。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在租约被收回或过期后，master会将快照操作记录到日志中，并写入到磁盘。随后，master会通过在内存中创建一个源文件或源目录树的元数据的副本的方式来进行快照操作。新创建的快照文件与源文件指向相同的chunk。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在快照操作后，首次想要对chunk C进行write操作的client会向master发送一个请求以找到当前的租约持有者。master会检测到chunk C的引用数超过1个。master会推迟对client的响应，并选取一个新的chunk handler C′。接着，master请求每个当前持有chunk C 副本的chunkserver去创建一个新chunk C′。通过在与源chunk相同的chunkserver上创建新chunk，可以保证数据只在本地拷贝，而不会通过网络拷贝（我们的磁盘大概比100Mb的以太网连接快3倍左右）。在这之后，请求的处理逻辑就与处理任何其他chunk的请求一样了：master向新chunk C′的一个副本授权租约并将其响应client的请求。这样，client就可以像平常一样对chunk进行write操作，且client并不知道这个chunk是刚刚从一个已有的chunk创建来的。&lt;/p&gt;
&lt;h1 id=&quot;4--master操作&quot;&gt;4. master操作&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master执行所有命名空间操作。除此之外，master还管理整个系统中chunk的副本：master做chunk分配（placement）决策、创建新chunk与副本、协调各种系统范围的活动以保持chunk副本数饱和、平衡所有chunkserver的负载并回收未使用的存储。现在我们将讨论这些主题。&lt;/p&gt;
&lt;h3 id=&quot;4-1-命名空间管理与锁&quot;&gt;4.1 命名空间管理与锁&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master的很多操作可能消耗很长时间，例如：快照操作必须收回其涉及到的chunk所在的chunkserver的租约。当这些操作执行时，我们不希望推迟master的其他操作。因此，我们允许同时存在多个运行中的操作，并对命名空间的区域使用锁机制来保证操作正确地串行执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不像很多传统的文件系统，GFS没有用来记录目录中有哪些文件的数据结构。GFS也不支持对同一个文件或目录起别名（alias）（如Unix系统中的硬链接（hard link）或软链接（symbolic link））。GFS在逻辑上用一个完整路径名到元数据的查找表来表示命名空间。通过前缀压缩技术，这个查找表可在内存中高效地表示。在命名空间树上的每个节点（既可能是一个文件的绝对路径名，也可能是一个目录的绝对路径名）都有一个与之关联的读写锁（read-write lock）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master的每个操作执行前都会请求一系列的锁。通常，如果master的操作包含命名空间&lt;span data-subtype=&quot;math&quot; data-content=&quot;/d1/d2/…/dn/leaf&quot;&gt;&lt;/span&gt;，master会在目录&lt;span data-subtype=&quot;math&quot; data-content=&quot;/d1&quot;&gt;&lt;/span&gt;、&lt;span data-subtype=&quot;math&quot; data-content=&quot;/d1/d2&quot;&gt;&lt;/span&gt;，…，&lt;span data-subtype=&quot;math&quot; data-content=&quot;/d1/d2/…/dn&quot;&gt;&lt;/span&gt;上请求读取锁，并在完整路径名&lt;span data-subtype=&quot;math&quot; data-content=&quot;/d1/d2/…/dn/leaf&quot;&gt;&lt;/span&gt;上请求读取锁或写入锁。其中，&lt;span data-subtype=&quot;math&quot; data-content=&quot;leaf&quot;&gt;&lt;/span&gt;可能是文件或者目录，这取决于执行的操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在，我们将说明锁机制如何在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user&quot;&gt;&lt;/span&gt;正在被快照到&lt;span data-subtype=&quot;math&quot; data-content=&quot;/save/user&quot;&gt;&lt;/span&gt;时，防止&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user/foo&quot;&gt;&lt;/span&gt;被创建。快照操作会在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home&quot;&gt;&lt;/span&gt;和&lt;span data-subtype=&quot;math&quot; data-content=&quot;/save&quot;&gt;&lt;/span&gt;上请求读取锁、在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user&quot;&gt;&lt;/span&gt;和&lt;span data-subtype=&quot;math&quot; data-content=&quot;/save/user&quot;&gt;&lt;/span&gt;上请求写入锁。文件创建操作需要在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home&quot;&gt;&lt;/span&gt;进和&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user&quot;&gt;&lt;/span&gt;上请求读取锁，在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user/foo&quot;&gt;&lt;/span&gt;上请求写入锁。由于它们试图在&lt;span data-subtype=&quot;math&quot; data-content=&quot;/home/user&quot;&gt;&lt;/span&gt;上获取锁时发生冲突，因此这两个操作可以正确地串行执行。因为GFS中没有目录数据结果或像inode一样的数据结构，所以无需在修改时对其进行保护，因此在文件创建操作时不需要获取其父目录的写入锁。其父目录上的读取锁已经足够保护其父目录不会被删除。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种锁机制提供了一个非常好的性质：允许在同一目录下并发地执行变更。例如，在同一目录下的多个文件创建操作可以并发执行：每个文件创建操作都获取其父目录的读取锁与被创建的文件的写入锁。目录名上的读取锁足够防止其被删除、重命名或快照。文件名上的写入锁可以防止相同同名文件被创建两次。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为命名空间可能含有很多的结点，所以读写锁对象会在使用时被懒式创建，并一旦其不再被使用就会被删除。此外，为了防止死锁，锁的获取顺序总是一致的：首先按照命名空间树中的层级排序，在同一层级内按照字典顺序排序。&lt;/p&gt;
&lt;h2 id=&quot;4-2-副本分配&quot;&gt;4.2 副本分配&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS集群在多个层级上都高度分布。GFS通常有数百个跨多个机架的chunkserver。这些chunkserver可能会被来自相同或不同机架上的数百个clienet访问。在不同机架上的两台机器的通信可能会跨一个或多个交换机。另外，一个机架的出入带宽可能小于这个机架上所有机器的出入带宽之和。多层级的分布为数据的可伸缩性、可靠性和可用性带来了特有的挑战。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;chunk副本分配策略有两个目标：最大化数据可靠性和可用性、最大化网络带宽的利用。对于这两个目标，仅将副本分散在所有机器上是不够的，这样做只保证了容忍磁盘或机器故障且只充分利用了每台机器的网络带宽。我们必须在机架间分散chunk的副本。这样可以保证在一整个机架都被损坏或离线时（例如，由交换机、电源电路等共享资源问题引起的故障），chunk的一些副本仍存在并保持可用状态。除此之外，这样还使对chunk的流量（特别是读流量）能够充分利用多个机架的总带宽。而另一方面，写流量必须流经多个机架，这是我们资源做出的权衡。&lt;/p&gt;
&lt;h2 id=&quot;4-3-chunk创建-重做副本-重均衡&quot;&gt;4.3 chunk创建、重做副本、重均衡&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;chunk副本的创建可能由三个原因引起：chunk创建、重做副本（re-replication）和重均衡（rebalance）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当master创建一个chunk的时候，它会选择初始化空副本的位置。位置的选择会参考很多因素：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-pnedvbf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们希望在磁盘利用率低于平均值的chunkserver上放置副本。随着时间推移，这样将平衡chunkserver间的磁盘利用率&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-syuarwu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们希望限制每台chunkserver上最近创建的chunk的数量。尽管创建chunk本身开销很小，但是由于chunk时写入时创建的，且在我们的一次追加多次读取（append-once-read-many）的负载下chunk在写入完成后经常是只读的，所以master还要会可靠的预测即将到来的大量的写入流量。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ccwet1n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于以上讨论的因素，我们希望将chunk的副本跨机架分散。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当chunk可用的副本数少于用户设定的目标值时，master会重做副本副本。chunk副本数减少可能有很多种原因，比如：chunkserver可能变得不可用、chunkserver报告其副本被损坏、chunkserver的磁盘因为错误变得不可用、或者目标副本数增加。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个需要重做副本的chunk会参考一些因素按照优先级排序。这些因素之一是当前chunk副本数与目标副本数之差。例如，我们给失去两个副本的chunk比仅失去一个副本的chunk更高的优先级。另外，我们更倾向于优先为还存在的文件的chunk重做副本，而不是优先为最近被删除的文件重做。最后，为了最小化故障对正在运行的应用程序的影响，我们提高了所有正在阻塞client进程的chunk的优先级。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master选取优先级最高的chunk，并通过命令若干chunkserver直接从一个存在且合法的副本拷贝的方式来克隆这个chunk。新副本位置的选取与创建新chunk时位置选取的目标类似：均衡磁盘空间利用率、限制在单个chunkserver上活动的克隆操作数、在机架间分散副本。为了防止克隆操作的流量远高于client流量的情况发生，master需要对整个集群中活动的克隆操作数和每个chunkserver上活动的克隆操作数进行限制。除此之外，在克隆操作中，每个chunkserver还会限制对源chunkserver的读请求，以限制每个克隆操作占用的总带宽。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后，每隔一段时间master会对副本进行重均衡：master会检测当前的副本分布并移动副本位置，使磁盘空间和负载更加均衡。同样，在这个过程中，master会逐渐填充一个新的chunkserver，而不会立刻让来自新chunk的高负荷的写入流量压垮新的chunkserver。新副本放置位置的选择方法与我们上文中讨论过的类似。此外，master必须删除一个已有副本。通常，master会选择删除空闲磁盘空间低于平均的chunkserver上的副本，以均衡磁盘空间的使用。&lt;/p&gt;
&lt;h2 id=&quot;4-4-垃圾回收&quot;&gt;4.4 垃圾回收&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在文件被删除后，GFS不会立刻回收可用的物理存储空间。master仅在周期性执行懒式垃圾回收时回收物理存储空间，其中垃圾回收分为文件级垃圾回收和chunk级垃圾回收。我们发现这种方法可以让系统更为简单可靠。&lt;/p&gt;
&lt;h3 id=&quot;4-4-1-垃圾回收机制&quot;&gt;4.4.1 垃圾回收机制&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当一个文件被应用程序删除时，master会像执行其他操作时一样立刻将删除操作写入日志。但是master不会立刻对资源进行回收，而是将待删除的文件重命名为一个带有删除时间戳的隐藏文件名。当master周期性地扫描文件系统命名空间时，它会删除已经存在超过三天（用户可以配置这个间隔时间）的这种隐藏文件。在文件被彻底删除之前，仍可通过该文件被重命名后的特殊的新文件名对其进行访问，也可以通过将其重命名为正常文件的方式撤销删除。当隐藏文件被从命名空间中移除时，其在内存中的元数据也会被删除。这种方式可以有效地切断文件和其对应的chunk的链接。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和上文介绍的文件级垃圾回收类似，在进行chunk级垃圾回收时，master会周期性扫描chunk命名空间，并找出孤儿chunk（orphaned chunk）（例如哪些无法被任何文件访问到的chunk）并删除这些chunk的元数据。在chunkserver周期性地与master进行心跳消息交换时，chunkserver会报告其拥有的chunk的子集，而master会回复这些chunk中元数据已经不存在的chunk的标识。chunkserver可以自由地删除这些元数据已经不存在的chunk的副本。&lt;/p&gt;
&lt;h3 id=&quot;4-4-2-关于垃圾回收的讨论&quot;&gt;4.4.2 关于垃圾回收的讨论&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式系统垃圾回收通常是一个很困难的问题，其往往需要在编程时使用复杂的解决方案。但是在我们的场景下它非常简单。因为文件到chunk的映射由master专门管理，所以我们可以轻松地识别所有chunk的引用。同样，因为chunk的副本在每个chunkserver上都是Linux系统中指定目录下的文件，所以我们也可以轻松地识别所有chunk的副本。所有master中没有记录的副本都会被视为垃圾。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种暂存待回收文件的垃圾回收方法相比饿汉式回收有很多优势。第一，这种方法在设备经常出现故障的大规模可伸缩分布式系统中非常简单可靠。chunk的创建可能仅在部分chunkserver上成功而在其他chunkserver上失败，这样会导致系统中出现master不知道的副本。且副本删除消息可能会丢失，这样master在其自身和chunkserver故障时都必须重新发送该消息。垃圾回收机制为清理那些不知道是否有用的副本提供了一个统一且可靠的方法。第二，垃圾回收机制将对存储空间的回收操作合并为master的后台活动，如周期性扫描命名空间和周期性地与chunkserver握手。因此，垃圾回收机制可以分批回收存储空间并平摊回收的开销。另外，垃圾回收仅在master相对空闲时执行。这样，master可以更迅速的相应需要及时响应的来自client的请求。第三，延迟回收存储空间可以防止意外的不可逆删除操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据我们的实际经验，延迟回收的主要缺点是：当用户存储空间紧张时，延迟回收会让用户难以释放存储空间。快速创建并删除临时文件的应用程序可能无法立刻重用存储空间。为了解决这个问题，我们在用户再次显示删除已删除文件时，加快了对存储空间的回收。同时，我们允许用户对不同的命名空间应用不同的副本与回收策略。例如，用户可以指定某个目录树下的所有文件都不需要副本，且当这个目录树下的文件被删除时立刻且无法撤销地将其从文件系统中移除。&lt;/p&gt;
&lt;h2 id=&quot;4-5-陈旧副本检测&quot;&gt;4.5 陈旧副本检测&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果chunkserver因故障离线时错过了对其中的chunk的变更，那么该chunkserver中chunk的副本会变为陈旧的副本。master会为每一个chunk维护一个chunk版本号（chunk version number），用来区分最新的和陈旧的副本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master每当为一个chunk授权新租约时，都会增加chunk的版本号并同时其最新的副本。master和这些副本都持久化保存这个新版本号。这一步发生在master响应任何client前，即在chunk可以被写入前。如果一个副本当前不可用，那么这个副本的chunk版本号不会增长。这样，当这个chunkserver重启时并向master报告其包含的chunk和chunk对应的版本号时，master会检测出这个chunkserver中的副本是陈旧的。如果master收到了比它的记录中更高的chunk版本号，master会认为其授权租约失败，并将更高的版本号视为最新的版本号。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master在周期性垃圾回收时会删除陈旧的副本。即使在master回收陈旧副本之前，当client向master请求该副本的chunk时，master仍会认为该陈旧的副本不存在。另一种保护措施是，当master通知client哪个chunkserver持有指定chunk的租约时，和当master在克隆操作中命令一个chunkserver从另一个chunkserver读取chunk时，其请求中需要带有chunk的版本号。client或者chunkserver会在执行操作时验证版本号以确保其始终在操作最新的数据。&lt;/p&gt;
&lt;h1 id=&quot;5--错误容忍与诊断&quot;&gt;5. 错误容忍与诊断&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们设计GFS时，最大的挑战之一就是处理经常发生的设备故障。设备的质量和数量让故障发生不再是异常事件，而是经常发生的事。我们既无法完全信任机器，也无法完全信任磁盘。设备故障可能导致系统不可用，甚至会导致数据损坏。我们将讨论我们是如何应对这些挑战的，以及系统内建的用来诊断系统中发生的不可避免的问题的工具。&lt;/p&gt;
&lt;h2 id=&quot;5-1-高可用&quot;&gt;5.1 高可用&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在由数百台服务器组成的GFS集群中，在任意时间总会有一些服务器不可用。我们通过两个简单但有效的策略保证整个系统高可用：快速恢复和副本。&lt;/p&gt;
&lt;h3 id=&quot;5-1-1-快速恢复&quot;&gt;5.1.1 快速恢复&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在master和chunkserver的设计中，它们都会保存各自的状态，且无论它们以哪种方式终止运行，都可以在数秒内重新启动。事实上，我们并不区分正常终止和非正常的终止。通常，服务会直接被通过杀死进程的方式终止。当client和其他服务器的请求超时时，它们会在发生一个时间很短的故障，并随后重新连接到重启后的服务器并重试该请求。&lt;/p&gt;
&lt;h3 id=&quot;5-1-2-chunk副本&quot;&gt;5.1.2 chunk副本&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正如之前讨论的，每个chunk会在不同机架的多个chunkserver上存有副本。用户可以为不同命名空间的文件制定不同的副本级别。副本级别默认为3。当有chunkserver脱机或通过校验和检测到损坏的副本时，master根据需求克隆现有的副本以保证每个chunk的副本数都是饱和的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管副本策略可以很好地满足我们的需求，我们还是探索了其他形式的跨服务器的冗余策略以满足我们日益増长的只读数据存储需求，如：奇偶校验码（parity code）或擦除码（erasure code）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为我们的流量主要来自append和读操作，而不是小规模的随机写操作，所以我们希望在松散耦合的系统中，既有挑战性又要可管理地去实现这些复杂的冗余策略。&lt;/p&gt;
&lt;h3 id=&quot;5-1-3-master副本&quot;&gt;5.1.3 master副本&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证可靠性，master的状态同样有副本。master的操作日志和检查点被在多台机器上复制。只有当变更在被日志记录并被写入，master本地和所有master副本的磁盘中后，这个变更才被认为是已提交的。为了简单期间，一个master进程既要负责处理所有变更又要负责处理后台活动，如垃圾回收等从内部改变系统的活动。当master故障时，其几乎可以立刻重启。如果运行master进程的机器故障或其磁盘故障，在GFS之外的负责监控的基础架构会在其它持有master的操作日志副本的机器上启动一个新的master进程。client仅通过一个规范的命名来访问master结点（例如gfs-test），这个规范的命名是一个DNS别名，其可以在master重新被分配到另一台机器时被修改为目标机器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，“影子”master节点（“shadow” master）可以提供只读的文件系统访问，即使在主master结点脱机时它们也可以提供服务。因为这些服务器可能稍稍滞后于主master服务器（通常滞后几分之一秒），所以这些服务器是影子服务器而非镜像服务器。这些影子master服务器增强了那些非正在被变更的文件和不介意读到稍旧数据的应用程序的可用性。实际上，由于文件内容是从chunkserver上读取的，所以应用程序不会读取到陈旧的文件内容。能够在一个很短的时间窗口内被读取到的陈旧的数据只有文件元数据，如目录内容和访问控制信息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了让自己的元数据跟随主master变化，影子master服务器会持续读取不断增长的操作日志副本，并像主master一样按照相同的顺序对其数据结构应用变更。像主master一样，影子master服务器也会在启动时从chunkserver拉取数据来获取chunk副本的位置（启动后便很少拉取数据），并频繁地与chunkserver交换握手信息来监控它们的状态。只有因主master决定创建或删除副本时，影子master服务器上的副本位置才取决于主master服务器。&lt;/p&gt;
&lt;h2 id=&quot;5-2-数据完整性&quot;&gt;5.2 数据完整性&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个chunkserver都使用校验和来检测存储的数据是否损坏。由于GFS集群通常在数百台机器上有数千chunk磁盘，所以集群中经常会出现磁盘故障，从而导致数据损坏或丢失。我们可以通过chunk的其他副本来修复损坏的chunk，但不能通过比较chunkserver间的副本来检测chunk是否损坏。除此之外，即使内容不同的副本中的数据也可能都是合法的：GFS中变更的语义（特别是前文中讨论过的record append）不会保证副本完全相同。因此，每个chunkserver必须能够通过维护校验和的方式独立的验证副本中数据的完整性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个chunk被划分为64KB的block。每个block有其对应的32位校验和。就像其他元数据一样，校验和也在内存中保存且会被通过日志的方式持久化存储。校验和与用户数据是分开存储的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于读取操作，无论请求来自client还是其他chunkserver，chunkserver都会在返回任何数据前校验所有包含待读取数据的block的校验和。因此，chunkserver不会将损坏的数据传给其他机器。如果一个block中数据和记录中低的校验和不匹配，那么chunkserver会给请求者返回一个错误，并向master报告校验和不匹配。随后，请求者会从其他副本读取数据，而master会从该chunk的其他副本克隆这个chunk。当该chunk新的合法的副本被安置后，master会通知报告了校验和不匹配的chunkserver删除那份损坏的副本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;校验和对读取性能的影响很小。因为我们的大部分读操作至少会读跨几个block的内容，我们只需要读取并校验相对少量的额外数据。GFS客户端代码通过尝试将读取的数据与需要校验的block边界对其的方式，进一步地减小了校验开销。除此之外，chunkserver上校验和的查找与比较不需要I/O操作，且校验和计算操作经常与其他操作在I/O上重叠，因此几乎不存在额外的I/O开销。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为向chunk末尾append数据的操作在我们的工作负载中占主要地位，所以我们对这种写入场景的校验和计算做了大量优化。在append操作时，我们仅增量更新上一个block剩余部分的校验和，并为append的新block计算新校验和。即使最后一个block已经损坏且目前没被检测到，增量更新后的该block的新校验和也不会与block中存储的数据匹配。在下一次读取该block时，GFS会像往常一样检测到数据损坏。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相反，如果write操作覆盖了一个chunk已存在的范围，那么我们必须读取并验证这个范围的头一个和最后一个block，再执行write操作，最后计算并记录新的校验和。如果我们没有在写入前校验头一个和最后一个block，新的校验和可能会掩盖这两个block中没被覆写的区域中存在的数据损坏问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;chunkserver可以在空闲期间扫描并验证非活动的chunk的内容。这样可以让我们检测到很少被读取的chunk中的数据损坏。一旦检测到数据损坏，master可以创建一个新的未损坏的副本并删除损坏的副本。这样可以防止master将chunk的非活动的但是已损坏的副本识别成数据合法的副本。&lt;/p&gt;
&lt;h2 id=&quot;5-3-诊断工具&quot;&gt;5.3 诊断工具&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;全面且详细的诊断日志以极小的开销为问题定位、调试和性能分析提供了很大的帮助。如果没有日志，理解机器间短暂且不重复的交互将变得非常困难。GFS服务器会生成用来记录重要事件（如chunkserver上线或离线）和所有RPC请求与响应的诊断日志。这些诊断日志可以随意删除，不会影响到系统正确性。不过，如果磁盘空间允许，我们将尽可能地保持这些日志。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RPC日志包括通过网络收发的请求和响应中除读写的文件数据之外的详细内容。在诊断问题时，我们可以通过整合不同机器中的日志并将请求与响应匹配的方式，重建整个交互历史。同样，这些日志也可用来跟踪压力测试、性能分析等情况。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为日志是顺序且异步写入的，因此日志对性能的影响非常小，并带来了很大的好处。其中最近的事件也会在内存中保存，以便在持续的在线监控中使用。&lt;/p&gt;
&lt;h1 id=&quot;6--性能测试&quot;&gt;6. 性能测试&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在本章中，我们将展示一些小批量的benchmark，以说明在GFS架构和实现中的瓶颈。我们还将展示一些Google在真是集群中使用时的一些指标。&lt;/p&gt;
&lt;h2 id=&quot;6-1-小批量benchmark&quot;&gt;6.1 小批量benchmark&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在一个由1个master、2个master副本、16个chunkserver和16个client组成的GFS集群中测量性能表现。该配置的选择仅为了便于测试。通常一个GFS集群会由数百个chunkserver和数百个client组成。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有的机器都采用双核1.4GHz的奔腾III处理器、2GB内存、两块5400转的80GB磁盘和100Mbpc全双工以太网，并连接到一台HP2524交换机。其中所有的19台GFS服务器都连接到同一台交换机，所有的16台client机器都连接到另一台交换机。这两个交换机之间通过1Gbps连接。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;max-width: 1186px;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220505165824.png&quot; alt=&quot;&quot; title=&quot;图3 总吞吐量（上面的曲线表示在网络拓扑中的理论极限。下面的曲线表示测量到的吞吐量。测量结果曲线显示了95%置信区间的误差柱，在一些情况下，由于测量值的方差很低，置信区间在图中难以辨认。&quot; parent-style=&quot;max-width: 1186px;&quot; /&gt;&lt;span class=&quot;protyle-action__title&quot;&gt;图3 总吞吐量（上面的曲线表示在网络拓扑中的理论极限。下面的曲线表示测量到的吞吐量。测量结果曲线显示了95%置信区间的误差柱，在一些情况下，由于测量值的方差很低，置信区间在图中难以辨认。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;6-1-1-read操作&quot;&gt;6.1.1 read操作&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;个client同时从GFS读取数据。每个client从320GB的数据集中随机选取4MB的区域读取。读操作将重复256次，即每个client最终将读取1GB的数据。chunkserver总计有32GB内存，因此我们预测读操作中最多10%命中Linux缓冲区缓存。我们的测试结果应该接近冷缓存的结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图3(a)&lt;/strong&gt;展示了&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;个client的总读取速率和理论速率上限。整体的理论速率在&lt;span data-subtype=&quot;math&quot; data-content=&quot;125MB/s&quot;&gt;&lt;/span&gt;时达到峰值，此时两个交换机间的&lt;span data-subtype=&quot;math&quot; data-content=&quot;1Gbps&quot;&gt;&lt;/span&gt;的链路达到饱和；或者每个client的理论速率在&lt;span data-subtype=&quot;math&quot; data-content=&quot;12.5MB/s&quot;&gt;&lt;/span&gt;时达到峰值，此时它的&lt;span data-subtype=&quot;math&quot; data-content=&quot;100Mbps&quot;&gt;&lt;/span&gt;的网络接口达到饱和。当仅有一台client在读取时，我们观测到其读取速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;10MB/s&quot;&gt;&lt;/span&gt;，在每台client理论上限的80%。当16个client一起读取时，总读取速率达到了&lt;span data-subtype=&quot;math&quot; data-content=&quot;94MB/s&quot;&gt;&lt;/span&gt;，大致达到了理论上限&lt;span data-subtype=&quot;math&quot; data-content=&quot;125MB/s&quot;&gt;&lt;/span&gt;的75%，平均每个client的读取速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;6MB/s&quot;&gt;&lt;/span&gt;。因为reader的数量增加导致多个reader从同一个chunkserver读取的概率增加，所以读取速率从理论值的80%下降到了75%。&lt;/p&gt;
&lt;h3 id=&quot;6-1-2-write操作&quot;&gt;6.1.2 write操作&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;N个client同时向&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;个不同的文件写入。每个client通过一系列的&lt;span data-subtype=&quot;math&quot; data-content=&quot;1MB&quot;&gt;&lt;/span&gt;的写操作向一个新文件写入总计&lt;span data-subtype=&quot;math&quot; data-content=&quot;1GB&quot;&gt;&lt;/span&gt;数据。&lt;strong&gt;图3(b)&lt;/strong&gt;展示了整体的写入速率和理论速率上限。因为我们需要将每个字节写入16个chunkserver中的三个，每个chunkserver的连接输入速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;12.5MB/s&quot;&gt;&lt;/span&gt;，所以整体的理论写入速率上限为&lt;span data-subtype=&quot;math&quot; data-content=&quot;67MB/s&quot;&gt;&lt;/span&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实验观测到的每个client的写入速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;6.3MB/s&quot;&gt;&lt;/span&gt;，大概是理论上限的一半。网络栈是造成这一现象的罪魁祸首。在我们使用流水线的方式将数据推送到chunk副本时，网络栈的表现不是很好。数据从一个副本传递给另一个副本的时延降低了整体的写入速率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;16个client的整体写入速率达到了&lt;span data-subtype=&quot;math&quot; data-content=&quot;35MB/s&quot;&gt;&lt;/span&gt;，大概是理论上限的一半。与读取相同，当client的数量增加时，更有可能出现多个client并发地向同一个chunkserver写入的情况。此外，因为write操作需要向3份不同的副本写入，所以16个writer比16个reader更有可能出现碰撞的情况。write操作比我们预想的要慢。但是在实际环境中，这并不是主要问题。即使它增加了单个client的时延，但是在有大量client的情况下它并没有显著影响系统的整体写入带宽。&lt;/p&gt;
&lt;h3 id=&quot;6-1-3-record-append操作&quot;&gt;6.1.3 record append操作&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图3(c)&lt;/strong&gt;展示了record append操作的性能表现。&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;个client同时向同一个文件append数据。其性能受存储该文件最后一个chunk的chunkserver的网络带宽限制，与client的数量无关。当仅有1个client时，record append的速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;6.0MB/s&quot;&gt;&lt;/span&gt;，当client的数量增加到16个时，速率下降到&lt;span data-subtype=&quot;math&quot; data-content=&quot;4.8MB/s&quot;&gt;&lt;/span&gt;。网络拥塞和不同client的网络传输速率不同是造成record append速率下降的主要原因。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在实际环境中，我们的应用程序往往会并发地向多个这样的文件追加数据。换句话说，即&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;个client同时地向&lt;span data-subtype=&quot;math&quot; data-content=&quot;M&quot;&gt;&lt;/span&gt;个共享的文件append数据，其中&lt;span data-subtype=&quot;math&quot; data-content=&quot;N&quot;&gt;&lt;/span&gt;与&lt;span data-subtype=&quot;math&quot; data-content=&quot;M&quot;&gt;&lt;/span&gt;均为数十或数百。因此，实验中出现的chunkserver的网络拥塞在实际环境中并不是大问题，因个client可以在chunkserver忙着处理一个文件时向另一个文件写入数据。&lt;/p&gt;
&lt;h2 id=&quot;6-2-现实中的集群&quot;&gt;6.2 现实中的集群&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在我们来考察在Google中使用的两个集群，它们代表了其他类似的集群。集群A是数百个工程师常用来研究或开发的集群。其中典型的任务由人启动并运行几个小时。这些任务会读几MB到几TB的数据，对其分析处理，并将结果写回到集群中。集群B主要用于生产数据的处理。其中的任务持续时间更长，会不断地生成数TB的数据集，且偶尔才会有人工干预。在这两种情况中，每个任务都有许多过程进程组成，这些进程包括许多机器对许多文件同时的读写操作。&lt;/p&gt;
&lt;h3 id=&quot;6-2-1-存储&quot;&gt;6.2.1 存储&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正如表2所示，两个集群都有数百个chunkserver，有数TB的磁盘存储空间，且大部分存储空间都被使用，但还没满。其中“已使用空间”包括所有chunk的副本占用的空间。几乎所有文件都以3份副本存储。因此，集群分别存储了&lt;span data-subtype=&quot;math&quot; data-content=&quot;18TB&quot;&gt;&lt;/span&gt;和&lt;span data-subtype=&quot;math&quot; data-content=&quot;52TB&quot;&gt;&lt;/span&gt;的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这两个集群中的文件数相似，但集群B中停用文件（dead file）比例更大。停用文件即为被删除或被新副本替换后还未被回收其存储空间的文件。同样，集群B中chunk数量更多，因为其中文件一般更大。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;表2 两个GFS集群的特征&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;集群&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;A&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;Chunkserver数量&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;342&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;227&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;可用磁盘空间&lt;br /&gt;已使用空间&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;72 TB&lt;br /&gt;55 TB&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;180 TB&lt;br /&gt;155 TB&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;文件数&lt;br /&gt;停用文件数&lt;br /&gt;chunk数&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;735 k&lt;br /&gt;22 k&lt;br /&gt;992 k&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;737 k&lt;br /&gt;232 k&lt;br /&gt;1550 k&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;chunkserver元数据大小&lt;br /&gt;master元数据大小&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;13 GB&lt;br /&gt;48 MB&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;21 GB&lt;br /&gt;60 MB&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;6-2-2-元数据&quot;&gt;6.2.2 元数据&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在chunkserver中，总共存储了数十GB的元数据，其中大部分是用户数据的每64KB大小的block的校验和。除此之外，chunkserver中的保存元数据只有章节4.5中讨论的chunk版本号。大部分的文件元数据是文件名，我们对其采用前缀压缩的形式存储。其他的文件元数据包括文件所有权和权限、文件到chunk的映射、每个chunk当前的版本号。除此之外，我们还存储了chunk当前的副本位置和chunk的引用计数（以实现写入时拷贝等）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无论是chunkserver还是master，每个服务器中仅有50MB到100MB元数据。因此，服务器恢复的速度很快。服务器只需要几秒钟的时间从磁盘读取元数据，随后就能应答查询请求。然而，master的恢复稍微有些慢，其通常需要30到60秒才能恢复，因为master需要从所有的chunkserver获取chunk的位置信息。&lt;/p&gt;
&lt;h3 id=&quot;6-2-3-读写速率&quot;&gt;6.2.3 读写速率&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;表3&lt;/strong&gt;展示了不同时间段的读写速率。两个集群在测量开始后均运行了大概一周的时间。（集群最近已因升级到新版本的GFS而重启过。）&lt;br /&gt;
从重启后，集群的平均写入速率小于&lt;span data-subtype=&quot;math&quot; data-content=&quot;30MB/s&quot;&gt;&lt;/span&gt;。当我们测量时，集群B正在执行以大概&lt;span data-subtype=&quot;math&quot; data-content=&quot;100MB/s&quot;&gt;&lt;/span&gt;写入生成的数据的活动，因为需要将数据传递给三份副本，该活动造成了&lt;span data-subtype=&quot;math&quot; data-content=&quot;300MB/s&quot;&gt;&lt;/span&gt;的网络负载。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读操作的速率比写操作的速率要高得多。正如我们假设的那样，整体负载主要有读操作组成而非写操作。在测量时两个集群都在执行高负荷的读操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实际上，集群A已经维持&lt;span data-subtype=&quot;math&quot; data-content=&quot;580MB/s&quot;&gt;&lt;/span&gt;的读操作一周了。集群A的网络配置能够支持&lt;span data-subtype=&quot;math&quot; data-content=&quot;750MB/s&quot;&gt;&lt;/span&gt;的读操作，所以集群A在高效利用其资源。集群B能够支持峰值在&lt;span data-subtype=&quot;math&quot; data-content=&quot;1300MB/s&quot;&gt;&lt;/span&gt;的读操作，但集群B的应用程序仅使用了&lt;span data-subtype=&quot;math&quot; data-content=&quot;380MB/s&quot;&gt;&lt;/span&gt;。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;表3 两个GFS集群的性能指标&lt;br /&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;集群&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;A&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;读速率（过去一分钟）&lt;br /&gt;读速率（过去一小时）&lt;br /&gt;读速率（重启后至今）&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;583 MB/s&lt;br /&gt;562 MB/s&lt;br /&gt;589 MB/s&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;380 MB/s&lt;br /&gt;384 MB/s&lt;br /&gt;49 MB/s&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;写速率（过去一分钟）&lt;br /&gt;写速率（过去一小时）&lt;br /&gt;写速率（重启后至今）&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1 MB/s&lt;br /&gt;2 MB/s&lt;br /&gt;25 MB/s&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;101 MB/s&lt;br /&gt;117 MB/s&lt;br /&gt;13 MB/s&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;master操作数（过去一分钟）&lt;br /&gt;master操作数（过去一小时）&lt;br /&gt;master操作数（重启后至今）&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;325 Ops/s&lt;br /&gt;381 Ops/s&lt;br /&gt;202 Ops/s&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;533 Ops/s&lt;br /&gt;518 Ops/s&lt;br /&gt;347 Ops/s&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;6-2-4-master的负载&quot;&gt;6.2.4 master的负载&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;表3&lt;/strong&gt;中还展示了向master发送操作指令的速率，该速率大概在美妙200到500次左右。master可以在该速率下轻松地工作，因此这不会成为负载的瓶颈。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS在早期版本中，在某些负载场景下，master偶尔会成为瓶颈。当时master会消耗大量的时间来扫描包含成百上千个文件的目录以寻找指定文件。在那之后，我们修改了master中的数据结构，允许其通过二分查找的方式高效地搜索命名空间。目前，master已经可以轻松地支持每秒上千次的文件访问。如果有必要，我们还可以通过在命名空间数据结构前放置名称缓存的方式进一步加快速度。&lt;/p&gt;
&lt;h3 id=&quot;6-2-5-恢复时间&quot;&gt;6.2.5 恢复时间&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当chunkserver故障后，一些chunk的副本数会变得不饱和，系统必须克隆这些块的副本以使副本数重新饱和。恢复所有chunk需要的时间取决于资源的数量。在一次实验中，我们杀掉集群B中的一个chunkserver。该chunkserver上有大概15000个chunk，总计约600GB的数据。为了限制重分配副本对正在运行的应用程序的影响并提供更灵活的调度策略，我们的默认参数限制了集群中只能有91个并发的克隆操作（该值为集群中chunkserver数量的40%）。其中，每个克隆操作的速率上限为&lt;span data-subtype=&quot;math&quot; data-content=&quot;6.25MB/s&quot;&gt;&lt;/span&gt;（&lt;span data-subtype=&quot;math&quot; data-content=&quot;50Mbps&quot;&gt;&lt;/span&gt;）。所有的chunk在23.2分钟内完成恢复，有效地复制速率为&lt;span data-subtype=&quot;math&quot; data-content=&quot;440MB/s&quot;&gt;&lt;/span&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在另一个实验中，我们杀掉了两台均包含16000个chunk和660GB数据的chunkserver。这两个chunkserver的故障导致了266个chunk仅剩一分副本。这266个块在克隆时有着更高的优先级，在2分钟内即恢复到至少两份副本的状态，此时可以保证集群中即使再有一台chunkserver故障也不会发生数据丢失。&lt;/p&gt;
&lt;h2 id=&quot;6-3-负载分解&quot;&gt;6.3 负载分解&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在本节中，我们将详细介绍两个GFS集群中的工作负载。这两个集群与章节6.2中的类似但并不完全相同。集群X用来研究和开发，集群Y用来处理生产数据。&lt;/p&gt;
&lt;h3 id=&quot;6-3-1-方法和注意事项&quot;&gt;6.3.1 方法和注意事项&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这些实验结果仅包含来自client的请求，因此结果反映了我们的应用程序为整个文件系统带来的负载情况。结果中不包括用来处理client请求的内部请求和内部的后台活动，如chunkserver间传递write数据和副本重分配等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;I/O操作的统计数据来源于GFS通过RPC请求日志启发式重建得到的信息。例如，GFS的client代码可能将一个read操作分解为多个RPC请求以提高并行性，通过日志启发式重建后，我们可以推断出原read操作。因为我们的访问模式是高度一致化的，所以我们期望的错误都在数据噪声中。应用程序中显式的日志可能会提供更加准确的数据，但是重新编译并重启上千个正在运行的client是现实的，且从上千台机器上采集数据结果也非常困难。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要注意的一点是，不要过度地推广我们的负载情况。因为Google对GFS和它的应用程序具有绝对的控制权，所以应用程序会面向GFS优化，而GFS也正是为这些应用程序设计的。虽然这种应用程序与文件系统间的互相影响在一般情况下也存在，但是这种影响在我们的例子中可能会更明显。&lt;/p&gt;
&lt;h3 id=&quot;6-3-2-chunkserver的负载&quot;&gt;6.3.2 chunkserver的负载&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;表4&lt;/strong&gt;展示了各种大小的操作占比。读操作的大小呈双峰分布。64KB以下的小规模read来自client从大文件查找小片数据的seek密集操作。超过512KB的大规模read来自读取整个文件的线性读取。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在集群Y中，大量的read没有返回任何数据。在我们的应用程序中（特别是生产系统中的应用程序），经常将文件作为生产者-消费者队列使用。在多个生产者并发地向同一个文件支架数据的同时，会有一个消费者读末尾的数据。偶尔当消费者超过生产者时，read即不会返回数据。集群X中这种情况出现的较少，因为在集群X中的应用程序通常为短期运行的数据分析程序，而非长期运行的分布式应用程序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;write也呈同样的双峰分布。超过256KB的大规模write操作通常是由writer中的大量的缓冲区造成的。小于64KB的小规模写操作通常来自于那些缓冲区小、创建检查点操作或者同步操作更频繁、或者是仅生成少量数据的writer。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于record append操作，集群Y中大规模的record append操作比集群X中要高很多。因为我们的生产系统使用了集群Y，生产系统的应用程序会更激进地面向GFS优化。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;表4 各种大小的操作占比（%）&lt;br /&gt;对于read操作，数据大小为实际读取和传输的数据大小，而非请求读取的总大小。&lt;br /&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;操作类型&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;read&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;write&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;record append&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;集群&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.6&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1B...1K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.6&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1K...8K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;65.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;38.5&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;18.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;15.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8K...64K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;29.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;45.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;17.8&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;43.0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;78.0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64K...128K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128K...256K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;31.6&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;10.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;256K...512K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;31.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512K...1M&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;35.5&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;28.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;25.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1M...inf&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.8&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.5&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;12.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;表5&lt;/strong&gt;中展示了不同大小的操作中传输数据的总量的占比。对于所有类型的操作，超过256KB的大规模操作通常都是字节传输导致的。小于64KB的小规模read操作通常来自seek操作，这些读操作传输了很小但很重要的数据。&lt;/p&gt;
&lt;h3 id=&quot;6-3-3-append-vs-write&quot;&gt;6.3.3 append vs write&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;record append操作在我们的系统中被大量使用，尤其是我们的生产系统。在集群X中，write操作和record append操作的操作次数比例为8:1，字节传输比例为108:1。在集群Y中，这二者的比例分别为2.5:1和3.7:1。这些数据显示了对于两个集群来说，record append操作的规模通常比write打。然而。在集群X中，测量期间record append的使用量非常的少。因此。这个测量结果可能受一两个有特定缓冲区大小的应用程序影响较大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正如我们预期的那样，我们的数据变更负载主要来自于append而非overwrite。我们测量了primary副本上overwrite的数据总量。测量值很接近client故意overwrite数据而不append的情况。对于集群X，overwrite的操作总量低于变更操作的0.0003%，字节数占比低于总量的0.0001%。对于集群Y，这两个数据均为0.05%。尽管这个比例已经很小了，但仍比我们预期的要高。大部分的overwrite都是由client因错误或超时而重试造成的。这本质上是由重试机制造成的而非工作负载。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;表5 各种大小的操作字节传输量占比（%）&lt;br /&gt;对于read操作，数据大小为实际读取和传输的数据大小，而非请求读取的总大小。二者的区别为，读取请求可能会试图读取超过文件末尾的内容。在我们的设计中，这不是常见的负载。&lt;br /&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;操作类型&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;read&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;write&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;record append&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;集群&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1B...1K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1K...8K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;13.8&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8K...64K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;11.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;9.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;5.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64K...128K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;22.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128K...256K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.8&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.6&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;16.5&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;5.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;256K...512K&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&amp;lt;0.1&lt;br /&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;38.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512K...1M&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;65.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;55.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;74.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;58.0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;46.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1M...inf&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;30.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;28.0&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;53.9&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7.4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;6-3-4-master的负载&quot;&gt;6.3.4 master的负载&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;表6&lt;/strong&gt;展示了对master的各种类型的请求占比。其中，大部分请求来自read操作询问chunk位置的请求（FindLocation）和数据变更操作询问租约持有者（FindLeaseLocker）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;集群X与集群Y中Delete请求量差异很大，因为集群Y存储被经常重新生成或者移动的生产数据。一些Delete请求量的差异还隐藏在Open请求中，因为打开并从头写入文件时（Unix中以“w”模式打开文件），会隐式地删除旧版本的文件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;FindMatchingFiles是用来支持“ls”或类似文件系统操作的模式匹配请求。不像给master的其他请求，FindMatchingFiles请求可能处理很大一部分命名空间，因此这种请求开销很高。在集群Y中，这种请求更加频繁，因为自动化的数据处理任务常通过检查部分文件系统的方式来了解应用程序的全局状态。相反，使用集群X的应用程序会被用户更明确地控制，通常会提交知道所需的文件名。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;表6 master请求类型占比（%）&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;集群&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Open&lt;/td&gt;
&lt;td&gt;26.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;16.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Delete&lt;/td&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FindLocation&lt;/td&gt;
&lt;td&gt;64.3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;65.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FindLeaseHolder&lt;/td&gt;
&lt;td&gt;7.8&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;13.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FindMatchingFiles&lt;/td&gt;
&lt;td&gt;0.6&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;All order combined&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;7--开发经历&quot;&gt;7. 开发经历&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在构建和部署GFS的过程中，我们经历了很多问题。其中，有些是操作问题，有些是技术问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最初，GFS的构思是将其作为我们生产系统的后端文件系统。随着时间推移，GFS的用途演变为包括了研究和开发任务。GFS开始时几乎不支持权限、配额之类的功能，但现在这些功能都变为GFS包含的基本功能。虽然生产系统有着良好的纪律并被良好地控制着，但用户有时却没有。因此，其需要更多的基础设施来防止用户互相干扰。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们最大的一些问题是磁盘问题和Linux相关问题。我们的许多磁盘都想Linux驱动程序声称它们支持很多版本的IDE（译注：本文IDE指集成设备电路Intergated Drive Electronics）协议，但事实上，它们可能只能可靠地响应最近几个版本的协议。因为这些协议都非常相似，所以大部分时间驱动器都能正常工作。但协议版本偶尔不匹配就会导致驱动器和内核中所认为的驱动器的状态不一致。由于内核中的问题，数据会无法察觉地损坏。这个问题驱动我们通过校验和的方式检测数据是否损坏，同时我们修改了内核去处理协议不匹配的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;早些时候，由于&lt;em&gt;fsync()&lt;/em&gt;的开销，我们在Linux2.2内核中遇到了一些问题。这个函数的开销和文件成正比，而不是和修改的部分大小成正比。这对我们使用较大的操作日志造成了问题（特别是在我们实现检查点机制以前）。我们曾经通过同步写入的方式来解决这个问题，直到迁移到Linux2.4。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另一个Linux的问题是一个读写锁。当任何地址空间的线程从磁盘换入页（读锁）或者通过&lt;em&gt;mmap()&lt;/em&gt;函数修改地址空间（写锁）时，都必须持有这一个读写锁。我们发现系统在轻负载下的一个瞬间会出现超时问题，所以我们努力地去寻找资源瓶颈和零星的硬件故障。最终，我们发现在磁盘线程正在换入之前映射的文件时，这个读写锁阻塞了网络主线程，导致其无法将新数据映射到内存。因为我们主要受网络接口限制而非受内存拷贝带宽限制，所以我们用&lt;em&gt;pread()&lt;/em&gt;替换了&lt;em&gt;mmap()&lt;/em&gt;函数，其代价是多了一次额外的拷贝操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管偶尔会有问题发生，Linux代码的可用性还是帮助了我们一次又一次地探索和理解系统行为。当时机合适时，我们会改进内核并将这些改进与开源社区分享。&lt;/p&gt;
&lt;h1 id=&quot;8--相关工作&quot;&gt;8. 相关工作&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就像其他大型的分布式文件系统一样（如AFS &lt;sup&gt;[5]&lt;/sup&gt; ），GFS提供了与位置无关的命名空间，这可以允许数据为了负载均衡和容错地移动，这一操作对client是透明的。但与AFS不同，GFS将文件数据通过类似xFS &lt;sup&gt;[1]&lt;/sup&gt; 和Swtift &lt;sup&gt;[3]&lt;/sup&gt; 的方式分散到了存储服务器上，以释放集群整体性能并提高容错能力。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为磁盘相对廉价且副本的方式比复杂的RAID &lt;sup&gt;[9]&lt;/sup&gt; 的方式简单很多，所以GFS仅通过副本的方式作为冗余，因此GFS会比xFS或Swift消耗更多的原始存储空间。与类似AFS、xFS、Frangipani &lt;sup&gt;[12]&lt;/sup&gt; 和Intermezzo &lt;sup&gt;[6]&lt;/sup&gt; 的文件系统不同，GFS在系文件系统接口下没有提供任何的缓存。在我们的目标工作负载中，一个应用程序几乎不会重用数据，因为其或者流式地处理一个大型数据集，或者每次仅在大型数据及中随机地seek并读取很小一部分的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一些分布式文件系统移除了集中式的服务器，并依赖分布式算法来实现一致性和管理，如Frangipani、xFS、Minnesota’s GFS &lt;sup&gt;[11]&lt;/sup&gt; 和GPFS &lt;sup&gt;[10]&lt;/sup&gt; 。我们选择了集中式的方法来简化设计、增强可靠性，同时还获得了灵活性。集中式的master还大大简化了复杂的chunk分配操作和重分配副本的策略，因为master已经有了大部分相关信息，且由master来控制如何变化。我们通过保持master的状态大小很小并在其他机器上有充足的副本的方式来提高容错能力。可伸缩性和高可用性（对于read操作来说）目前通过影子master服务器机制提供。master状态的变化会通过追加到预写日志的方式进行持久化。因此我们可以通过适配像Harp &lt;sup&gt;[7]&lt;/sup&gt; 中的主拷贝模式（primary-copy scheme）的方法，来提供比当前的一致性有更强保证的高可用性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们遇到了一个类似Lustre &lt;sup&gt;[8]&lt;/sup&gt; 的问题，即为大量client提供整体的性能。然而，我们通过将重点放在我们的应用程序的需求而不是构架一个兼容POSIX文件系统的方式，大幅简化了这个问题。除此之外，GFS假设大量的设备是不可靠的，因此容错是我们设计中的中心问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS非常接近NASD架构 &lt;sup&gt;[4]&lt;/sup&gt; 。NASD架构基于通过网络连接的磁盘驱动器，而GFS使用一般的商用机器作为chunkserver，就像NASD的原型那样。与NASD不同是，我们的chunkserver懒式分配固定大小的chunk，而不是可变长的对象。另外，GFS实现了如负载均衡、副本重分配和恢复等在生产环境中需要的特性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与Minnesota’s GFS或NASD不同，我们不希望改变存储设备的模型。我们着重解决由已有的商用设备组成的复杂的分布式系统的日常数据处理问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对生产者-消费者队列的原子性record append操作解决了类似于River的分布式队列问题。River &lt;sup&gt;[2]&lt;/sup&gt; 使用了分布在不同机器上的基于内存的队列和谨慎的数据流控制，而GFS采用了可以被多个生产者并发追加的持久化文件。River的模型支持M:N的分布式队列，但缺少持久化存储带来的容错能力。而GFS仅支持M:1的高效的队列。多个消费者可一个读相同的文件，但必须相互协调载入的分区。&lt;/p&gt;
&lt;h1 id=&quot;9--结论&quot;&gt;9. 结论&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Google File System论证了在产品级硬件上支持大规模数据处理负载的必要特性。虽然很多设计是为我们特殊的场景定制的，但很多设计可能适用于规模和预算相似的数据处理任务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们根据我们当前和预期的应用程序负载和技术环境，重新考察了传统文件系统设计中的假设。我们的考察结果指向了完全不同的设计。我们视设备故障为平常事件而非异常事件。我们优化了大部分操作为追加（可能是并发追加）和读取（通常为顺序读取）的大文件。我们还扩展并放宽了标准文件系统接口来改进整个系统。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的系统通过持续的监控、备份关键数据、自动且快速的恢复来提供容错能力。chunk副本让我们能够容忍chunkserver故障。这些故障的频率让我们设计了一种新的在线修复机制：周期性地对client不可见的修复损坏数据，并尽快补充丢失的副本。另外，我们通过校验和的方式来检测磁盘或IDE子系统级别的数据损坏，因为GFS系统中磁盘数量很多，这类问题是非常普遍的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的设计为并发执行多种任务的reader和writer提供了很高的整体吞吐量。为了实现这一点，我们将通过master进行的文件系统控制和通过chunkserver、client的数据传输分离开来。我们还通过选取较大的chunk大小和chunk租约（将数据变更授权给primary副本）的方式最小化了master对一般操作的参与度。这种方式让master变得简单，且中心化的master不会成为系统瓶颈。我们相信，通过改进网络栈，会减少当前对单个client的写入吞吐量的限制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;GFS成功地满足了我们的存储需求，并已经在Google内部作为研究、开发和生产数据处理的存储平台使用。GFS是让我们能够进一步创新并攻克web规模问题的重要工具。&lt;/p&gt;
&lt;h1 id=&quot;致谢&quot;&gt;致谢&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;感谢以下对本系统或本论文做出了贡献的人。Brain Bershad（我们的指导者）和给我我们珍贵的评论和建议的匿名评审员。Anurag Acharya、Jeff Dean和David Desjardins为系统的早期设计做出了贡献。Fay Chang致力于chunkserver间副本比较的研究。Guy Edjlali致力于存储配额的研究。Markus Gutschke致力于测试框架与安全性增强的研究。Fay Chang、Urs Hoelzle、Max Ibel、Sharon Perl、Rob Pike和Debby Wallach对本论文早期的草稿做出了评论。我们在Google的许多勇敢的同事，他们信任这个新文件系统并给我们提出了很多很有用的反馈。Yoshka在早期的测试中提供了帮助。&lt;/p&gt;
&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[1] Thomas Anderson, Michael Dahlin, Jeanna Neefe, David Patterson, Drew Roselli, and Randolph Wang. Serverless networkfile systems. In Proceedings of the 15th ACM Symposium on Operating System Principles, pages 109–126, Copper Mountain Resort, Colorado, December 1995.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[2] Remzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I/O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input/Output in Parallel and Distributed Systems (IOPADS ’99), pages 10–22, Atlanta, Georgia, May 1999.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[3] Luis-Felipe Cabrera and Darrell D. E. Long. Swift: Using distributed diskstriping to provide high I/O data rates. Computer Systems, 4(4):405–436, 1991.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[4] Garth A. Gibson, David F. Nagle, Khalil Amiri, Jeff Butler, Fay W. Chang, Howard Gobioff, Charles Hardin, ErikRiedel, David Rochberg, and Jim Zelenka. A cost-effective, high-bandwidth storage architecture. In Proceedings of the 8th Architectural Support for Programming Languages and Operating Systems, pages 92–103, San Jose, California, October 1998.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[5] John Howard, Michael Kazar, Sherri Menees, David Nichols, Mahadev Satyanarayanan, Robert Sidebotham, and Michael West. Scale and performance in a distributed file system. ACM Transactions on Computer Systems, 6(1):51–81, February 1988.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[6] InterMezzo. &lt;a href=&quot;http://www.inter-mezzo.org/&quot;&gt;http://www.inter-mezzo.org&lt;/a&gt;, 2003.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[7] Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. Replication in the Harp file system. In 13th Symposium on Operating System Principles, pages 226–238, Pacific Grove, CA, October 1991.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[8] Lustre. &lt;a href=&quot;http://www.lustreorg/&quot;&gt;http://www.lustreorg&lt;/a&gt;, 2003.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[9] David A. Patterson, Garth A. Gibson, and Randy H. Katz. A case for redundant arrays of inexpensive disks (RAID). In Proceedings of the 1988 ACM SIGMOD International Conference on Management of Data, pages 109–116, Chicago, Illinois, September 1988.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[10] FrankSchmuckand Roger Haskin. GPFS: A shared-diskfile system for large computing clusters. In Proceedings of the First USENIX Conference on File and Storage Technologies, pages 231–244, Monterey, California, January 2002.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[11] Steven R. Soltis, Thomas M. Ruwart, and Matthew T. O’Keefe. The Gobal File System. In Proceedings of the Fifth NASA Goddard Space Flight Center Conference on Mass Storage Systems and Technologies, College Park, Maryland, September 1996.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;[12] Chandramohan A. Thekkath, Timothy Mann, and Edward K. Lee. Frangipani: A scalable distributed file system. In Proceedings of the 16th ACM Symposium on Operating System Principles, pages 224–237, Saint-Malo, France, October 1997.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;转载: https://mrcroxx.github.io/posts/paper-reading/gfs-sosp2003/&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[MapReduce]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/三驾马车/MapReduce</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/三驾马车/MapReduce</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><category><![CDATA[三驾马车]]></category><pubDate>Wed, 04 May 2022 14:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;MapReduce&quot;&gt;MapReduce&lt;/h1&gt;
&lt;h1 id=&quot;摘要&quot;&gt;摘要&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce是一个用来处理和生成大型数据集的编程模型和相关实现。用户需要指定&lt;em&gt;map&lt;/em&gt;函数和&lt;em&gt;reduce&lt;/em&gt;函数。&lt;em&gt;map&lt;/em&gt;函数处理键值对并生成一组由键值对组成的中间值，&lt;em&gt;reduce&lt;/em&gt;函数将所有键相同的中间值合并。就像本文中展示的那样，现实世界中的很多任务都可以通过这个模型表示。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以这种函数式风格编写的程序可以自动地作为并行程序在大型商用机集群上执行，运行时（run-time）系统负责对输入数据分区、在一系列机器间调度程序执行、处理机器故障、管理必要的机器间的通信。这让没有任何并行程序和分布式系统开发经验的编程人员能够轻松利用一个大型分布式系统的资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的MapReduce实现是高度可伸缩的，其运行在一个由商用机器组成的大型分布式集群上。通常，一个MapReduce计算会处理上千台机器上数TB的数据。每天都有数百个MapReduce程序提交的高达上千个MapReduce任务在Google集群上执行。开发人员认为这个系统非常易用。&lt;/p&gt;
&lt;h1 id=&quot;引言&quot;&gt;引言&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在过去的五年中，本文作者和其他在Google的开发者实现了数以百计的计算程序，以计算处理不同来源的大规模原始数据（如爬取到的文档、web请求日志等）。这些程序可能用来计算倒排索引（inverted index）、web文档在图论中的各种表示、每个主机爬取到的页面数量之和、给定的某天中查询最频繁的集合等等。虽然大部分的计算程序逻辑非常简单，但是由于其输入数据的规模通常很大，所以这些程序必须在成百上千台机器上分布式执行以在可可接受的时间内完成。解决并行计算、数据分布、故障处理等问题需要大量复杂的代码，让原本简单的问题不再简单。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了应对这种复杂性，我们设计了一个新的程序抽象。其允许我们通过简单的描述表达我们要执行的计算，同时将并行化、容错、数据分布、负载均衡等细节隐藏在库中。我们的抽象收到了Lisp和许多其他函数式语言中的&lt;em&gt;map&lt;/em&gt;和&lt;em&gt;reduce&lt;/em&gt;原语的启发。我们意识到，我们大部分的计算都设计&lt;em&gt;map&lt;/em&gt;操作和&lt;em&gt;reduce&lt;/em&gt;操作。首先对输入数据中每条逻辑记录应用&lt;em&gt;map&lt;/em&gt;操作以计算出一系列的中间键值对，然后对所有键相同的值应用&lt;em&gt;reduce&lt;/em&gt;操作以合理地整合这些派生数据。用户可以自定义&lt;em&gt;map&lt;/em&gt;和&lt;em&gt;reduce&lt;/em&gt;操作，这让大型计算的并行化更为简单，且可以使用“重跑（re-execution）”的方法作为主要容错机制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本工作的主要贡献为一个简单且功能强大的能实现自动并行化、高伸缩性分布式计算的的接口，和该接口在大型商用PC集群上的高性能的实现。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3oo4ymf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二章描述了基本编程模型，并给出了几个例子。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p2x2esu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第三章描述了为我们基于集群的计算环境定制的MapReduce接口实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-srrveeh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第四章描述了该编程模型中我们认为有帮助的细节。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n6xmhsb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第五章我们的实现在各种任务重的性能测试。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g02hhgg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第六章探究了MapReduce在Google中的使用，其中包括了我们以MapReduce为基础重写我们产品索引系统的经历。第七章探讨了相关工作与未来的工作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;编程模型&quot;&gt;编程模型&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;计算任务以一系列&lt;em&gt;输入键值对&lt;/em&gt;作为输入，并产出一系列&lt;em&gt;输出键值对&lt;/em&gt;作为输出。MapReduce库的用户将计算表示为两个函数：&lt;em&gt;map&lt;/em&gt;和 &lt;em&gt;reduce&lt;/em&gt; 。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-b7uar8v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;是由用户编写的，取一个输入对，并且产生一系列中间的键值对。MapReduce 库将那些具有相同的中间键I的中间值聚集在一起，然后将它们传递给 Reduce 函数。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u5gnojo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Reduce&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;同样是由用户编写的，接收一个中间键I和该键对应的一系列的中间值。Reduce 函数通过将这些值合并来组成一个可能更小的集合（值的集合）。通常每个 Reduce 函数只产生 0 个或 1 个输出值。Reduce 函数一般通过一个迭代器（via an iterator）来获取中间值，从而在中间值的数目远远大于内存容量时，我们也能够处理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;示例&quot;&gt;示例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;考虑如下一个问题：统计一个大量文档集合中每个单词出现的次数。用户会编写如下的伪代码。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;　　map(String key, String value):
　　　　// key: document name
　　　　// value: document contents
　　　　for each word w in value:
　　　　　　EmitIntermediate(w, &amp;quot;1&amp;quot;);

　　reduce(String key, Iterator values):
　　　　// key: a word
　　　　// values: a list of counts
　　　　int result = 0;
　　　　for each v in values:
　　　　　　result += ParseInt(v);
　　　　Emit(AsString(result));
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;em&gt;map&lt;/em&gt;计算出每个单词与其（译注：在每个文档中的）出现的次数（在本例中为“1”）。&lt;em&gt;reduce&lt;/em&gt;函数会求出每个单词出现次数的和。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，用户编写代码来一个&lt;em&gt;mapreduce specification（规格/规范）&lt;/em&gt;对象，填写输入输出文件名和可选的调节参数。随后，用户调用MapReduce函数，将&lt;em&gt;mapreduce specification&lt;/em&gt;对象作为参数传入。用户代码会被与MapReduce库（C++实现）链接到一起。&lt;a href=&quot;https://mrcroxx.github.io/posts/paper-reading/mapreduce-osdi04/#%e9%99%84%e5%bd%95a-%e8%af%8d%e9%a2%91%e7%bb%9f%e8%ae%a1&quot;&gt;附录A&lt;/a&gt;包含本示例的完整程序。&lt;/p&gt;
&lt;h2 id=&quot;类型&quot;&gt;类型&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管前面的伪代码中使用了字符串作为输入输出类型，但理论上用户提供的&lt;em&gt;map&lt;/em&gt;和&lt;em&gt;reduce&lt;/em&gt;函数可以使用相关联的类型：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;map     (k1,v1)  -&amp;gt;  list(k2,v2)
reduce  (k2,list(v2)) -&amp;gt; list(v2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要注意的是，输入的 key 和 value 与输出的 key 和 value 是不同的类型，而中间的 key 和 value 与输出的 key 和 value 是相同的类型（用 k1 和 k2 表示）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的 C++实现都是以字符串的形式和用户代码进行交互的，至于将字符串类型转换成相应合适的类型的工作则由用户代码来完成了。&lt;/p&gt;
&lt;h2 id=&quot;更多示例&quot;&gt;更多示例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本节中，我们给出了一些简单的示例。这些示例是可以简单地通过MapReduce计算表示的有趣的程序。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m3pvam3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Distributed Grep&lt;/strong&gt; ：Map函数获取匹配提供的模式的行，Reduce函数只是简单地将这些中间数据拷贝到输出&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mq7sep0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Count of URL Access Frequency&lt;/strong&gt; ：Map函数处理web请求的日志，并且输出&amp;lt;URL, 1&amp;gt;。Reduce函数将拥有相同URL的value相加，得到&amp;lt;URL, total count&amp;gt;对&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-q6w7w2s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Reverse Web-Link Graph&lt;/strong&gt; ：Map函数输出&amp;lt;target, source&amp;gt;对，其中source所在的page都有连向target这个URL的链接。Reduce函数将给定target的所有的source URL连接起来，输出&amp;lt;target, list(source)&amp;gt;对&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gjhdkl1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Term-Vector per Host&lt;/strong&gt; ：一个term vector表示一系列&amp;lt;word, frequency&amp;gt;的键值对，word表示一篇或者一系列文章中出现的比较重要的单词，frequency表示它们出现的次数。Map函数对于每篇输入的文章输出&amp;lt;hostname, term vector&amp;gt;键值对（其中hostname是从文章所在的URL中抽取出来的）Reduce函数获取给定host的term vectors。它将这些term vectors累加起来，丢弃非频繁出现的term，并产生一个最终的&amp;lt;hostname, term vector&amp;gt;对。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nmwmobg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Inverted Index：&lt;/strong&gt; Map函数对每篇文章进行处理，并输出一系列的&amp;lt;word, document ID&amp;gt;对。Reduce函数接收给定word的所有键值对，对相应的document ID进行排序并且输出&amp;lt;word, list&amp;lt;document ID&amp;gt;&amp;gt;对。所有输出对的集合构成了一个简单的倒排索引。用了MapReduce模型，对单词位置的追踪就变得非常简单了。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2qmibde&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Distributed Sort：&lt;/strong&gt; Map函数从每个record中抽取出key，产生&amp;lt;key, record&amp;gt;键值对。Reduce函数只是简单地将所有对输出。这个计算模型依赖于Section 4.1中描述的划分技巧以及Section 4.2中描述的排序特性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;实现&quot;&gt;实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于MapReduce的接口，各种各样不同的实现都是可能的。所有正确的实现都是基于应用环境的。比如，一种实现可能适合于小的共享内存的机器，另一种可能适合于大型的NUMA多处理器机器，甚至有的是为更大的互联的机器集群设计的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本节中描述的实现基于的是Google中最常用的计算环境：一个由大量商用PC机通过交换以太网互联的集群。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们的环境中：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-f0wv46r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;机器通常都是x86的双核处理器，其上运行Linux，每台机器拥有2-4G的内存&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9hc281r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商用网络硬件---通常是100 M/s或者1 G/s，但是综合起来要小于平均带宽&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y8whx1r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个集群由成千上万台机器组成，因此机器故障是常有的事&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6pk745g&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;存储由便宜的IDE磁盘提供，它们都与独立的机器直接相连。一个内部研发的文件系统用于管理所有存储于这些硬盘上的文件。该文件系统通过Replication在不可靠的硬件上提供了可用性和可靠性&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-shk67l6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户提交jobs给调度系统。每个job由一系列的task组成，并且由调度器分配到集群中一系列可用的机器上&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;执行概览&quot;&gt;执行概览&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过将输入数据自动分割成 M 份，Map 函数得以在多台机器上分布式执行。每一个输入块都能并行地在不同的机器上执行。通过划分函数(例如，hash(key) mod R)将中间键划分为 R 份，Reduce 函数也能被分布式地调用。其中划分的数目 R 和划分函数都是由用户指定的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;max-width: 1186px;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220504223220.png&quot; alt=&quot;图1 执行概览&quot; title=&quot;图1 执行概览&quot; parent-style=&quot;max-width: 1186px;&quot; /&gt;&lt;span class=&quot;protyle-action__title&quot;&gt;图1 执行概览&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上图 1 展示了在我们的实现中 MapReduce 全部的流程。当用户程序调用 MapReduce 函数时，接下来的动作将按序发生（图 1 中标记的数字与下面的数字是一一对应的）：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-hozhk8l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户程序中的 MapReduce 库首先将输入文件划分为M片，每片大小一般在 16MB 到 64MB 之间（由用户通过一个可选的参数指定）。之后，它在集群的很多台机器上都启动了相同的程序拷贝。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b0ww5dc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中有一个拷贝程序是特别的——master。剩下的都是 worker，它们接收 master 分配的任务。其中有 M 个 Map 任务和 R 个 Reduce 任务要分配。master 挑选一个空闲的 worker 并且给它分配一个 map 任务或者 reduce 任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jivhtpw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;被分配到 Map 任务的 worker 会去读取相应的输入块的内容。它从输入文件中解析出键值对并且将每个键值对传送给用户定义的 Map 函数。而由 Map 函数产生的中间键值对缓存在内存中。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-d6qsau3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;被缓存的键值对会阶段性地写回本地磁盘，并且被划分函数分割成 R 份。这些缓存对在磁盘上的位置会被回传给 master，master 再负责将这些位置转发给 Reduce worker。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p3jnx40&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当 Reduce worker 从 master 那里接收到这些位置信息时，它会使用远程过程调用从 Map worker 的本地磁盘中获取缓存的数据。当 Reduce worker 读入全部的中间数据之后，它会根据中间键对它们进行排序，这样所有具有相同键的键值对就都聚集在一起了。排序是必须的，因为会有许多不同的键被映射到同一个 reduce task 中。如果中间数据的数量太大，以至于不能够装入内存的话，还需要另外的排序。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5fr7gki&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Reduce worker 遍历已经排完序的中间数据。每当遇到一个新的中间键，它会将 key 和相应的中间值传递给用户定义的 Reduce 函数。Reduce 函数的输出会被添加到这个 Reduce 部分的输出文件中。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bjn8tpx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当所有的 Map tasks 和 Reduce tasks 都已经完成的时候，master 将唤醒用户程序。到此为止，用户代码中的 MapReduce 调用返回。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当成功执行完之后，MapReduce 的执行结果被存放在 R 个输出文件中（每个 Reduce task 对应一个，文件名由用户指定）。通常用户并不需要将 R 个输出文件归并成一个。因为它们通常将这些文件作为另一个 MapReduce 调用的输入，或者将它们用于另外一个能够以多个文件作为输入的分布式应用。&lt;/p&gt;
&lt;h2 id=&quot;master数据结构&quot;&gt;master数据结构&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 master 中保存了许多的数据结构。对于每个 Map task 和 Reduce task，master 都保存了它们的状态（idle，in-progress 或者是 completed）以及 worker 所在机器的标识（对于非 idle 空转状态的 tasks 而言）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master 相当于是一个管道，通过它 Map task 所产生的中间文件被传递给了 Reduce task。因此，对于每一个已经完成的 Map task，master 会存储由它产生的 R 个中间文件的位置和大小（分配给 R 个 Reduce task 执行，需要远程读取这些数据，所以要记录位置和大小）。当 Map task 完成的时候，master 就会收到位置和大小的更新信息。而这些信息接下来就会逐渐被推送到处于 in-progress 状态的 Reduce task 中。&lt;/p&gt;
&lt;h2 id=&quot;容错&quot;&gt;容错&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为MapReduce库是为使用成百上千台机器处理大规模数据提供帮助而设计的，所以必须能够优雅地对机器故障进行容错。&lt;/p&gt;
&lt;h3 id=&quot;worker故障&quot;&gt;worker故障&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master会定期ping每个worker。如果在一定时间内没有收到worker的响应，master会将该worker标记为故障。被故障的worker处理的已完成的&lt;em&gt;map&lt;/em&gt;任务会被重设为其初始的“等待中”的状态，因此其符合被调度到其他worker的条件。同样，在故障的worker上任何执行中的&lt;em&gt;map&lt;/em&gt;或&lt;em&gt;reduce&lt;/em&gt;任务也会被重设为“等待中”的状态，符合重新调度的条件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当worker故障发生时，该worker完成的&lt;em&gt;map&lt;/em&gt;任务也需要被重新执行，因为&lt;em&gt;map&lt;/em&gt;任务的输出被存储在故障的机器的本地磁盘上，无法被访问。故障worker完成的&lt;em&gt;reduce&lt;/em&gt;任务则不需要被重新执行，因为他们的输出被存储在全局的文件系统中&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当一个起初被worker A执行的&lt;em&gt;map&lt;/em&gt;任务因A发生故障而随后被worker B执行时，所有正在执行&lt;em&gt;reduce&lt;/em&gt;任务的worker会被告知这个&lt;em&gt;map&lt;/em&gt;任务被重新执行。任何没从worker A中读取完数据的&lt;em&gt;reduce&lt;/em&gt;任务将会从worker B中读取数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce可以弹性处理大规模worker故障。例如，在MapReduce操作中，由于在正在运行的集群中的网络维护工作导致了80台机器在几分钟内同时变得不可访问。MapReduce的master会简单地重新执行不可访问的worker的机器上已完成的工作，并继续执行后续任务，最终完成整个MapReduce操作。&lt;/p&gt;
&lt;h3 id=&quot;master故障&quot;&gt;master故障&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于master，我们可以简单地对上文所述的master数据结构做周期性的快照。如果一个master task死了，我们可以很快地根据最新的快照来重新启动一个master task。但是，因为我们只有一个master，因此故障的概率比较低。所以，在我们的实现中如果master出现了故障就只是简单地停止MapReduce操作。用户可以检测到这种情况，并且如果他们需要的话可以重新开始一次MapReduce操作。&lt;/p&gt;
&lt;h3 id=&quot;故障出现时的语义&quot;&gt;故障出现时的语义&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果用户提供的Map和Reduce操作是关于输入值的确定性函数，那么我们分布式的实现将会产生同样的输出，在整个程序经过没有出现故障的顺序执行之后。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; 我们依赖Map task和Reduce task原子性地提交输出来实现上述特性。每一个正在执行的task都会将它的输出写到一个私有的临时文件中。一个Reduce task产生一个这样的文件，而一个Map task产生R个这样的文件（每个Reduce work一个）。当一个Map task完成的时候，worker就会给master发送一个信息，，其中包含了R个临时文件的名字。如果master收到了一个来自于已经完成了的Map task的完成信息，那么它就将它自动忽略。否则，将R个文件的名称记录到一个master数据结构中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当一个Reduce task完成的时候，Reduce worker会自动将临时输出文件命名为最终输出文件。如果同一个Reduce task在多台机器上运行，那么多个重命名操作产生的最终输出文件名将会产生冲突。对此，我们依赖底层文件系统提供的原子重命名操作来保证最终文件系统中的数据来自一个Reduce task。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大多数的Map和Reduce操作都是确定性的，事实上，我们的语义等同于顺序执行。因此这让程序员非常容易地能够解释他们程序的行为。当Map和Reduce操作是非确定性的时候，我们提供较弱，但仍然合理的语义。在非确定性的操作中，对于一个特定的Reduce task R1的输出是和非确定性程序顺序执行产生R1产生的输出是相同的。然而，对于另一个Reduce task R2，它的输出对应于非确定性程序另一个顺序执行的结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面考虑Map task M和Reduce task R1和R2。让e(Ri)表示Ri的执行结果。更弱的语义意味着，e(R1)可能从M的一次执行结果中读取输入，而e(R2)可能从M的另一次执行中读取输入。&lt;/p&gt;
&lt;h2 id=&quot;位置分配&quot;&gt;位置分配&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;网络带宽在我们的计算环境中是相对稀缺的资源。我们通过将输入数据存储在集群中每台机器的本地磁盘的方法来节省带宽。GFS将输入文件切分成64MB大小的块，并且将每个块的多份拷贝（通常为3份）存储在不同的机器上。MapReduce的master获取所有输入文件的位置信息，然后将Map task调度到有相应输入文件副本的机器上。当发生故障时，再将Map task调度到邻近的具有该task输入文件副本的机器（即在同一台交换机内具有相同数据的机器）。当在一个集群的大量机器上做MapReduce操作时，大多数的输入数据都是从本地读取的，而不用消耗带宽。&lt;/p&gt;
&lt;h2 id=&quot;任务粒度&quot;&gt;任务粒度&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如上所述，我们将Map操作分成M份，Reduce操作分成R份。在理想的情况下，M和R的值应该要比集群中worker machine的数量多得多。让一个worker同时进行许多不同的task有利于提高动态的负载均衡，同时在一个worker故障的时候能尽快恢复。许多已经完成的Map task也能尽快地传播到其他所有的worker machine上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们的实现中，M和R的大小是有一个实用范围的。因为我们的master需要做O（M+R）个调度决定，并且还要在内存中保存O（M&lt;em&gt;R）个状态。（但是内存使用的常数还是比较小的，O（M&lt;/em&gt;R）个Map task/Reduce task 状态对，每个的大小大概在一个字节）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，R通常受限于用户，因为每个Reduce task的输出都分散在不同的输出文件中。事实上，我们会选择M，因此每个输入文件大概16MB到64MB的输入文件（因此上文所述的局部性优化会达到最优）。而我们会让R成为worker machine数量的一个较小的倍数。因此，我们通常在进行MapReduce操作时，将M设为200000，R设为5000，使用2000个worker machine。&lt;/p&gt;
&lt;h2 id=&quot;任务副本&quot;&gt;任务副本&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;“straggler”（落伍的士兵）的存在是拖慢整个MapReduce操作的通常的原因之一。所谓的&amp;quot;straggler&amp;quot;是指一台机器用了过长的时间去完成整个计算任务中最后几个Map或者Reduce task。Straggler出现的原因有很多。比如一台机器上硬盘坏了，它就会经历大量的可纠正错误，从而让它的性能从30MB/s下降到1MB/s。集群的调度系统可能将其他task调度到该机器上，导致它执行MapReduce代码的速度变慢很多，因为CPU，内存，本地磁盘，网络带宽的竞争加剧。我们最近遇到的一个问题是一台机器的初始化代码有点问题，它会导致处理器的缓存被禁用，在这些受影响的机器上进行的计算速度会下降到原来的百分之一。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对此，我们有一个通用的机制用来缓解straggler的问题。当MapReduce操作接近结束的时候，master会将那些还在执行的task的备份进行调度执行。无论是原来的还是备份执行完成，该task都被标记为已完成。我们通过调整将该操作导致的计算资源消耗仅仅提高了几个百分点。但是在完成大型的MapReduce操作时，却让整个执行时间下降了好多。例如，Section 5.3中所描述的排序算法在备份机制关闭的情况下，需要多消耗44%的时间。&lt;/p&gt;
&lt;h1 id=&quot;改进&quot;&gt;改进&lt;/h1&gt;
&lt;h2 id=&quot;分区函数&quot;&gt;分区函数&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce用户决定他们的Reduce task或者输出文件的数目R。通过一个划分函数，根据中间键值将各个task的数据进行划分。默认的划分函数是通过哈希（比如，hash(key) mod R）。这通常会产生非常好的较为均衡的划分。但是在其他一些情况下，通过键值的其他函数来划分要更好一些。例如，有的时候输出键值是一些URL，我们希望同一个host的内容能放在同一个输出文件中。为了支持这种情况，MapReduce库的用户可以提供一个特殊的划分函数。例如，使用“hash(Hostname(urlKey)) mod R”作为划分函数，从而让所有来自于同一个host的URL的内容都输出到同一个输出文件。&lt;/p&gt;
&lt;h2 id=&quot;有序性保证&quot;&gt;有序性保证&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们确保在一个给定的划分中，中间键值对都按照键值的升序进行处理。这样的处理顺序确保了每一个划分产生一个排好序的输出文件。这样的话，如果输出文件格式需要支持根据 key 进行有效的随机查找会比较方便。同时，输出文件（应用）的用户也会觉得已经排好序的数据使用起来特别方便。&lt;/p&gt;
&lt;h2 id=&quot;合并函数&quot;&gt;合并函数&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在有些情况下，每个Map task都会产生大量的中间键的重复而用户指定的Reduce函数是交互和关联的。Section 2.1中的单词统计就是一个很好的例子。因为单词的出现频率服从于Zipf分布，每个Map Task都会产生成百上千个&amp;lt;the, 1&amp;gt;这样的记录。所有这些记录都会通过网络被送到一个Reduce task中，并且由Reduce函数加在一起去产生一个数。我们允许用户使用了可选的Cominer函数，用于在网络传输之前部分地进行归并操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Combiner函数在每个执行Map task的机器上执行。通常Combiner和Reduce函数使用的是相同的代码。Reduce函数和Combiner函数唯一的不同是MapReduce库如何处理函数的输出。Reduce函数的输出写到最终的输出文件中。而Combiner函数的输出会被写到一个最终将被送给Reduce task的中间文件中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;部分的合并操作能极大地加速某类特定的MapReduce操作。Appendix A包含了一个使用Combiner的例子。&lt;/p&gt;
&lt;h2 id=&quot;输入输出类型&quot;&gt;输入输出类型&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce库提供了对读入数据文件多种的格式支持。例如，&amp;quot;text&amp;quot;格式的输入将每一行作为键值对：key是文件内的偏移，value是该行的内容。另外一种比较常用的格式存储一系列按照键进行排序的键值对。每一个输出格式的实现都知道如何将自己进行合理的划分从而能让不同的Map task进行处理（例如，text模式就知道将区域划分到以行为边界）。用户可以通过简单地定义一个reader接口来提供一个新的输入类型的实现。事实上，大多数用户只使用了预定义输入类型的很小一部分。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;reader并不一定要从文件中读取数据。例如，我们可以很容易地定义一个从数据库，或者内存中映射的数据结构中读取记录的reader。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;同理，我们也支持产生不同格式的输出数据，用户也能编写新的输出数据格式。&lt;/p&gt;
&lt;h2 id=&quot;附属输出&quot;&gt;附属输出&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在有些情况下，MapReduce的用户会很容易发现Map或者Reduce操作会产生一些辅助文件作为额外的输出文件。我们依赖应用的编写者去保证这些副作用是原子和幂等的。一般来说，应用会写到一个临时文件中，并且在它完全产生之后，通过一个原子操作将它重命名。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于一个单一的task产生的多个输出文件，我们不提供原子性的两相提交支持。因此，产生多个输出文件并且有跨文件一致性要求的task需要是确定性的。但是这样的限制在实践过程中并不是什么问题。&lt;/p&gt;
&lt;h2 id=&quot;跳过损坏的记录&quot;&gt;跳过损坏的记录&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有时候，如果用户的代码中有bug的话，会导致Map或者Reduce操作在某些记录上崩溃。这些bug会导致MapReduce操作的正常完成。对于这种情况，通常就是去修bug。不过有时候这是不可行的，也许bug是第三方库造成的，而我们并不能得到它的源代码。而且，有时候我们允许忽略掉一些记录，例如在对一个大数据集做分析的时候。因此我们提供了一种可选的执行模式，当MapReduce库检测到一些记录会造成崩溃时，就会主动跳过它们，从而保证正常地运行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每一个worker进程都安装了一个signal handler用于捕捉段错误和bug。在调用用户的Map和Reduce操作之前，MapReduce库会将参数的序号保存在一个全局变量中。如果用户代码产生了一个信号，signal handler就会传输一个参数含有序号的&amp;quot;last gasp&amp;quot;UDP包给MapReduce的master。当master在一个特定的记录中发现了不知一次的错误，这表示在下一次执行相应的Map或者Reduce操作的时候一个将它跳过。&lt;/p&gt;
&lt;h2 id=&quot;本地执行&quot;&gt;本地执行&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Map或者Reduce函数的调试问题是非常tricky的。因为实际的计算发生在分布式的系统中，通常由成百上千台机器组成，并且工作的分配由master动态执行。为了帮助调试，分析，以及小规模的测试，我们开发了另外一个MapReduce库的实现，它能够在本地机器上顺序执行一个MapReduce操作的所有工作。它的控制交给用户，因此计算可以被限定到制定的Map task中执行。用户利用指定的flag启动程序，然后就能非常简单地使用任何它们觉得有用的调试或者测试工具了。&lt;/p&gt;
&lt;h2 id=&quot;状态信息&quot;&gt;状态信息&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;master运行了一个内置的HTTP server并且暴露了一系列供人类使用的状态页。状态页会显示程序的计算过程，例如已经完成了多少个task，还有多少个task正在执行，输入的字节数，中间数据的字节数，输出的字节数，以及处理速度等等。该页还包含了指向各个task的标准错误和标准输出链接。用户可以利用这些数据来判断计算会持续多长时间，以及计算是否需要添加更多的资源。这些页面还能用来发现什么时候处理速度比预期地下降好多。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，顶层的状态页显示了那些worker出错了，以及在它们出错时正在执行哪些Map和Reduce task。这些信息在诊断用户代码出现的bug时是非常有用的。&lt;/p&gt;
&lt;h2 id=&quot;计数器&quot;&gt;计数器&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce库提供了一个叫counter的设施用于统计各种不同事件出现的次数。例如，用户可能想要统计已经处理过的单词的数目或者德国文件的索引数量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了使用这一特性，用户代码创建一个命名的counter对象，并且在Map以及Reduce函数中对counter进行增加。例如：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;
Counter* uppercase;
uppercase = GetCounter(&amp;quot;uppercase&amp;quot;);

map(String name, String contents):
  for each word w in contents:
    if (IsCapitalized(w)):
      uppercase-&amp;gt;Increment();
    EmitIntermediate(w, &amp;quot;1&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个worker机器上counter的值会定期传给master（捎带在给master的ping回复中）。master将来自成功执行的Map和Reduce task的counter值聚集起来。然后在MapReduce操作完成之后返回给用户代码。当前的counter值也会显示在master的状态页上，所以用户能从实时观看计算的进行。在聚集counter的值的时候，master会消除Map或者Reduce task的重复执行造成的重复计算。（重复执行可能由backup tasks或者因为错误重新执行的task引起）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有些counter的值是由MapReduce库自动维护的，例如已经处理的输入键值对数目以及已经产生的输出键值对数目。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户发现counter特性对于检查MapReduce操作的执行是非常有用的。例如，在有些MapReduce操作中，用户代码想要确保产生的输出对的数目和已经处理的输入对的数目是恰好相等的，或者处理的德语文件的数目占总处理文件数目的比重在一个可容忍的范围内。&lt;/p&gt;
&lt;h1 id=&quot;性能&quot;&gt;性能&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个section中，我们通过运行在一个集群上的两个computation来测试MapReduce的性能。一个Computation搜索一个T的数据，从中获取一个特定的模式。另一个computation对一个T的数据进行排序。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这两个程序代表了由用户实际编写的MapReduce程序的一个子集------一类程序用于将数据从一种表示方法切换到另一种表示方法。另一类程序则从大数据集中抽取出一小部分有趣的数据。&lt;/p&gt;
&lt;h2 id=&quot;集群配置&quot;&gt;集群配置&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有程序都运行在一个由 1800 台机器组成的机器上。每一台机器都有两个 2GHz 的 Intel Xeon 处理器，并且允许 Hper-Threading（超线程）， 4GB 内存，两个 160GB 的 IDE 磁盘，以及一个 G 比特的以太网链路。这些机器被安排在一个两层树状的交换网络中，根节点的带宽大概在 100-200Gbps。因为所有机器都在同一个托管设备中，因此任意两台机器间的 RTT 少于 1ms。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中 4GB 中的 1-1.5G 是为集群中运行的其他任务预留的。程序在一个周末的下午运行，此时 CPU，磁盘，网络基本都处于空闲状态。&lt;/p&gt;
&lt;h2 id=&quot;grep&quot;&gt;grep&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;em&gt;grep&lt;/em&gt;程序会扫描101010^{10}&lt;strong&gt;1&lt;/strong&gt;0&lt;strong&gt;10&lt;/strong&gt;条100B的记录，以搜索匹配一个相对较少的三个字母的模板（92,337条记录命中）。输入数据被分割为约64MB的分片（M=15000M=15000&lt;strong&gt;M&lt;/strong&gt;=&lt;strong&gt;15000&lt;/strong&gt;），所有的输出被放置在一个文件中（R=1R=1&lt;strong&gt;R&lt;/strong&gt;=&lt;strong&gt;1&lt;/strong&gt;）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图2&lt;/strong&gt;展示了计算进度随时间的变化。Y轴展示了输入数据被扫描的速率。随着分配给MapReduce计算的机器越来越多，其速度也逐渐提高。当有1764个worker被分配到该任务时，速率峰值超过了30GB/s。当&lt;em&gt;map&lt;/em&gt;任务完成时，速率开始逐渐下降并在整个计算时间的大概第80s时下降到0。整个计算从开始到结束大概消耗了150s。这包括了大概一分钟的启动时间开销。这一开销的原因是程序需要传播到所有worker机器与打开1000个输入文件并获取局部优化所需的信息时与GFS交互的时延。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot; style=&quot;max-width: 1283px;&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220505131347.png&quot; alt=&quot;图2 数据传输速率随时间变化图&quot; title=&quot;图2 数据传输速率随时间变化图&quot; parent-style=&quot;max-width: 1283px;&quot; /&gt;&lt;span class=&quot;protyle-action__title&quot;&gt;图2 数据传输速率随时间变化图&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;sort&quot;&gt;sort&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;em&gt;sort&lt;/em&gt;程序会对10的十次方条100B的记录进行排序（大约1TB的数据）。这个程序是模仿&lt;em&gt;TeraSort&lt;/em&gt;的&lt;em&gt;benchmark&lt;/em&gt;程序构建的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;排序程序的用户代码少于50行。三行的&lt;em&gt;map&lt;/em&gt;函数从一行文本中提取一个10字节的排序用的键，并将这个键与原始文本作为&lt;em&gt;中间键值对&lt;/em&gt;输出。我们使用了一个内建的恒等函数作为&lt;em&gt;reduce&lt;/em&gt;操作。这个函数不对&lt;em&gt;中间键值对&lt;/em&gt;就行修改，直接作为&lt;em&gt;输出键值对&lt;/em&gt;传递。最终排序的输出被写入一系列2副本的GFS文件中（即，程序输出总计写入了2TB）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与前者相同，输入数据被分割为64MB的分片（M=15000）。我们将排序的输出分区到4000个文件中（R=4000）。分区函数根据键的首字节将其划分到&lt;strong&gt;R&lt;/strong&gt;个分区之一中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;该benchmark的分区函数内建了键的分布情况。在通常的排序程序中，我们会增加一个提前执行的MapReduce操作，该操作会采集一些键的样本，并通过这些样本来计算最终排序时的分割点。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图3&lt;/strong&gt;展示了以普通方式执行时程序的进度。左上角的图表展示了输入数据读取的速率。速率的峰值达到大概13GB/s，随后快速下降，因为所有&lt;em&gt;map&lt;/em&gt;任务都在大概第200秒前完成。需要注意的是该程序数据输入速率比&lt;em&gt;grep&lt;/em&gt;低。这是因为&lt;em&gt;sort&lt;/em&gt;的&lt;em&gt;map&lt;/em&gt;任务消耗了大概一半的时间和I/O带宽用于将中间数据写入到本地磁盘，而&lt;em&gt;grep&lt;/em&gt;的中间数据大小几乎可以忽略不计。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;左侧中间的图表展示了数据通过网络从&lt;em&gt;map&lt;/em&gt;任务发送到&lt;em&gt;reduce&lt;/em&gt;任务的速率。该数据转移（shuffle）在第一个&lt;em&gt;map&lt;/em&gt;任务完成时便开始。图表中第一个峰中的数据转移是为了第一批约1700个&lt;em&gt;reduce&lt;/em&gt;任务（整个MapReduce被分配到1700台机器上，每台机器同时最多执行1个&lt;em&gt;reduce&lt;/em&gt;任务）。在整个计算任务的大概第300秒时，部分第一批&lt;em&gt;reduce&lt;/em&gt;任务完成了，并开始为剩余的&lt;em&gt;reduce&lt;/em&gt;任务转移数据。所有的数据转移在整个计算的大概第600秒是完成。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;左下角的图表展示了排好序的数据被&lt;em&gt;reduce&lt;/em&gt;任务写入最终输出文件的速率。在第一个数据转移阶段和数据开始被&lt;em&gt;reduce&lt;/em&gt;任务写入到最终文件间有一段延时，这是因为这期间机器都在忙于排序中间数据。写入操作以2~4GB/s的速率持续了一段时间，在整个计算过程的大概第850秒时完成了数据写入。算上启动的开销，整个计算过程消耗了891秒。这与目前在TeraSort benchmark中报道的最佳结果1057秒非常接近 。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这有一些需要注意的点：由于我们的局部性优化，大部分数据直接从本地磁盘读取，绕过了带宽相对受限的玩过，所以数据输入速率比数据转移速率高。由于数据输出阶段写入了两份排好序的数据的副本，所以数据转移的速率比输出的速率高（为了可靠性和可用性，我们为输出数据设置了两份副本）。我们的下层文件系统为了可靠性和可用性的考虑而写入了两份副本。如果我们使用擦除编码（erasure code）的方式而不是副本的方式，写入数据时网络带宽的需求会减少。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220504224925.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;任务副本的影响&quot;&gt;任务副本的影响&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在图 3（b）中，我们展示了禁止 backup tasks 情况下执行排序操作的结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;流程与图 3（a）很相似，但存在一个相当长的且看不出有明显活动的尾部。960 秒后，除了剩余的 5 个，其余 reduce tasks 均已完成，然而剩余的 stragglers 直到 300 秒后才完成任务，着导致整体耗时 1283 秒，比具备 backup tasks（最终备份处理任务）情况下多耗时 44%。&lt;/p&gt;
&lt;h2 id=&quot;机器故障&quot;&gt;机器故障&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在图 3（c）中，我们展示了将 1746 台工作机器中的 200 台机器故意宕机几分钟以模拟机器故障情况下排序操作的执行结果，底层的集群立刻重启新的工作进程（因为仅仅是 kill 进程，实际上机器功能良好）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;worker 的 deaths 通过图表中负值输入速率来表示，因为先前一些已完成的 map work 丢失而需要被重新执行（根据先前分析，由于 map task 得到的中间结果存储在本地，宕机后无法正确访问，使得之前的任务需要被重新执行 re-execute）。重执行开始得十分迅速，整体耗时仅仅比正常情况多耗时 5%。&lt;/p&gt;
&lt;h1 id=&quot;研发经历&quot;&gt;研发经历&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们得 MapReduce 库首个版本于 2003 年 2 月写成，并在 2003 年 8 月进行了重要加强，包括引入局部优化，worker 执行任务间动态负载均衡等等。从那时起，我们非常欣喜得看到 MapReduce 在解决各类问题上的广泛应用。现在，它已 Google 用于以下广泛领域的研究。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-75cr76y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大规模机器学习问题&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jelanjj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Google News 和 Froogle products（Google 购物）的聚类问题&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4wzwrhl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提取用于生成热门查询报告的数据（如 Google Zeitgeiest）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hl4n1jh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提取网页上进行的试验或产品性能&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-izano3a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大规模图形计算&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220505131702.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;图4&lt;/strong&gt;中可见，在我们的主源代码管理系统中，独立的MapReduce程序随时间大幅增长。其数量从2003年初的0个增长到2004年9月末的几乎800个独立实例。MapReduce取得了很大的成功，它可以让用户仅编写简单的代码即可在半小时内在上千台机器上高效运行，这大大的提高了开发和设计周期。此外，MapReduce让没有任何分布式和（或）并行系统编程经验的开发者能够轻松利用大量资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在每个工作的最后，MapReduce库会记录该工作使用的计算资源的统计数据。&lt;strong&gt;表1&lt;/strong&gt;展示了Google在2004年8月运行的MapReduce工作的子集的统计数据。&lt;/p&gt;
&lt;h2 id=&quot;大规模索引&quot;&gt;大规模索引&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前，我们使用MapReduce做的最重要的工作之一是完全重写了一个索引系统，该系统被用作生成用于Google web搜索服务的数据结构。该索引系统将大量被我们爬虫系统检索到的文档（作为GFS文件存储）作为输入。这些文档的原始内容的数据大小超过20TB。索引进程会运行一系列5~10个MapReduce操作。使用MapReduce（而不是旧版索引系统中ad-hoc分布式传递方案）提供了很多好处：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-re8erw3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;索引代码更简单、短、便于理解，因为处理容错、分布式和并行的代码被隐藏在了MapReduce库中。例如，计算中的有一个阶段的代码量从3800行C++代码所见到了700行使用MapReduce的代码。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ytg8jta&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce库的性能足够好，这让我们可以将概念上不相关的计算分离开，而不是将它们混合在一起，这样可以避免传递过多额外的数据。这使改变索引程序变得非常简单。例如，在我们旧的索引系统中，一处修改会花费几个月的时间，而新的系统仅需要几天就能实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-98f1y9o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;索引系统变得更容易操作。大部分因机器故障、缓慢的机器、网络不稳定等引起的问题都被MapReduce库自动处理了，不需要引入额外的操作。此外，向索引集群添加新机器以获得更好的性能变得更加简单。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;相关工作&quot;&gt;相关工作&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;许多系统提供了受限制的编程模型，并通过这些限制来进行自动化并行计算。例如，使用并行前缀和计算（parallel prefix computation），可以使用N个处理器上在O(logN)的时间内计算有N个元素的数组中所有前缀和。MapReduce可被看做是对一些这类模型基于我们在现实世界中对大型计算的经验做出的简化和升华。更重要的是，我们提供了适用于大规模的数千个处理器的带有容错机制的实现。相反，大部分并行处理系统仅被小规模使用，且将处理机器故障的细节留给了开发者。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BSP模型（Bulk Synchronous Programming）和一些MPI（Message Passing Interface，消息传递接口）原语提供了让开发者编写并行程序更简单的高层抽象。这些系统和MapReduce的关键区别在于MapReduce提供了一个受限的编程模型，以自动地并行化用户程序，并提供了透明的容错机制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的局部性优化的灵感来自于如活动磁盘（active disk）技术，即计算程序被推送到靠近本地磁盘的处理设备中，这减少了I/O子系统或者网络的总数据发送量。我们在直连少量磁盘的商用处理器上运行程序，而不是直接在磁盘控制处理器上运行，但最终目的都是一样的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们的任务副本机制类似Charlotte System 中使用的Eager调度机制。简单的Eager调度的一个缺点是，当一个任务反复故障时，整个计算都无法完成。我们通过跳过损坏记录的方式来解决导致该问题的一些情况。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce的实现依赖了一个内部的集群管理系统，该系统负责在大量共享的机器上分配并运行用户任务。该系统比较神似如Condor &lt;sup&gt;[16]&lt;/sup&gt; 的其他系统，但这并不是本文的重点。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce中的排序机制在操作上类似NOW-Sort。源机器（&lt;em&gt;map&lt;/em&gt; worker）将待排序的数据分区，并将其发送到R个&lt;em&gt;reduce&lt;/em&gt; worker之一。每个&lt;em&gt;reduce&lt;/em&gt; worker将其数据在本地排序（如果可以，会在内存中执行）。当然，NOW-Sort不支持用户自定义&lt;em&gt;map&lt;/em&gt;和&lt;em&gt;reduce&lt;/em&gt;函数，这让我们的库适用范围更广。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;River 提供了一个通过分布式队列发送数据来处理程序间交互的编程模型。就像MapReduce，River系统试图在存在由异构硬件或系统干扰导致的性能不均匀的情况下提供良好的平均性能。River通过小心地调度磁盘和网络传输以使计算时间平衡的方式实现这一点。而MapReduce框架通过对编程模型进行限制，将问题划分为大量更细致的任务。这些任务在可用的worker间动态调度，以让更快的worker处理更多任务。这种受限的编程模型还允许在工作末期调度冗余执行的任务，这样可以大大缩减离群机器（如慢速或者卡死的worker）中的计算时间。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BAD-FS 采用了和MapReduce区别非常大的编程模型。与MapReduce不同，BAD-FS的目标是在广域网中执行工作。然而，有两个基本点很相似。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（1）二者都使用了冗余执行的方式恢复因故障丢失的数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（2）二者都使用了有位置感知（locality-aware）调度方式来减少拥堵的网络连接中数据发送的总量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TACC是一个为简化高可用网络服务设计的系统。像MapReduce一样，TACC依赖重新执行的方式作为容错机制。&lt;/p&gt;
&lt;h1 id=&quot;结论&quot;&gt;结论&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MapReduce编程模型被成功应用于Google中的很多目标。我们将这种成功归结于几个原因。第一，因为该模型隐藏了并行化、容错、本地优化和复杂均衡的细节，所以甚至没有相关经验的程序员都可以轻松使用。第二，很多不同的问题都可以被表示为MapReduce计算。例如，MapReduce在Google的生产系统的web搜索服务、排序、数据挖掘、机器学习和很多其他系统中被作为数据生成工具使用。第三，我们开发了一个适用于由上千台机器组成的大型集群的MapReduce实现。该实现可以高效利用这些机器的资源，因此其非常适用于Google中的大型计算问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们从这项工作中学习到了很多事。第一，对编程模型进行限制可以让并行化、分布式计算、容错等更加简单。第二，网络带宽是非常稀缺的资源。我们系统中的大量优化都是为了减少网络发送的数据量：局部性优化允许我们从本地磁盘读取数据，在本地磁盘中写单个中间数据的副本同样节约了网络带宽。第三，冗余执行可以用来减少缓慢的机器带俩的影响，并可以用来处理机器故障和数据丢失。&lt;/p&gt;
&lt;h1 id=&quot;致谢&quot;&gt;致谢&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Josh Levenberg在修订和扩展用户级MapReduce API方面提供了很大帮助，他根据自己对MapReduce的使用经验和其他人对功能增强的建议，提供了很多新特性。MapReduce从GFS 读取输入并写入输出。感谢Mohit Aron, Howard Gobioff, Markus Gutschke, David Kramer, Shun-Tak Leung和Josh Redstone在开发GFS中做出做出的工作。同样感谢Percy Liang和Olcan Sercinoglu在MapReduce使用的集群管理系统中做出的工作。Mike Burrows, Wilson Hsieh, Josh Levenberg, Sharon Perl, Rob Pike和Debby Wallach为本文的早期草稿提供了有帮助的评论。OSDI的匿名审稿者和我们的领导者Eric Brewer对本文的改进提供了帮助。最后，我们希望感谢来自Google工程师的MapReduce使用者，他们给出了很多有帮助的反馈、建议和bug报告。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[三驾马车]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/三驾马车</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/三驾马车</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><pubDate>Wed, 04 May 2022 14:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;三驾马车&quot;&gt;三驾马车&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[如何设置线程数]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/创建线程池的参数/如何设置线程数</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/创建线程池的参数/如何设置线程数</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><category><![CDATA[创建线程池的参数]]></category><pubDate>Fri, 29 Apr 2022 08:43:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;如何设置线程数&quot;&gt;如何设置线程数&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大多数文章都在扯要区分是计算密集型还是IO密集型，但是实际情况远比区分这两种复杂的多，一个线程数的设置会收到多个方面的影响。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个方面，美团给出了一个回答，动态设置 &lt;a href=&quot;https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html&quot;&gt;《Java线程池实现原理及其在美团业务中的实践》&lt;/a&gt;&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池使用面临的核心的问题在于： &lt;strong&gt;线程池的参数并不好配置&lt;/strong&gt; 。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一方面线程池的运行机制不是很好理解，配置合理需要强依赖开发人员的个人经验和知识；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另一方面，线程池执行的情况和任务类型相关性较大，IO密集型和CPU密集型的任务运行起来的情况差异非常大，这导致业界并没有一些成熟的经验策略帮助开发人员参考。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;美团给出的方案是线程池参数动态化:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;尽管经过谨慎的评估，仍然不能够保证一次计算出来合适的参数，那么我们是否可以将修改线程池参数的成本降下来，这样至少可以发生故障的时候可以快速调整从而缩短故障恢复的时间呢？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于这个思考，我们是否可以将线程池的参数从代码中迁移到分布式配置中心上，实现线程池参数可动态配置和即时生效&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220429164749.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;现有的解决方案&quot;&gt;现有的解决方案&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前市场上都是在区分&lt;code&gt;IO密集型&lt;/code&gt; 还是&lt;code&gt;计算密集型&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在《Java并发编程实战》是这么描述的&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设机器有N个CPU，那么对于计算密集型的任务，应该设置线程数为N+1；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于IO密集型的任务，应该设置线程数为2N；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于同时有计算工作和IO工作的任务，应该考虑使用两个线程池，一个处理计算任务，一个处理IO任务，分别对两个线程池按照计算密集型和IO密集型来设置线程数。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种方式有几个问题:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ds8nak5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实际项目中，往往会有多个线程池对业务进行一个线程隔离，如果都是2*N的线程数量，肯定是不合理的&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-38vo38x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池承担的流量不可能是均衡的，每个时间点都会由于自身的业务特点，出现毛刺&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-110f4bm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池尝尝会被用于调用下游接口，线程池设置了2*N，直接把下游打挂了&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，种种问题催生出了美团的动态化配置，动态化配置+线程池监控完美的解决的以上的问题。&lt;/p&gt;
&lt;h1 id=&quot;动态更新的原理&quot;&gt;动态更新的原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JDK原生线程池ThreadPoolExecutor提供了如下几个public的setter方法，如下图所示：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220429171400.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JDK允许线程池使用方通过ThreadPoolExecutor的实例来动态设置线程池的核心策略，以setCorePoolSize为方法例，在运行期线程池使用方调用此方法设置corePoolSize之后，线程池会直接覆盖原来的corePoolSize值，并且基于当前值和原始值的比较结果采取不同的处理策略。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于当前值小于当前工作线程数的情况，说明有多余的worker线程，此时会向当前idle的worker线程发起中断请求以实现回收，多余的worker在下次idel的时候也会被回收；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于当前值大于原始值且当前队列中有待执行任务，则线程池会创建新的worker线程来执行队列任务，setCorePoolSize具体流程如下：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220429171432.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;面试考点&quot;&gt;面试考点&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rlrvd1f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池被创建后里面有线程吗？如果没有的话，你知道有什么方法对线程池进行预热吗？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池被创建后如果没有任务过来，里面是不会有线程的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以通过&lt;code&gt;prestartAllCoreThreads&lt;/code&gt;方法启动所有线程&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者通过&lt;code&gt;prestartCoreThread&lt;/code&gt;预先启动一个线程&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zvlhrpm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;核心线程数会被回收吗？需要什么设置？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;核心线程数默认是不会被回收的，如果需要回收核心线程数，需要调用&lt;code&gt;allowCoreThreadTimeOut&lt;/code&gt; 该值默认为 &lt;code&gt;false&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[服务降级和熔断]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/服务治理/服务降级和熔断</link><guid isPermaLink="false">/topic/分布式解决方案/服务治理/服务降级和熔断</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[服务治理]]></category><pubDate>Fri, 29 Apr 2022 06:20:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;服务降级和熔断&quot;&gt;服务降级和熔断&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[链路追踪]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/服务治理/链路追踪</link><guid isPermaLink="false">/topic/分布式解决方案/服务治理/链路追踪</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[服务治理]]></category><pubDate>Fri, 29 Apr 2022 06:20:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;链路追踪&quot;&gt;链路追踪&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[服务监控]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/服务治理/服务监控</link><guid isPermaLink="false">/topic/分布式解决方案/服务治理/服务监控</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[服务治理]]></category><pubDate>Fri, 29 Apr 2022 06:19:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;服务监控&quot;&gt;服务监控&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[服务注册和发现]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/服务治理/服务注册和发现</link><guid isPermaLink="false">/topic/分布式解决方案/服务治理/服务注册和发现</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[服务治理]]></category><pubDate>Fri, 29 Apr 2022 06:19:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;服务注册和发现&quot;&gt;服务注册和发现&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[服务治理]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/服务治理</link><guid isPermaLink="false">/topic/分布式解决方案/服务治理</guid><category><![CDATA[分布式解决方案]]></category><pubDate>Fri, 29 Apr 2022 06:19:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;服务治理&quot;&gt;服务治理&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[分布式ID]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式ID</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式ID</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><pubDate>Fri, 29 Apr 2022 06:19:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式ID&quot;&gt;分布式ID&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[分布式锁]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式锁</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式锁</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><pubDate>Fri, 29 Apr 2022 06:18:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式锁&quot;&gt;分布式锁&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[数据库]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/数据库</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/数据库</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><pubDate>Fri, 29 Apr 2022 06:18:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;数据库&quot;&gt;数据库&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[分布式缓存]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式缓存</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式缓存</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><pubDate>Fri, 29 Apr 2022 06:18:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式缓存&quot;&gt;分布式缓存&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[数据调度]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度</guid><category><![CDATA[分布式解决方案]]></category><pubDate>Fri, 29 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;数据调度&quot;&gt;数据调度&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[服务路由]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/流量调度/服务路由</link><guid isPermaLink="false">/topic/分布式解决方案/流量调度/服务路由</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[流量调度]]></category><pubDate>Fri, 29 Apr 2022 06:16:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;服务路由&quot;&gt;服务路由&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[负载均衡]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/流量调度/负载均衡</link><guid isPermaLink="false">/topic/分布式解决方案/流量调度/负载均衡</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[流量调度]]></category><pubDate>Fri, 29 Apr 2022 06:16:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;负载均衡&quot;&gt;负载均衡&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[流量控制]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/流量调度/流量控制</link><guid isPermaLink="false">/topic/分布式解决方案/流量调度/流量控制</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[流量调度]]></category><pubDate>Fri, 29 Apr 2022 06:16:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;流量控制&quot;&gt;流量控制&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[流量调度]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/流量调度</link><guid isPermaLink="false">/topic/分布式解决方案/流量调度</guid><category><![CDATA[分布式解决方案]]></category><pubDate>Fri, 29 Apr 2022 06:16:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;流量调度&quot;&gt;流量调度&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[通讯协议-Gossip]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/通讯协议-Gossip</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/通讯协议-Gossip</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><pubDate>Fri, 29 Apr 2022 06:14:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;通讯协议-Gossip&quot;&gt;通讯协议-Gossip&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Paxos算法]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/共识算法/Paxos算法</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/共识算法/Paxos算法</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><category><![CDATA[共识算法]]></category><pubDate>Fri, 29 Apr 2022 06:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Paxos算法&quot;&gt;Paxos算法&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Raft算法]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/共识算法/Raft算法</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/共识算法/Raft算法</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><category><![CDATA[共识算法]]></category><pubDate>Fri, 29 Apr 2022 06:10:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Raft算法&quot;&gt;Raft算法&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[共识算法]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/共识算法</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/共识算法</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><pubDate>Fri, 29 Apr 2022 06:08:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;共识算法&quot;&gt;共识算法&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[分布式理论]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论</guid><category><![CDATA[分布式解决方案]]></category><pubDate>Fri, 29 Apr 2022 05:59:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式理论&quot;&gt;分布式理论&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式系统是一个硬件或者软件分布在不同的网络计算机上，位于不同网络的计算机通过消息传递进行通信和协调。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;典型引用就是区块链，区块链技术将世界各地的计算机通过分布式网络给组成到一起，使其能够将算力分摊到各个计算机中。&lt;/p&gt;
&lt;h1 id=&quot;分布式特性&quot;&gt;分布式特性&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-9ix8pss&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;性能&lt;/strong&gt; ：用于衡量一个系统处理各种任务的能力。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m4au055&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;吞吐量&lt;/strong&gt; ：系统在一定时间内可以处理的任务数。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mpjk0br&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;QPS&lt;/strong&gt; ，即每秒查询数&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yreu4x1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;TPS&lt;/strong&gt; ，即每秒事务数&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jn1zzd4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;响应时间&lt;/strong&gt; ：系统响应一个请求或输入需要花费的时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lfz6drl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;可用性&lt;/strong&gt; ：指的是系统在面对各种异常时可以正确提供服务的能力。系统的可用性可以用系统停止服务的时间与总的时间之比衡量。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gza8gax&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;可扩展性&lt;/strong&gt; ：指的是分布式系统通过扩展集群机器规模提高系统性能 (吞吐、响应时间、 完成时间)、存储容量、计算能力的特性，是分布式系统的特有性质。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;分布式分类&quot;&gt;分布式分类&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mbp0kof&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;分布式计算&lt;/strong&gt; ：解决应用的分布式计算问题。基于分布式计算模式，包括批处理计算、离线计算、在线计算、融合计算等，根据应用类型构建高效智能的分布式计算框架。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-l0defm8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;分布式存储&lt;/strong&gt; ：解决数据的分布式和多元化问题。包括分布式数据库、分布式文件系统、分布式缓存等，支持不同类型的数据的存储和管理。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pdkyq7y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;分布式通信&lt;/strong&gt; ：解决进程间的分布式通信问题。通过消息队列、远程调用等方式，实现简单高效的通信。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9bhhur5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;分布式资源管理&lt;/strong&gt; ：解决资源的分布式和异构性问题。将 CPU、内存、IO 等物理资源虚拟化，形成逻辑资源池，以便统一管理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;分布式面临的问题&quot;&gt;分布式面临的问题&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-n55iv3z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;通信异常&lt;/strong&gt; ： &lt;strong&gt;网络本身的不可靠性&lt;/strong&gt; ，因此每次网络通信都会伴随着网络不可用的风险（光纤、路由、DNS等硬件设备或系统的不可用），都会导致最终分布式系统无法顺利进行一次网络通信，另外，即使分布式系统各节点之间的网络通信能够正常执行，其延时也会大于单机操作，存在巨大的延时差别，也会影响消息的收发过程，因此消息丢失和消息延迟变的非常普遍。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ijsfgxh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;网络分区&lt;/strong&gt; ： &lt;strong&gt;网络之间出现了网络不连通，但各个子网络的内部网络是正常的&lt;/strong&gt; ，从而导致整个系统的网络环境被切分成了若干个孤立的区域， &lt;strong&gt;分布式系统就会出现局部小集群&lt;/strong&gt; ，在极端情况下，这些小集群会独立完成原本需要整个分布式系统才能完成的功能，包括数据的事务处理，这就对分布式一致性提出非常大的挑战。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kfl7bh6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;节点故障&lt;/strong&gt; ：节点故障是分布式系统下另一个比较常见的问题，指的是组成分布式系统的服务器节点出现的宕机或&amp;quot;僵死&amp;quot;现象，每个节点都有可能出现故障，并且经常发生.&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qlw3jj1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;三态&lt;/strong&gt; ：分布式系统每一次请求与响应存在特有的“三态”概念，即 &lt;strong&gt;成功、失败和超时&lt;/strong&gt; 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[缓存穿透]]></title><link>https://www.ztianzeng.com/topic/redis/Redis分布式缓存/缓存穿透</link><guid isPermaLink="false">/topic/redis/Redis分布式缓存/缓存穿透</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis分布式缓存]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;缓存穿透&quot;&gt;缓存穿透&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;是值查询一个缓存和数据库中都没有的数据，由于大部分的缓存策略是被动加载的，并且处于容错考虑，如果从存储层查不到数据则不写入缓存。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个不存在的数据每次都会到存储层去查询，失去缓存的意义，用户不断发起请求，量大甚至可以导致缓存雪崩。&lt;/p&gt;
&lt;h1 id=&quot;接口校验&quot;&gt;接口校验&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不要相信前端传来的东西，所以数据一定要在后端进行校验。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以在接口层添加校验，不合法的直接返回即可，没必要做后续的操作。&lt;/p&gt;
&lt;h1 id=&quot;空对象缓存或者缺省值&quot;&gt;空对象缓存或者缺省值&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般情况下OK。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;但是&lt;/strong&gt;黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2o573t7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;id相同:&lt;/strong&gt; 第一次打到DB，空对象缓存后第二次就返回null了，避免DB被攻击，不用再到数据库中去走一圈了&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0410pat&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;id不同:&lt;/strong&gt; 由于存在空对象缓存和缓存回写，redis中的无关紧要的key也会越写越多&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;布隆过滤器&quot;&gt;布隆过滤器&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20210918170608143.png&quot; alt=&quot;image-20210918170608143&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[缓存雪崩]]></title><link>https://www.ztianzeng.com/topic/redis/Redis分布式缓存/缓存雪崩</link><guid isPermaLink="false">/topic/redis/Redis分布式缓存/缓存雪崩</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis分布式缓存]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;缓存雪崩&quot;&gt;缓存雪崩&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当某一个时刻出现大规模的缓存失效，那么就会导致大量的请求打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就导致数据库党纪。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这个时候，马上重启数据库，马上又会有新的流量把数据库打死。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Xnip2021-09-16_16-10-29.jpg&quot; alt=&quot;Xnip2021-09-16_16-10-29&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;造成缓存大规模失效的原因：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-oja7ee0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis宕机&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bvgiaos&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大量的热点Key在相同的时间过期&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;解决方案&quot;&gt;解决方案&lt;/h1&gt;
&lt;h2 id=&quot;三步骤&quot;&gt;三步骤&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-s7azmg1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事前：redis高可用部署，避免全盘崩溃；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jfpc9wt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事中：本地缓存 + 限流降级，避免数据库被打死；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j8xlgdo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事后：redis持久化，快速恢复缓存数据；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-93r607f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis集群高可用&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-agz6i1i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主从+哨兵&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gkmd8r2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis Cluster&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5higjcp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis开启AOF/RDB，尽快恢复redis访问&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s6owpa4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;热点key随机过期时间&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dhd4d3x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;避免在同一个时间，请求涌入数据库&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hk5s3kk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提高数据库的容灾能力&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nqr0b91&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分库分表&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ogqold1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读写分离&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8folgu8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;熔断限流降级&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vnzu587&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Hystrix&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cx7en63&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阿里sentinel&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[缓存预热]]></title><link>https://www.ztianzeng.com/topic/redis/Redis分布式缓存/缓存预热</link><guid isPermaLink="false">/topic/redis/Redis分布式缓存/缓存预热</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis分布式缓存]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;缓存预热&quot;&gt;缓存预热&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存预热就是系统上线后，后者系统在重启的时候，将相关的缓存数据直接加载到Redis。&lt;br /&gt;
这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解决：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-w89ga83&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上线时加个接口，手动触发加载缓存，或者定时刷新缓存。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7ri9dhh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据量不大，可以在项目启动的时候自动进行加载。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[缓存击穿]]></title><link>https://www.ztianzeng.com/topic/redis/Redis分布式缓存/缓存击穿</link><guid isPermaLink="false">/topic/redis/Redis分布式缓存/缓存击穿</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis分布式缓存]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;缓存击穿&quot;&gt;缓存击穿&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大量的请求同时查询一个key时，假设此时，这个key正好失效了，就会导致大量的请求都打到数据库上面去。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存击穿和缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库。&lt;/p&gt;
&lt;h1 id=&quot;解决方案&quot;&gt;解决方案&lt;/h1&gt;
&lt;h2 id=&quot;不过期&quot;&gt;不过期&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们简单粗暴点，直接让热点数据永远不过期，定时任务定期去刷新数据就可以了。不过这样设置需要区分场景，比如某宝首页可以这么做&lt;/p&gt;
&lt;h2 id=&quot;互斥锁&quot;&gt;互斥锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了避免出现缓存击穿的情况，我们可以在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，后面的线程进来发现已经有缓存了，就直接走缓存，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Test {
    public String get(String key) {
        //查询缓存
        String value = redis.get(key);
        if (value != null) {
            //缓存存在直接返回
            return value;
        } else {
            //缓存不存在则对方法加锁
            //假设请求量很大，缓存过期
            synchronized (Test.class) {
                //再查一遍redis
                value = redis.get(key);
                if (value != null) {
                    // 查到数据直接返回
                    return value;
                } else {
                    // 二次查询缓存也不存在，直接查DB
                    value = dao.get(key);
                    // 数据缓存
                    redis.setnx(key, value, time);
                    //返回
                    return value;
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[redis持久化]]></title><link>https://www.ztianzeng.com/topic/redis/Redis集群/redis持久化</link><guid isPermaLink="false">/topic/redis/Redis集群/redis持久化</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis集群]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;redis持久化&quot;&gt;redis持久化&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为Redis是一个内存数据库，所有的数据都保存在内存里面，一旦发生关机或者重启，内存中的数据都会丢失，所以为了重启的时候能够及时的恢复数据，redis提供了持久化机制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在运行正常期间根据策略生成持久化文件，在机器重启后，能够根据持久化文件恢复内存中的数据。即使redis有主从同步的模式，主节点挂掉之后可以让从节点变成主节点，但是如果整个机房都发生停电，那么从节点和从节点内存中的数据都会丢失。&lt;/p&gt;
&lt;h1 id=&quot;策略&quot;&gt;策略&lt;/h1&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;持久化策略&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;大概原理&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;优缺点&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;配置方法&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;AOF&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;记录所有的操作命令，&lt;br /&gt;并以文本的形式追加到文件中&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;文件大，恢复慢，性能影响大，但实时性高，丢失数据最少,持久化保存的数据更加完整&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;默认关闭&lt;br /&gt;redis.conf中appendonly设置为true&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;RDB&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;当前进程数据生成快照保存到硬盘&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;文件小，恢复快，不影响性能，实时性低，兼容性差(老版本redis不兼容新版本的RDB文件)&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;默认开启，满足一定条件就会触发RDB文件的生成&lt;br /&gt;也可以执行SAVE和BGSAVE手动触发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;混合持久化&lt;br /&gt;(Redis 4.0 之后新增)&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，&lt;br /&gt;再将后续的操作命令以 AOF 的格式存入文件&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Redis 可以更快的启动，同时结合 AOF 的优点，又减低了大量数据丢失的风险。&lt;br /&gt;AOF 文件中添加了 RDB 格式的内容，会使得 AOF 文件的可读性会很差，不容易阅读&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;默认关闭，通过redis.conf中的aof-use-rdb-preamble开启&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;AOF持久化&quot;&gt;AOF持久化&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/1460000022911658.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;执行流程&quot;&gt;执行流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AOF的持久化主要是在Redis执行命令之后，将命令添加到aof_buf的末尾,然后在每次事件结束时根据appendfsync的配置，来决定是否将aof_buf缓冲区的内容写入和保存到AOF文件中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于性能考虑一般生产环境的配置都是everysec&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;appendfsync 参数有三个选项：&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-s9b8ntv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;always：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fz44r7p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，即每秒刷盘1次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o09uac2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。即不执行刷盘，让操作系统自己执行刷盘。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;怎么防止AOF文件越来越大-&quot;&gt;怎么防止AOF文件越来越大？&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了防止AOF文件越来越大，可以通过执行BGREWRITEAOF命令，会fork子进程出来，读取当前数据库的键值对信息，生成所需的写命令，写入新的AOF文件。在生成期间，父进程继续正常处理请求，执行修改命令后，不仅会将命令写入aof_buf缓冲区，还会写入重写aof_buf缓冲区。当新的AOF文件生成完毕后，子进程父进程发送信号，父进程将重写aof_buf缓冲区的修改命令写入新的AOF文件，写入完毕后，对新的AOF文件进行改名，原子地（atomic）地替换旧的AOF文件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;BGREWRITEAOF命令&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BGREWRITEAOF命令用于异步执行一个 AOF 文件重写操作。重写会创建一个当前 AOF 文件的体积优化版本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;即使 Bgrewriteaof 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 Bgrewriteaof 成功之前不会被修改。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;br /&gt;
从 Redis 2.4 开始， AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操作。&lt;/p&gt;
&lt;h4 id=&quot;AOF文件追加阻塞-&quot;&gt;AOF文件追加阻塞？&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改命令添加到aof_buf之后，如果配置是everysec那么会每秒执行fsync操作，调用write写入磁盘一次，但是如果硬盘负载过高，fsync操作可能会超过1s，Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快，所以Redis的处理逻辑是会对比上次fsync成功的时间，如果超过2s，则主线程阻塞直到fsync同步完成，所以最多可能丢失2s的数据，而不是1s。&lt;/p&gt;
&lt;h1 id=&quot;RDB持久化&quot;&gt;RDB持久化&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RDB持久化指的是在满足一定的触发条件时（在一个的时间间隔内执行修改命令达到一定的数量，或者手动执行SAVE和BGSAVE命令），对这个时间点的数据库所有键值对信息生成一个压缩文件dump.rdb，然后将旧的删除，进行替换。&lt;/p&gt;
&lt;h4 id=&quot;执行流程-&quot;&gt;执行流程&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现原理是fork一个子进程，然后对键值对进行遍历，生成rdb文件，在生成过程中，父进程会继续处理客户端发送的请求，当父进程要对数据进行修改时，会对相关的内存页进行拷贝，修改的是拷贝后的数据。（也就是COPY ON WRITE，写时复制技术，就是当多个调用者同时请求同一个资源，如内存或磁盘上的数据存储，他们会共用同一个指向资源的指针，指向相同的资源，只有当一个调用者试图修改资源的内容时，系统才会真正复制一份专用副本给这个调用者，其他调用者还是使用最初的资源,在CopyOnWriteArrayList的实现中，也有用到，添加或者插入一个新元素时过程是，加锁，对原数组进行复制，然后添加新元素，然后替代旧数组，解锁）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/1460000022911660.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;    //CopyOnWriteArrayList的添加元素的方法
public boolean add(E e) {
  final ReentrantLock lock = this.lock;
  lock.lock();
  try {
    Object[] elements = getArray();
    int len = elements.length;
    Object[] newElements = Arrays.copyOf(elements, len + 1);
    newElements[len] = e;
    setArray(newElements);
    return true;
  } finally {
    lock.unlock();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;混合持久化-Redis4-0--&quot;&gt;混合持久化（Redis4.0+）&lt;/h1&gt;
&lt;h2 id=&quot;执行流程--&quot;&gt;执行流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;混合持久化同样也是通过&lt;strong&gt;bgrewriteaof&lt;/strong&gt;命令完成的，不同的是当开启混合持久化时，fork出的子进程先将当前内存中的键值对信息全量的以RDB方式写入aof文件，然后在将重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。&lt;/p&gt;
&lt;h1 id=&quot;Redis的数据恢复策略&quot;&gt;Redis的数据恢复策略&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;优先级:&lt;br /&gt;
混合持久化 &amp;gt; AOF &amp;gt; RDB&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8idabqw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果配置了混合持久化，那么根据混合持久化文件进行恢复数据。（Redis4.0+）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-f4np6sm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只配置 AOF ，重启时加载 AOF 文件恢复数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zba9gje&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;同时配置了 RDB 和 AOF ，启动时只加载 AOF文件恢复数据，如果AOF文件损坏，那么根据RDB文件恢复数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0rt3pwc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只配置 RDB，启动时加载RDB持久化文件恢复数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;Redis持久化策略该如何进行选择&quot;&gt;Redis持久化策略该如何进行选择&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（因为混合持久化是Redis 4.0之后支持的，目前一般生成环境使用的Redis版本可能都还较低，所以这里的策略选择主要是针对AOF持久和RDB持久化进行技术选型。）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以下是几种持久化方案选择的场景：&lt;/p&gt;
&lt;h4 id=&quot;1-不需要考虑数据丢失的情况&quot;&gt;1.不需要考虑数据丢失的情况&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么不需要考虑持久化。&lt;/p&gt;
&lt;h4 id=&quot;2-单机实例情况下&quot;&gt;2.单机实例情况下&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以接受丢失十几分钟及更长时间的数据，可以选择RDB持久化，对性能影响小，如果只能接受秒级的数据丢失，只能选择AOF持久化。&lt;/p&gt;
&lt;h4 id=&quot;3-在主从环境下&quot;&gt;3.在主从环境下&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为主服务器在执行修改命令后，会将命令发送给从服务器，从服务进行执行后，与主服务器保持数据同步，实现数据热备份，在master宕掉后继续提供服务。同时也可以进行读写分离，分担Redis的读请求。&lt;/p&gt;
&lt;h5 id=&quot;那么在从服务器进行数据热备份的情况下-是否还需要持久化呢-&quot;&gt;那么在从服务器进行数据热备份的情况下，是否还需要持久化呢？&lt;/h5&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要持久化，因为不进行持久化，主服务器，从服务器同时出现故障时，会导致数据丢失。（例如：机房全部机器断电）。如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的。应尽量避免“自动拉起机制”和“不做持久化”同时出现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以一般可以采用以下方案：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主服务器不开启持久化，使得主服务器性能更好。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从服务器开启AOF持久化，关闭RDB持久化，并且定时对AOF文件进行备份，以及在凌晨执行bgaofrewrite命令来进行AOF文件重写，减小AOF文件大小。（当然如果对数据丢失容忍度高也可以开启RDB持久化，关闭AOF持久化）&lt;/p&gt;
&lt;h5 id=&quot;4-异地灾备&quot;&gt;4.异地灾备&lt;/h5&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般性的故障（停电，关机）不会影响到磁盘，但是一些灾难性的故障（地震，洪水）会影响到磁盘，所以需要定时把单机上或从服务器上的AOF文件，RDB文件备份到其他地区的机房。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[ZSet的底层实现]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构/ZSet的底层实现</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构/ZSet的底层实现</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis基本数据结构]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ZSet的底层实现&quot;&gt;ZSet的底层实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当有序集合中包含的元素数量超过服务器属性&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;zset_max_ziplist_entries 的值（默认值为 128 ），&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者 有序集合中新添加元素的 member 的长度大于服务器属性&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;zset_max_ziplist_value 的值（默认值为 64 ）时，&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis会使用 跳跃表 作为有序集合的底层实现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;否则会使用ziplist作为有序集合的底层实现&lt;/p&gt;
&lt;h1 id=&quot;跳表是什么-&quot;&gt;跳表是什么?&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;跳表 = 链表 + 多级索引.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;skiplist是一种以空间换取时间的结构。 时间复杂度O(logN),空间复杂度O(n);&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于链表，无法进行二分查找，因此借鉴数据库索引的思想，提取出链表中关键节点（索引），先在关键节点上查找，再进入下层链表查找。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提取多层关键节点，就形成了跳跃表.&lt;/p&gt;
&lt;h2 id=&quot;优缺点&quot;&gt;优缺点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只有在 数据量较大的情况下 才能体现出来优势。&lt;br /&gt;
而且应该是 读多写少的情况下 才能使用，所以它的适用范围应该还是比较有限的&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;维护成本相对要高, 新增或者删除时需要把所有索引都更新一遍；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后在新增和删除的过程中的更新，时间复杂度也是O(log n)&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;../img/redis_jump.jpg&quot; alt=&quot;跳表&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Set的底层实现]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构/Set的底层实现</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构/Set的底层实现</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis基本数据结构]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Set的底层实现&quot;&gt;Set的底层实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis用intset或hashtable存储set。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果元素都是整数类型，就用intset存储。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不是整数类型，就用hashtable（数组+链表的存来储结构）。key就是元素的值，value为null。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[String的底层实现]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构/String的底层实现</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构/String的底层实现</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis基本数据结构]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;String的底层实现&quot;&gt;String的底层实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;String的底层实现是SDS（Simple dynamic String）。&lt;/p&gt;
&lt;h1 id=&quot;SDS-结构&quot;&gt;SDS 结构&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* 当前字符串数组的长度 */
    uint8_t alloc; /* 当前字符串分配的总内存大小 */
    unsigned char flags; /* 当前的字符串标记，用来标识是sdshdr8,sdshdr16等 */
    char buf[]; /* 字符串真正的值 */
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;相对于C语言的优势&quot;&gt;相对于C语言的优势&lt;/h1&gt;
&lt;h2 id=&quot;统计长度时间复杂度-O-1-&quot;&gt;统计长度时间复杂度 O(1)&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;工作中使用redis，经常会通过STRLEN命令得到一个字符串的长度， 在SDS结构中len属性记录了字符串的长度，所以我们获取一个字符串长度直接取len的值，复杂度是O(1)。&lt;/p&gt;
&lt;div data-content=&quot;graph LR;
  &apos;A&apos;--&amp;gt;&apos;B&apos;
  &apos;B&apos;--&amp;gt;&apos;C&apos;
  &apos;C&apos;--&amp;gt;&apos;D&apos;
  &apos;D&apos;--&amp;gt;&apos;\0&apos;
  &apos;\0&apos;--&amp;gt;&apos;1&apos;
  &apos;\0&apos;--&amp;gt;|发现&apos;\0&apos;不计数|&apos;\0&apos;
  &apos;1&apos;--&amp;gt;&apos;2&apos;
  &apos;2&apos;--&amp;gt;2(&apos;\0&apos;)
  &apos;A&apos;--&amp;gt;|len=1|&apos;A&apos;
  &apos;D&apos; &amp;lt;--&amp;gt; |len=4|&apos;A&apos;&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而如果用C字符串，在获取一个字符串长度时，需对整个字符串进行遍历，直至遍历到空格符结束（C中遇到空格符代表一个完整字符串），此时的复杂度是O(N)。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在高并发场景下频繁遍历字符串，获取字符串的长度很有可能成为redis的性能瓶颈，所以SDS性能更好一些。数据溢出&lt;/p&gt;
&lt;h2 id=&quot;数据溢出&quot;&gt;数据溢出&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于C字符串是不记录自身长度的，相邻的两个字符串存储的方式可能如下图，在创建字符串的时候就分配了合适的内存空间。&lt;/p&gt;
&lt;div data-content=&quot;graph LR;
  &apos;A&apos;--&amp;gt;&apos;B&apos;
  &apos;B&apos;--&amp;gt;&apos;C&apos;
  &apos;C&apos;--&amp;gt;&apos;D&apos;
  &apos;D&apos;--&amp;gt;&apos;\0&apos;
  &apos;\0&apos;--&amp;gt;&apos;1&apos;
  &apos;1&apos;--&amp;gt;&apos;2&apos;
  &apos;2&apos;--&amp;gt;2(&apos;\0&apos;)&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这个时候，想修改字符串 ABCD 成 ABCDE ，就会侵占相邻字符串的空间，自身数据溢出导致其他字符串的内容被修改。&lt;/p&gt;
&lt;div data-content=&quot;graph LR;
  &apos;A&apos;--&amp;gt;&apos;B&apos;
  &apos;B&apos;--&amp;gt;&apos;C&apos;
  &apos;C&apos;--&amp;gt;&apos;D&apos;
  &apos;D&apos;--&amp;gt;&apos;E&apos;
  &apos;E&apos;--&amp;gt;&apos;\0&apos;
  &apos;\0&apos;--&amp;gt;&apos;2&apos;
  &apos;2&apos;--&amp;gt;2(&apos;\0&apos;)&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而SDS很好的规避了这点，当我们需要修改数据时，首先会检查当前SDS空间len是否满足，不满足则自动扩容空间至修改所需的大小，然后再执行修改。&lt;/p&gt;
&lt;h2 id=&quot;内存重分配策略&quot;&gt;内存重分配策略&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;C字符串的长度是一定的，所以每次在增长或者是缩短字符串的时候，都需要做内存的重新分配，而内存重新分配又是一个&lt;br /&gt;
比较耗时的操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SDS通过两种内存重分配策略，在解决字符串增长和缩短时兼顾效率和性能&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-aso86dn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空间预分配 优化SDS字符串增长&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当修改字符串并需要对SDS空间进行扩展式，不仅会分配修改所必要的空间，还会为SDS分配额外的未使用空间，&lt;br /&gt;
下次修改先检查未使用空间是否满足，满足则不用再扩展空间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m4bt7bz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果对 SDS 字符串修改后，len 值小于 1M，那么此时额外分配未使用空间 free 的大小与len相等。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mlprbr9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果对 SDS 字符串修改后，len 值大于等于 1M，那么此时额外分配未使用空间 free 的大小为1M。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&quot;3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qpjrq8j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;惰性空间释放 优化SDS字符串缩短&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;惰性空间释放策略则用于优化SDS字符串缩短操作，当缩短SDS字符串后，并不会立即执行内存重分配来回收多余的空间，而是用free属性将这些空间记录下来，如果后续有增长操作，则可直接使用。&lt;/p&gt;
&lt;h2 id=&quot;数据格式多样性&quot;&gt;数据格式多样性&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;C字符串中的字符必须符合某些特定的编码格式，C字符串以\0空字符结尾标识一个字符串结束，所以字符串里边是不能包含\0的，不然就会被误认是多个。&lt;br /&gt;
由于这种限制，使得C字符串只能保存文本数据，像音视频、图片等二进制格式的数据是无法存储的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis 会以处理二进制的方式操作Buf数组中的数据，所以对存入其中的数据做任何的限制、过滤，只要存进来什么样，取出来还是什么样。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th&gt;C语言&lt;/th&gt;
&lt;th&gt;SDS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;字符串长度处理&lt;/td&gt;
&lt;td&gt;需要从头开始遍历，直到遇到 &apos;\0&apos; 为止，时间复杂度O(N)&lt;/td&gt;
&lt;td&gt;记录当前字符串的长度，直接读取即可，时间复杂度 O(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;内存重新分配&lt;/td&gt;
&lt;td&gt;分配内存空间超过后，&lt;br /&gt;会导致数组下标越级或者内存分配溢出&lt;/td&gt;
&lt;td&gt;空间预分配 &amp;lt;br&amp;gt;SDS 修改后，len 长度小于 1M，那么将会额外分配与 len 相同长度的未使用空间。如果修改后长度大于 1M，那么将分配1M的使用空间。&amp;lt;br&amp;gt;惰性空间释放有&amp;lt;br&amp;gt;空间分配对应的就有空间释放。SDS 缩短时并不会回收多余的内存空间，而是使用 free 字段将多出来的空间记录下来。如果后续有变更操作，直接使用 free 中记录的空间，减少了内存的分配。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;二进制安全&lt;/td&gt;
&lt;td&gt;二进制数据并不是规则的字符串格式，可能会包含一些特殊的字符，比如 &apos;\0&apos; 等。&lt;br /&gt;前面提到过，C中字符串遇到 &apos;\0&apos; 会结束，那 &apos;\0&apos; 之后的数据就读取不上了&lt;/td&gt;
&lt;td&gt;根据 len 长度来判断字符串结束的，二进制安全的问题就解决了&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;三大编码&quot;&gt;三大编码&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 内部会根据用户给的不同键值而使用不同的编码格式!&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ur00cou&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;int: 保存long型的64位有符号整数,范围 [ -2&lt;sup&gt;63 , 2&lt;/sup&gt;63-1 ]&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pqlkj4z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;embstr: 保存长度小于44字节的字符串&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1aoue20&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;raw: 保存长度大于44字节的字符串&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以下是处理流程&lt;/p&gt;
&lt;div data-content=&quot;graph TD;
    开始--&amp;gt;B(是不是embstr或者raw字符串?);
    B--&amp;gt;|否|结束;
    B--&amp;gt;|是|C{字符串长度&amp;lt;20 并且可以 转换为long类型};
    C--&amp;gt;|是|D{是否配置maxmemory切整数范围 0 ,10000};
    D--&amp;gt;|是|E(直接从共享数据里面拿到);
    D--&amp;gt;|否,根据embstr和raw再分别处理|结束;
    C--&amp;gt;|否|F{字符串长度&amp;lt;44}
    F--&amp;gt;|是,编码为emstr|结束
    F--&amp;gt;|否,直接返回原始对象|结束
    E--&amp;gt;结束&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
</content:encoded></item><item><title><![CDATA[看门狗模式]]></title><link>https://www.ztianzeng.com/topic/redis/Redis的分布式锁/看门狗模式</link><guid isPermaLink="false">/topic/redis/Redis的分布式锁/看门狗模式</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis的分布式锁]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;看门狗模式&quot;&gt;看门狗模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/e0ecde8897f3a08baed00866f0c6525dd539ecaa.png@942w_593h_progressive.webp&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;看门狗的工作模式如上图所示。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本质就是当某个线程获取到锁之后，在业务结束之前，需要定时对目标所的过期时间持续延期，以此来确保解锁的时候业务状态是正确的。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redlock]]></title><link>https://www.ztianzeng.com/topic/redis/Redis的分布式锁/Redlock</link><guid isPermaLink="false">/topic/redis/Redis的分布式锁/Redlock</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis的分布式锁]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redlock&quot;&gt;Redlock&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RedLock的基本思路就是为锁准备多个副本，避免Redis主从切换的时候，数据丢失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redlock是分布式锁在利用Redis上的一种具体实现，RedLock 是利用了Redis实现了DLM (Distributed Lock Manager), 包含了首先获得多数选票，并设置一个租约(lease)时间的功能, 来保证分布式锁的正确性，和高效性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设有N个master节点，通常情况下为5个节点，而且这些节点完全独立，5个节点既保证了性能的同时，又增加了可靠的容错性。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h4kmc6s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端首先获取当前时间，单位为毫秒&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-r6t0iqa&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端依次尝试在N个redis节点上获取锁，使用通用key和随机数。客户端请求redis的超时时间要远小于锁的释放时间，假如锁的有效时间为10s，则客户端请求的超时时间要设置5-50ms。这避免了当某个redis不可用时，客户端会hold住很长时间&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k751fui&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端会计算请求锁时消耗的时间，当客户端获取超过半数成功，且流逝的时间小于锁的有效期时间，则说明客户端成功获取到锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b1jtxy3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;成功获得锁后，锁的有效期 = 原来锁的有效期(10s) - 流逝的时间&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vnxtv24&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果锁获取失败了，那么客户端应该立即向所有reids节点发起释放锁的操作&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;问题1&quot;&gt;问题1&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于N个Redis节点中的大多数能正常功能就能保证Redlock正常工作，因此理论上它的可用性更高。单Redis节点的分布式锁在failover的时候锁失效的问题，在Redlock中不存在了，但如果有节点发生崩溃重启，还是会对锁的安全性有影响。具体的影响程度跟Redis对数据的持久化程度有关。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设一共有5个Redis节点：A B C D E。设想发生了如下的事件序列：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-cki4k1p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端1成功锁住了A B C，获取锁成功（但D和E没有锁住）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n3g2s14&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hcr1cv2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点C重启后，客户端2锁住了C D E，获取锁成功&lt;br /&gt;
这样，客户端1和客户端2同时获得了锁（针对同一资源）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在默认情况下，Redis的AOF持久化方式是每秒写一次磁盘（即执行fsync），因此最坏情况下可能丢失1秒的数据。为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据（这取决于系统而不是Redis的实现）。所以上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，antirez又提出了延迟重启（delayed restarts）的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间（lock validty time）。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。&lt;/p&gt;
&lt;h2 id=&quot;问题2&quot;&gt;问题2&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/redlock1.png&quot; alt=&quot;redlock&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如上面的时序图所示，假设锁服务本身是没有问题的，它总是能保证任一时刻最多只有一个客户端获得锁。上图中出现的lease这个词可以暂且认为就等同于一个带有自动过期功能的锁。客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除了GC以外，有很多原因会导致进程的pause，比如需存造成的缺页故障(page falut)，再比如CPU资源的竞争。即使不考虑进程pause的情况，网络延迟也仍然会造成类似的结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总结起来就是说，即使锁服务本身是没有问题的，而仅仅是客户端有长时间的pause或网络延迟，仍然会造成两个客户端同时访问共享资源的冲突情况发生。&lt;/p&gt;
&lt;h2 id=&quot;问题3&quot;&gt;问题3&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下示例说明了Redlock对系统计时(timing)过分依赖，还是假设有5个Redis节点A B C D E：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5cu32eu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端1从Redis节点A B C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o9kyif1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-17brso2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户单2从Redis节点C D E成功获取了同一个资源的锁（多数节点）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1vtxwjk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端1和客户端2现在都认为自己持有了锁&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面这种情况之所以有可能发生，本质上是因为Redlock的安全性(safety property)对系统的时钟有比较强的依赖，一旦系统的时钟变得不准确，算法的安全性也就保证不了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;好的分布式算法应该基于异步模型(asynchronous model)，算法的安全性不应该依赖于任何计时假设(timing assumption)。在异步模型中：进程可能pause任意上的时间，消息可能在网络中延迟任意长的时间，甚至丢失，系统时钟也可能以任意方式出错。一个好的分布式算法，这些因素不应该影响它的安全性(safety property)，只可能影响它的活性(liveness property)，也就是说，即使在非常极端的情况下(比如系统时钟严重错误)，算法顶多是不能再有限的时间内给出结果而已，而不应该给出错误的结果。这样的算法在现实中是存在的，像比较著名的Paxos或Raft。但显然按这个标准的话，Redlock的安全性级别是达不到的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;锁的用途可以分为以下两种：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bo32qpl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了效率(efficiency)。协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其他的不良后果。比如重复发送一封同样的email。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8l2s17q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，或者其他严重的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此应该根据不同的场景选择不同的锁：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-j316ecm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果是为了效率(efficiency)而使用分布式锁，允许锁的偶尔失效，那么使用单Redis节点的锁方案就足够了，简单而且效率高。Redlock而是一个过重的实现&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9ii4q8e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果是为了正确性(correctness)在很严肃的场合使用分布式锁，那么不要使用Redlock。它不是建立在异步模型上的一个足够强的算法，它对于系统模型的假设中包含很多危险的成分(对于timing)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[redis单线程的问题]]></title><link>https://www.ztianzeng.com/topic/redis/Redis为什么这么快/redis单线程的问题</link><guid isPermaLink="false">/topic/redis/Redis为什么这么快/redis单线程的问题</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis为什么这么快]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;redis单线程的问题&quot;&gt;redis单线程的问题&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正常情况下使用del指令可以很快的删除数据，&lt;br /&gt;
而当被删除的 key 是一个非常大的对象时，&lt;br /&gt;
例如时包含了成千上万个元素的 hash 集合时，&lt;br /&gt;
那么 del 指令就会造成 Redis 主线程卡顿。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在高并发下面，redis的表现就是其他客户端请求无响应。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis分布式缓存]]></title><link>https://www.ztianzeng.com/topic/redis/Redis分布式缓存</link><guid isPermaLink="false">/topic/redis/Redis分布式缓存</guid><category><![CDATA[redis]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis分布式缓存&quot;&gt;Redis分布式缓存&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用redis作为最基本的功能，缓存mysql中的数据，加快响应速度&lt;/p&gt;
&lt;h1 id=&quot;双写一致性&quot;&gt;双写一致性&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;双写一致性，是redis做为缓存的时候一道非常经典的问题&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为无论先操作db还是cache，都会有各自的问题，根本原因是cache和db的更新不是一个原子操作，因此总会有不一致的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一致性可以分为三个等级:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4nejdwv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;强一致性&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8spaemj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o819opf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;弱一致性&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-n03pclm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7uwaaxn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最终一致性&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-o264b2e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;缓存更新策略&quot;&gt;缓存更新策略&lt;/h1&gt;
&lt;h2 id=&quot;最常见的策略&quot;&gt;最常见的策略&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-01-01.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;优点剖析&quot;&gt;优点剖析&lt;/h4&gt;
&lt;h4 id=&quot;1---先淘汰缓存-再写数据库--合理&quot;&gt;1. “先淘汰缓存，再写数据库” 合理&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为什么说这也算优点呢？试想一下&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果把写流程改一下：&lt;strong&gt;先更新缓存，再更新DB&lt;/strong&gt;。 如果我们更新缓存成功，而更新数据库失败，就会导致缓存中的数据是错误的，而我们大部分的业务一般能忍受数据延迟，但是数据错误这是无法接受的，所以先淘汰缓存是比较合理的。 如果把写流程改一下：&lt;strong&gt;不删缓存，先更新DB，再更新缓存&lt;/strong&gt;。 如果我们更新DB成功，而更新缓存失败，则会导致缓存中就会一直是旧的数据（也算是一种错误数据），所以先淘汰缓存是比较合理的。&lt;/p&gt;
&lt;h4 id=&quot;2--异步刷新-补缺补漏&quot;&gt;2. 异步刷新，补缺补漏&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在很多业务场景中，缓存只是辅助，&lt;strong&gt;所以在很多业务中，缓存的读写失败不会影响主流程&lt;/strong&gt;，啥意思呢？就是说很多情况下，即使操作缓存失败（比如步骤1.1中的’DEL缓存失败’），程序还是会继续往下走（继续步骤1.2 更新数据库)，所以这个时候异步刷新就能在一定程度上，对1.1的失败进行错误数据的修补&lt;/p&gt;
&lt;h4 id=&quot;缺点剖析&quot;&gt;缺点剖析&lt;/h4&gt;
&lt;h4 id=&quot;1--容灾不足&quot;&gt;1. 容灾不足&lt;/h4&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在分布式领域，“Everything will fails”，任何可能出现问题的地方都会出现问题&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们来分析一下写流程，第一步，’DEL缓存失败’怎么办？流程是否还继续走？如果继续执行，那么从’更新完DB’到异步’刷新缓存’缓存期间，数据处于滞后状态。而且如果缓存处于不可写状态，那么异步刷新那步也可能会失败，那缓存就会长期处于旧数据，问题就比较严重了&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果A线程更新数据库内容失败，导致B线程请求再次访问缓存时，发现redis里面没数据，缓存缺失，再去读取mysql时， 从数据库中读取到旧值&lt;/p&gt;
&lt;h4 id=&quot;2--并发问题&quot;&gt;2. 并发问题&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写写并发：&lt;/strong&gt;试想一下，同时有多个服务器的多个线程进行’步骤1.2更新DB’，更新DB完成之后，它们就要进行异步刷缓存，我们都知道多服务器的异步操作，是无法保证顺序的，所以后面的刷新操作存在相互覆盖的并发问题，&lt;strong&gt;也就是说，存在先更新的DB操作，反而很晚才去刷新缓存&lt;/strong&gt;，那这个时候，数据也是错的&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读写并发：&lt;/strong&gt;再试想一下，服务器A在进行’读操作’，，在A服务器刚完成2.2时，服务器B在进行’写操作’，假设B服务器1.3完成之后，服务器A的1.3才被执行，这个时候就相当于更新前的老数据写入缓存，最终数据还是错的&lt;/p&gt;
&lt;h4 id=&quot;方案总结&quot;&gt;方案总结&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;适合大部分的业务场景，很多人都在用，香还是很香的，实现起来也简单。&lt;br /&gt;
&lt;strong&gt;适合使用的场景：并发量、一致性要求都不是很高的情况&lt;/strong&gt;。&lt;br /&gt;
我觉得这个方案有一个比较大的缺陷在于&lt;strong&gt;刷新缓存有可能会失败，而失败之后缓存中数据就一直会处于错误状态，所以它并不能保证数据的最终一致性&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证“数据最终一致性”，我们引入binlog，通过解析binlog来刷新缓存，这样即使刷新失败，依然可以进行日志回放，再次刷新缓存&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-02-01.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;写流程-&quot;&gt;写流程：&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一步先删除缓存，删除之后再更新DB，我们监听从库(资源少的话主库也ok)的binlog，通过分析binlog我们解析出需要需要刷新的数据，然后读主库把最新的数据写入缓存。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里需要提一下：最后刷新前的读主库或者读从库，甚至不读库直接通过binlog解析出需要的数据都是ok的，这由业务决定，&lt;strong&gt;比如刷新的数据只是表的一行，那直接通过binlog就完全能解析出来；然而如果需要刷新的数据来自多行，多张表，甚至多个库的话，那就需要读主库或是从库才行&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;读流程-&quot;&gt;读流程：&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一步先读缓存，如果缓存没读到，则去读DB，之后再异步将数据刷回缓存&lt;/p&gt;
&lt;h2 id=&quot;方案分析&quot;&gt;方案分析&lt;/h2&gt;
&lt;h3 id=&quot;优点剖析-&quot;&gt;优点剖析&lt;/h3&gt;
&lt;h4 id=&quot;1--容灾&quot;&gt;1. 容灾&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写步骤1.4或1.5 如果失败，可以进行日志回放，再次重试。&lt;br /&gt;
无论步骤1.1是否删除成功，后续的刷新操作是有保证的&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;妈耶，怎么就一个优点，讲道理这个其实很常用的，那我们再来看看缺点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;缺点剖析-&quot;&gt;缺点剖析&lt;/h3&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分析缺点之前，我们先来看一下知识点&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1cl6vpv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于同一张表的同一条记录的更新，Databus会以串行形式的通知下游服务，也就是说，只有当我们正确返回后，它才会推送该记录的下一次更新。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2r6r6ih&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于同一张表的不同记录的更新， Databus会以事件时间为顺序的通知下游服务，但并不会等待我们返回后才推送下一条，也就是说它是非串行的。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-axzxp6x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于不同表，根据其下游的消费速度，不同表之间没有明确的时间顺序。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;1--只适合简单业务-复杂业务容易发生并发问题&quot;&gt;1. 只适合简单业务，复杂业务容易发生并发问题&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里先来解释一下这里说的“简单业务”是啥意思？&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;简单业务：每次需要刷新的数据，都来自&lt;strong&gt;单表单行&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为什么复杂业务就不行呢？我举个例子&lt;br /&gt;
我们假设 &lt;strong&gt;一个订单 = A表信息 + B表信息&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-02-02.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于A表先变化，经过1，2，3步后，线程1获取了A’B （A表是新数据，B表的老数据），当线程1还没来得及刷新缓存时，并发发生了：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时，B表发生了更新，经过4，5，6，7将最新的数据A’B’写入缓存，此时此刻缓存数据是符合要求的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，后来线程1进行了第8步，将A’B写入数据，使得缓存最终结果 与 DB 不一致。&lt;/p&gt;
&lt;h5 id=&quot;缺点1的改进&quot;&gt;缺点1的改进&lt;/h5&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dfu4qo5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;针对单库多表单次更新的改进：利用事务&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-02-03.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当AB表的更新发生在一个事务内时，不管线程1、线程2如何读取，他们都能获取两张表的最新数据，所以刷新缓存的数据都是符合要求的。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是这种方案具有局限性：那就是只对单次更新有效，或者说更新频率低的情况下才适应，比如我们并发的单独更新C表，并发问题依然会发生。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以&lt;strong&gt;这种方案只针对多表单次更新的情况&lt;/strong&gt;。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-p182xw7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;针对多表多次更新的改进：增量更新&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-02-04.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每张表的更新，在同步缓存时，只获取该表的字段覆盖缓存。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样，线程1，线程2总能获取对应表最新的字段，而且Databus对于同表同行会以串行的形式通知下游，所以能保证缓存的最终一致性。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里有一点需要提一下：更新“某张表多行记录“时，这个操作要在一个事务内，不然并发问题依然存在，正如前面分析的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;2--依然是并发问题&quot;&gt;2. 依然是并发问题&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;即使对于&lt;strong&gt;缺点1&lt;/strong&gt;我们提出了改进方案，虽然它解决了部分问题，但在极端场景下依然存在并发问题。&lt;br /&gt;
这个场景，就是&lt;strong&gt;缓存中没有数据&lt;/strong&gt;的情况：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-gud8r0s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读的时候，缓存中的数据已失效，此时又发生了更新&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3ww25nb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;数据更新的时候，缓存中的数据已失效，此时又发生了更新&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，我们在上面提到的“增量更新”就不起作用了，我们需要读取&lt;strong&gt;所有的表&lt;/strong&gt;来拼凑出初始数据，那这个时候又涉及到&lt;strong&gt;读所有表的操作&lt;/strong&gt;了，那我们在&lt;strong&gt;缺点1&lt;/strong&gt;中提到的并发问题会再次发生&lt;/p&gt;
&lt;h2 id=&quot;方案总结-&quot;&gt;方案总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;适合使用的场景：业务简单，读写QPS比较低的情况&lt;/strong&gt;。&lt;br /&gt;
今天这个方案呢，优缺点都比较明显，binlog用来刷新缓存是一个很棒的选择，它天然的顺序性用来做同步操作很具有优势；其实&lt;strong&gt;它的并发问题来自于Canal 或 Databus。拿Databus来说，由于不同行、表、库的binlog的消费并不是时间串行的&lt;/strong&gt;，那怎么解决这个问题呢&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;强一致性，包含两种含义：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-thlocfc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存和DB数据一致&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xmuk3bo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存中没有数据（或者说：不会去读缓存中的老版本数据）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先我们来分析一下，既然已经实现了“&lt;strong&gt;最终一致性&lt;/strong&gt;”，那它和“&lt;strong&gt;强一致性&lt;/strong&gt;”的区别是什么呢？没错，就是“&lt;strong&gt;时间差&lt;/strong&gt;”，所以：&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;“&lt;strong&gt;最终一致性方案&lt;/strong&gt;” + “&lt;strong&gt;时间差&lt;/strong&gt;” = “&lt;strong&gt;强一致性方案&lt;/strong&gt;”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那我们的工作呢，就是加上时间差，实现方式：&lt;strong&gt;我们加一个缓存，将近期被修改的数据进行标记锁定。读的时候，标记锁定的数据强行走DB，没锁定的数据，先走缓存&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/db-and-cache-04-01.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;写流程--&quot;&gt;写流程：&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们把修改的数据通过Cache_0标记“正在被修改”，如果标记成功，则继续往下走；&lt;strong&gt;那如果标记失败，则要放弃这次修改。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;何为标记锁定呢？比如你可以设定一个有效期为10S的key，Key存在即为锁定。一般来说10S对于后面的同步操作来说基本是够了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;如果说，还想更严谨一点，怕DB主从延迟太久、MQ延迟太久，或Databus监听的从库挂机之类的情况，我们可以考虑增加一个监控定时任务&lt;/strong&gt;。&lt;br /&gt;
比如我们增加一个时间间隔2S的worker的去对比以下两个数据：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-stka9ql&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;时间1： 最后修改数据库的时间&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;VS&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bo9rsfc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;时间2： 最后由更新引起的’MQ刷新缓存对应数据的实际更新数据库’的时间&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据1： 可由步骤1.1获得，并存储&lt;br /&gt;
数据2： 需要由binlog中解析获得，需要透传到MQ，这样后面就能存储了&lt;br /&gt;
这里提一下：如果多库的情况的话，存储这两个key需要与库一一对应&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 时间1 VS 时间2 相差超过5S，那我们就自动把相应的缓存分片读降级。&lt;/p&gt;
&lt;h3 id=&quot;读流程--&quot;&gt;读流程：&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;先读Cache_0，看看要读的数据是否被标记，如果被标记，则直接读主库；&lt;/p&gt;
&lt;h2 id=&quot;方案分析-&quot;&gt;方案分析&lt;/h2&gt;
&lt;h3 id=&quot;优点剖析--&quot;&gt;优点剖析&lt;/h3&gt;
&lt;h4 id=&quot;1--容灾完善&quot;&gt;1. 容灾完善&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们一步一步来分析：&lt;/p&gt;
&lt;h6 id=&quot;写流程容灾分析&quot;&gt;写流程容灾分析&lt;/h6&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-92uojtp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写1.1 标记失败&lt;/strong&gt;：没关系，放弃整个更新操作&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-34q6pjr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写1.3 DEL缓存失败&lt;/strong&gt;：没关系，后面会覆盖&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zhh9u8h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写1.5 写MQ失败&lt;/strong&gt;：没关系，Databus或Canal都会重试&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n05tzn3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;消费MQ的：1.6 || 1.7 失败&lt;/strong&gt;：没关系，重新消费即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&quot;读流程容灾分析&quot;&gt;读流程容灾分析&lt;/h6&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-q0cvx80&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读2.1 读Cache_0失败&lt;/strong&gt;：没关系，直接读主库&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vh7tj0f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读2.3 异步写MQ失败&lt;/strong&gt;：没关系，缓存为空，是OK的，下次还读库就好了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;2--无并发问题&quot;&gt;2. 无并发问题&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方案让“读库 + 刷缓存”的操作串行化，这就不存在老数据覆盖新数据的并发问题了&lt;/p&gt;
&lt;h3 id=&quot;缺点剖析--&quot;&gt;缺点剖析&lt;/h3&gt;
&lt;h4 id=&quot;1--增加Cache-0强依赖&quot;&gt;1. 增加Cache_0强依赖&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个其实有点没办法，你要强一致性，必然要牺牲一些的。&lt;br /&gt;
但是呢，你这个可以吧Cache_0设计成多机器多分片，这样的话，即使部分分片挂了，也只有小部分流量透过Cache直接打到DB上，这是完全是可接受的&lt;/p&gt;
&lt;h4 id=&quot;2--复杂度是比较高的&quot;&gt;2. 复杂度是比较高的&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;涉及到Databus、MQ、定时任务等等组件，实现起来复杂度还是有的&lt;/p&gt;
&lt;h2 id=&quot;方案总结--&quot;&gt;方案总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;OK，到此呢，我们已经实现了&lt;strong&gt;“数据库和缓存强一致性”&lt;/strong&gt;，这个系列就先这样啦，等我学到了更好的方案，再来分享~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;https://blog.kido.site/2018/11/24/db-and-cache-preface/&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis数据淘汰策略]]></title><link>https://www.ztianzeng.com/topic/redis/Redis集群/Redis数据淘汰策略</link><guid isPermaLink="false">/topic/redis/Redis集群/Redis数据淘汰策略</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis集群]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis数据淘汰策略&quot;&gt;Redis数据淘汰策略&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis将数据存储在内存中，但是内存有限，当存储的数据超过内存容量时，需要对缓存的数据进行剔除。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;淘汰算法一般有以下几种&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rtj68bo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;FIFO: 淘汰最早数据&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kb6zmyc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LRU: 剔除最近最少使用&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ymsfsvs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LFU: 剔除最近使用频率最低的数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Redis的内存淘汰策略-有以下几种&quot;&gt;Redis的内存淘汰策略，有以下几种&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-k5h69q2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;noeviction:&lt;/strong&gt; (默认策略) 返回错误。当内存达到限制，客户端尝试执行的命令（大部分的写入指令，但DEL和几个例外）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jfbvwj2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;allkeys-lru:&lt;/strong&gt; 尝试回收最少使用的键（LRU）（适用所有缓存数据，不管是否设置过期时间）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4qblat8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;volatile-lru:&lt;/strong&gt; 尝试回收最少使用的键（LRU），（仅限于在过期集合的键）。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nrvx9t4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;allkeys-random:&lt;/strong&gt; 随机回收数据（适用所有缓存数据，不管是否设置过期时间）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iieme6s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;volatile-random:&lt;/strong&gt; 随机回收数据（仅限于在过期集合的键）。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jzc4fm1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;volatile-ttl:&lt;/strong&gt; 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;数据库中有-3000w-的数据-而-Redis-中只有-100w-数据-如何保证-Redis-中存放的都是热点数据&quot;&gt;数据库中有 3000w 的数据，而 Redis 中只有 100w 数据，如何保证 Redis 中存放的都是热点数据&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个题你说它的考点是什么？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;考的就是淘汰策略呀，同志们，只是方式比较隐晦而已。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们先指定淘汰策略为 allkeys-lru 或者 volatile-lru，然后再计算一下 100w 数据大概占用多少内存，根据算出来的内存，限定 Redis 占用的内存。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis数据删除策略]]></title><link>https://www.ztianzeng.com/topic/redis/Redis集群/Redis数据删除策略</link><guid isPermaLink="false">/topic/redis/Redis集群/Redis数据删除策略</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis集群]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis数据删除策略&quot;&gt;Redis数据删除策略&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis可以对Key设置过期时间，如果Key到过期时间，Redis是如何删除的？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis会将过期时间的键和过期时间存放到一个字典当中。当我们查询一个键时，redis首先检查是否在过期字典当中，如果存在，则获取其过期时间，然后将过期时间和当前时间进行对比，如果比当前时间大则认定过期，否则则认定没有过期。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis采用惰性删除+定期删除&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;删除模式&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;优点&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;惰性删除&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;对 CPU友好，&lt;br /&gt;我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;如果一个键已经过期，但是一直没有使用，&lt;br /&gt;该键就会一直存在内存中，内存永远不会释放。&lt;br /&gt;如有较多这样的过期键，容易造成内存泄漏。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;定期删除&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。&lt;br /&gt;另外定期删除，也能有效释放过期键占用的内存。&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;难以确定删除操作执行的时长和频率。&lt;br /&gt;如果执行的太频繁对CPU不友好。&lt;br /&gt;如果执行频率过低，那又和惰性删除一样了，&lt;br /&gt;过期键占用的内存不会及时得到释放。&lt;br /&gt;另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;惰性删除&quot;&gt;惰性删除&lt;/h1&gt;
&lt;div data-content=&quot;flowchart TD;
	A(所有读写数据库的命令) --&amp;gt; B(调用expireIfNeeded方法)
	B--&amp;gt;C{输入键已过期?}
	C--&amp;gt;|是|D(删除键)
	C--&amp;gt;|否|E(执行实际流程)
	D--&amp;gt;E&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;int expireIfNeeded(redisDb *db, robj *key) {
    // 键未过期返回0
    if (!keyIsExpired(db,key)) return 0;
    // 如果运行在从节点上，直接返回1，因为从节点不执行删除操作
    if (server.masterhost != NULL) return 1;
    // 运行到这里，表示键带有过期时间且运行在主节点上
    // 删除过期键个数
    server.stat_expiredkeys++;
    // 向从节点和AOF文件传播过期信息
    propagateExpire(db,key,server.lazyfree_lazy_expire);
    // 发送事件通知
    notifyKeyspaceEvent(NOTIFY_EXPIRED,
        &amp;quot;expired&amp;quot;,key,db-&amp;gt;id);
    // 根据配置（默认是同步删除）判断是否采用惰性删除（这里的惰性删除是指采用后台线程处理删除操做，这样会减少卡顿）
    int retval = server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                               dbSyncDelete(db,key);
    if (retval) signalModifiedKey(NULL,db,key);
    return retval;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;定期删除&quot;&gt;定期删除&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;定期策略是每隔一段时间执行一次删除过期键的操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU 时间的影响，同时也减少了内存浪费&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 默认会每秒进行 10 次（redis.conf 中通过 hz 配置）过期扫描，扫描并不是遍历过期字典中的所有键，而是采用了如下方法&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xitnmud&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从过期字典中随机取出 20 个键(ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dfg56mr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;删除这 20 个键中过期的键&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cxtyusz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果过期键的比例超过 25% ，重复步骤 1 和 2&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证扫描不会出现循环过度，导致线程卡死现象，还增加了扫描时间的上限，默认是 25 毫秒(ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC)（即默认在慢模式下，如果是快模式，扫描上限是 1 毫秒）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从定期回收策略的慢速检查中，我们可以看到，redis 处理到期数据，通过采样，判断到期数据的密集度。到期数据越密集，处理时间越多。我们使用中，不应该把大量数据设置在同一个时间段到期。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;底层源码实现:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;void activeExpireCycle(int type) {
    /* Adjust the running parameters according to the configured expire
     * effort. The default effort is 1, and the maximum configurable effort
     * is 10. */
    unsigned long
    // 努力力度，默认 1，也就是遍历过期字典的力度，力度越大，遍历数量越多，但是性能损耗更多。
    effort = server.active_expire_effort-1, /* Rescale from 0 to 9. */
    // 每次循环遍历键值个数。力度越大，遍历个数越多。
    config_keys_per_loop = ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP +
                           ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP/4*effort,
    // 快速遍历时间范围，力度越大，给予遍历时间越多。
    config_cycle_fast_duration = ACTIVE_EXPIRE_CYCLE_FAST_DURATION +
                                 ACTIVE_EXPIRE_CYCLE_FAST_DURATION/4*effort,
    // 慢速遍历检查时间片
    config_cycle_slow_time_perc = ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC +
                                  2*effort,
    // 已经到期数据 / 检查数据 比例。达到可以接受的比例。
    config_cycle_acceptable_stale = ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE-
                                    effort;

    /* This function has some global state in order to continue the work
     * incrementally across calls. */
    static unsigned int current_db = 0; /* Last DB tested. */
    // 检查是否已经超时。
    static int timelimit_exit = 0;      /* Time limit hit in previous call? */
    // 上一次快速检查数据起始时间。
    static long long last_fast_cycle = 0; /* When last fast cycle ran. */

    // iteration 迭代检查个数，每 16 次循环遍历，确认一下是否检查超时。
    int j, iteration = 0;
    // 每次周期检查的数据库个数。redis 默认有 16 个库。
    int dbs_per_call = CRON_DBS_PER_CALL;
    long long start = ustime(), timelimit, elapsed;

    /* When clients are paused the dataset should be static not just from the
     * POV of clients not being able to write, but also from the POV of
     * expires and evictions of keys not being performed. */
    /* 如果链接已经停止了，那么要保留现场，不允许修改数据，也不允许到期淘汰数据。
     * 使用命令 ‘pause’ 暂停 redis 工作或者主服务正在进行从服务的故障转移。*/
    if (clientsArePaused()) return;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {
        /* 检查还没超时，但是到期数据密集度已经达到了可以接受的范围，不要快速检查了，
           毕竟它是快速的，留给其它方式的检查。*/
        if (!timelimit_exit &amp;amp;&amp;amp;
            server.stat_expired_stale_perc &amp;lt; config_cycle_acceptable_stale)
            return;
        /* 限制快速检查频次，在两个 config_cycle_fast_duration 内，只能执行一次快速检查。 */
        if (start &amp;lt; last_fast_cycle + (long long)config_cycle_fast_duration*2)
            return;

        last_fast_cycle = start;
    }

    /* We usually should test CRON_DBS_PER_CALL per iteration, with
     * two exceptions:
     *
     * 1) Don&apos;t test more DBs than we have.
     * 2) If last time we hit the time limit, we want to scan all DBs
     * in this iteration, as there is work to do in some DB and we don&apos;t want
     * expired keys to use memory for too much time. */
    if (dbs_per_call &amp;gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    /* 检查过期数据，但是不能太损耗资源，得有个限制。server.hz 默认为 10
      hz 是执行后台任务的频率，越大表明执行的次数越频繁，一般用默认值 10 */
    timelimit = config_cycle_slow_time_perc*1000000/server.hz/100;
    timelimit_exit = 0;
    if (timelimit &amp;lt;= 0) timelimit = 1;
    // 如果是快速模式，更改检查周期时间。
    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = config_cycle_fast_duration; /* in microseconds. */


    /* 过期数据一般是异步方式，检查到过期数据，都是从字典中移除键值信息，
     * 避免再次使用，但是数据回收放在后台回收，不是实时的，有数据有可能还存在数据库里。*/
    // 检查数据个数。
    long total_sampled = 0;
    // 检查数据，数据已经过期的个数。
    long total_expired = 0;

    for (j = 0; j &amp;lt; dbs_per_call &amp;amp;&amp;amp; timelimit_exit == 0; j++) {
        /* Expired and checked in a single loop. */
        unsigned long expired, sampled;

        redisDb *db = server.db+(current_db % server.dbnum);

        /* Increment the DB now so we are sure if we run out of time
         * in the current DB we&apos;ll restart from the next. This allows to
         * distribute the time evenly across DBs. */
        current_db++;

        /* Continue to expire if at the end of the cycle there are still
         * a big percentage of keys to expire, compared to the number of keys
         * we scanned. The percentage, stored in config_cycle_acceptable_stale
         * is not fixed, but depends on the Redis configured &amp;quot;expire effort&amp;quot;. */
        // 遍历数据库检查过期数据，直到超出检查周期时间，或者过期数据比例已经很少了。
        do {
            // num 数据量，slots 哈希表大小（字典数据如果正在迁移，双表大小）
            unsigned long num, slots;
            long long now, ttl_sum;
            int ttl_samples;
            iteration++;

            /* If there is nothing to expire try next DB ASAP. */
            if ((num = dictSize(db-&amp;gt;expires)) == 0) {
                db-&amp;gt;avg_ttl = 0;
                break;
            }
            slots = dictSlots(db-&amp;gt;expires);
            now = mstime();

            /* 过期存储数据结构是字典，数据经过处理后，字典存储的数据可能已经很少，
            * 但是字典还是大字典，这样遍历数据有效命中率会很低，处理起来会浪费资源，
            * 后面的访问会很快触发字典的缩容，缩容后再进行处理效率更高。*/
            if (num &amp;amp;&amp;amp; slots &amp;gt; DICT_HT_INITIAL_SIZE &amp;amp;&amp;amp;
                (num*100/slots &amp;lt; 1)) break;

            // 过期的数据个数。
            expired = 0;
            // 检查的数据个数。
            sampled = 0;
            // 没有过期的数据时间差之和。
            ttl_sum = 0;
            // 没有过期的数据个数。
            ttl_samples = 0;

            // 每次检查的数据限制。
            if (num &amp;gt; config_keys_per_loop)
                num = config_keys_per_loop;

            /* 哈希表本质上是一个数组，可能有键值碰撞的数据，用链表将碰撞数据串联起来，
            * 放在一个数组下标下，也就是放在哈希表的一个桶里。max_buckets 是最大能检查的桶个数。
            * 跳过空桶，不处理。*/
            long max_buckets = num*20;
            // 当前已经检查哈希表桶的个数。
            long checked_buckets = 0;
            // 一个桶上有可能有多个数据。所以检查从两方面限制：一个是数据量，一个是桶的数量。
            while (sampled &amp;lt; num &amp;amp;&amp;amp; checked_buckets &amp;lt; max_buckets) {
                for (int table = 0; table &amp;lt; 2; table++) {
                    // 如果 dict 没有正在进行扩容，不需要检查它的第二张表了。
                    if (table == 1 &amp;amp;&amp;amp; !dictIsRehashing(db-&amp;gt;expires)) break;

                    unsigned long idx = db-&amp;gt;expires_cursor;
                    idx &amp;amp;= db-&amp;gt;expires-&amp;gt;ht[table].sizemask;
                    dictEntry *de = db-&amp;gt;expires-&amp;gt;ht[table].table[idx];
                    long long ttl;

                    // 检查数据是否已经超时。
                    checked_buckets++;
                    while(de) {
                        /* Get the next entry now since this entry may get
                         * deleted. */
                        dictEntry *e = de;
                        de = de-&amp;gt;next;

                        ttl = dictGetSignedIntegerVal(e)-now;
                        // 如果数据过期了，进行回收处理。
                        if (activeExpireCycleTryExpire(db,e,now)) expired++;
                        if (ttl &amp;gt; 0) {
                            /* We want the average TTL of keys yet
                             * not expired. */
                            ttl_sum += ttl;
                            ttl_samples++;
                        }
                        sampled++;
                    }
                }
                db-&amp;gt;expires_cursor++;
            }
            total_expired += expired;
            total_sampled += sampled;

            /* Update the average TTL stats for this database. */
            if (ttl_samples) {
                long long avg_ttl = ttl_sum/ttl_samples;

                /* Do a simple running average with a few samples.
                 * We just use the current estimate with a weight of 2%
                 * and the previous estimate with a weight of 98%. */
                if (db-&amp;gt;avg_ttl == 0) db-&amp;gt;avg_ttl = avg_ttl;
                // 对没过期的数据，平均过期时间进行采样，上一次统计的平均时间占 98 %，本次占 2%。
                db-&amp;gt;avg_ttl = (db-&amp;gt;avg_ttl/50)*49 + (avg_ttl/50);
            }

            /* We can&apos;t block forever here even if there are many keys to
             * expire. So after a given amount of milliseconds return to the
             * caller waiting for the other active expire cycle. */
            /* 避免检查周期太长，当前数据库每 16 次循环迭代检查，检查是否超时，超时退出。*/
            if ((iteration &amp;amp; 0xf) == 0) { /* check once every 16 iterations. */
                elapsed = ustime()-start;
                if (elapsed &amp;gt; timelimit) {
                    timelimit_exit = 1;
                    server.stat_expired_time_cap_reached_count++;
                    break;
                }
            }
            /* 当前数据库，如果没有检查到数据，或者过期数据已经达到可接受比例
             * 就退出该数据库检查，进入到下一个数据库检查。*/
        } while (sampled == 0 ||
                 (expired*100/sampled) &amp;gt; config_cycle_acceptable_stale);
    }

    elapsed = ustime()-start;
    server.stat_expire_cycle_time_used += elapsed;
    latencyAddSampleIfNeeded(&amp;quot;expire-cycle&amp;quot;,elapsed/1000);

    // 添加统计信息
    double current_perc;
    if (total_sampled) {
        current_perc = (double)total_expired/total_sampled;
    } else
        current_perc = 0;
    // 通过累加每次检查的过期概率影响，保存过期数据占数据比例。
    server.stat_expired_stale_perc = (current_perc*0.05)+
                                     (server.stat_expired_stale_perc*0.95);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;AOF-RDB-和复制功能对过期键的处理&quot;&gt;AOF、RDB 和复制功能对过期键的处理&lt;/h1&gt;
&lt;h2 id=&quot;RDB&quot;&gt;RDB&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;生成 RDB 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在执行 save 命令或 bgsave 命令创建一个新的 RDB文件时，程序会对数据库中的键进行检查，已过期的键就不会被保存到新创建的 RDB文件中&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;载入 RDB 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;主服务器&lt;/strong&gt;：载入 RDB 文件时，会对键进行检查，过期的键会被忽略&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;从服务器&lt;/strong&gt;：载入 RDB文件时，所有键都会载入。但是会在主从同步的时候，清空从服务器的数据库，所以过期的键载入也不会造成啥影响&lt;/p&gt;
&lt;h2 id=&quot;AOF&quot;&gt;AOF&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;AOF 文件写入&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当过期键被惰性删除或定期删除后，程序会向 AOF 文件追加一条 del 命令，来显示的记录该键已经被删除&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;AOF 重写&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重启过程会对键进行检查，如果过期就不会被保存到重写后的 AOF 文件中&lt;/p&gt;
&lt;h2 id=&quot;复制&quot;&gt;复制&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;从服务器的过期键删除动作由主服务器控制&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主服务器在删除一个过期键后，会显示地向所有从服务器发送一个 del 命令，告知从服务器删除这个过期键&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从服务器收到在执行客户端发送的读命令时，即使碰到过期键也不会将其删除，只有在收到主服务器的 del 命令后，才会删除，这样就能保证主从服务器的数据一致性&lt;/p&gt;
&lt;h1 id=&quot;疑问点-&quot;&gt;疑问点？&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ck307un&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果主从服务器链接断开怎么办？&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lbo5wwi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果发生网络抖动，主服务器发送的 del 命令没有传递到从服务器怎么办？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其实上面两个问题 Redis 开发者已经考虑到了，只是主从复制涉及到的知识点还挺多，下面我就简单的说下解决的思路，后面会再分享一篇主从复制的文件&lt;/p&gt;
&lt;h2 id=&quot;如果主从服务器链接断开怎么办-&quot;&gt;如果主从服务器链接断开怎么办？&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 采用 PSYNC 命令来执行复制时的同步操作，当从服务器在断开后重新连接主服务器时，主服务器会把从服务器断线期间执行的写命令发送给从服务器，然后从服务器接收并执行这些写命令，这样主从服务器就会达到一致性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那主服务器如何判断从服务器断开链接的过程需要哪些命令？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主服务器会维护一个固定长度的先进先出的队列，即复制积压缓冲区，缓冲区中保存着主服务器的写命令和命令对应的偏移量，在主服务器给从服务器传播命令时，同时也会往复制积压缓冲区中写命令。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从服务器在向主服务器发送 PSYNC 命令时，同时会带上它的最新写命令的偏移量，这样主服务器通过对比偏移量，就可以知道从服务器从哪里断开的了&lt;/p&gt;
&lt;h2 id=&quot;如果发生网络抖动-主服务器发送的-del-命令没有传递到从服务器怎么办-&quot;&gt;如果发生网络抖动，主服务器发送的 del 命令没有传递到从服务器怎么办？&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其实主从服务器之间会有心跳检测机制，主从服务器通过发送和接收 REPLCONF ACK 命令来检查两者之间的网络连接是否正常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当从服务器向主服务器发送 REPLCONF ACK 命令时，主服务器会对比自己的偏移量和从服务器发过来的偏移量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果从服务器的偏移量小于自己的偏移量，主服务器会从复制积压缓冲区中找到从服务器缺少的数据，并将数据发送给从服务器，这样就达到了数据一致性&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis集群]]></title><link>https://www.ztianzeng.com/topic/redis/Redis集群</link><guid isPermaLink="false">/topic/redis/Redis集群</guid><category><![CDATA[redis]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis集群&quot;&gt;Redis集群&lt;/h1&gt;
&lt;h1 id=&quot;三种集群方案&quot;&gt;三种集群方案&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-tqm84yk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主从复制模式&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5z9s0wq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哨兵模式&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7ggi9xe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Cluster 模式&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;主从复制模式&quot;&gt;主从复制模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20210920222454496.png&quot; alt=&quot;image-20210920222454496&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过持久化功能，Redis保证了即使在服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。 但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为此， &lt;strong&gt;Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;引入主从复制机制的目的有两个&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-fezfyt9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个是读写分离，分担 &amp;quot;master&amp;quot; 的读写压力&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-eb3oiju&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个是方便做容灾恢复&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;主从复制优点&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-s44hcs5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5y5u1bf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ljmrn6z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Slave 同样可以接受其它 Slaves 的连接和同步请求，这样可以有效的分载 Master 的同步压力；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j3bxtqe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Master Server 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tvjocdr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Slave Server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;主从复制缺点&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zbh4hu6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（&lt;strong&gt;也就是要人工介入&lt;/strong&gt;）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jlu2634&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ibx5poq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-v8fbnli&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;div data-content=&quot;sequenceDiagram
    participant 从服务器
    participant 主服务器
    从服务器-&amp;gt;&amp;gt;主服务器: SYNC请求
    主服务器-&amp;gt;&amp;gt;主服务器: 创建快照、缓冲快照生成期间的写命令
    主服务器-&amp;gt;&amp;gt;从服务器: 同步快照
    从服务器-&amp;gt;&amp;gt;从服务器: 载入、解析快照
    主服务器-&amp;gt;&amp;gt;主服务器: 缓冲快照同步的写命令
    主服务器-&amp;gt;&amp;gt;从服务器: 同步写缓冲
    从服务器-&amp;gt;&amp;gt;从服务器: 载入缓冲
    loop Healthcheck
        主服务器-&amp;gt;&amp;gt;从服务器: 同步增量
    end&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zx978wf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从数据库启动成功后，连接主数据库，发送 SYNC 命令；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-svqpt7q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dtog9lc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-elsbjvt&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dkm9whn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lv1byel&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（&lt;strong&gt;从数据库初始化完成&lt;/strong&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qnrg19j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（&lt;strong&gt;从数据库初始化完成后的操作&lt;/strong&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-l4x768x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8e64ohw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;redis主从复制的坑&quot;&gt;redis主从复制的坑&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis高可用最常见的方案就是主从复制（master-slave），这种模式也给redis分布式锁挖了一坑。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis cluster集群环境下，假如现在A客户端想要加锁，它会根据路由规则选择一台master节点写入key mylock，在加锁成功后，master节点会把key异步复制给对应的slave节点。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果此时redis master节点宕机从节点复制失败，为保证集群可用性，会进行主备切换，slave变为了redis master。B客户端在新的master节点上加锁成功，而A客户端也以为自己还是成功加了锁的。另外如果主从复制延迟同样也会造成加锁和解锁延迟的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时就会导致同一时间内多个客户端对一个分布式锁完成了加锁，导致各种脏数据的产生。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;至于解决办法嘛，目前看还没有什么根治的方法，只能尽量保证机器的稳定性，减少发生此事件的概率,即便是redis作者也没有特别完美的解决这个问题&lt;/p&gt;
&lt;h1 id=&quot;哨兵模式&quot;&gt;哨兵模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一种主从同步/复制的模式，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，&lt;strong&gt;哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/1460000022808580.png&quot; alt=&quot;单哨兵&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;哨兵模式的作用&quot;&gt;哨兵模式的作用&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-cmpuafp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g78zlko&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过&lt;strong&gt;发布订阅模式&lt;/strong&gt;通知其他的从服务器，修改配置文件，让它们切换主机；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://segmentfault.com/img/remote/1460000022808582&quot; alt=&quot;多哨兵&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;故障切换的过程&quot;&gt;故障切换的过程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为&lt;strong&gt;主观下线&lt;/strong&gt;。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为&lt;strong&gt;客观下线&lt;/strong&gt;。这样对于客户端而言，一切都是透明的。&lt;/p&gt;
&lt;h2 id=&quot;哨兵模式的工作方式-&quot;&gt;哨兵模式的工作方式：&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-u9ixfw6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cf0kr7i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hxf1sk1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-c1pc6gs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iadzbd4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master 主服务器、Slave 从服务器发送 INFO 命令。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yns759t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当 Master 主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1xgzel6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;哨兵模式的优缺点&quot;&gt;哨兵模式的优缺点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wyey8db&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dd893kd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主从可以自动切换，系统更健壮，可用性更高(&lt;strong&gt;可以看作自动版的主从复制&lt;/strong&gt;)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-d9unwy0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Cluster-集群模式-Redis官方-&quot;&gt;Cluster 集群模式（Redis官方）&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，&lt;strong&gt;也就是说每台 Redis 节点上存储不同的内容&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/1460000022808584.png&quot; alt=&quot;image-20200531184321294&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个图中，每一个蓝色的圈都代表着一个 redis 的服务器节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作。&lt;/p&gt;
&lt;h2 id=&quot;集群的数据分片&quot;&gt;集群的数据分片&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 集群有16384 个哈希槽，每个 key 通过+693&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-migs196&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点 A 包含 0 到 5460 号哈希槽&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-12pnui0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点 B 包含 5461 到 10922 号哈希槽&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-71o44h7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点 C 包含 10923 到 16383 号哈希槽&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D ， 我需要从节点 A， B， C 中得部分槽到 D 上。如果我想移除节点 A ，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是 cluster，可以理解为是一个集群管理的插件。当我们的存取的 Key到达的时候，Redis 会根据 CRC16 的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。&lt;/p&gt;
&lt;h2 id=&quot;Redis-集群的主从复制模型&quot;&gt;Redis 集群的主从复制模型&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。&lt;/p&gt;
&lt;h2 id=&quot;集群的特点&quot;&gt;集群的特点&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5k73eis&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有的 redis 节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-boppzap&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点的 fail 是通过集群中超过半数的节点检测失效时才生效。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bwoyfb2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;客户端与 Redis 节点直连，不需要中间代理层.客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来源: https://segmentfault.com/a/1190000022808576&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Hash的底层实现]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构/Hash的底层实现</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构/Hash的底层实现</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis基本数据结构]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Hash的底层实现&quot;&gt;Hash的底层实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Hash的底层编码格式是HashTable和ZipList。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Hash底层存储结构HashTable和ZipLit会互相转化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;控制他们转化的参数:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-y68ytbu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;hash-max-ziplist-entries,默认512,使用压缩列表保存时哈希集合中的最大元素个数。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cfvq0d2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;hash-max-ziplist-value,默认64,使用压缩列表保存时哈希集合中单个元素的最大长度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;redis&amp;gt; config get hash*
        hash-max-ziplist-entries
        512
        hash-max-ziplist-value
        64
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当哈希对象同时符合下面两个条件时，将使用 ziplist 编码：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0a03jbo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哈希对象保存的所有键值对中，键和值的字符串长度都小于 64 个字节；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-plk6zau&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哈希对象保存的键值对数量小于 512 个。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ZipList可以转换到HashTable，一旦从ZipList转为了HashTable，Hash类型就会一直用HashTable进行保存而不会再转回ZipList了。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;void hashTypeConvert(robj *o, int enc) {
     // 原始编码是ZipList才进行转换
    if (o-&amp;gt;encoding == OBJ_ENCODING_ZIPLIST) {
        hashTypeConvertZiplist(o, enc);
    } else if (o-&amp;gt;encoding == OBJ_ENCODING_HT) {
        // 无法降级到ZipList
        serverPanic(&amp;quot;Not implemented&amp;quot;);
    } else {
        serverPanic(&amp;quot;Unknown hash encoding&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;ZipList编码的哈希对象&quot;&gt;ZipList编码的哈希对象&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-grhcccc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;普通的双向链表会有两个指针，在存储数据很小的情况下， 我们存储的实际数据的大小可能还没有指针占用的内存大，得不偿失 。&lt;br /&gt;
ziplist是一个特殊的双向链表没有维护双向指针:prev next；而是存储上一个 entry的长度和 当前entry的长度，通过长度推算下一个元素在什么地方。&lt;br /&gt;
牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度更费内存。这是典型的“时间换空间”。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zon5sxk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;链表在内存中一般是不连续的，遍历相对比较慢，而ziplist可以很好的解决这个问题，普通数组的遍历是根据数组里存储的数据类型找到下一个元素的，但是ziplist的每个节点的长度是可以不一样的，而我们面对不同长度的节点又不可能直接sizeof(entry)，所以ziplist只好将一些必要的偏移量信息记录在了每一个节点里，使之能跳到上一个节点或下一个节点。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gb7o2nr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;头节点里有头节点里同时还有一个参数 len，和string类型提到的 SDS 类似，这里是用来记录链表长度的。因此 获取链表长度时不用再遍历整个链表,直接拿到len值就可以了，这个时间复杂度是 O(1)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ZipList的总体布局如下:&lt;br /&gt;
因为压缩列表的操作中涉及到的位运算很多，如果不统一的话会出现混乱。后续的所有位运算都是在小端存储的基础上进行的&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/redis_ziplist_%E7%BB%93%E6%9E%84.png&quot; alt=&quot;redis_ziplist_结构&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;typedef struct zlentry {
    /**
     * 前一个节点大小
     */
    unsigned int prevrawlensize;
    /**
     * 前一个节点长度
     */
    unsigned int prevrawlen;
    /**
     * 当前节点大小
     */
    unsigned int lensize;
    /**
     * 当前节点长度
     */
    unsigned int len;
    /**
     * 当前节点头部信息长度
     */
    unsigned int headersize;   
    /**
     * 当前节点数据编码  ZIP_STR_* or ZIP_INT_*
     */
    unsigned char encoding;  
    /**
     * 指向节点的指针 
     */    
    unsigned char *p;
} zlentry;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;hashtable对象&quot;&gt;hashtable对象&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;hashtable 被称为字典（dictionary），它是一个数组+链表的结构.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哈希条目&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;字典对象&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[List的底层实现]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构/List的底层实现</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构/List的底层实现</guid><category><![CDATA[redis]]></category><category><![CDATA[Redis基本数据结构]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;List的底层实现&quot;&gt;List的底层实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;List的底层采用quickList进行编码。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;QuickList是ZipList和LinkList的混合体.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它将 linkedList按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/redis_quicklist_%E7%BB%93%E6%9E%84.jpg&quot; alt=&quot;结构&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis基本数据结构]]></title><link>https://www.ztianzeng.com/topic/redis/Redis基本数据结构</link><guid isPermaLink="false">/topic/redis/Redis基本数据结构</guid><category><![CDATA[redis]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis基本数据结构&quot;&gt;Redis基本数据结构&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis提供了5种常用的数据结构。&lt;/p&gt;
&lt;h1 id=&quot;常用的&quot;&gt;常用的&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;已经涵盖了开发过程中的绝大多数情况&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面列举的应用场景是包括但不限于&lt;/p&gt;
&lt;h2 id=&quot;string&quot;&gt;string&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;字符串是最基本的Redis值。Redis字符串是二进制安全的，这意味着Redis字符串可以包含任何类型的数据，例如JPEG图像或序列化的Ruby对象。 字符串的长度最大为512兆字节。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内部的实现是通过 SDS（Simple Dynamic String ）来存储的。SDS 类似于 Java 中的 ArrayList，可以通过预分配冗余空间的方式来减少内存的频繁分配。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rflhl0n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fr5u9iq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缓存功能&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ythci01&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;利用自增的API作为原子计数器，统计阅读量，点赞数&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-335uqp1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Web集群的session&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5flrsku&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式系统全局序列号&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hash&quot;&gt;hash&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;类似Map的一种结构.场景单一 应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-do6wqbf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;电商购物车&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;list&quot;&gt;list&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有序列表。存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-036gooy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;微博和公众号的消息流&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-21i960t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商品评论，文章列表或者数据分页展示的应用。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5ek6wqy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;set&quot;&gt;set&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会自动去重的无序集合。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-pnw61qh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抽奖（从集合中随机弹出一个元素，元素出一个删一个）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pkr9bf9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;微信朋友圈点赞、收藏、标签&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6qe9w73&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;微信微博关注模型&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;zset&quot;&gt;zset&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会自动去重的有序集合。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-q0ofhwk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抖音微博热搜&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-92pd499&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;商品销售榜，根据销售量进行排行&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yan9zl6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用Sorted Sets来做带权重的队列&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于上面的五种结构，还提供了几种基于上面结构的扩展。&lt;/p&gt;
&lt;h1 id=&quot;扩展结构&quot;&gt;扩展结构&lt;/h1&gt;
&lt;h2 id=&quot;bitmap&quot;&gt;bitmap&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于String类型扩展出来的数据结构，按照Bit位来存储信息&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h9x0mp6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;布隆过滤器&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hyperloglog&quot;&gt;hyperloglog&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提供不精确的去重计数功能，适合大规模数据的去重统计&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;应用场景:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xmj5xmw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;亿级别的UV统计&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;GEO&quot;&gt;GEO&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用于保存地理位置信息，并提供了位置距离计算或者根据半径计算的API。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有不常用的扩展功能&lt;/p&gt;
&lt;h1 id=&quot;扩展功能&quot;&gt;扩展功能&lt;/h1&gt;
&lt;h2 id=&quot;pub-sub&quot;&gt;pub/sub&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提供了简单的消息队列，不常用，用的最多的还是mq&lt;/p&gt;
&lt;h2 id=&quot;pipeline&quot;&gt;pipeline&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;像是Linux的管道&lt;/p&gt;
&lt;h2 id=&quot;Lua-脚本&quot;&gt;Lua 脚本&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;特点是能够原子性执行&lt;/p&gt;
&lt;h2 id=&quot;事务&quot;&gt;事务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis 提供的不是严格的事务，Redis 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis为什么这么快]]></title><link>https://www.ztianzeng.com/topic/redis/Redis为什么这么快</link><guid isPermaLink="false">/topic/redis/Redis为什么这么快</guid><category><![CDATA[redis]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis为什么这么快&quot;&gt;Redis为什么这么快&lt;/h1&gt;
&lt;h1 id=&quot;完全基于内存&quot;&gt;完全基于内存&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有的运算都是内存级别的。&lt;/p&gt;
&lt;h1 id=&quot;数据结构简单&quot;&gt;数据结构简单&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis中所有的数据结构都是重新设计过的，这些重新设计的数据结构大部分时间复杂度都是O(1)。 举例：string这个类型没有采用C原生的string，而是重新设计了一套sds(simple dynamic string)的结构&lt;/p&gt;
&lt;h1 id=&quot;工作线程采用单线程-避免了线程上下文切换所带来的损耗&quot;&gt;工作线程采用单线程，避免了线程上下文切换所带来的损耗&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;redis的作者认为，性能瓶颈是在于内存或者网络带宽并非cpu，所以多线程并不会带来更大的提升（其实是作者懒，强行解释）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis的网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求时包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。&lt;br /&gt;
这也是Redis对外提供键值存储服务的主要流程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;6.0之后，Redis的其他功能， 比如持久化、异步删除、集群数据同步等等，其实是由额外的线程执行的。 因此说，Redis工作线程是单线程的，但是，整个Redis来说，是多线程的(多线程默认是关闭的).&lt;/p&gt;
&lt;h1 id=&quot;对于客户端的连接采用多路复用和非阻塞I-O&quot;&gt;对于客户端的连接采用多路复用和非阻塞I/O&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Redis使用I/O多路复用功能来监听多个socket连接客户端， 这样就可以使用一个线程连接来处理多个请求，减少线程切换带来的开销，同时也避免了 I/O 阻塞操作&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Redis的分布式锁]]></title><link>https://www.ztianzeng.com/topic/redis/Redis的分布式锁</link><guid isPermaLink="false">/topic/redis/Redis的分布式锁</guid><category><![CDATA[redis]]></category><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Redis的分布式锁&quot;&gt;Redis的分布式锁&lt;/h1&gt;
&lt;h1 id=&quot;利用redis实现分布式锁&quot;&gt;利用redis实现分布式锁&lt;/h1&gt;
&lt;h2 id=&quot;三个重要因素&quot;&gt;三个重要因素&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-k9h7k4u&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加锁:  加锁实际上就是在redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jwmxgck&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解锁: 将Key键删除。但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉，只能自己删除自己的锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m2evgil&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;超时: 不能长期占用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;涉及命令&quot;&gt;涉及命令&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ic2n1i6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SETNX: 当KEY不存在的时候设置KEY的值为value，返回1，当KEY存在的时候，不做任何动作返回0。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;redis&amp;gt; setnx key value
	1
redis&amp;gt; setnx key value
	0
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-014q2o3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;EXPIRE: 为KEY设计一个超时时间，到期自动释放，避免死锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n3aarh3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DELETE: 删除KEY，用于业务处理完手动释放锁。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;实现思想&quot;&gt;实现思想&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-a27t48z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随机生成一个UUID，标记是当前线程，调用SETNX方法设置值，并且调用expire方法为锁加一个超期时间，到期自动释放锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dg9wogh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取锁的时候，加一个超期时间，超过时间则放弃去竞争锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oek6dwy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;释放锁的时候，判断UUID是不是  该锁，如果是则执行DELETE进行释放。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div data-content=&quot;flowchart TD;
    获取锁--&amp;gt;B(执行SETNX命令);
    B--&amp;gt;C{是否返回1};
    C--&amp;gt;|是|E(执行expire延长时间);
    E--&amp;gt;F(获取到锁,执行业务逻辑);
    F--&amp;gt;G(释放锁);
    G--&amp;gt;结束;
    B--&amp;gt;|否|结束;
 
    释放锁--&amp;gt;执行GET;
    执行GET--&amp;gt;Z{返回的值\n是否是自己设定的值};
    Z--&amp;gt;|是|执行del;
    执行del--&amp;gt;Y(结束);
    Z--&amp;gt;|否|Y;&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面这么实现有什么问题么?&lt;/p&gt;
&lt;h2 id=&quot;业务执行的时间大于redis锁过期的时间&quot;&gt;业务执行的时间大于redis锁过期的时间&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个锁设置了1分钟超时释放，如果拿到这个锁的线程在一分钟内没有执行完毕，那么这个锁就会被其他线程拿到，可能会导致严重的线上问题。&lt;/p&gt;
&lt;h2 id=&quot;redis部署模式的影响&quot;&gt;redis部署模式的影响&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在单机模式下，redis是CP模式，在对并发量不大的情况下，是可以用这种代码去实现的，单机也能够扛得住。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果在集群模式下，redis异步复制造成的锁丢失，如果主节点没来的及把刚刚set进来这条数据给从节点，就挂了，就导致锁没有锁上，释放也是同样的逻辑&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此针对上述的情况，业界有统一的解决方案: Redlock 红锁。&lt;/p&gt;
&lt;h2 id=&quot;原子性问题&quot;&gt;原子性问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SETNX + EXPIRE不是原子性的，不满足事务性 , 如果expire未执行成功，锁只能主动释放，锁存在永远得不到释放的情况, 可以使用下面的命令进行设置。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;SET key value NX EX 1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者可以用lua进行设置&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;lua&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;local key     = KEYS[1]
local content = ARGV[1]
local ttl     = tonumber(ARGV[2])
local lockSet = redis.call(&apos;setnx&apos;, key, content)
if lockSet == 1 then
  redis.call(&apos;PEXPIRE&apos;, key, ttl)
else
  -- 如果value相同，则认为是同一个线程的请求，则认为重入锁
  local value = redis.call(&apos;get&apos;, key)
  if(value == content) then
    lockSet = 1;
    redis.call(&apos;PEXPIRE&apos;, key, ttl)
  end
end
return lockSet
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;同样的，get+delete也不是原子性的&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;lua&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;local key     = KEYS[1]
local content = ARGV[1]
local value = redis.call(&apos;get&apos;, key)
if value == content then
  return redis.call(&apos;del&apos;, key)
else
    return 0
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用java代码优化上述的问题:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@RestController
public class GoodController {
    public static final String REDIS_LOCK_KEY = &amp;quot;redisLockPay&amp;quot;;
    @Autowired
    private StringRedisTemplate stringRedisTemplate;
    @Value(&amp;quot;${server.port}&amp;quot;)
    private String serverPort;

    @GetMapping(&amp;quot;/buy_goods&amp;quot;)
    public String buy_Goods() {
        String value = UUID.randomUUID().toString() + Thread.currentThread().getName();
        try {
            Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(REDIS_LOCK_KEY, value, 30L, TimeUnit.SECONDS);
            if (!flag) {
                return &amp;quot; 抢夺锁失败，请下次尝试 &amp;quot;;
            }
            String result = stringRedisTemplate.opsForValue().get(&amp;quot;goods:001&amp;quot;);
            int goodsNumber = result == null ? 0 : Integer.parseInt(result);
            if (goodsNumber &amp;gt; 0) {
                int realNumber = goodsNumber - 1;
                stringRedisTemplate.opsForValue().set(&amp;quot;goods:001&amp;quot;, realNumber + &amp;quot;&amp;quot;);
                System.out.println(&amp;quot; 你已经成功秒杀商品，此时还剩余： &amp;quot; + realNumber + &amp;quot; 件 &amp;quot; + &amp;quot; \t  服务器端口： &amp;quot; + serverPort);
                return &amp;quot; 你已经成功秒杀商品，此时还剩余： &amp;quot; + realNumber + &amp;quot; 件 &amp;quot; + &amp;quot; \t  服务器端口： &amp;quot; + serverPort;
            } else {
                System.out.println(&amp;quot; 商品已经售罄 / 活动结束 / 调用超时，欢迎下次光临 &amp;quot; + &amp;quot; \t  服务器端口： &amp;quot; + serverPort);
            }
            return &amp;quot; 商品已经售罄 / 活动结束 / 调用超时，欢迎下次光临 &amp;quot; + &amp;quot; \t  服务器端口： &amp;quot; + serverPort;
        } finally {
            Jedis jedis = RedisUtils.getJedis();
            String script = &amp;quot;if redis.call(&apos;get&apos;, KEYS[1]) == ARGV[1] &amp;quot; + &amp;quot;then &amp;quot; + &amp;quot;return redis.call(&apos;del&apos;, KEYS[1]) &amp;quot; + &amp;quot;else &amp;quot; + &amp;quot;   return 0 &amp;quot; + &amp;quot;end&amp;quot;;
            try {
                Object result = jedis.eval(script, Collections.singletonList(REDIS_LOCK_KEY), Collections.singletonList(value));
                if (&amp;quot;1&amp;quot;.equals(result.toString())) {
                    System.out.println(&amp;quot;------del REDIS_LOCK_KEY success&amp;quot;);
                } else {
                    System.out.println(&amp;quot;------del REDIS_LOCK_KEY error&amp;quot;);
                }
            } finally {
                if (null != jedis) {
                    jedis.close();
                }
            }
        }
    }
}   
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[redis]]></title><link>https://www.ztianzeng.com/topic/redis</link><guid isPermaLink="false">/topic/redis</guid><pubDate>Thu, 28 Apr 2022 06:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;redis&quot;&gt;redis&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Seata解决方案]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[Seata框架]]></category><pubDate>Tue, 26 Apr 2022 08:02:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Seata解决方案&quot;&gt;Seata解决方案&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata 会有 4 种分布式事务解决⽅案，分别是 AT 模式、TCC 模式、Saga模式和 XA 模式。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[XA模式]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/XA模式</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/XA模式</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[Seata框架]]></category><category><![CDATA[Seata解决方案]]></category><pubDate>Tue, 26 Apr 2022 08:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;XA模式&quot;&gt;XA模式&lt;/h1&gt;
&lt;h1 id=&quot;前提&quot;&gt;前提&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7y7y2aq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;支持XA 事务的数据库。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-a35y6pu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 应用，通过 JDBC 访问数据库。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;整体机制&quot;&gt;整体机制&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427111452.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ffvzv21&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行阶段：&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rbhnj5s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2hhnofj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可回滚：业务 SQL 操作放在 XA 分支中进行，由资源对 XA 协议的支持来保证 &lt;em&gt;可回滚&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7kvci1w&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;持久化：XA 分支完成后，执行 XA prepare，同样，由资源对 XA 协议的支持来保证  &lt;em&gt;持久化&lt;/em&gt; （即，之后任何意外都不会造成无法回滚的情况）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wdmjh59&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完成阶段：&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5ep6dfq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-lxa9eiw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分支提交：执行 XA 分支的 commit&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g1ib70m&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分支回滚：执行 XA 分支的 rollback&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;工作机制&quot;&gt;工作机制&lt;/h1&gt;
&lt;h4 id=&quot;1--整体运行机制&quot;&gt;1. 整体运行机制&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA 模式 运行在 Seata 定义的事务框架内：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427111511.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-tw12g4d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行阶段（E xecute）：&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-a1f8og9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-uv1mf1a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA start/XA end/XA prepare + SQL + 注册分支&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ylzf9dm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完成阶段（F inish）：&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2cbefj1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7r156cl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA commit/XA rollback&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;2--数据源代理&quot;&gt;2. 数据源代理&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA 模式需要 XAConnection。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取 XAConnection 两种方式：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0r9gpyi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;方式一：要求开发者配置 XADataSource&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-aq4r9m4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;方式二：根据开发者的普通 DataSource 来创建&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一种方式，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与 透明化 XA 编程模型的设计目标相违背。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二种方式，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;类比 AT 模式的数据源代理机制，如下：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427111529.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，第二种方法有局限：无法保证兼容的正确性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实际上，这种方法是在做数据库驱动程序要做的事情。不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，我们只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这点在 Oracle 上体现非常明显。参见 Druid issue：&lt;a href=&quot;https://github.com/alibaba/druid/issues/3707&quot;&gt;https://github.com/alibaba/druid/issues/3707&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;综合考虑，XA 模式的数据源代理设计需要同时支持第一种方式：基于 XA 数据源进行代理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;类比 AT 模式的数据源代理机制，如下：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427111546.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;3--分支注册&quot;&gt;3. 分支注册&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA start 需要 Xid 参数。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将来一个可能的优化方向：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个优化方向需要 BranchId 生成机制的变化来配合。BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。&lt;/p&gt;
&lt;h2 id=&quot;XA-模式的使用&quot;&gt;XA 模式的使用&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从编程模型上，XA 模式与 AT 模式保持完全一致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以参考 Seata 官网的样例：&lt;a href=&quot;https://github.com/seata/seata-samples/tree/master/seata-xa&quot;&gt;seata-xa&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;样例场景是 Seata 经典的，涉及库存、订单、账户 3 个微服务的商品订购业务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在样例中，上层编程模型与 AT 模式完全相同。只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;    @Bean(&amp;quot;dataSource&amp;quot;)
    public DataSource dataSource(DruidDataSource druidDataSource) {
        // DataSourceProxy for AT mode
        // return new DataSourceProxy(druidDataSource);

        // DataSourceProxyXA for XA mode
        return new DataSourceProxyXA(druidDataSource);
    }
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Sega模式]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/Sega模式</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/Sega模式</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[Seata框架]]></category><category><![CDATA[Seata解决方案]]></category><pubDate>Tue, 26 Apr 2022 08:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Sega模式&quot;&gt;Sega模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga模式是SEATA提供的⻓事务解决⽅案，在Saga模式中，业务流程中 每个参与者都提交本地事务，当出现某⼀个参与者失败则补偿前⾯已经成 功的参与者，⼀阶段正向服务和⼆阶段补偿服务都由业务开发实现。&lt;/p&gt;
&lt;h1 id=&quot;基于状态机引擎的-Saga-实现&quot;&gt;基于状态机引擎的 Saga 实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽬前SEATA提供的Saga模式是基于状态机引擎来实现的，机制是：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jc2xi7t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于json格式定义服务调用状态图；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w89buwv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;状态图的一个节点可以是一个服务，节点可以配置补偿节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-f93jlz0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;状态图json由状态机执行引擎驱动执行，当出现异常状态时状态机引擎执行反向补偿任务将事物回滚；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mqa0kg7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;异常状态发生时是否进行补偿由用户自定义决定；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zc45tiw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以实现服务编排的需求，支持单项选择、并发、异步、子状态机调用、参数转换、参数映射、服务执行状态判断、异常捕获等功能；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427111055.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;springCloud-seata-saga接入指南&quot;&gt;springCloud seata saga接入指南&lt;/h1&gt;
&lt;h3 id=&quot;配置状态机&quot;&gt;配置状态机&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;json&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;{
  &amp;quot;Name&amp;quot;: &amp;quot;purchaseProcess&amp;quot;,
  &amp;quot;Comment&amp;quot;: &amp;quot;用户下单流程-saga流程&amp;quot;,
  &amp;quot;StartState&amp;quot;: &amp;quot;CreateOrderNo&amp;quot;,
  &amp;quot;Version&amp;quot;: &amp;quot;1.0.0&amp;quot;,
  &amp;quot;States&amp;quot;: {
    &amp;quot;CreateOrderNo&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;生成订单号服务&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.OrderApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;createOrderNo&amp;quot;,
      &amp;quot;CompensateState&amp;quot;: &amp;quot;CompensationCanalOrder1&amp;quot;,
      &amp;quot;Catch&amp;quot;: [
        {
          &amp;quot;Exceptions&amp;quot;: [
            &amp;quot;java.lang.Throwable&amp;quot;
          ],
          &amp;quot;Next&amp;quot;: &amp;quot;CompensationTrigger&amp;quot;
        }],
      &amp;quot;Output&amp;quot;: {
        &amp;quot;orderNo&amp;quot;:&amp;quot;$.#root&amp;quot;
      },
      &amp;quot;Next&amp;quot;: &amp;quot;CreateOrder&amp;quot;,
      &amp;quot;Status&amp;quot;: {
        &amp;quot;$Exception{java.lang.Throwable}&amp;quot;: &amp;quot;UN&amp;quot;,
        &amp;quot;#root != null&amp;quot;: &amp;quot;SU&amp;quot;,
        &amp;quot;#root == null&amp;quot;: &amp;quot;FA&amp;quot;
      }
    },
    &amp;quot;CreateOrder&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;创建订单服务&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.OrderApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;createOrder&amp;quot;,
      &amp;quot;CompensateState&amp;quot;: &amp;quot;CompensationCanalOrder2&amp;quot;,
      &amp;quot;Next&amp;quot;: &amp;quot;ReduceStorage&amp;quot;,
      &amp;quot;Input&amp;quot;: [{
          &amp;quot;orderNo&amp;quot;: &amp;quot;$.[orderNo]&amp;quot;,
          &amp;quot;userId&amp;quot;: &amp;quot;$.[order].userId&amp;quot;,
          &amp;quot;productId&amp;quot;: &amp;quot;$.[order].productId&amp;quot;,
          &amp;quot;count&amp;quot;: &amp;quot;$.[order].count&amp;quot;,
          &amp;quot;price&amp;quot;: &amp;quot;$.[order].price&amp;quot;
        }],
      &amp;quot;Catch&amp;quot;: [{
          &amp;quot;Exceptions&amp;quot;: [
            &amp;quot;java.lang.Throwable&amp;quot;
          ],
          &amp;quot;Next&amp;quot;: &amp;quot;CompensationTrigger&amp;quot;
        }],
      &amp;quot;Status&amp;quot;: {
        &amp;quot;$Exception{java.lang.Throwable}&amp;quot;: &amp;quot;UN&amp;quot;,
        &amp;quot;#root != null&amp;quot;: &amp;quot;SU&amp;quot;,
        &amp;quot;#root == null&amp;quot;: &amp;quot;FA&amp;quot;
      }
    },
    &amp;quot;ReduceStorage&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;扣减库存服务&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.StorageApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;reduce&amp;quot;,
      &amp;quot;CompensateState&amp;quot;: &amp;quot;CompensatingReduceStorage&amp;quot;,
      &amp;quot;Next&amp;quot;:&amp;quot;Succeed&amp;quot;,
      &amp;quot;Input&amp;quot;: [{
        &amp;quot;orderNo&amp;quot;: &amp;quot;$.[orderNo]&amp;quot;,
        &amp;quot;productId&amp;quot;: &amp;quot;$.[order].productId&amp;quot;,
        &amp;quot;count&amp;quot;: &amp;quot;$.[order].count&amp;quot;
      }],
      &amp;quot;Catch&amp;quot;: [{
        &amp;quot;Exceptions&amp;quot;: [
          &amp;quot;java.lang.Throwable&amp;quot;
        ],
        &amp;quot;Next&amp;quot;: &amp;quot;CompensationTrigger&amp;quot;
      }]
    },
    &amp;quot;CompensationCanalOrder1&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;取消订单补偿服务1--用于订单号生成失败&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.OrderApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;canalOrder&amp;quot;,
      &amp;quot;Input&amp;quot;: [
        &amp;quot;$.[orderNo]&amp;quot;,
        1
      ]
    },
    &amp;quot;CompensationCanalOrder2&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;取消订单补偿服务2--用于订单生成失败&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.OrderApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;canalOrder&amp;quot;,
      &amp;quot;Input&amp;quot;: [
        &amp;quot;$.[orderNo]&amp;quot;,
        2
      ]
    },
    &amp;quot;CompensatingReduceStorage&amp;quot;: {
      &amp;quot;Comment&amp;quot;: &amp;quot;库存补偿服务&amp;quot;,
      &amp;quot;Comment&amp;quot;: &amp;quot;扣减库存服务&amp;quot;,
      &amp;quot;Type&amp;quot;: &amp;quot;ServiceTask&amp;quot;,
      &amp;quot;ServiceName&amp;quot;: &amp;quot;com.fly.seata.api.StorageApi&amp;quot;,
      &amp;quot;ServiceMethod&amp;quot;: &amp;quot;compensateReduce&amp;quot;,
      &amp;quot;Input&amp;quot;: [{
        &amp;quot;orderNo&amp;quot;: &amp;quot;$.[orderNo]&amp;quot;,
        &amp;quot;productId&amp;quot;: &amp;quot;$.[order].productId&amp;quot;,
        &amp;quot;count&amp;quot;: &amp;quot;$.[order].count&amp;quot;
      }]
    },
    &amp;quot;CompensationTrigger&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;CompensationTrigger&amp;quot;
    },
    &amp;quot;Succeed&amp;quot;: {
      &amp;quot;Type&amp;quot;:&amp;quot;Succeed&amp;quot;
    },
    &amp;quot;Fail&amp;quot;: {
      &amp;quot;Type&amp;quot;:&amp;quot;Fail&amp;quot;,
      &amp;quot;ErrorCode&amp;quot;: &amp;quot;STORAGE_FAILED&amp;quot;,
      &amp;quot;Message&amp;quot;: &amp;quot;purchase failed&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;配置状态机引擎&quot;&gt;配置状态机引擎&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@Configuration
public class SagaConfig {

  @ConfigurationProperties(&amp;quot;spring.datasource.saga&amp;quot;)
  @Bean
  public DataSource dataSource(){
    return new DruidDataSource();
  }

  @Bean
  public DbStateMachineConfig dbStateMachineConfig(){
    DbStateMachineConfig dbStateMachineConfig = new DbStateMachineConfig();
    dbStateMachineConfig.setDataSource(dataSource());
    Resource[] resources = {new ClassPathResource(&amp;quot;statelang/purchase.json&amp;quot;)};
    dbStateMachineConfig.setResources(resources);
    dbStateMachineConfig.setEnableAsync(true);
    dbStateMachineConfig.setThreadPoolExecutor(threadPoolExecutor());
    dbStateMachineConfig.setApplicationId(&amp;quot;sage-tm&amp;quot;);
    dbStateMachineConfig.setTxServiceGroup(&amp;quot;my_test_tx_group&amp;quot;);
    return dbStateMachineConfig;
  }

  /**
   * saga状态图执行引擎
   * @return
   */
  @Bean
  public StateMachineEngine processCtrlStateMachineEngine(){
    ProcessCtrlStateMachineEngine stateMachineEngine = new ProcessCtrlStateMachineEngine();
    stateMachineEngine.setStateMachineConfig(dbStateMachineConfig());
    return stateMachineEngine;
  }

  @Bean
  public StateMachineEngineHolder stateMachineEngineHolder(){
    StateMachineEngineHolder stateMachineEngineHolder = new StateMachineEngineHolder();
    stateMachineEngineHolder.setStateMachineEngine(processCtrlStateMachineEngine());
    return stateMachineEngineHolder;
  }

  @Bean
  public ThreadPoolExecutor threadPoolExecutor(){
    ThreadPoolExecutorFactoryBean threadPoolExecutorFactoryBean = new ThreadPoolExecutorFactoryBean();
    threadPoolExecutorFactoryBean.setCorePoolSize(1);
    threadPoolExecutorFactoryBean.setMaxPoolSize(20);
    threadPoolExecutorFactoryBean.setThreadNamePrefix(&amp;quot;saga_&amp;quot;);
    return (ThreadPoolExecutor)threadPoolExecutorFactoryBean.getObject();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;状态机执行&quot;&gt;状态机执行&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@RequestMapping(&amp;quot;/tm&amp;quot;)
@RestController
public class TmController {

  /**
   * 模拟购买商品流程
   * @return
   */
  @GlobalTransactional
  @GetMapping(&amp;quot;/purchase&amp;quot;)
  public String purchase(){
    Map&amp;lt;String, Object&amp;gt; startParams = new HashMap&amp;lt;&amp;gt;();
    OrderDTO orderDTO = new OrderDTO();
    orderDTO.setUserId(1l);
    orderDTO.setCount(1);
    orderDTO.setPrice(new BigDecimal(19));
    orderDTO.setProductId(1l);
    startParams.put(&amp;quot;order&amp;quot;,orderDTO);
    StateMachineInstance stateMachineInstance = stateMachineEngine.start(&amp;quot;purchaseProcess&amp;quot;,null,startParams);
    return &amp;quot;执行状态:&amp;quot;+stateMachineInstance.getStatus().getStatusString();
  }

}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[TCC模式]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/TCC模式</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/TCC模式</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[Seata框架]]></category><category><![CDATA[Seata解决方案]]></category><pubDate>Tue, 26 Apr 2022 08:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;TCC模式&quot;&gt;TCC模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 与 Seata AT 事务⼀样都是两阶段事务，它与 AT 事务的主要区别为：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dn295mv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 对业务代码侵⼊严重&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个阶段的数据操作都要⾃⼰进⾏编码来实现，事务框架⽆法⾃动处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iidoz3k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 性能更⾼&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不必对数据加全局锁，允许多个事务同时操作数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/ecaeda572495e4ea5e308fb938a38fd5.png&quot; alt=&quot;ecaeda572495e4ea5e308fb938a38fd5&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata TCC整体是&lt;code&gt;两阶段提交&lt;/code&gt;的模型。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀个分布式的全局事务，全局事务是由若⼲分⽀事务组成的，分⽀事务要满⾜&lt;code&gt;两阶段提交&lt;/code&gt;的模型要求，即需要每个分⽀事务都具备⾃⼰的：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-r6kzkxq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀阶段 prepare ⾏为&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8kpzac5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆阶段 commit 或 rollback ⾏为&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427100423.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 模式，不依赖于底层数据资源的事务⽀持：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-930haiu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀阶段 prepare ⾏为：调⽤ ⾃定义 的 prepare 逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6tmjs7s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆阶段 commit ⾏为：调⽤ ⾃定义 的 commit 逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-i9vm2k3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆阶段 rollback ⾏为：调⽤ ⾃定义 的 rollback 逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 模式，是指⽀持把&lt;code&gt;⾃定义&lt;/code&gt;的分⽀事务纳⼊到全局事务的管理中。&lt;/p&gt;
&lt;h1 id=&quot;第-阶段-Try&quot;&gt;第⼀阶段 Try&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以账户服务为例，当下订单时要扣减⽤户账户⾦额：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假如⽤户购买 100 元商品，要扣减 100 元。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427100935.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 事务⾸先对这100元的扣减⾦额进⾏预留，或者说是先冻结这100元&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427101002.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;第-阶段-Confirm&quot;&gt;第⼆阶段 Confirm&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果第⼀阶段能够顺利完成，那么说明“扣减⾦额”业务(分⽀事务)最终肯定 是可以成功的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当全局事务提交时， TC会控制当前分⽀事务进⾏提交，如 果提交失败，TC 会反复尝试，直到提交成功为⽌。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当全局事务提交时，就可以使⽤冻结的⾦额来最终实现业务数据操作：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427101024.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;第-阶段-Cancel&quot;&gt;第⼆阶段 Cancel&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果全局事务回滚，就把冻结的⾦额进⾏解冻，恢复到以前的状态，TC 会 控制当前分⽀事务回滚，如果回滚失败，TC 会反复尝试，直到回滚完成为⽌。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;assets/image-20220427101106-zhsw0mu.png&quot; alt=&quot;image.png&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;多个事务并发的情况&quot;&gt;多个事务并发的情况&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;多个TCC全局事务允许并发，它们执⾏扣减⾦额时，只需要冻结各⾃的⾦额即可：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20220427101229.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;SpringCloud集成TCC&quot;&gt;SpringCloud集成TCC&lt;/h1&gt;
&lt;h3 id=&quot;定义TCC接口&quot;&gt;定义TCC接口&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于我们使用的是 SpringCloud + Feign，Feign的调用基于http，因此此处我们使用&lt;code&gt;@LocalTCC&lt;/code&gt;便可。值得注意的是，&lt;code&gt;@LocalTCC&lt;/code&gt;一定需要注解在接口上，此接口可以是寻常的业务接口，只要实现了TCC的两阶段提交对应方法便可，TCC相关注解如下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jigzm0k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;@LocalTCC&lt;/code&gt; 适用于SpringCloud+Feign模式下的TCC&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oezm2nb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;@TwoPhaseBusinessAction&lt;/code&gt; 注解try方法，其中name为当前tcc方法的bean名称，写方法名便可（全局唯一），commitMethod指向提交方法，rollbackMethod指向事务回滚方法。指定好三个方法之后，seata会根据全局事务的成功或失败，去帮我们自动调用提交方法或者回滚方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rimab9a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;@BusinessActionContextParameter&lt;/code&gt; 注解可以将参数传递到二阶段（commitMethod/rollbackMethod）的方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6vst91b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;BusinessActionContext&lt;/code&gt; 便是指TCC事务上下文&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * 这里定义tcc的接口
 * 一定要定义在接口上
 * 我们使用springCloud的远程调用
 * 那么这里使用LocalTCC便可
 *
 * @author tanzj
 */
@LocalTCC
public interface TccService {
 
    /**
     * 定义两阶段提交
     * name = 该tcc的bean名称,全局唯一
     * commitMethod = commit 为二阶段确认方法
     * rollbackMethod = rollback 为二阶段取消方法
     * BusinessActionContextParameter注解 传递参数到二阶段中
     *
     * @param params  -入参
     * @return String
     */
    @TwoPhaseBusinessAction(name = &amp;quot;insert&amp;quot;, commitMethod = &amp;quot;commitTcc&amp;quot;, rollbackMethod = &amp;quot;cancel&amp;quot;)
    String insert(
            @BusinessActionContextParameter(paramName = &amp;quot;params&amp;quot;) Map&amp;lt;String, String&amp;gt; params
    );
 
    /**
     * 确认方法、可以另命名，但要保证与commitMethod一致
     * context可以传递try方法的参数
     *
     * @param context 上下文
     * @return boolean
     */
    boolean commitTcc(BusinessActionContext context);
 
    /**
     * 二阶段取消方法
     *
     * @param context 上下文
     * @return boolean
     */
    boolean cancel(BusinessActionContext context);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;TCC接口的业务实现&quot;&gt;TCC接口的业务实现&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了保证代码的简洁，此处将路由层与业务层结合讲解，实际项目则不然。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-goxynjl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在try方法中使用&lt;code&gt;@Transational&lt;/code&gt;可以直接通过spring事务回滚关系型数据库中的操作，而非关系型数据库等中间件的回滚操作可以交给rollbackMethod方法处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nuqh6vw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用context.getActionContext(&amp;quot;params&amp;quot;)便可以得到一阶段try中定义的参数，在二阶段对此参数进行业务回滚操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x94tmim&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;注意1：&lt;/strong&gt;此处亦不可以捕获异常（同理切面处理异常），否则TCC将识别该操作为成功，二阶段直接执行commitMethod。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yuut4ff&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;注意2：&lt;/strong&gt;TCC模式要&lt;strong&gt;开发者自行&lt;/strong&gt;保证幂等和事务防悬挂&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@Slf4j
@RestController
public class TccServiceImpl implements  TccService {
 
    @Autowired
    TccDAO tccDAO;
 
    /**
     * tcc服务t（try）方法
     * 根据实际业务场景选择实际业务执行逻辑或者资源预留逻辑
     *
     * @param params - name
     * @return String
     */
    @Override
    @PostMapping(&amp;quot;/tcc-insert&amp;quot;)
    @Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRED)
    public String insert(@RequestBody Map&amp;lt;String, String&amp;gt; params) {
        log.info(&amp;quot;xid = &amp;quot; + RootContext.getXID());
        //todo 实际的操作，或操作MQ、redis等
        tccDAO.insert(params);
        //放开以下注解抛出异常
        //throw new RuntimeException(&amp;quot;服务tcc测试回滚&amp;quot;);
        return &amp;quot;success&amp;quot;;
    }
 
    /**
     * tcc服务 confirm方法
     * 若一阶段采用资源预留，在二阶段确认时要提交预留的资源
     *
     * @param context 上下文
     * @return boolean
     */
    @Override
    public boolean commitTcc(BusinessActionContext context) {
        log.info(&amp;quot;xid = &amp;quot; + context.getXid() + &amp;quot;提交成功&amp;quot;);
        //todo 若一阶段资源预留，这里则要提交资源
        return true;
    }
 
    /**
     * tcc 服务 cancel方法
     *
     * @param context 上下文
     * @return boolean
     */
    @Override
    public boolean cancel(BusinessActionContext context) {
        //todo 这里写中间件、非关系型数据库的回滚操作
        System.out.println(&amp;quot;please manually rollback this data:&amp;quot; + context.getActionContext(&amp;quot;params&amp;quot;));
        return true;
    }
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[AT模式]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/AT模式</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架/Seata解决方案/AT模式</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[Seata框架]]></category><category><![CDATA[Seata解决方案]]></category><pubDate>Tue, 26 Apr 2022 07:55:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;AT模式&quot;&gt;AT模式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata AT模式是最早⽀持的模式。AT模式是指Automatic (Branch) Transaction Mode⾃动化分⽀事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata AT 模式是增强型2pc模式，或者说是增强型的XA模型。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总体来说，AT 模式，是 2pc两阶段提交协议的演变，不同的地⽅，SeataAT 模式不会⼀直锁表。&lt;/p&gt;
&lt;h1 id=&quot;使用前提&quot;&gt;使用前提&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bxr2kkm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于支持本地 ACID 事务的关系型数据库&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3xnsccf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 应用，通过 JDBC 访问数据库&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;整体机制&quot;&gt;整体机制&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata AT模型图&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两阶段提交协议的演变：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qoi20a4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀阶段：业务数据和回滚⽇志记录在同⼀个本地事务中提交，释放本地锁和连接资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-55b5le4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆阶段：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rz3b1kn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提交异步化，⾮常快速地完成&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j5o72gv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或回滚通过⼀阶段的回滚⽇志进⾏反向补偿&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完整的AT在Seata所制定的事务模式下的模型图：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20201009172509465.png&quot; alt=&quot;20201009172509465&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&quot;数据隔离性&quot;&gt;数据隔离性&lt;/h1&gt;
&lt;h2 id=&quot;写隔离&quot;&gt;写隔离&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h5mrklg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一阶段本地事务提交前，需要确保先拿到 &lt;strong&gt;全局锁&lt;/strong&gt; 。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ck3pf32&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;拿不到 &lt;strong&gt;全局锁&lt;/strong&gt; ，不能提交本地事务。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mx3vrry&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;拿 &lt;strong&gt;全局锁&lt;/strong&gt; 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以一个示例来说明：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 &lt;strong&gt;全局锁&lt;/strong&gt; ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 &lt;strong&gt;全局锁&lt;/strong&gt; ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 &lt;strong&gt;全局锁&lt;/strong&gt; 。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/seata_at-1.png&quot; alt=&quot;seata_at-1&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;tx1 二阶段全局提交，释放 &lt;strong&gt;全局锁&lt;/strong&gt; 。tx2 拿到 &lt;strong&gt;全局锁&lt;/strong&gt; 提交本地事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/52J1Ew.jpg&quot; alt=&quot;52J1Ew&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时，如果 tx2 仍在等待该数据的  &lt;strong&gt;全局锁&lt;/strong&gt; ，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 &lt;strong&gt;全局锁&lt;/strong&gt; 等锁超时，放弃 &lt;strong&gt;全局锁&lt;/strong&gt; 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为整个过程 &lt;strong&gt;全局锁&lt;/strong&gt; 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 &lt;strong&gt;脏写&lt;/strong&gt; 的问题。&lt;/p&gt;
&lt;h2 id=&quot;读隔离&quot;&gt;读隔离&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在数据库本地事务隔离级别 &lt;strong&gt;读已提交（Read Committed）&lt;/strong&gt; 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 &lt;strong&gt;读未提交（Read Uncommitted）&lt;/strong&gt; 。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果应用在特定场景下，必需要求全局的 &lt;strong&gt;读已提交&lt;/strong&gt; ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/EmlTOi.jpg&quot; alt=&quot;EmlTOi&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SELECT FOR UPDATE 语句的执行会申请 &lt;strong&gt;全局锁&lt;/strong&gt; ，如果 &lt;strong&gt;全局锁&lt;/strong&gt; 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 &lt;strong&gt;全局锁&lt;/strong&gt; 拿到，即读取的相关数据是 &lt;strong&gt;已提交&lt;/strong&gt; 的，才返回。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Seata框架]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/Seata框架</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/Seata框架</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><pubDate>Tue, 26 Apr 2022 06:56:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Seata框架&quot;&gt;Seata框架&lt;/h1&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata 是⼀款开源的分布式事务解决⽅案，致⼒于提供⾼性能和简单易⽤的分布式事务服务。Seata 将为⽤户提供了 AT、TCC、SAGA 和 XA 事务模式，为⽤户打造⼀站式的分布式解决⽅案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Seata 开源之前，Seata 对应的内部版本在阿⾥经济体内部⼀直扮演着分布式⼀致性中间件的⻆⾊，帮助经济体平稳的度过历年的双11，对各BU业务进⾏了有⼒的⽀撑。商业化产品GTS 先后在阿⾥云、⾦融云进⾏售卖&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Seata模块&quot;&gt;Seata模块&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata分为三大模块:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wsqznys&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TC ：事务协调者。负责我们的事务ID的⽣成，事务注册、提交、回滚等。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fyuybk8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TM：事务发起者。定义事务的边界，负责告知 TC，分布式事务的开始，提交，回滚。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ocmj0b4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RM：资源管理者。管理每个分⽀事务的资源，每⼀个 RM 都会作为⼀个分⽀事务注册在 TC。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在Seata的AT模式中，TM和RM都作为SDK的⼀部分和业务服务在⼀起，我们可以认为是Client。TC是⼀个独⽴的服务，通过服务的注册、发现将⾃⼰暴露给Client们。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Seata 中有三⼤模块中， TM 和 RM 是作为 Seata 的客户端与业务系统集成在⼀起，TC 作为 Seata 的服务端独立部署。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Seata 中，分布式事务的执⾏流程：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nj73gul&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TM 开启分布式事务（TM 向 TC 注册全局事务记录）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2fw40gw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9f18uhm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TM 结束分布式事务，事务⼀阶段结束（TM 通知 TC 提交/回滚分布式事务）；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t8nosj3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TC 汇总事务信息，决定分布式事务是提交还是回滚；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2dsq9d4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TC 通知所有 RM 提交/回滚 资源，事务⼆阶段结束；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20210710161530943.png&quot; alt=&quot;20210710161530943&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[总体的⽅案对⽐]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/事务分类/总体的⽅案对⽐</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/事务分类/总体的⽅案对⽐</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[事务分类]]></category><pubDate>Tue, 26 Apr 2022 06:39:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;总体的-案对-&quot;&gt;总体的⽅案对⽐&lt;/h1&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;属性&lt;/th&gt;
&lt;th&gt;2PC&lt;/th&gt;
&lt;th&gt;TCC&lt;/th&gt;
&lt;th&gt;Saga&lt;/th&gt;
&lt;th&gt;事务消息&lt;/th&gt;
&lt;th&gt;本地消息表&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;事务一致性&lt;/td&gt;
&lt;td&gt;强&lt;/td&gt;
&lt;td&gt;弱&lt;/td&gt;
&lt;td&gt;弱&lt;/td&gt;
&lt;td&gt;弱&lt;/td&gt;
&lt;td&gt;弱&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;复杂性&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;业务侵入性&lt;/td&gt;
&lt;td&gt;小&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;使用局限性&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;小&lt;/td&gt;
&lt;td&gt;小&lt;br /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;性能&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;维护成本&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content:encoded></item><item><title><![CDATA[SpringCloud并发请求其他系统接口，导致链路追踪失效]]></title><link>https://www.ztianzeng.com/posts/SpringCloud并发请求其他系统接口，导致链路追踪失效</link><guid isPermaLink="false">/posts/SpringCloud并发请求其他系统接口，导致链路追踪失效</guid><pubDate>Mon, 25 Apr 2022 10:46:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;SpringCloud并发请求其他系统接口-导致链路追踪失效&quot;&gt;SpringCloud并发请求其他系统接口，导致链路追踪失效&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在有一次使用线程池调用feign接口请求下游接口，下游接口拿不到系统的spanId和traceId，导致多线程下的链路追踪就不起作用，以致于难以排查问题&lt;/p&gt;
&lt;h2 id=&quot;分析&quot;&gt;分析&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于项目中重写了&lt;code&gt;Feigin&lt;/code&gt;中的&lt;code&gt;RequestInterceptor&lt;/code&gt;，在重写方法中会通过&lt;code&gt;RequestContextHolder&lt;/code&gt;提取header头做了一些对应的属性设置，在多线程开启的子线程下 &lt;code&gt;RequestContextHolder&lt;/code&gt; 拿到的&lt;code&gt;request&lt;/code&gt;是null，应该是这边导致的问题。&lt;/p&gt;
&lt;h2 id=&quot;原理分析&quot;&gt;原理分析&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;RequestContextHolder&lt;/code&gt;是&lt;code&gt;Spring-Web&lt;/code&gt;提供，用于方便的获取当前请求的信息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其内部中有两个ThreadLocal，一个是用于当前线程的&lt;code&gt;requestAttributesHolder&lt;/code&gt;，另一个是作用于子线程的&lt;code&gt;inheritableRequestAttributesHolder&lt;/code&gt;，在不做任何设置的情况下，是通过当前线程的&lt;code&gt;requestAttributesHolder&lt;/code&gt;来存储对象的.&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public abstract class RequestContextHolder  {
	private static final ThreadLocal&amp;lt;RequestAttributes&amp;gt; requestAttributesHolder =
			new NamedThreadLocal&amp;lt;&amp;gt;(&amp;quot;Request attributes&amp;quot;);

	private static final ThreadLocal&amp;lt;RequestAttributes&amp;gt; inheritableRequestAttributesHolder =
			new NamedInheritableThreadLocal&amp;lt;&amp;gt;(&amp;quot;Request context&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在&lt;code&gt;Spring-Web&lt;/code&gt;的实现中，是在&lt;code&gt;FrameworkServlet#processRequest&lt;/code&gt;中，在进入请求处理之前，会将&lt;code&gt;Request&lt;/code&gt;的信息设置到&lt;code&gt;requestAttributesHolder&lt;/code&gt;中去&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;protected final void processRequest(HttpServletRequest request, HttpServletResponse response)
      throws ServletException, IOException {
​
   RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();
   ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes);
​
   initContextHolders(request, localeContext, requestAttributes);
​
   try {
      doService(request, response);
   }
}
​
private void initContextHolders(HttpServletRequest request,
      @Nullable LocaleContext localeContext, @Nullable RequestAttributes requestAttributes) {
​
    if (requestAttributes != null) {
      RequestContextHolder.setRequestAttributes(requestAttributes, this.threadContextInheritable);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在从&lt;code&gt;RequestContextHolder&lt;/code&gt;中取出数据的时候，则会从&lt;code&gt;requestAttributesHolder&lt;/code&gt;中取，如果取不到则会从&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;inheritableRequestAttributesHolder&lt;/code&gt;取。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static RequestAttributes getRequestAttributes() {
	RequestAttributes attributes = requestAttributesHolder.get();
	if (attributes == null) {
		attributes = inheritableRequestAttributesHolder.get();
	}
	return attributes;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;解决方案&quot;&gt;解决方案&lt;/h2&gt;
&lt;h3 id=&quot;修改配置&quot;&gt;修改&lt;code&gt;ServletRegistrationBean&lt;/code&gt;配置&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以通过设置&lt;code&gt;threadContextInheritable&lt;/code&gt;来修改存储位置，存储到&lt;code&gt;inheritableRequestAttributesHolder&lt;/code&gt;中&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; @Bean
    public ServletRegistrationBean apiServlet(DispatcherServlet dispatcherServlet) {
	// 设置到子线程
        dispatcherServlet.setThreadContextInheritable(true);
        ServletRegistrationBean bean = new ServletRegistrationBean(dispatcherServlet);
        return bean;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;新开子线程之前手动设置子线程共享&quot;&gt;新开子线程之前手动设置子线程共享&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;ServletRequestAttributes sra = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
RequestContextHolder.setRequestAttributes(sra, true);
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;InheritableThreadLocal是怎么做到主子线程共享的&quot;&gt;InheritableThreadLocal是怎么做到主子线程共享的&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;InheritableThreadLocal&lt;/code&gt;是在创建&lt;code&gt;Thread&lt;/code&gt;的时候初始化进去的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看&lt;code&gt;Thread&lt;/code&gt;构造方法:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public Thread() {
    this(null, null, &amp;quot;Thread-&amp;quot; + nextThreadNum(), 0);
}

public Thread(ThreadGroup group, Runnable target, String name,
                  long stackSize) {
    this(group, target, name, stackSize, null, true);
}

private Thread(ThreadGroup g, Runnable target, String name,
                   long stackSize, AccessControlContext acc,
                   boolean inheritThreadLocals) {
     ......
    Thread parent = currentThread();
    if (inheritThreadLocals &amp;amp;&amp;amp; parent.inheritableThreadLocals != null)
            this.inheritableThreadLocals =
                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
     ......
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后在创建&lt;code&gt;Thread&lt;/code&gt; 的时候，会调用一个带&lt;code&gt;inheritThreadLocals&lt;/code&gt;标记的构造方法&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果&lt;code&gt;inheritThreadLocals&lt;/code&gt;为true，并且当前线程&lt;code&gt;inheritableThreadLocals&lt;/code&gt;不为空，就将&lt;code&gt;inheritableThreadLocals&lt;/code&gt;设置成父类的&lt;code&gt;inheritableThreadLocals&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;继续点进去看:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; private ThreadLocalMap(ThreadLocalMap parentMap) {
            Entry[] parentTable = parentMap.table;
            int len = parentTable.length;
            setThreshold(len);
            table = new Entry[len];

            for (Entry e : parentTable) {
                if (e != null) {
                    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
                    ThreadLocal&amp;lt;Object&amp;gt; key = (ThreadLocal&amp;lt;Object&amp;gt;) e.get();
                    if (key != null) {
                        Object value = key.childValue(e.value);
                        Entry c = new Entry(key, value);
                        int h = key.threadLocalHashCode &amp;amp; (len - 1);
                        while (table[h] != null)
                            h = nextIndex(h, len);
                        table[h] = c;
                        size++;
                    }
                }
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就是通过&lt;code&gt;ThreadLocalMap&lt;/code&gt;的构造方法，将父类的值一个一个拷贝到子线程中,然后新创建的&lt;code&gt;inheritableThreadLocals&lt;/code&gt;就有了值，我们也就能通过这个对象，将父线程的值给拿过来了，自然也就完成了主子线程的传递&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[柔性事务的实现]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/事务分类/柔性事务的实现</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/事务分类/柔性事务的实现</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[事务分类]]></category><pubDate>Sat, 23 Apr 2022 13:53:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;柔性事务的实现&quot;&gt;柔性事务的实现&lt;/h1&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在电商领域等互联⽹场景下，刚性事务在数据库性能和处理能⼒上都暴露出了瓶颈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务有两个特性：基本可⽤和柔性状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基本可⽤是指分布式系统出现故障的时候允许损失⼀部分的可⽤性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性状态是指允许系统存在中间状态，这个中间状态不会影响系统整体的可⽤性，⽐如数据库读写分离的主从同步延迟等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务的⼀致性指的是最终⼀致性。&lt;/p&gt;
&lt;h1 id=&quot;柔性事务的分类&quot;&gt;柔性事务的分类&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务主要分为两大类:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0p3kxbu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通知型: 实现方案 -&amp;gt; MQ事务消息、本地消息表，特点: 异步调用&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n57hxui&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿型: 实现方案-&amp;gt; TCC、Sega ，特点: 同步调用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;通知型事务&quot;&gt;通知型事务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通知型事务的主流实现是通过MQ（消息队列）来通知其他事务参与者⾃⼰事务的执⾏状态，引⼊MQ组件，有效的将事务参与者进⾏解耦，各参与者都可以异步执⾏，所以通知型事务⼜被称为异步事务。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-kvl9p9z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;异步确保型事务：主要适⽤于内部系统的数据最终⼀致性保障，因为内部相对⽐较可控，如订单和购物⻋、收货与清算、⽀付与结算等等场景&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vtpsqvv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最⼤努⼒通知：主要⽤于外部系统，因为外部的⽹络环境更加复杂和不可信，所以只能尽最⼤努⼒去通知实现数据最终⼀致性，⽐如充值平台与运营商、⽀付对接等跨⽹络系统级别对接&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;异步确保型事务&quot;&gt;异步确保型事务&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;指将⼀系列同步的事务操作修改为基于消息队列异步执⾏的操作，来避免分布式事务中同步阻塞带来的数据操作性能的下降。&lt;/p&gt;
&lt;h4 id=&quot;MQ事务消息&quot;&gt;MQ事务消息&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于MQ的事务消息⽅案主要依靠MQ的半消息机制来实现投递消息和参与者⾃身本地事务的⼀致性保障。半消息机制实现原理其实借鉴的2PC的思路，是⼆阶段提交的⼴义拓展。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/RSb0i0.jpg&quot; alt=&quot;RSb0i0&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;事务消息发送步骤如下：&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xe9r0ec&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者将半事务消息发送至MQ服务端。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kn92445&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息为半事务消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zxfb785&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者开始执行本地事务逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-sxknp57&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2mtwwm8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4eqjdno&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5o8saej&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;事务消息回查步骤如下：&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2jldvi0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w2r0peh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/zS54uh.jpg&quot; alt=&quot;zS54uh&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;本地消息表&quot;&gt;本地消息表&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有时候我们⽬前的MQ组件并不⽀持事务消息，或者我们想尽量少的侵⼊业务⽅。这时我们需要另外⼀种⽅案——基于DB本地消息表。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本地消息表最初由eBay 提出来解决分布式事务的问题。是⽬前业界使⽤的⽐较多的⽅案之⼀，它的核⼼思想就是将分布式事务拆分成本地事务进⾏处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20200825135927900.png&quot; alt=&quot;20200825135927900&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;发送消息⽅：&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-izar5af&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要有⼀个消息表，记录着消息状态相关信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dbvc8m4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务数据和消息表在同⼀个数据库，要保证它俩在同⼀个本地事务。直接利⽤本地事务，将业务数据和事务消息直接写⼊数据库。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h86r42p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在本地事务中处理完业务数据和写消息表操作后，通过写消息到 MQ 消息队列。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3q3mzoo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使⽤专⻔的投递⼯作线程进⾏事务消息投递到MQ，根据投递ACK去删除事务消息表记录消息会发到消息消费⽅，如果发送失败，即进⾏重试。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;消息消费⽅：&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yzesc1p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;处理消息队列中的消息，完成⾃⼰的业务逻辑。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gsqiuaz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果本地事务处理成功，则表明已经处理成功了。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bhfturl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果本地事务处理失败，那么就会重试执⾏。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-efihk98&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果是业务层⾯的失败，给消息⽣产⽅发送⼀个业务补偿消息，通知进⾏回滚等操作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;需要注意的问题:&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0dyjy0x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务主动⽅在完成业务处理后，向业务被动⽅(第三⽅系统)发送通知消息，允许存在消息丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-f0q7efo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务主动⽅提供递增多挡位时间间隔(5min、10min、30min、1h、24h)，⽤于失败重试调⽤业务被动⽅的接⼝；在通知N次之后就不再通知，报警+记⽇志+⼈⼯介⼊。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ncmneme&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务被动⽅提供幂等的服务接⼝，防⽌通知重复消费。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gp9akpp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务主动⽅需要有定期校验机制，对业务数据进⾏兜底；防⽌业务被动⽅⽆法履⾏责任时进⾏业务回滚，确保数据最终⼀致性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;MQ事务消息-VS-本地消息表&quot;&gt;MQ事务消息 VS 本地消息表&lt;/h4&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4f6axtb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆者的共性：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;1、 事务消息都依赖MQ进⾏事务通知，所以都是异步的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2、 事务消息在投递⽅都是存在重复投递的可能，需要有配套的机制去降低重复投递率，实现更友好的消息投递去重。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;3、 事务消息的消费⽅，因为投递重复的⽆法避免，因此需要进⾏消费去重设计或者服务幂等设计。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8uw2q8b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼆者的区别：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xs4lsr7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MQ事务消息：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要MQ⽀持半消息机制或者类似特性，在重复投递上具有⽐较好的去重处理；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;具有⽐较⼤的业务侵⼊性，需要业务⽅进⾏改造，提供对应的本地操作成功的回查功能；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-v7tej0w&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DB本地消息表：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使⽤了数据库来存储事务消息，降低了对MQ的要求，但是增加了存储成本；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务消息使⽤了异步投递，增⼤了消息重复投递的可能性；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;通知型事务的问题&quot;&gt;通知型事务的问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通知型事务，是⽆法解决本地事务执⾏和消息发送的⼀致性问题的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为消息发送是⼀个⽹络通信的过程，发送消息的过程就有可能出现发送失败、或者超时的情况。超时有可能发送成功了，有可能发送失败了，消息的发送⽅是⽆法确定的，所以此时消息发送⽅⽆论是提交事务还是回滚事务，都有可能不⼀致性出现。&lt;/p&gt;
&lt;h3 id=&quot;消息发送-致性&quot;&gt;消息发送⼀致性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息中间件在分布式系统中的核⼼作⽤就是异步通讯、应⽤解耦和并发缓冲（也叫作流量削峰）。在分布式环境下，需要通过⽹络进⾏通讯，就引⼊了数据传输的不确定性，也就是CAP理论中的分区容错性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;消息发送⼀致性是指产⽣消息的业务动作与消息发送动作⼀致，也就是说如果业务操作成功，那么由这个业务操作所产⽣的消息⼀定要发送出去，否则就丢失。&lt;/p&gt;
&lt;h4 id=&quot;常规MQ消息处理流程和特点&quot;&gt;常规MQ消息处理流程和特点&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;常规的MQ队列处理流程⽆法实现消息的⼀致性。所以，需要借助半消息、本地消息表，保障⼀致性。&lt;/p&gt;
&lt;h3 id=&quot;消息重复投递和业务幂等性&quot;&gt;消息重复投递和业务幂等性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于未确认的消息，采⽤按规则重新投递的⽅式进⾏处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于以上流程，消息重复发送会导致业务处理接⼝出现重复调⽤的问题。消息消费过程中消息重复发送的主要原因就是消费者成功接收处理完消息后，消息中间件没有及时更新投递状态导致的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果允许消息重复发送，那么消费⽅应该实现业务接⼝的幂等性设计。&lt;/p&gt;
&lt;h2 id=&quot;补偿型事务&quot;&gt;补偿型事务&lt;/h2&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是基于消息实现的事务并不能解决所有的业务场景，例如以下场景：某笔订单完成时，同时扣掉⽤户的现⾦。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这⾥事务发起⽅是管理订单库的服务，但对整个事务是否提交并不能只由订单服务决定，因为还要确保⽤户有⾜够的钱，才能完成这笔交易，⽽这个信息在管理现⾦的服务⾥。这⾥我们可以引⼊基于补偿实现的事务，其流程如下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-re9p4j1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;创建订单数据，但暂不提交本地事务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-purh6ar&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;订单服务发送远程调⽤到现⾦服务，以扣除对应的⾦额&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zlh2f84&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上述步骤成功后提交订单库的事务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以上这个是正常成功的流程，异常流程需要回滚的话，将额外发送远程调⽤到现⾦服务以加上之前扣掉的⾦额。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以上流程⽐基于消息队列实现的事务的流程要复杂，同时开发的⼯作量也更多：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-fwfmt93&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编写订单服务⾥创建订单的逻辑&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ob93eo4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编写现⾦服务⾥扣钱的逻辑&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-la1nvyn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编写现⾦服务⾥补偿返还的逻辑&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看到，该事务流程相对于基于消息实现的分布式事务更为复杂，需要额外开发相关的业务回滚⽅法，也失去了服务间流量削峰填⾕的功能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但其仅仅只⽐基于消息的事务复杂多⼀点，若不能使⽤基于消息队列的最终⼀致性事务，那么可以优先考虑使⽤基于补偿的事务形态。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿模式使⽤⼀个额外的协调服务来协调各个需要保证⼀致性的业务服务，协调服务按顺序调⽤各个业务微服务，如果某个业务服务调⽤异常（包括业务异常和技术异常）就取消之前所有已经调⽤成功的业务服务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿模式也大致分为两大类:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ca6hd0k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC事务模型&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rrpoo9t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Sega模型&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;TCC-事务模型&quot;&gt;TCC 事务模型&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC（Try-Confirm-Cancel）的概念来源于 Pat Helland 发表的⼀篇名为“Life beyond Distributed Transactions:an Apostate’s Opinion”的论⽂。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 分布式事务模型包括三部分：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-j81u784&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主业务服务：主业务服务为整个业务活动的发起⽅，服务的编排者，负责发起并完成整个业务活动。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6vafnpi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从业务服务：从业务服务是整个业务活动的参与⽅，负责提供 TCC 业务操作，实现初步操作(Try)、确认操作(Confirm)、取消操作(Cancel)三个接⼝，供主业务服务调⽤。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20210710092138838.png&quot; alt=&quot;20210710092138838&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&quot;3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-z7urx3g&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务活动管理器：业务活动管理器管理控制整个业务活动，包括记录维护 TCC 全局事务的事务状态和每个从业务服务的⼦事务状态，并在业务活动提交时调⽤所有从业务服务的 Confirm 操作，在业务活动取消时调⽤所有从业务服务的 Cancel 操作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 提出了⼀种新的事务模型，基于业务层⾯的事务定义，锁粒度完全由业务⾃⼰控制，⽬的是解决复杂业务中，跨表跨库等⼤颗粒度资源锁定的问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 把事务运⾏过程分成 Try、Confirm / Cancel 两个阶段，每个阶段的逻辑由业务代码控制，避免了⻓事务，可以获取更⾼的性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;工作流程&quot;&gt;工作流程&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC(Try-Confirm-Cancel)分布式事务模型相对于 XA 等传统模型，其特征在于它不依赖资源管理器(RM)对分布式事务的⽀持，⽽是通过对业务逻辑的分解来实现分布式事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 模型认为对于业务系统中⼀个特定的业务逻辑，其对外提供服务时，必须接受⼀些不确定性，即对业务逻辑初步操作的调⽤仅是⼀个临时性操作，调⽤它的主业务服务保留了后续的取消权。如果主业务服务认为全局事务应该回滚，它会要求取消之前的临时性操作，这就对应从业务服务的取消操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽽当主业务服务认为全局事务应该提交时，它会放弃之前临时性操作的取消权，这对应从业务服务的确认操作。每⼀个初步操作，最终都会被确认或取消。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，针对⼀个具体的业务服务，TCC 分布式事务模型需要业务系统提供三段业务逻辑：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-iwqsyu0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;初步操作 Try：完成所有业务检查，预留必须的业务资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yvm6t4c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;确认操作 Confirm：真正执⾏的业务逻辑，不作任何业务检查，只使⽤ Try阶段预留的业务资源。因此，只要 Try操作成功，Confirm 必须能成功。另外，Confirm 操作需满⾜幂等性，保证⼀笔分布式事务有且只能成功⼀次&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-28l3dpv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;取消操作 Cancel：释放 Try 阶段预留的业务资源。同样的，Cancel 操作也需要满⾜幂等性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/1bf0b27725f150295091457167_1001046.png&quot; alt=&quot;1bf0b27725f150295091457167_1001046&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;Try 阶段失败可以 Cancel，如果 Confirm 和 Cancel 阶段失败了怎么办？&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC 中会添加事务⽇志，如果 Confirm 或者 Cancel 阶段出错，则会进⾏重试，所以这两个阶段需要⽀持幂等；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果重试失败，则需要⼈⼯介⼊进⾏恢复和处理等。&lt;/p&gt;
&lt;h3 id=&quot;TCC事务模型-VS-DTP事务模型&quot;&gt;TCC事务模型 VS DTP事务模型&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽐较⼀下TCC事务模型和DTP事务模型，如下所示：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20191210222510796.png&quot; alt=&quot;20191210222510796&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;1、TCC模型中的 &lt;code&gt;主业务服务&lt;/code&gt; 相当于 DTP模型中的&lt;code&gt;AP&lt;/code&gt;，TCC模型中的&lt;code&gt;从业务服务&lt;/code&gt; 相当于 DTP模型中的&lt;code&gt;RM&lt;/code&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3w8aqsk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在DTP模型中，应⽤AP操作多个资源管理器RM上的资源；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2nyn6tc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在TCC模型中，是主业务服务操作多个从业务服务上的资源。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;例如航班预定案例中，美团App就是主业务服务，⽽川航和东航就是从业务服务，主业务服务需要使⽤从业务服务上的机票资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不同的是DTP模型中的资源提供者是类似于Mysql这种关系型数据库，⽽TCC模型中资源的提供者是其他业务服务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2、TCC模型中，从业务服务提供的&lt;code&gt;try&lt;/code&gt;、&lt;code&gt;confirm&lt;/code&gt;、&lt;code&gt;cancel&lt;/code&gt;接⼝ 相当于DTP模型中RM提供的&lt;code&gt;prepare&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;rollback&lt;/code&gt;接⼝&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5s2cfgr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA协议中规定了DTP模型中定RM需要提供&lt;code&gt;prepare&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;rollback&lt;/code&gt;接⼝给TM调⽤，以实现两阶段提交。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g581xpb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在TCC模型中，从业务服务相当于&lt;code&gt;RM&lt;/code&gt;，提供了类似的&lt;code&gt;try&lt;/code&gt;、&lt;code&gt;confirm&lt;/code&gt;、&lt;code&gt;cancel&lt;/code&gt;接⼝。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC是可以解决部分场景下的分布式事务的，但是，它的⼀个问题在于，需要每个参与者都分别实现Try，Confirm和Cancel接⼝及逻辑，这对于业务的侵⼊性是巨⼤的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC ⽅案严重依赖回滚和补偿代码，最终的结果是：回滚代码逻辑复杂，业务代码很难维护。所以，TCC ⽅案的使⽤场景较少，但是也有使⽤的场景。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽐如说跟钱打交道的，⽀付、交易相关的场景，⼤家会⽤ TCC⽅案，严格保证分布式事务要么全部成功，要么全部⾃动回滚，严格保证资⾦的正确性，保证在资⾦上不会出现问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/20201102225620490.jpg&quot; alt=&quot;20201102225620490&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;Sega事务模型&quot;&gt;Sega事务模型&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SAGA可以看做⼀个异步的、利⽤队列实现的补偿事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/TB1Y2kuw7T2gK0jSZFkXXcIQFXa-445-444.png&quot; alt=&quot;TB1Y2kuw7T2gK0jSZFkXXcIQFXa-445-444&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;相关概念&quot;&gt;相关概念&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;1987年普林斯顿⼤学的Hector Garcia-Molina和Kenneth Salem发表了⼀篇Paper Sagas，讲述的是如何处理long lived transaction（⻓活事务）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga是⼀个⻓活事务可被分解成可以交错运⾏的⼦事务集合。其中每个⼦事务都是⼀个保持数据库⼀致性的真实事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;论⽂地址：&lt;a href=&quot;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&quot;&gt;sagas&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga模型是把⼀个分布式事务拆分为多个本地事务，每个本地事务都有相应的执⾏模块和补偿模块（对应TCC中的Confirm和Cancel），当Saga事务中任意⼀个本地事务出错时，可以通过调⽤相关的补偿⽅法恢复之前的事务，达到事务最终⼀致性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样的SAGA事务模型，是牺牲了⼀定的隔离性和⼀致性的，但是提⾼了长事务的可⽤性。&lt;/p&gt;
&lt;h4 id=&quot;组成部分&quot;&gt;组成部分&lt;/h4&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-edszmbf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LLT（Long Live Transaction）：由⼀个个本地事务组成的事务链。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wy7muu2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本地事务：事务链由⼀个个⼦事务（本地事务）组成，LLT = T1+T2+T3+...+Ti。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pm4n7mz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿：每个本地事务 Ti 有对应的补偿 Ci。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;执-顺序&quot;&gt;执⾏顺序&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;sega 有两种执行顺序:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vaoh7zn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;T1, T2, T3, ..., Tn&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7hl0o1v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;T1, T2, ..., Tj, Cj,..., C2, C1，其中0 &amp;lt; j &amp;lt; n&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果没有出异常的话，就按照第一种执行顺序向下执行即可，如果出现了异常需要通过逆向操作将之前的事务进行回滚&lt;/p&gt;
&lt;h4 id=&quot;恢复策略&quot;&gt;恢复策略&lt;/h4&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-a8xti74&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;向后恢复（Backward Recovery）：撤销掉之前所有成功⼦事务。如果任意本地⼦事务失败，则补偿已完成的事务。如异常情况的执⾏顺序T1,T2,T3,..Ti,Ci,...C3,C2,C1。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ocfomat&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;向前恢复（Forward Recovery）：即重试失败的事务，适⽤于必须要成功的场景，该情况下不需要Ci。执⾏顺序：T1,T2,...,Tj（失败）,Tj（重试）,...,Ti。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;向前恢复没有必要提供补偿事务，如果你的业务中，⼦事务（最终）总会成功，或补偿事务难以定义或不可能，向前恢复更符合你的需求。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;理论上补偿事务永不失败，然⽽，在分布式世界中，服务器可能会宕机，⽹络可能会失败，甚⾄数据中⼼也可能会停电。在这种情况下我们能做些什么？ 最后的⼿段是提供回退措施，⽐如⼈⼯⼲预。&lt;/p&gt;
&lt;h4 id=&quot;使用条件&quot;&gt;使用条件&lt;/h4&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ogfddj2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga只允许两个层次的嵌套，顶级的Saga和简单⼦事务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x5ednbc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;saga可能会看到其他saga的部分结果&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-to630zp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个⼦事务应该是独立的原⼦⾏为&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pfo6z8c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在我们的业务场景下，各个业务环境（如：航班预订、租⻋、酒店预订和付款）是⾃然独⽴的⾏为，⽽且每个事务都可以⽤对应服务的数据库保证原⼦操作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;补偿也有需考虑的事项：&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿事务从语义⻆度撤消了事务Ti的⾏为，但未必能将数据库返回到执⾏Ti时的状态。（例如，如果事务触发导弹发射， 则可能⽆法撤消此操作）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但这对我们的业务来说不是问题。其实难以撤消的⾏为也有可能被补偿。例如，发送邮件的事务可以通过发送解释问题的另⼀封邮件来补偿。&lt;/p&gt;
&lt;h4 id=&quot;对于ACID的保证&quot;&gt;对于ACID的保证&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga对于ACID的保证和TCC⼀样：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-gew8qsh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;原⼦性（Atomicity）：正常情况下保证。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-35d99h5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀致性（Consistency），在某个时间点，会出现A库和B库的数据违反⼀致性要求的情况，但是最终是⼀致的。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pmdbjwo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;隔离性（Isolation），在某个时间点，A事务能够读到B事务部分提交的结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uat8prv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;持久性（Durability），和本地事务⼀样，只要commit则数据被持久。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Saga和TCC对-&quot;&gt;Saga和TCC对⽐&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Saga相⽐TCC的缺点是缺少预留动作，导致补偿动作的实现⽐较麻烦：Ti就是commit，⽐如⼀个业务是发送邮件，在TCC模式下，先保存草稿（Try）再发送（Confirm），撤销的话直接删除草稿（Cancel）就⾏了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽽Saga则就直接发送邮件了（Ti），如果要撤销则得再发送⼀份邮件说明撤销（Ci），实现起来有⼀些麻烦。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果把上⾯的发邮件的例⼦换成：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;A服务在完成Ti后⽴即发送Event到ESB（企业服务总线，可以认为是⼀个消息中间件），下游服务监听到这个Event做⾃⼰的⼀些⼯作然后再发送Event到ESB，如果A服务执⾏补偿动作Ci，那么整个补偿动作的层级就很深。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不过没有预留动作也可以认为是优点&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有些业务很简单，套⽤TCC需要修改原来的业务逻辑，⽽Saga只需要添加⼀个补偿动作就⾏了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TCC最少通信次数为2n，⽽Saga为n（n=sub-transaction的数量）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有些第三⽅服务没有Try接⼝，TCC模式实现起来就⽐较困难了，⽽Saga则很简单。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;没有预留动作就意味着不必担⼼资源释放的问题，异常处理起来也更简单。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[刚性事务的实现]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/事务分类/刚性事务的实现</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/事务分类/刚性事务的实现</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><category><![CDATA[事务分类]]></category><pubDate>Sat, 23 Apr 2022 10:09:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;刚性事务的实现&quot;&gt;刚性事务的实现&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;刚性事务的是通过XA模型来进行实现的，XA模型是X/Open组织提出来的分布式事务的实现标准。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;X/OPEN是⼀个组织.X/Open国际联盟有限公司是⼀个欧洲基⾦会，它的建⽴是为了向UNIX环境提供标准。它主要的⽬标是促进对UNIX语⾔、接⼝、⽹络和应⽤的开放式系统协议的制定。它还促进在不同的UNIX环境之间的应⽤程序的互操作性，以及⽀持对电⽓电⼦⼯程师协会（IEEE）对UNIX的可移植操作系统接⼝（POSIX）规范。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA模型主要使⽤了两段提交(2PC - Two-Phase-Commit)来保证分布式事务的完整性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在XA模型中，定义了三个角色，AP、TM、RM。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; AP: Application，应⽤程序。也就是业务层。哪些操作属于⼀个事务，就是AP定义的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; TM: Transaction Manager，事务管理器。接收AP的事务请求，对全局事务进⾏管理，管理事务分⽀状态，协调RM的处理，通知RM哪些操作属于哪些全局事务以及事务分⽀等等。这个也是整个事务调度模型的核⼼部分。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; RM：Resource Manager，资源管理器。⼀般是数据库，也可以是其他的资源管理器，如消息队列(如JMS数据源)，⽂件系统等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/adfns079.gif&quot; alt=&quot;Developing Applications with Oracle XA&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA则规范了TM与RM之间的通信接⼝，在TM与多个RM之间形成⼀个双向通信桥梁，从⽽在多个数据库资源下保证ACID四个特性。⽬前知名的数据库，如Oracle, DB2,mysql等，都是实现了XA接⼝的，都可以作为RM。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA是数据库的分布式事务，强⼀致性，在整个过程中，数据⼀张锁住状态，即从prepare到commit、rollback的整个过程中，TM⼀直把持折数据库的锁，如果有其他⼈要修改数据库的该条数据，就必须等待锁的释放，存在⻓事务⻛险。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XA事务处理流程示意图如下：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/XA%E4%BA%8B%E5%8A%A1.png&quot; alt=&quot;XA事务&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;2PC-标准XA模型-&quot;&gt;2PC(标准XA模型)&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2PC 将数据分为两个阶段进行处理:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阶段⼀：提交事务请求&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阶段⼆：执⾏事务提交;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果阶段⼀超时或者出现异常，2PC的阶段⼆：中断事务&lt;/p&gt;
&lt;h3 id=&quot;阶段--提交事务请求&quot;&gt;阶段⼀：提交事务请求&lt;/h3&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-a2zyrtz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务询问。协调者向所有参与者发送事务内容，询问是否可以执⾏提交操作，并开始等待各参与者进⾏响应&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ctugvou&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执⾏事务。各参与者节点，执⾏事务操作，并将Undo和Redo操作计⼊本机事务⽇志&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o2haic8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;各参与者向协调者反馈事务问询的响应。成功执⾏返回Yes，否则返回No&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;阶段--执-事务提交&quot;&gt;阶段⼆：执⾏事务提交&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;协调者在阶段⼆决定是否最终执⾏事务提交操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这⼀阶段包含两种情形：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;事务提交&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执⾏事务提交所有参与者Reply Yes，那么执⾏事务提交&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-pc392yk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送提交请求。协调者向所有参与者发送Commit请求&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lq9sgrr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务提交。参与者收到Commit请求后，会正式执⾏事务提交操作，并在完成提交操作之后，释放在整个事务执⾏期间占⽤的资源&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o2s8bg5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反馈事务提交结果。参与者在完成事务提交后，写协调者发送Ack消息确认&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3l6wwvd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完成事务。协调者在收到所有参与者的Ack后，完成事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/5wRmVD.jpg&quot; alt=&quot;5wRmVD&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;事务中断&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当存在某⼀参与者向协调者发送No响应，或者等待超时。协调者只要⽆法收到所有参与者的Yes响应，就会中断事务。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-y56hawi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送回滚请求。协调者向所有参与者发送Rollback请求&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nx9gvfv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;回滚。参与者收到请求后，利⽤本机Undo信息，执⾏Rollback操作。并在回滚结束后释放该事务所占⽤的系统资源&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n1ts7gl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反馈回滚结果。参与者在完成回滚操作后，向协调者发送Ack消息&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n5ynx0c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;中断事务。协调者收到所有参与者的回滚Ack消息后，完成事务中断&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/37WkXj.jpg&quot; alt=&quot;37WkXj&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;二阶段的优缺点&quot;&gt;二阶段的优缺点&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;优点主要体现在实现原理简单；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;缺点⽐较多：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8qkbzcd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;性能问题&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从流程上我们可以看得出，其最⼤缺点就在于它的执⾏过程中间，节点都处于阻塞状态。各个操作数据库的节点此时都占⽤着数据库资源，只有当&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所有节点准备完毕，事务协调者才会通知进⾏全局提交，参与者进⾏本地事务提交后才会释放资源。这样的过程会⽐较漫⻓，对性能影响⽐较⼤。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4kpkiga&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;协调者单点故障问题&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务协调者是整个XA模型的核⼼，⼀旦事务协调者节点挂掉，会导致参与者收不到提交或回滚的通知，从⽽导致参与者节点始终处于事务⽆法完成&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;的中间状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yvhvrux&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;丢失消息导致的数据不⼀致问题&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在第⼆个阶段，如果发⽣局部⽹络问题，⼀部分事务参与者收到了提交消息，另⼀部分事务参与者没收到提交消息，那么就会导致节点间数据的不⼀致问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;3PC&quot;&gt;3PC&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;针对2PC的缺点，研究者提出了3PC，即Three-Phase Commit。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作为2PC的改进版，3PC将原有的两阶段过程，重新划分为CanCommit、PreCommit和do Commit三个阶段。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/fxQv2n.jpg&quot; alt=&quot;fxQv2n&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;阶段--CanCommit&quot;&gt;阶段⼀：CanCommit&lt;/h3&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zboqh5e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务询问。协调者向所有参与者发送包含事务内容的canCommit的请求，询问是否可以执⾏事务提交，并等待应答；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2m7bzjq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;各参与者反馈事务询问。正常情况下，如果参与者认为可以顺利执⾏事务，则返回Yes，否则返回No。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;阶段--PreCommit&quot;&gt;阶段⼆：PreCommit&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在本阶段，协调者会根据上⼀阶段的反馈情况来决定是否可以执⾏事务的PreCommit操作&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有以下两种可能：执⾏事务预提交&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0l9x7r3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送预提交请求。协调者向所有节点发出PreCommit请求，并进⼊prepared阶段；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-obzp709&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务预提交。参与者收到PreCommit请求后，会执⾏事务操作，并将Undo和Redo⽇志写⼊本机事务⽇志；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8lmgvxr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;各参与者成功执⾏事务操作，同时将反馈以Ack响应形式发送给协调者，同事等待最终的Commit或Abort指令。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;中断事务&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加⼊任意⼀个参与者向协调者发送No响应，或者等待超时，协调者在没有得到所有参与者响应时，即可以中断事务:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-njndywr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送中断请求。 协调者向所有参与者发送Abort请求；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0t46wnq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;中断事务。⽆论是收到协调者的Abort请求，还是等待协调者请求过程中出现超时，参与者都会中断事务；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;阶段三-doCommit&quot;&gt;阶段三：doCommit&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个阶段，会真正的进⾏事务提交，同样存在两种可能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;执⾏提交&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-y258o3f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送提交请求。假如协调者收到了所有参与者的Ack响应，那么将从预提交转换到提交状态，并向所有参与者，发送doCommit请求；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mf30653&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务提交。参与者收到doCommit请求后，会正式执⾏事务提交操作，并在完成提交操作后释放占⽤资源；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uwbh5z7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反馈事务提交结果。参与者将在完成事务提交后，向协调者发送Ack消息；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-sxp6rdh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;完成事务。协调者接收到所有参与者的Ack消息后，完成事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;中断事务&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在该阶段，假设正常状态的协调者接收到任⼀个参与者发送的No响应，或在超时时间内，仍旧没收到反馈消息，就会中断事务：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7upo5ji&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;发送中断请求。协调者向所有的参与者发送abort请求；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kdx8xtx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;事务回滚。参与者收到abort请求后，会利⽤阶段⼆中的Undo消息执⾏事务回滚，并在完成回滚后释放占⽤资源；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yp7xtl7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反馈事务回滚结果。参与者在完成回滚后向协调者发送Ack消息；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ymh9l7l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;中端事务。协调者接收到所有参与者反馈的Ack消息后，完成事务中断。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;2PC和3PC的区别&quot;&gt;2PC和3PC的区别&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;3PC有效降低了2PC带来的参与者阻塞范围，并且能够在出现单点故障后继续达成⼀致；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但3PC带来了新的问题，在参与者收到preCommit消息后，如果⽹络出现分区，协调者和参与者⽆法进⾏后续的通信，这种情况下，参与者在等待超时后，依旧会执⾏事务提交，这样会导致数据的不⼀致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;三阶段提交协议在协调者和参与者中都引⼊ 超时机制，并且把两阶段提交协议的第⼀个阶段拆分成了两步：询问，然后再锁资源，最后真正提交。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220421204125-ux86w8m.png&quot; alt=&quot;image-20220421204125-ux86w8m&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[About]]></title><link>https://www.ztianzeng.com/pages/About</link><guid isPermaLink="false">/pages/About</guid><pubDate>Sat, 23 Apr 2022 05:09:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;About&quot;&gt;About&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;——一期一会，世当珍惜。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[事务分类]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务/事务分类</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务/事务分类</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><category><![CDATA[分布式事务]]></category><pubDate>Fri, 22 Apr 2022 13:17:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;事务分类&quot;&gt;事务分类&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com//uPic/image-20220420200307251.png&quot; alt=&quot;image-20220420200307251&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面所示，列出了目前所有的分布式解决方案&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式事务实现⽅案从类型上去分刚性事务、柔型事务：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-cpf1trr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;刚性事务满⾜CAP的CP理论&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ed3wwe1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务满⾜BASE理论&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;刚性事务&quot;&gt;刚性事务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通常⽆业务改造，强⼀致性，原⽣⽀持回滚/隔离性，低并发，适合短事务。要使分布式事务，达到像本地式事务⼀样，具备数据强⼀致性，从CAP来看，就是说，要达到CP状态。&lt;/p&gt;
&lt;h2 id=&quot;柔性事务&quot;&gt;柔性事务&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务指的是，不要求强⼀致性，⽽是要求最终⼀致性，允许有中间状态，也就是Base理论，换句话说，就是AP状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与刚性事务相⽐，柔性事务的特点为：有业务改造，最终⼀致性，实现补偿接⼝，实现资源锁定接⼝，⾼并发，适合⻓事务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;柔性事务分三大类为：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-f5a2hq4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;补偿型&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b5u9e0z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;异步确保型&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oe0n7a5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最⼤努⼒通知型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[天增的博客]]></title><link>https://www.ztianzeng.com/</link><guid isPermaLink="false">/</guid><pubDate>Fri, 22 Apr 2022 06:14:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;天增的博客&quot;&gt;天增的博客&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一期一会，世当珍惜&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[pages]]></title><link>https://www.ztianzeng.com/pages</link><guid isPermaLink="false">/pages</guid><pubDate>Fri, 22 Apr 2022 06:14:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;pages&quot;&gt;pages&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[java内存模型]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/java内存模型</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/java内存模型</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><pubDate>Thu, 21 Apr 2022 14:56:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;java内存模型&quot;&gt;java内存模型&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[底层原理]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理</guid><category><![CDATA[Java并发工具包]]></category><pubDate>Thu, 21 Apr 2022 14:55:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;底层原理&quot;&gt;底层原理&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[线程协作]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程协作</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程协作</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:54:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程协作&quot;&gt;线程协作&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[Future]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/Future</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/Future</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:53:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Future&quot;&gt;Future&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[ThreadLocal]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/ThreadLocal</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/ThreadLocal</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:53:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ThreadLocal&quot;&gt;ThreadLocal&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[原子类]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/原子类</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/原子类</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:52:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;原子类&quot;&gt;原子类&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[阻塞队列]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/阻塞队列</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/阻塞队列</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:51:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;阻塞队列&quot;&gt;阻塞队列&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[并发容器]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/并发容器</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/并发容器</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:50:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;并发容器&quot;&gt;并发容器&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[各种锁]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:49:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;各种锁&quot;&gt;各种锁&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[线程池]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><pubDate>Thu, 21 Apr 2022 14:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程池&quot;&gt;线程池&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[并发工具]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具</guid><category><![CDATA[Java并发工具包]]></category><pubDate>Thu, 21 Apr 2022 14:46:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;并发工具&quot;&gt;并发工具&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[线程安全]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程安全</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程安全</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><pubDate>Thu, 21 Apr 2022 14:46:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程安全&quot;&gt;线程安全&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[线程基础]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><pubDate>Thu, 21 Apr 2022 14:43:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程基础&quot;&gt;线程基础&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[并发基础]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础</guid><category><![CDATA[Java并发工具包]]></category><pubDate>Thu, 21 Apr 2022 14:43:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;并发基础&quot;&gt;并发基础&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[理论基础]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/分布式理论/理论基础</link><guid isPermaLink="false">/topic/分布式解决方案/分布式理论/理论基础</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[分布式理论]]></category><pubDate>Thu, 21 Apr 2022 12:28:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;理论基础&quot;&gt;理论基础&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库的四大特性ACID，无法解决现在微服务调用链路长和调用数据库多的问题。在此基础上，有诞生了两个新的理论，用于指导在分布式环境下的数据一致性问题。&lt;/p&gt;
&lt;h2 id=&quot;CAP定理&quot;&gt;CAP定理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CAP定理是由加州⼤学伯克利分校Eric Brewer教授提出来的，他指出WEB服务⽆法同时满⾜⼀下3个属性：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6jethdz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⼀致性(Consistency) ： 客户端知道⼀系列的操作都会同时发⽣(⽣效)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3y4mzyc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可⽤性(Availability) ： 每个操作都必须以可预期的响应结束&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o3wl7ql&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分区容错性(Partition tolerance) ： 即使出现单个组件⽆法可⽤，操作依然可以完成&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;具体地讲在分布式系统中，⼀个Web应⽤⾄多只能同时⽀持上⾯的两个属性。因此，设计⼈员必须在⼀致性与可⽤性之间做出选择。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;2000年7⽉Eric Brewer教授仅仅提出来的是⼀个猜想，2年后，麻省理⼯学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP理论，并且⽽⼀个分布式系统最多只能满⾜CAP中的2项。之后，CAP理论正式成为分布式计算领域的公认定理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;定理说明原文: &lt;a href=&quot;https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/&quot;&gt;https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/bg2018071607.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;一致性&quot;&gt;一致性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据⼀致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同⼀时间的数据完全⼀致，不能存在中间状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分布式环境中，⼀致性是指多个副本之间能否保持⼀致的特性。在⼀致性的需求下，当⼀个系统在数据⼀致的状态下执⾏更新操作后，应该保证系统的数据仍然处理⼀致的状态。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;电商系统⽤户下单操作，库存减少、⽤户资⾦账户扣减、积分增加等操作必须在⽤户下单操作完成后必须是⼀致的。不能出现类似于库存已经减少，⽽⽤户资⾦账户尚未扣减，积分也未增加的情况。如果出现了这种情况，那么就认为是不⼀致的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;数据⼀致性分为强⼀致性、弱⼀致性、最终⼀致性。&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-b7cxt2j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果的确能像上⾯描述的那样时刻保证客户端看到的数据都是⼀致的，那么称之为强⼀致性。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ubvrxfm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果允许存在中间状态，只要求经过⼀段时间后，数据最终是⼀致的，则称之为最终⼀致性。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hz1wtpx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，如果允许存在部分数据不⼀致，那么就称之为弱⼀致性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;可用性&quot;&gt;可用性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统提供的服务必须⼀直处于可⽤的状态，对于⽤户的每⼀个操作请求总是能够在有限的时间内返回结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个度量的维度：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ear75ed&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有限时间内&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于⽤户的⼀个操作请求，系统必须能够在指定的时间（响应时间）内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可⽤的。即这个响应时间必须在⼀个合理的值内，不让⽤户感到失望。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8f9w7dv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回正常结果&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;要求系统在完成对⽤户请求的处理后，返回⼀个正常的响应结果。正常的响应结果通常能够明确地反映出对请求的处理结果，即成功或失败，⽽不是⼀个让⽤户感到困惑的返回结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;分区容错性&quot;&gt;分区容错性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;即分布式系统在遇到任何⽹络分区故障时，仍然需要能够保证对外提供满⾜⼀致性和可⽤性的服务，除⾮是整个⽹络环境都发⽣了故障。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⽹络分区，是指分布式系统中，不同的节点分布在不同的⼦⽹络（机房/异地⽹络）中，由于⼀些特殊的原因导致这些⼦⽹络之间出现⽹络不连通的状态，但各个⼦⽹络的内部⽹络是正常的，从⽽导致整个系统的⽹络环境被切分成了若⼲孤⽴的区域。组成⼀个分布式系统的每个节点的加⼊与退出都可以看做是⼀个特殊的⽹络分区。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任何⼀个分布式系统都⽆法同时满⾜⼀致性（Consistency）、可⽤性（Availability）和分区容错性（Partition tolerance），最多只能同时满⾜两项。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在互联⽹领域的绝⼤多数的场景中，都需要牺牲强⼀致性来换取系统的⾼可⽤性，系统往往只需要保证最终⼀致性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;CAP权衡&quot;&gt;CAP权衡&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;​	对于多数⼤型互联⽹应⽤的场景，主机众多、部署分散，⽽且现在的集群规模越来越⼤，所以节点故障、⽹络故障是常态，⽽且要保证服务可⽤性达到 N 个 9，即保证 P 和 A，舍弃C（退⽽求其次保证最终⼀致性）。虽然某些地⽅会影响客户体验，但没达到造成⽤户流程的严重程度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;​	对于涉及到钱财这样不能有⼀丝让步的场景，C 必须保证。⽹络发⽣故障宁可停⽌服务，这是保证 CA，舍弃 P。貌似这⼏年国内银⾏业发⽣了不下10 起事故，但影响⾯不⼤，报道也不多，⼴⼤群众知道的少。还有⼀种是保证 CP，舍弃 A。例如⽹络故障是只读不写。&lt;/p&gt;
&lt;h2 id=&quot;BASE定理&quot;&gt;BASE定理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BASE基于CAP定理演化⽽来，核⼼思想是即时⽆法做到强⼀致性，但每个应⽤都可以根据⾃身业务特点，采⽤适当的⽅式来使系统达到最终⼀致性。主要是对CAP中AP模式的进一步补充。&lt;/p&gt;
&lt;h3 id=&quot;Basically-Available-基本可--&quot;&gt;Basically Available（基本可⽤）&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基本可⽤是指分布式系统在出现不可预知的故障的时候，允许损失部分可⽤性，但不等于系统不可⽤。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主要是损失下面两个方面，来提高系统的可用性。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4w8851y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;响应时间上的损失 -&amp;gt; 当出现故障时，响应时间增加&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bceahug&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;功能上的损失 -&amp;gt; 当流量⾼峰期时，屏蔽⼀些功能的使⽤以保证系统稳定性（服务降级）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Soft-state-软状态-&quot;&gt;Soft state（软状态）&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与硬状态相对，即是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可⽤性，即允许系统在不同节点的数据副本之间进⾏数据同步的过程存在延时。&lt;/p&gt;
&lt;h3 id=&quot;Eventually-consistent-最终-致性-&quot;&gt;Eventually consistent（最终⼀致性）&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;强调系统中所有的数据副本，在经过⼀段时间的同步后，最终能够达到⼀个⼀致的状态。其本质是需要系统保证最终数据能够达到⼀致，⽽不需要实时保证系统数据的强⼀致性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最终⼀致性可分为如下⼏种：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-swyhwhk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因果⼀致性（Causal consistency）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-58wgcvm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读⼰之所写（Read your writes）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-azb5dl5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会话⼀致性（Session consistency）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9o1i1jj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;单调读⼀致性（Monotonic read consistency）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-spbqr9r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;单调写⼀致性（Monotoic write consistency）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个系统要能够保证来自同一个节点的写操作被顺序的执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BASE理论是提出通过牺牲⼀致性来获得可⽤性，并允许数据在⼀段时间内是不⼀致的，但最终达到⼀致状态。在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。&lt;/p&gt;
&lt;h2 id=&quot;BASE理论的特点&quot;&gt;BASE理论的特点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;BASE理论⾯向的是⼤型⾼可⽤可扩展的分布式系统，和传统的事物ACID特性是相反的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它完全不同于ACID的强⼀致性模型，⽽是通过牺牲强⼀致性来获得可⽤性，并允许数据在⼀段时间内是不⼀致的，但最终达到⼀致状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但同时，在实际的分布式场景中，不同业务单元和组件对数据⼀致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性和BASE理论往往⼜会结合在⼀起。&lt;/p&gt;
&lt;h2 id=&quot;ACID-和-BASE-的区别与联系&quot;&gt;ACID 和 BASE 的区别与联系&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ACID 是传统数据库常⽤的设计理念，追求强⼀致性模型。BASE ⽀持的是⼤型分布式系统，提出通过牺牲强⼀致性获得⾼可⽤性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ACID 和 BASE 代表了两种截然相反的设计哲学，在分布式系统设计的场景中，系统组件对⼀致性要求是不同的，因此 ACID 和 BASE ⼜会结合使⽤。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[进程与线程]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/进程与线程</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/进程与线程</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;进程与线程&quot;&gt;进程与线程&lt;/h1&gt;
&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-x2cry3n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程是资源执行的基本单位，而进程是程序的执行的基本单位&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rh6d4hx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个进程可以使用一个CPU，而线程则使用的是CPU中的核；因此单进程并不能完全利用多CPU，造成资源你浪费，而多进程才能真正利用多CPU的能力&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w7trnto&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于Java而言，所有的Java程序都是在JVM中运行，每个JVM都是一个进程，因此每启动一个Java程序其实都启动了一个进程，Mian方法是进程内的主线程。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-sba6egs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在Java中我们很少谈及多进程，但也可以通过以下两种方法实现。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2vw596l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（1）使用Runtime的exec()方法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-08rid18&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（2）使用ProcessBuilder的start()方法&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gbcy0xe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一般在Java编程中，我们一般考虑多线程的运用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示，可以看到，该系统一共有2颗CPU，每个CPU有4个核心，每个物理核心又可以超线程变成两个虚拟的核心，因此理论上可以同时运行的最大线程数为：2 * 4 * 2 = 16. 因此一共多线程的程序，理论上最大的线程数可以设置为16.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211009143104434.png&quot; alt=&quot;image-20211009143104434&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[正确停止线程的方式]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/正确停止线程的方式</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/正确停止线程的方式</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;正确停止线程的方式&quot;&gt;正确停止线程的方式&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正常情况下，我们不会主动去停止线程，而是让程序执行完，线程自动停止。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，在某些情况下，比如用户主动关闭程序、或者程序出错的时候，需要我们提前停止线程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是,&lt;strong&gt;在Java中，没有干净，快速或可靠的方法来阻止线程。&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不过在Java中，依然可以使用不太优雅的方式来停止线程，大致可以分为三种&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4uyr6ci&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接调用thread.stop、或者thread.suspend&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-brvedtn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过volatile关键字&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-65b0eat&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过interrupt机制&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中，第一种方式，已经被JDK废弃，会带来不可预知的风险&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二种方式，则不够完美，也不建议使用&lt;/p&gt;
&lt;h2 id=&quot;废弃的停止方式&quot;&gt;废弃的停止方式&lt;/h2&gt;
&lt;h3 id=&quot;Thread-stop和suspend被废弃的原因&quot;&gt;Thread.stop和suspend被废弃的原因&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在官方文档注释中，已经标明了废弃的原因。https://docs.oracle.com/javase/8/docs/technotes/guides/concurrency/threadPrimitiveDeprecation.html&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;**对于stop被废弃的原因: **&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Because it is inherently unsafe. Stopping a thread causes it to unlock all the monitors that it has locked. (The monitors are unlocked as the ThreadDeath exception propagates up the stack.) If any of the objects previously protected by these monitors were in an inconsistent state, other threads may now view these objects in an inconsistent state. Such objects are said to be damaged. When threads operate on damaged objects, arbitrary behavior can result. This behavior may be subtle and difficult to detect, or it may be pronounced. Unlike other unchecked exceptions, ThreadDeath kills threads silently; thus, the user has no warning that his program may be corrupted. The corruption can manifest itself at any time after the actual damage occurs, even hours or days in the future.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为stop方法天生就是不安全的，调用stop方法来停止线程，会导致这个线程释放所有的监视器锁，如果有其他线程也在获取这个监视器锁，那么就会看到这个被解锁的对象，当线程去操作这个对象的时候会导致意外的结果。这些行为可能是微妙且难以预测，或者也有可能展现出明显的错误。不想其他的受检的异常，ThreadDeath会默默的杀死线程，因此在用户在没有收到这个异常的错误的时候，运行结果可能是错误的。但是错误可能在几个小时甚至是几天之后才能被发现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;对于suspend被废弃的原因&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;Thread.suspend&lt;/code&gt; is inherently deadlock-prone. If the target thread holds a lock on the monitor protecting a critical system resource when it is suspended, no thread can access this resource until the target thread is resumed. If the thread that would resume the target thread attempts to lock this monitor prior to calling &lt;code&gt;resume&lt;/code&gt;, deadlock results. Such deadlocks typically manifest themselves as &amp;quot;frozen&amp;quot; processes.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;suspend有天然的死锁情况，如果目标线程持有了监视器锁，在他挂起的时候，没有任何线程可以访问这个锁资源，知道目标线程调用resume唤起了线程。如果在某种情况下要先获取锁在执行resume方法， 那么这个时候就会造成死锁，这个表现为线程的冻结。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;volatile标记停止位的错误&quot;&gt;volatile标记停止位的错误&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在一般情况下没有问题，如下面的代码:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过canceled来标记取消状态，正常情况下没有任何问题&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Demo implements Runnable {
    private static volatile boolean canceled = false;
    @Override
    public void run() {
        int num = 0;
        while(num &amp;lt;= Integer.MAX_VALUE / 2 &amp;amp;&amp;amp; !canceled){
            if(num % 100 == 0){
                System.out.println(num + &amp;quot;是100的倍数&amp;quot;);
            }
            num++;
        }
        System.out.println(&amp;quot;退出&amp;quot;);
    }
    public static void main(String[] args) throws InterruptedException {
        Thread thread = new Thread(new Demo7());
        thread.start();
        Thread.sleep(1000);
        canceled = true;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，在线程进入了阻塞状态，将不能通过修改volatile变量来停止线程.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面的例子展示了，不断的向阻塞队列里面塞入数据，一旦塞入满了线程就会被阻塞在&lt;strong&gt;this.storage.put(num);&lt;/strong&gt;那里。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，即使修改cancel变量，线程也无法停止。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * 通过生产者消费者模式演示volatile的局限性，volatile不能唤醒已经阻塞的线程
 * 生产者生产速度很快，消费者消费速度很慢，通过阻塞队列存储商品
 */
public class Demo {
    public static void main(String[] args) throws InterruptedException {
        ArrayBlockingQueue storage = new ArrayBlockingQueue(10);

        Producer producer = new Producer(storage);
        Thread producerThread = new Thread(producer);
        producerThread.start();
        Thread.sleep(1000);//1s足够让生产者把阻塞队列塞满

        Consumer consumer = new Consumer(storage);
        while(consumer.needMoreNums()){
            System.out.println(storage.take() + &amp;quot;被消费&amp;quot;);
            Thread.sleep(100);//让消费者消费慢一点，给生产者生产的时间
        }

        System.out.println(&amp;quot;消费者消费完毕&amp;quot;);
        producer.canceled = true;//让生产者停止生产（实际情况是不行的，因为此时生产者处于阻塞状态，volatile不能唤醒阻塞状态的线程）

    }
}

class Producer implements Runnable{

    public volatile boolean canceled = false;

    private BlockingQueue storage;

    public Producer(BlockingQueue storage) {
        this.storage = storage;
    }

    @Override
    public void run() {
        int num = 0;
        try{
            while(num &amp;lt; Integer.MAX_VALUE / 2 &amp;amp;&amp;amp; !canceled){
                if(num % 100 == 0){
                    this.storage.put(num);
                    System.out.println(num + &amp;quot;是100的倍数，已经被放入仓库&amp;quot;);
                }
                num++;
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            System.out.println(&amp;quot;生产者停止生产&amp;quot;);
        }
    }
}

class Consumer{
    private BlockingQueue storage;

    public Consumer(BlockingQueue storage) {
        this.storage = storage;
    }

    public boolean needMoreNums(){
        return Math.random() &amp;lt; 0.95 ? true : false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;正确的停止方式&quot;&gt;正确的停止方式&lt;/h2&gt;
&lt;h3 id=&quot;通过interrupt方式停止&quot;&gt;通过interrupt方式停止&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还是刚刚那个例子，在生产者满了之后，无法监听到volatile状态的变化导致无法停止线程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果通过interrupt的方式就很容易解决。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * 通过生产者消费者模式演示volatile的局限性，volatile不能唤醒已经阻塞的线程
 * 生产者生产速度很快，消费者消费速度很慢，通过阻塞队列存储商品
 */
public class Demo {
    public static void main(String[] args) throws InterruptedException {
        ArrayBlockingQueue storage = new ArrayBlockingQueue(10);

        Producer producer = new Producer(storage);
        Thread producerThread = new Thread(producer);
        producerThread.start();
        Thread.sleep(1000);//1s足够让生产者把阻塞队列塞满

        Consumer consumer = new Consumer(storage);
        while(consumer.needMoreNums()){
            System.out.println(storage.take() + &amp;quot;被消费&amp;quot;);
            Thread.sleep(100);//让消费者消费慢一点，给生产者生产的时间
        }

        System.out.println(&amp;quot;消费者消费完毕&amp;quot;);
        producerThread.interrupt();
    }
}

class Producer implements Runnable{

    private BlockingQueue storage;

    public Producer(BlockingQueue storage) {
        this.storage = storage;
    }

    @Override
    public void run() {
        int num = 0;
        try{
            while(num &amp;lt; Integer.MAX_VALUE / 2 &amp;amp;&amp;amp; !Thread.currentThread().isInterrupted()){
                if(num % 100 == 0){
                    this.storage.put(num);
                    System.out.println(num + &amp;quot;是100的倍数，已经被放入仓库&amp;quot;);
                }
                num++;
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            System.out.println(&amp;quot;生产者停止生产&amp;quot;);
        }
    }
}

class Consumer{
    private BlockingQueue storage;

    public Consumer(BlockingQueue storage) {
        this.storage = storage;
    }

    public boolean needMoreNums(){
        return Math.random() &amp;lt; 0.95 ? true : false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;所以Java中如何正确的停止线程&quot;&gt;所以Java中如何正确的停止线程&lt;/h2&gt;
&lt;h3 id=&quot;答题思路&quot;&gt;答题思路&lt;/h3&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-thhn12q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;停止线程的正确方式是使用中断&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-240yla5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;想停止线程需要停止方，被停止方，被停止方的子方法相互配合&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5wtqwxz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解释为何不用已被废弃的stop/suspend&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-egcnfgw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解释volatile为何不能用于中断线程&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;​&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[生产者消费者模型]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/生产者消费者模型</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/生产者消费者模型</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;生产者消费者模型&quot;&gt;生产者消费者模型&lt;/h1&gt;
&lt;h2 id=&quot;生产者消费者模式&quot;&gt;生产者消费者模式&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者消费者，是在软件开发中很常见的一种设计模式，大致结构如下图&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B.png&quot; alt=&quot;生产者消费者模型&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者和消费者最核心的就是那个队列，用于平衡&lt;strong&gt;生产者生产速度和消费者消费速度不一致&lt;/strong&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xjfq0rk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在队列满了之后，生产者则会阻塞，在队列空了之后，消费者则会阻塞。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bkfhrm2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;队列非空组则提醒消费者继续消费，队列非慢则提醒生产者继续生产&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用-BlockingQueue-实现生产者消费者模式&quot;&gt;使用 BlockingQueue 实现生产者消费者模式&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码很简单&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就是创建两个消费者线程和两个生产者线程，通过BlockQueue这个中间媒介，时期不断的进行生产-&amp;gt; 消费的循环&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) {
        BlockingQueue&amp;lt;Object&amp;gt; queue = new ArrayBlockingQueue&amp;lt;&amp;gt;(10);
        Runnable producer = () -&amp;gt; {
            while (true) {
                try {
                    queue.put(new Object());
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
        new Thread(producer).start();
        new Thread(producer).start();
        Runnable consumer = () -&amp;gt; {
            while (true) {
                try {
                    queue.take();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

        };
        new Thread(consumer).start();
        new Thread(consumer).start();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;使用-Condition-实现生产者消费者模式&quot;&gt;使用 Condition 实现生产者消费者模式&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们利用lock的Condition来实现一个简易版的BlockingQueue&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static class MyBlockingQueueForCondition {
        private Queue queue;
        private int max = 16;
        private ReentrantLock lock = new ReentrantLock();
        private Condition notFull = lock.newCondition();
        private Condition notEmpty = lock.newCondition();

        public MyBlockingQueueForCondition(int max) {
            this.max = max;
            queue = new LinkedList();
        }

        public void put(Object v) throws InterruptedException {
            lock.lock();
            try {
                while (queue.size() == max) {
                    notFull.await();
                }
                queue.add(v);
                notEmpty.signalAll();
            } finally {
                lock.unlock();
            }
        }

        public Object take() throws InterruptedException {
            lock.lock();
            try {
                while (queue.size() == 0) {
                    notEmpty.await();
                }
                Object o = queue.remove();
                notFull.signalAll();
                return o;
            } finally {
                lock.unlock();
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最灵魂的操作是使用while循环来判断临界情况 ，&lt;strong&gt;为什么不用if来进行判断&lt;/strong&gt;?&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多个线程进入put操作的时候，发现队列已经满了，多个线程都进入等待状态，然后在notFull.signalAll()的时候多个线程都会调用add(v)操作，导致队列中的数量大于max的限定值;反之，同理。&lt;/p&gt;
&lt;h2 id=&quot;使用-wait-notify-实现生产者消费者模式&quot;&gt;使用 wait/notify 实现生产者消费者模式&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用wait/notify的方式，是使用lock的方式相似。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;class MyBlockingQueue {

   private int maxSize;

   private LinkedList&amp;lt;Object&amp;gt; storage;

   public MyBlockingQueue(int size) {

       this.maxSize = size;

       storage = new LinkedList&amp;lt;&amp;gt;();

   }

   public synchronized void put() throws InterruptedException {
       while (storage.size() == maxSize) {
           wait();
       }
       storage.add(new Object());
       notifyAll();
   }

   public synchronized void take() throws InterruptedException {
       while (storage.size() == 0) {
           wait();
       }
       storage.poll();
       notifyAll();
   }

}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[线程不安全]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程安全/线程不安全</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程安全/线程不安全</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程安全]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程不安全&quot;&gt;线程不安全&lt;/h1&gt;
&lt;h2 id=&quot;线程不安全示例&quot;&gt;线程不安全示例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ThreadUnsafeExample {

    private int cnt = 0;

    public void add() {
        cnt++;
    }

    public int get() {
        return cnt;
    }
}

public static void main(String[] args) throws InterruptedException {
    final int threadSize = 1000;
    ThreadUnsafeExample example = new ThreadUnsafeExample();
    final CountDownLatch countDownLatch = new CountDownLatch(threadSize);
    ExecutorService executorService = Executors.newCachedThreadPool();
    for (int i = 0; i &amp;lt; threadSize; i++) {
        executorService.execute(() -&amp;gt; {
            example.add();
            countDownLatch.countDown();
        });
    }
    countDownLatch.await();
    executorService.shutdown();
    System.out.println(example.get());
}

997 // 结果总是小于1000

&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[线程安全]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程安全/线程安全</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程安全/线程安全</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程安全]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程安全&quot;&gt;线程安全&lt;/h1&gt;
&lt;h2 id=&quot;什么是线程安全问题&quot;&gt;什么是线程安全问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们要先了解什么是线程安全，才可以在工作中尽量避免使用线程不安全的代码。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虽然线程安全经常被提及，但是对于线程安全并没有一个明确的定义。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在《Java Concurrency In Practice》这种书中，作者Brian Goetz 对线程安全是这样理解的&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当多线程访问一个对象的时候,如果不用考虑在多线程下的调度和交替执行的问题，也不需要进行额外的同步，而调用这个对象的结果都可以获得正确的结果，那这个线程就是安全的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果某个对象是线程安全的，那个对于使用者来说，在使用时就不用考虑方法间的协调，比如不用考虑读写和写入不能不行的问题，也不用考虑任何额外的同步问题。&lt;/p&gt;
&lt;h2 id=&quot;为何会出现线程安全问题&quot;&gt;为何会出现线程安全问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;众所周知，CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8owswg0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CPU 增加了缓存，以均衡与内存的速度差异；// 导致 &lt;code&gt;可见性&lt;/code&gt;问题&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5ion0cc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 &lt;code&gt;原子性&lt;/code&gt;问题&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0ruu1g0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 &lt;code&gt;有序性&lt;/code&gt;问题&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;可见性--CPU缓存引起&quot;&gt;可见性: CPU缓存引起&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;//线程1执行的代码
int i = 0;
i = 10;
 
//线程2执行的代码
int j = i;

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。&lt;/p&gt;
&lt;h3 id=&quot;原子性--分时复用引起&quot;&gt;原子性: 分时复用引起&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在现代操作系统中，CPU都是分时间片运行的,多个程序在cpu中以一段时间间隔内进行轮转。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个程序依次执行一段时间。宏观上所有程序同时执行，其实内部还是每时处理一个程序。在程序执行到一半就切换到下一个程序了，就会造成原子性问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;经典的转账问题：比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。&lt;/p&gt;
&lt;h3 id=&quot;有序性--重排序引起&quot;&gt;有序性: 重排序引起&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有序性：即程序执行的顺序按照代码的先后顺序执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-szuljqp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-1t1uvih&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-c8ckmsj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;int i = 0;              
boolean flag = false;
i = 1;                //语句1  
flag = true;          //语句2
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗? 不一定，为什么呢? 这里可能会发生指令重排序（Instruction Reorder）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/java-jmm-3.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。&lt;/p&gt;
&lt;h2 id=&quot;一共有哪三类线程安全问题&quot;&gt;一共有哪三类线程安全问题&lt;/h2&gt;
&lt;h3 id=&quot;运行结果错误&quot;&gt;运行结果错误&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先，来看一个经典的例子，正常情况下结果应该在20000，但是运行结束之后会远小于20000&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;	public class Test{
    public static int i = 0;

    public static void main(String[] args) throws InterruptedException {
        Runnable r = new Runnable() {

            @Override
            public void run() {
                for (int j = 0; j &amp;lt; 10000; j++) {
                    i++;
                }
            }
        };
        Thread t1 = new Thread(r);
        t1.start();
        Thread t2 = new Thread(r);
        t2.start();
        t1.join();
        t2.join();
        System.out.println(r);
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于i++不是一个原子操作，分为3步&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yjzkcis&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一个步骤是读取；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8ub75od&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二个步骤是增加；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2qs4b6t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第三个步骤是保存。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;又因为CPU执行的过程中，是分时间片执行的&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-iqvin0q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在线程1的时候在增加完之后没有保存，&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-afz9dzj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;切换到线程2的，线程2读取到的是0&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9kbocq7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程2执行增加并保存，此时 i = 1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-t9dstby&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程1执行保存，i = 1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y57yxj9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;进行一次循环之后，依然等于1&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;发布和初始化导致线程安全问题&quot;&gt;发布和初始化导致线程安全问题&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们创建对象并发布和初始化供其他的类或者对象使用是很常见的操作，如果类初始化的时机不对就有可能导致线程安全问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面这段代码演示了，在构造函数中使用线程，在创建对象的时候，会调用线程对students进行初始化操作，然后在获取students的时候，将就会导致报错，原因是在主线程执行到get方法的时候，子线程可能还没有启动&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class WrongInit {
  
  private Map&amp;lt;Integer,String&amp;gt; students;
  
  public WrongInit(){
    new Thread(()-&amp;gt;{
      students = new Map&amp;lt;Integer,String&amp;gt;();
      students.put(1,&amp;quot;小红&amp;quot;);
      students.put(2,&amp;quot;小绿&amp;quot;);
      students.put(3,&amp;quot;小蓝&amp;quot;);
    }).start();
  }
  
  public static void main(String[] args){
    WrongInit wrongInit = new WrongInit();
    System.out.println(wrongInit.students.get(1));
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;活跃性问题&quot;&gt;活跃性问题&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;活跃性问题，典型情况有三种。死锁、活锁、饥饿&lt;/p&gt;
&lt;h4 id=&quot;死锁&quot;&gt;死锁&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;死锁的典型场景就是，两个线程都等着互相释放锁。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class TestLock{
  private static Object o1 = null;
  private static Object o2 = null;
  public static void main(String[] args){
     new Thread(()-&amp;gt;{
       synchronized(o1){
          synchronized(o2){
             System.out.println(&amp;quot;线程1拿到2把锁&amp;quot;);
          }
       }
     }).start();
    
    new Thread(()-&amp;gt;{
       synchronized(o2){
          synchronized(o1){
             System.out.println(&amp;quot;线程2拿到2把锁&amp;quot;);
          }
       }
     }).start();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&quot;产生死锁的原因主要是-&quot;&gt;产生死锁的原因主要是：&lt;/h5&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（1） 因为系统资源不足。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（2） 进程运行推进的顺序不合适。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（3） 资源分配不当等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。&lt;/p&gt;
&lt;h5 id=&quot;产生死锁的四个必要条件-&quot;&gt;产生死锁的四个必要条件：&lt;/h5&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（1） 互斥条件：一个资源每次只能被一个进程使用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一不满足，就不会发生死锁。&lt;/p&gt;
&lt;h5 id=&quot;死锁的解除与预防-&quot;&gt;死锁的解除与预防：&lt;/h5&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;的情况下占用资源。因此，对资源的分配要给予合理的规划。&lt;/p&gt;
&lt;h4 id=&quot;活锁&quot;&gt;活锁&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设有一个消息队列，里面放着各种各样的消息，这个时候有一个消息自身写错了导致订阅失败，无法正确的被处理，这个时候重试队列会把这个消息放到队列的第一个，然后无限重复。就造成后续的消息无法成功的被处理。&lt;/p&gt;
&lt;h4 id=&quot;饥饿&quot;&gt;饥饿&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;java中的线程有优先级的概念，从1~10。默认为5，最高10，最低1.如果一个线程被设置为1，那就有可能永远没有办法被调度。也就形成了饥饿。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[需要注意线程安全问题的情况]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程安全/需要注意线程安全问题的情况</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程安全/需要注意线程安全问题的情况</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程安全]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;需要注意线程安全问题的情况&quot;&gt;需要注意线程安全问题的情况&lt;/h1&gt;
&lt;h2 id=&quot;访问共享变量或资源&quot;&gt;访问共享变量或资源&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个变量在被多个线程同时读写时候，就会有线程安全问题&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ThreadNotSafe {
    static int i;
    public static void main(String[] args) throws InterruptedException {
        Runnable r = new Runnable() {
            @Override
            public void run() {
                for (int j = 0; j &amp;lt; 10000; j++) {
                    i++;
                }
            }
        };
        Thread thread1 = new Thread(r);
        Thread thread2 = new Thread(r);
        thread1.start();
        thread2.start();
        thread1.join();
        thread2.join();
        System.out.println(i);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个线程同时操作i这个变量，但是在相加之后总数总小于20000&lt;/p&gt;
&lt;h2 id=&quot;依赖时序的操作&quot;&gt;依赖时序的操作&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看下面这段代码，在单线程的情况下没有任何问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多线程的情况下，存在多个线程同时都进入map.containsKey(key)的代码，在A线程已经删除了obj之后，B线程依然来进行删除。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多线程，进入一个不是原子的操作时，就会发生这种问题&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;if (map.containsKey(key)){
		map.remove(obj);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;对方没有声明自己是线程安全的&quot;&gt;对方没有声明自己是线程安全的&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用其他类时，如果对方没有声明自己是线程安全的，那么这种情况下对其他类进行多线程的并发操作，就有可能会发生线程安全问题。举个例子，比如说我们定义了 ArrayList，它本身并不是线程安全的，如果此时多个线程同时对 ArrayList 进行并发读/写，那么就有可能会产生线程安全问题，造成数据出错，而这个责任并不在 ArrayList，因为它本身并不是并发安全的，正如源码注释所写的：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Note that this implementation is not synchronized. If multiple threads

access an ArrayList instance concurrently, and at least one of the threads

modifies the list structurally, it must be synchronized externally.
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这段话的意思是说，如果我们把 ArrayList 用在了多线程的场景，需要在外部手动用 synchronized 等方式保证并发安全。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以 ArrayList 默认不适合并发读写，是我们错误地使用了它，导致了线程安全问题。所以，我们在使用其他类时如果会涉及并发场景，那么一定要首先确认清楚，对方是否支持并发操作，以上就是四种需要我们额外注意线程安全问题的场景，分别是访问共享变量或资源，依赖时序的操作，不同数据之间存在绑定关系，以及对方没有声明自己是线程安全的。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[线程池线程复用原理]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/线程池线程复用原理</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/线程池线程复用原理</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程池线程复用原理&quot;&gt;线程池线程复用原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池最大的优势就在于可以复用线程，以减少创建和销毁时带来的消耗。线程池运行一堆固定数量的任务，需要的线程数远小于任务的数量，精髓就在于线程复用，让同一个线程去执行不同的任务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%97%B6%E6%9C%BA.png&quot; alt=&quot;线程池创建线程的时机&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;依旧是这张图，我们能从中可以看到，有三个关键的地方&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-bw59u4n&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前线程数小于核心线程数创建线程&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-46qld8p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;核心线程数已满，就往任务队列里面塞&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xlx1i3j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务队列和核心线程都满了，就创建非核心线程用于分摊压力&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-79jedk7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前三个都无法塞入的时候，拒绝执行&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;具体执行的代码在 ThreadPoolExecutor的execute中。&lt;/p&gt;
&lt;h2 id=&quot;实现方式&quot;&gt;实现方式&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看看是怎么实现的。(最核心的代码)&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
  			// ctl属性的高3位，提供了线程池的运行状态，包含线程池主要生命周期。
  			// 剩余位记录线程池线程个数
        int c = ctl.get();
  		  // 如果工作线程的数量小于核心线程数 （步骤1）
        if (workerCountOf(c) &amp;lt; corePoolSize) {
          	// 如果核心线程没有满，创建核心线程执行任务，如果返回false说明在创建核心线程的时候线程数已经满了
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
  			// 当前线程池的状态是正在运行，就把任务放入到队列中
        if (isRunning(c) &amp;amp;&amp;amp; workQueue.offer(command)) {
            int recheck = ctl.get();
          	// 重新检查一番，如果这个时候线程池被关闭了，则从队列中移除这个任务，并执行拒绝策略
            if (! isRunning(recheck) &amp;amp;&amp;amp; remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
              	// 如果检查下来运行的线程数量为0，就调用addWorker创建新的线程
                addWorker(null, false);
        }
  			// 线程池关闭，或者队列已经满了，就去判断最大线程数是否满了，步骤3
        else if (!addWorker(command, false))
          	// 最大线程数满了，执行拒绝策略
            reject(command);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程复用的秘密就是在这个addWorker里面。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private boolean addWorker(Runnable firstTask, boolean core) {
	/**
	 * 跳过上面一大段检查队列的直接看启动
	 */
   			boolean workerStarted = false;
        boolean workerAdded = false;
        Worker w = null;
        try {
            w = new Worker(firstTask);
            final Thread t = w.thread;
          	..... 
            if (t != null) {
                // 加锁
                if (workerAdded) {
                  	// 启动，
                    t.start();
                    workerStarted = true;
                }
            }
        } finally {
            if (! workerStarted)
                addWorkerFailed(w);
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过内置的Worker对象，把自己的firstTask作为任务封装进去，重写了run方法，所以在调用start方法的时候会调用的worker的run方法&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;     public void run() {
            runWorker(this);
        }
final void runWorker(Worker w) {
        Thread wt = Thread.currentThread();
        Runnable task = w.firstTask;
        w.firstTask = null;
        w.unlock(); // allow interrupts
        boolean completedAbruptly = true;
        try {
          	// 加个死循环，不断的从队列中获取任务，并执行----这里的task才是我们要执行的业务代码
            while (task != null || (task = getTask()) != null) {
                w.lock();
                if ((runStateAtLeast(ctl.get(), STOP) ||
                     (Thread.interrupted() &amp;amp;&amp;amp;
                      runStateAtLeast(ctl.get(), STOP))) &amp;amp;&amp;amp;
                    !wt.isInterrupted())
                    wt.interrupt();
                try {
                    beforeExecute(wt, task);
                    try {
                        task.run();
                        afterExecute(task, null);
                    } catch (Throwable ex) {
                        afterExecute(task, ex);
                        throw ex;
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;复用的本质，就是将我们的Runable给封装起来，封装成一个个task，塞入到队列中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后使用worker线程，不断的轮训这个任务队列，直接执行，采用了代理模式，增强了原本runable的执行逻辑。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[创建线程池的参数]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/创建线程池的参数</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/创建线程池的参数</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;创建线程池的参数&quot;&gt;创建线程池的参数&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在Java中创建线程都是通过一个ThreadPoolExecutor对象来进行创建的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ThreadPoolExecutor类最多有5个构造函数，用于创建不同特性的线程池&lt;/p&gt;
&lt;h2 id=&quot;参数列表&quot;&gt;参数列表&lt;/h2&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;参数名&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;corePoolSize&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;核心线程数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;maximumPoolSize&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;最大线程数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;keepAliveTime&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;空闲线程存活时长&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;unit&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;空闲线程存活时间单位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;workQueue&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;用于存放任务的队列&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;threadFactory&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;线程工厂，用于来创建新线程&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;handler&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;处理被拒绝的任务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;创建时机&quot;&gt;创建时机&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%97%B6%E6%9C%BA.png&quot; alt=&quot;线程池创建线程的时机&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在最大线程创建出来之后，回去判断线程的存活时间，如果存活时间大于所设定的值，则会将这些创建出来的回收&lt;/p&gt;
&lt;h2 id=&quot;线程工厂ThreadFactory&quot;&gt;线程工厂ThreadFactory&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;hreadFactory 实际上是一个线程工厂，它的作用是生产线程以便执行任务。我们可以选择使用默认的线程工厂，创建的线程都会在同一个线程组，并拥有一样的优先级，且都不是守护线程，我们也可以选择自己定制线程工厂，以方便给线程自定义命名，不同的线程池内的线程通常会根据具体业务来定制不同的线程名。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;默认的线程工厂:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static class DefaultThreadFactory implements ThreadFactory {
        private static final AtomicInteger poolNumber = new AtomicInteger(1);
        private final ThreadGroup group;
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        DefaultThreadFactory() {
            SecurityManager s = System.getSecurityManager();
            group = (s != null) ? s.getThreadGroup() :
                                  Thread.currentThread().getThreadGroup();
            namePrefix = &amp;quot;pool-&amp;quot; +
                          poolNumber.getAndIncrement() +
                         &amp;quot;-thread-&amp;quot;;
        }

        public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r,
                                  namePrefix + threadNumber.getAndIncrement(),
                                  0);
            if (t.isDaemon())
                t.setDaemon(false);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;工作队列WorkQueue&quot;&gt;工作队列WorkQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用于存放任务的队列列表。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程的不同的特性，就是通过这个存放任务的列表来实现的。&lt;/p&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;线程池&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;实现队列&lt;/th&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;FixedThreadPool&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;LinkedBlockingQueue&lt;/td&gt;
&lt;td&gt;没有额外线程，只存在核心线程，而且核心线程没有超时机制，而且任务队列没有长度的限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;SingleThreadExecutor&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;LinkedBlockingQueue&lt;/td&gt;
&lt;td&gt;内部只有一个核心线程，它确保所有的任务都在同一个线程中按顺序执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;CachedThreadPool&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;SynchronousQueue&lt;/td&gt;
&lt;td&gt;只有非核心线程，并且其最大线程数为Integer.MAX_VALUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;ScheduledThreadPool&amp;lt;br&amp;gt;SingleThreadScheduledExecutor&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;DelayedWorkQueue&lt;/td&gt;
&lt;td&gt;按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;看下面ThreadPool的结构，workQueue就是用来存放添加的任务，然后交由给不同的线程去执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/ThreadPool%E7%BB%93%E6%9E%84.png&quot; alt=&quot;ThreadPool结构&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;拒绝策略Handler&quot;&gt;拒绝策略Handler&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用于处理核心线程满、队列满、最大线程满了之后，现在添加不进去之后的策略。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CgotOV3g0WWAVWVlAAEsBI6lEEA162.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;DiscardPolicy&quot;&gt;DiscardPolicy&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当新任务提交之后会被直接丢弃，也不会有任何的通知，相对而言存在一定的风险，因为在提交的时候并不知道线程会被丢弃，会存在数据丢失的风险&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;       /**
         * Does nothing, which has the effect of discarding task r.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;DiscardOldestPolicy&quot;&gt;DiscardOldestPolicy&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;丢弃任务队列中的头结点，通常是存活时间最长的任务，这种策略与DiscardPolicy不同之处在于它丢弃的不是最新提交的，而是队列中存活时间最长的，这样就可以腾出空间给新提交的任务，但同理它也存在一定的数据丢失风险。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;        /**
         * Obtains and ignores the next task that the executor
         * would otherwise execute, if one is immediately available,
         * and then retries execution of task r, unless the executor
         * is shut down, in which case task r is instead discarded.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                e.getQueue().poll();
                e.execute(r);
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;CallerRunsPolicy&quot;&gt;CallerRunsPolicy&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当触发拒绝策略时，只要线程池没有关闭，就由提交任务的当前线程处理。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;        /**
         * Executes task r in the caller&apos;s thread, unless the executor
         * has been shut down, in which case the task is discarded.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                r.run();
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;AbortPolicy&quot;&gt;AbortPolicy&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当任务提交到这里，会抛出RejectedExecutionException异常&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;        /**
         * Always throws RejectedExecutionException.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         * @throws RejectedExecutionException always
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            throw new RejectedExecutionException(&amp;quot;Task &amp;quot; + r.toString() +
                                                 &amp;quot; rejected from &amp;quot; +
                                                 e.toString());
        }
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[线程池的优势]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/线程池的优势</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/线程池的优势</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;线程池的优势&quot;&gt;线程池的优势&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池的诞生，是为了解决在大量线程下效率不见提升反而降低的情况。&lt;/p&gt;
&lt;h2 id=&quot;如何提升运行效率&quot;&gt;如何提升运行效率&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wxogibg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解决反复创建线程，性能开销大&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用固定的数量的线程一直保持工作状态，并返回执行任务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0fzeff9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;多线程占用内存资源&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据业务需要创建线程，控制线程总数量，避免占用过多内存资源&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用线程池的好处&quot;&gt;使用线程池的好处&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4wdnjb7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以解决线程生命周期的系统开销问题，同时还能够加快响应速度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为线程池中的线程是可以复用的，我们只需要少量的线程就可以执行大量的任务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大大的减少了创建线程时候的资源消耗&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-evb40iq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以统筹CPU和内存的使用，避免资源使用不当。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池能够根据配置灵活的控制线程数量，不够就创建，多了就回收，避免线程过多导致内存溢出，也避免了CPU资源的浪费&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vzy843c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以统一管理资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;统一管理任务队列和线程，可以统一开始或结束任务，比单个线程处理任务要更方便&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;线程池的思想&quot;&gt;线程池的思想&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CgotOV3bmEOAaIncAABOPHpwdNY412.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先创建了一个线程池，线程池中有 5 个线程，然后线程池将 10000 个任务分配给这 5 个线程，这 5 个线程反复领取任务并执行，直到所有任务执行完毕，这就是线程池的思想。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[共享锁独占锁]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/共享锁独占锁</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/共享锁独占锁</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><category><![CDATA[锁的种类和特点]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;共享锁独占锁&quot;&gt;共享锁独占锁&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最能够诠释共享锁和独占锁的，就是&lt;code&gt;读写锁&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;读写锁&lt;/code&gt;的特点是，多线程读取时共享同一把锁，多线程写入时必须拿到独占的锁才能够进行写入。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;读写锁&lt;/code&gt;提升了在某些读多写少的情况下的性能，试想一下，如果我们采用ReentrantLock来进行读写文件的操作，虽然能够保证了线程的安全，但是读取文件这种不会修改数据的操作也会对文件进行加锁，会造成资源的浪费。&lt;/p&gt;
&lt;h2 id=&quot;读写锁的规则&quot;&gt;读写锁的规则&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m0i4wbr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个线程已经占用了读锁，那另一个线程申请读锁的时候，可以申请成功。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3h24us4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个线程已经占用了读锁，那么另一个线程申请写锁的时候，申请写锁的线程会等待读锁的释放，因为读写不能同时进行。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9mpuqoe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个线程已经占用了写锁，那么另一个无论是申请读锁还是写锁都需要等待持有写锁的线程释放锁，同样也因为读写不能同时，并且两个线程不应该同时写。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;总结&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3jgrk6b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读读共享&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xp7li55&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其他互斥&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-uzllyhc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写写互斥&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-09wakk8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;读写互斥&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dda52sj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写读互斥&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;使用方式&quot;&gt;使用方式&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;   public class ReadWriteLockDemo {
    private ReadWriteLock readWriteLock = new ReentrantReadWriteLock(false);
    private Lock readLock = readWriteLock.readLock();
    private Lock writeLock = readWriteLock.writeLock();
    public void read() {
        readLock.lock();
        try {
            System.out.println(Thread.currentThread().getName() + &amp;quot;得到读锁，正在读取&amp;quot;);
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            System.out.println(Thread.currentThread().getName() + &amp;quot;释放读锁&amp;quot;);
            readLock.unlock();
        }
    }
    public void write() {
        writeLock.lock();
        try {
            System.out.println(Thread.currentThread().getName() + &amp;quot;得到写锁，正在写入&amp;quot;);
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            System.out.println(Thread.currentThread().getName() + &amp;quot;释放写锁&amp;quot;);
            writeLock.unlock();
        }
    }
    public static void main(String[] args) {
        ReadWriteLockDemo demo = new ReadWriteLockDemo();
        new Thread(demo::read).start();
        new Thread(demo::read).start();
        new Thread(demo::write).start();
        new Thread(demo::write).start();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;运行结果:&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/2021-11-29-13-04-32-image.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;加锁原理分析&quot;&gt;加锁原理分析&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/762a042b.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;写锁的加锁代码&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;protected final boolean tryAcquire(int acquires) {
  /**
   * 1. 如果读锁或者写锁的数量不为0，并且拥有锁的线程是其他的线程，
   * 2. 如果锁的数量饱和，则返回失败
   * 3. 如果这个线程有资格获得锁,重入或者队列允许，则更新状态并设置拥有者
   */
  Thread current = Thread.currentThread()q;
  // 获取当前锁的个数
  int c = getState();
  // 获取写锁的个数
  int w = exclusiveCount(c);
  if (c != 0) {// 如果线程已经持有了锁(c != 0)
    // (Note: if c != 0 and w == 0 then shared count != 0)
    // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败
    if (w == 0 || current != getExclusiveOwnerThread())  
      return false;
    if (w + exclusiveCount(acquires) &amp;gt; MAX_COUNT)
      // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。
      throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
    // Reentrant acquire
    setState(c + acquires);
    return true;
  }
  // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；
  // 或者如果通过CAS增加写线程数失败也返回失败。
  if (writerShouldBlock() ||
      !compareAndSetState(c, c + acquires))
    return false;
  setExclusiveOwnerThread(current);
  return true;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;读锁的加锁代码:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;	protected final int tryAcquireShared(int unused) {
    				/**
    				 * 1. 如果其他线程获取了写锁，则失败
    				 * 2. 如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。
    				 * 3. 读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&amp;lt;&amp;lt;16”。
    				 */
            Thread current = Thread.currentThread();
            int c = getState();
            if (exclusiveCount(c) != 0 &amp;amp;&amp;amp;
                getExclusiveOwnerThread() != current)
           	    // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态
                return -1;
            int r = sharedCount(c);
            if (!readerShouldBlock() &amp;amp;&amp;amp;
                r &amp;lt; MAX_COUNT &amp;amp;&amp;amp;
                compareAndSetState(c, c + SHARED_UNIT)) {
                if (r == 0) {
                    firstReader = current;
                    firstReaderHoldCount = 1;
                } else if (firstReader == current) {
                    firstReaderHoldCount++;
                } else {
                    HoldCounter rh = cachedHoldCounter;
                    if (rh == null ||
                        rh.tid != LockSupport.getThreadId(current))
                        cachedHoldCounter = rh = readHolds.get();
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    rh.count++;
                }
                return 1;
            }
            return fullTryAcquireShared(current);
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;从源码上看:&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于写锁的加锁，需要确保没有别的线程持有写锁、或者持有读锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于读锁的加锁，需要确保没有别的线程持有读锁即可。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面来讲讲，在真实业务中的线程插队逻辑。&lt;/p&gt;
&lt;h2 id=&quot;插队逻辑&quot;&gt;插队逻辑&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设线程 2 和线程 4 正在同时读取，线程 3 想要写入，但是由于线程 2 和线程 4 已经持有读锁了，所以线程 3 就进入等待队列进行等待。此时，线程 5 突然跑过来想要插队获取读锁：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E8%AF%BB%E9%94%81%E6%8F%92%E9%98%9F.png&quot; alt=&quot;读锁插队&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;面对这种情况有两种应对策略：&lt;/p&gt;
&lt;h3 id=&quot;第一种策略-允许插队&quot;&gt;第一种策略：允许插队&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于现在有线程在读，而线程 5 又不会特别增加它们读的负担，因为线程们可以共用这把锁，所以第一种策略就是让线程 5 直接加入到线程 2 和线程 4 一起去读取。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种策略看上去增加了效率，但是有一个严重的问题，那就是如果想要读取的线程不停地增加，比如线程 6，那么线程 6 也可以插队，这就会导致读锁长时间内不会被释放，导致线程 3 长时间内拿不到写锁，也就是那个需要拿到写锁的线程会陷入“饥饿”状态，它将在长时间内得不到执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E8%AF%BB%E9%94%81%E6%8F%92%E9%98%9F%E6%88%90%E5%8A%9F.png&quot; alt=&quot;读锁插队成功&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;第二种策略-不允许插队&quot;&gt;第二种策略：不允许插队&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种策略认为由于线程 3 已经提前等待了，所以虽然线程 5 如果直接插队成功，可以提高效率，但是我们依然让线程 5 去排队等待：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E8%AF%BB%E9%94%81%E4%B8%8D%E5%85%81%E8%AE%B8%E6%8F%92%E9%98%9F.png&quot; alt=&quot;读锁不允许插队&quot; /&gt;&lt;/span&gt;按照这种策略线程 5 会被放入等待队列中，并且排在线程 3 的后面，让线程 3 优先于线程 5 执行，这样可以避免“饥饿”状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这对于程序的健壮性是很有好处的，直到线程 3 运行完毕，线程 5 才有机会运行，这样谁都不会等待太久的时间。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E8%AF%BB%E9%94%81%E4%B8%8D%E5%85%81%E8%AE%B8%E6%8F%92%E9%98%9F-%E7%BB%93%E6%9E%9C2.png&quot; alt=&quot;读锁不允许插队-结果2&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以我们可以看出，即便是非公平锁，只要等待队列的头结点是尝试获取写锁的线程，那么读锁依然是不能插队的，目的是避免“饥饿”。&lt;/p&gt;
&lt;h2 id=&quot;锁的升降级&quot;&gt;锁的升降级&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;锁降级指的是写锁降级成为读锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;锁降级是指把持住当前拥有的写锁的同时，再获取到读锁，随后释放写锁的过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看看官方文档是怎么写的:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; class CachedData {
   Object data;
   boolean cacheValid;
   final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
   void processCachedData() {
     rwl.readLock().lock();
     if (!cacheValid) {
       // Must release read lock before acquiring write lock
       rwl.readLock().unlock();
       rwl.writeLock().lock();
       try {
         // Recheck state because another thread might have
         // acquired write lock and changed state before we did.
         if (!cacheValid) {
           data = ...
           cacheValid = true;
         }
         // Downgrade by acquiring read lock before releasing write lock
         rwl.readLock().lock();
       } finally {
         rwl.writeLock().unlock(); // Unlock write, still hold read
       }
     }
     try {
       use(data);
     } finally {
       rwl.readLock().unlock();
     }
   }
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;降级的过程&quot;&gt;降级的过程&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码中申明了一个cacheValid的变量用于检查缓存是否有效。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取读锁，如果cache不可用，则释放读锁去获取写锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;再次检查cache，修改data，并且将cache设置成true，然后在&lt;strong&gt;释放写锁前获取读锁&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时，cache中数据可用，处理cache中数据，最后释放读锁。&lt;/p&gt;
&lt;h3 id=&quot;为什么需要锁的降级&quot;&gt;为什么需要锁的降级&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其目的是保证数据可见性:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前的线程&lt;em&gt;C&lt;/em&gt;在修改完cache中的数据后，还需要对数据进行一些处理，但是此时没有获取读锁而是直接释放了写锁，那么假设此时另一个线程&lt;em&gt;T&lt;/em&gt;获取了写锁并修改了数据，那么&lt;em&gt;C&lt;/em&gt;线程无法感知到数据已被修改,则数据出现错误。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果遵循锁降级的步骤，线程&lt;em&gt;C&lt;/em&gt;在释放写锁之前获取读锁，那么线程&lt;em&gt;T&lt;/em&gt;在获取写锁时将被阻塞，直到线程&lt;em&gt;C&lt;/em&gt;完成数据处理过程，释放读锁。&lt;/p&gt;
&lt;h3 id=&quot;为什么不支持锁的升级-&quot;&gt;为什么不支持锁的升级？&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们运行下面这段代码，在不释放读锁的情况下直接尝试获取写锁，也就是锁的升级，会让线程直接阻塞，程序是无法运行的。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void upgrade() {
    rwl.readLock().lock();
    System.out.println(&amp;quot;获取到了读锁&amp;quot;);
    rwl.writeLock().lock();
    System.out.println(&amp;quot;成功升级&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们知道读写锁的特点是如果线程都申请读锁，是可以多个线程同时持有的，可是如果是写锁，只能有一个线程持有，并且不可能存在读锁和写锁同时持有的情况。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正是因为不可能有读锁和写锁同时持有的情况，所以升级写锁的过程中，需要等到所有的读锁都释放，此时才能进行升级。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于 ReentrantReadWriteLock 而言。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1jjlsy0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;插队策略&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ff9rhlm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;公平策略下，只要队列里有线程已经在排队，就不允许插队。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-enh982x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;非公平策略下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-qypt9nw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果允许读锁插队，那么由于读锁可以同时被多个线程持有，所以可能造成源源不断的后面的线程一直插队成功，导致读锁一直不能完全释放，从而导致写锁一直等待，为了防止“饥饿”，在等待队列的头结点是尝试获取写锁的线程的时候，不允许读锁插队。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dj4dnzx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;写锁可以随时插队，因为写锁并不容易插队成功，写锁只有在当前没有任何其他线程持有读锁和写锁的时候，才能插队成功，同时写锁一旦插队失败就会进入等待队列，所以很难造成“饥饿”的情况，允许写锁插队是为了提高效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-603270j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;升降级策略：只能从写锁降级为读锁，不能从读锁升级为写锁。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[自旋锁非自旋锁]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/自旋锁非自旋锁</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/自旋锁非自旋锁</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><category><![CDATA[锁的种类和特点]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;自旋锁非自旋锁&quot;&gt;自旋锁非自旋锁&lt;/h1&gt;
&lt;h2 id=&quot;对比自旋和非自旋获取锁的流程&quot;&gt;对比自旋和非自旋获取锁的流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E8%87%AA%E6%97%8B%E9%94%81%E9%80%BB%E8%BE%91.svg&quot; alt=&quot;自旋锁逻辑&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;自旋锁的好处&quot;&gt;自旋锁的好处&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先，阻塞和唤醒线程都是需要高昂的开销的，如果同步代码块中的内容不复杂，那么可能转换线程带来的开销比实际业务代码执行的开销还要大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在很多场景下，可能我们的同步代码块的内容并不多，所以需要的执行时间也很短，如果我们仅仅为了这点时间就去切换线程状态，那么其实不如让线程不切换状态，而是让它自旋地尝试获取锁，等待其他线程释放锁，有时我只需要稍等一下，就可以避免上下文切换等开销，提高了效率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用一句话总结自旋锁的好处，那就是自旋锁用循环去不停地尝试获取锁，让线程始终处于 Runnable 状态，节省了线程状态切换带来的开销。&lt;/p&gt;
&lt;h2 id=&quot;自旋锁的缺点&quot;&gt;自旋锁的缺点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虽然避免了线程切换的开销，但是它在避免线程切换开销的同时也带来了新的开销，因为它需要不停得去尝试获取锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这把锁一直不能被释放，那么这种尝试只是无用的尝试，会白白浪费处理器资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也就是说，虽然一开始自旋锁的开销低于线程切换，但是随着时间的增加，这种开销也是水涨船高，后期甚至会超过线程切换的开销，得不偿失。&lt;/p&gt;
&lt;h2 id=&quot;适用场景&quot;&gt;适用场景&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先，自旋锁适用于并发度不是特别高的场景，以及临界区比较短小的情况，这样我们可以利用避免线程切换来提高效率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可是如果临界区很大，线程一旦拿到锁，很久才会释放的话，那就不合适用自旋锁，因为自旋会一直占用 CPU 却无法拿到锁，白白消耗资源。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[公平锁非公平锁]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/公平锁非公平锁</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/公平锁非公平锁</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><category><![CDATA[锁的种类和特点]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;公平锁非公平锁&quot;&gt;公平锁非公平锁&lt;/h1&gt;
&lt;h2 id=&quot;特点&quot;&gt;特点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。&lt;/p&gt;
&lt;h2 id=&quot;案例&quot;&gt;案例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/a23d746a.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/4499559e.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/6edea205.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们来看一下公平锁与非公平锁的加锁方法的源码:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/bc6fe583.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/bd0036bb.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;From: https://tech.meituan.com/2018/11/15/java-lock.html&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[锁的种类和特点]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;锁的种类和特点&quot;&gt;锁的种类和特点&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;锁的种类有七种&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-stodn9d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;偏向锁/轻量级锁/重量级锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g7mccwi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可重入锁/不可重入锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qsbfgcp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;共享锁/独占锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uy00crj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;公平锁/非公平锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4jrnyvl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁/悲观锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-46mz7gk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自旋锁/非自旋锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y6wwsil&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可中断锁/不可中断锁&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;偏向锁-轻量级锁-重量级锁&quot;&gt;偏向锁/轻量级锁/重量级锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这三种是JVM为了提升synchronized修饰的方法的并发性能，而出现的锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现方式是通过对象头中的mark word 字段，来表明锁的状态。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-s45xrxk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;偏向锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;偏向锁指的是，如果一段代码的并发程度很低，只有一个线程在请求锁，那么其实就没有必要上锁，JVM的做法是，当一个对象被初始化之后，这个时候就是可偏向的，在第一个线程访问锁的时候会在这个对象标记上线程的信息，那么在下一次还是这个线程请求，就直接获取到锁，开销比较小，性能好&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8opha5h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;轻量级锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;轻量级锁，synchronized修饰的方法被多个线程访问，就会从偏向锁升级成轻量级锁。因为在绝大多数的情况下，线程都是交替执行只存在于少量的竞争，这个时候轻量级锁会通过CAS方式进行自旋，不会陷入到阻塞&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ha5ieru&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重量级锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重量级锁，是在操作系统层实现的一个完全互斥的锁。当有多个线程在竞争，且竞争的时间过长的时候，轻量级锁就会膨胀成重量级锁。重量级锁会让其他没有获取到锁的线程进入阻塞状态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，synchronized的锁是会经历 无锁 -&amp;gt; 偏向锁 -&amp;gt; 轻量级锁 -&amp;gt; 重量级锁 这几个过程，这个过程也被称之为锁的膨胀。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中，偏向锁性能最好，轻量级锁由于CAS自旋，所以性能次之，重量级锁存在线程的阻塞和唤醒，性能最差。&lt;/p&gt;
&lt;h2 id=&quot;可重入锁-不可重入锁&quot;&gt;可重入锁/不可重入锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可重入锁是指，在线程当前已经持有这把锁了，在不释放这把锁的情况下，再次获取这把锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不可重入锁是指，在线程当前已经只有这把锁了，必须得先释放掉持有的锁，才能够重新获取锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于可重入锁而言，最典型的就是 ReentrantLock 了，正如它的名字一样，reentrant 的意思就是可重入，它也是 Lock 接口最主要的一个实现类。&lt;/p&gt;
&lt;h2 id=&quot;共享锁-独占锁&quot;&gt;&lt;a href=&quot;共享锁独占锁.md&quot;&gt;共享锁/独占锁&lt;/a&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最好能够全是共享锁和独占锁的是&lt;code&gt;读写锁&lt;/code&gt;。读文件的时候，可以多个线程读取一个文件，但是在写入的时候只允许一个线程进行写入。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当读写锁是写加锁状态时, 在这个锁被解锁之前, 所有试图对这个锁加锁的线程都会被阻塞.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当读写锁在读加锁状态时, 所有试图以读模式对它进行加锁的线程都可以得到访问权, 但是如果线程希望以写模式对此锁进行加锁, 它必须直到所有的线程释放锁.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通常, 当读写锁处于读模式锁住状态时, 如果有另外线程试图以写模式加锁, 读写锁通常会阻塞随后的读模式锁请求, 这样可以避免读模式锁长期占用, 而等待的写模式锁请求长期阻塞.&lt;/p&gt;
&lt;h2 id=&quot;公平锁-非公平锁&quot;&gt;&lt;a href=&quot;公平锁非公平锁.md&quot;&gt;公平锁/非公平锁&lt;/a&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;公平锁是指，在线程拿不到锁的时候会进入到等待，开始排队，在队列中等待时间长的会优先分配到锁，先来先得。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;非公平锁是指，在线程拿不到锁的时候，开始排队，但是分配上是会忽略掉排队时间，随机分配到一个线程上&lt;/p&gt;
&lt;h2 id=&quot;乐观锁-悲观锁&quot;&gt;&lt;a href=&quot;乐观锁和悲观锁.md&quot;&gt;乐观锁/悲观锁&lt;/a&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;悲观锁在获取到资源之前，必须先拿到锁，JVM的重量级锁就是一种悲观锁，只有在独占锁的时候，才回去操作资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁在获取资源之前无需拿到锁，只有在最后更新的时候，会通过CAS的方式去更新资源，JVM的轻量级锁与之类似&lt;/p&gt;
&lt;h2 id=&quot;自旋锁-非自旋锁&quot;&gt;&lt;a href=&quot;自旋锁非自旋锁.md&quot;&gt;自旋锁/非自旋锁&lt;/a&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自旋锁的理念是如果线程现在拿不到锁，并不直接陷入阻塞或者释放 CPU 资源，而是开始利用循环，不停地尝试获取锁，这个循环过程被形象地比喻为“自旋”，就像是线程在“自我旋转”。相反，非自旋锁的理念就是没有自旋的过程，如果拿不到锁就直接放弃，或者进行其他的处理逻辑，例如去排队、陷入阻塞等。&lt;/p&gt;
&lt;h2 id=&quot;不可中断锁-可中断锁&quot;&gt;不可中断锁/可中断锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Java 中，synchronized 关键字修饰的锁代表的是不可中断锁，一旦线程申请了锁，就没有回头路了，只能等到拿到锁以后才能进行其他的逻辑处理。而我们的 ReentrantLock 是一种典型的可中断锁，例如使用 lockInterruptibly 方法在获取锁的过程中，突然不想获取了，那么也可以在中断之后去做其他的事情，不需要一直傻等到获取到锁才离开。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[常见的阻塞队列]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/阻塞队列/常见的阻塞队列</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/阻塞队列/常见的阻塞队列</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[阻塞队列]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;常见的阻塞队列&quot;&gt;常见的阻塞队列&lt;/h1&gt;
&lt;h2 id=&quot;ArrayBlockingQueue&quot;&gt;ArrayBlockingQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ArrayBlockingQueue 是最典型的&lt;strong&gt;有界队列&lt;/strong&gt;，其内部是用数组存储元素的，利用 ReentrantLock 实现线程安全。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在创建它的时候就需要指定它的容量，之后也不可以再扩容了，在构造函数中我们同样可以指定是否是公平的，代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;第一个参数是容量，第二个参数是是否公平。
ArrayBlockingQueue(int capacity, boolean fair)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正如 ReentrantLock 一样:&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 ArrayBlockingQueue 被设置为非公平的，那么就存在插队的可能；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果设置为公平的，那么等待了最长时间的线程会被优先处理，其他线程不允许插队，不过这样的公平策略同时会带来一定的性能损耗，因为非公平的吞吐量通常会高于公平的情况。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;LinkedBlockingQueue&quot;&gt;LinkedBlockingQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正如名字所示，这是一个内部用链表实现的 BlockingQueue。如果我们不指定它的初始容量，那么它容量默认就为整型的最大值 Integer.MAX_VALUE，由于这个数非常大，我们通常不可能放入这么多的数据，所以 LinkedBlockingQueue 也被称作无界队列，代表它几乎没有界限。&lt;/p&gt;
&lt;h2 id=&quot;SynchronousQueue&quot;&gt;SynchronousQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl4lhhSAZIuZAABMMZW2RVk163.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如图所示，SynchronousQueue 最大的不同之处在于，它的容量为 0，所以没有一个地方来暂存元素，导致每次取数据都要先阻塞，直到有数据被放入；同理，每次放数据的时候也会阻塞，直到有消费者来取。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要注意的是，SynchronousQueue 的容量不是 1 而是 0，因为 SynchronousQueue 不需要去持有元素，它所做的就是直接传递（direct handoff）。由于每当需要传递的时候，SynchronousQueue 会把元素直接从生产者传给消费者，在此期间并不需要做存储，所以如果运用得当，它的效率是很高的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，由于它的容量为 0，所以相比于一般的阻塞队列，SynchronousQueue 的很多方法的实现是很有意思的，我们来举几个例子：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SynchronousQueue 的 peek 方法永远返回 null，代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public E peek() {
    return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为 peek 方法的含义是取出头结点，但是 SynchronousQueue 的容量是 0，所以连头结点都没有，peek 方法也就没有意义，所以始终返回 null。同理，element 始终会抛出 NoSuchElementException 异常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而 SynchronousQueue 的 size 方法始终返回 0，因为它内部并没有容量，代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public int size() {
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接 return 0，同理，isEmpty 方法始终返回 true：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public boolean isEmpty() {
    return true;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为它始终都是空的。&lt;/p&gt;
&lt;h2 id=&quot;PriorityBlockingQueue&quot;&gt;PriorityBlockingQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Priority: 优先级的意思&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前面我们所说的 ArrayBlockingQueue 和 LinkedBlockingQueue 都是采用先进先出的顺序进行排序，可是如果有的时候我们需要自定义排序怎么办呢？这时就需要使用 PriorityBlockingQueue。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;PriorityBlockingQueue 是一个支持优先级的无界阻塞队列，可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。同时，插入队列的对象必须是可比较大小的，也就是 Comparable 的，否则会抛出 ClassCastException 异常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它的 take 方法在队列为空的时候会阻塞，但是正因为它是无界队列，而且会自动扩容，所以它的队列永远不会满，所以它的 put 方法永远不会阻塞，添加操作始终都会成功，也正因为如此，它的成员变量里只有一个 Condition：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private final Condition notEmpty;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这和之前的 ArrayBlockingQueue 拥有两个 Condition（分别是 notEmpty 和 notFull）形成了鲜明的对比，我们的 PriorityBlockingQueue 不需要 notFull，因为它永远都不会满，真是“有空间就可以任性”。&lt;/p&gt;
&lt;h2 id=&quot;DelayQueue&quot;&gt;DelayQueue&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DelayQueue 这个队列比较特殊，具有“延迟”的功能。我们可以设定让队列中的任务延迟多久之后执行，比如 10 秒钟之后执行，这在例如“30 分钟后未付款自动取消订单”等需要延迟执行的场景中被大量使用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它是无界队列，放入的元素必须实现 Delayed 接口，而 Delayed 接口又继承了 Comparable 接口，所以自然就拥有了比较和排序的能力，代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public interface Delayed extends Comparable&amp;lt;Delayed&amp;gt; {
    long getDelay(TimeUnit unit);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看出这个 Delayed 接口继承自 Comparable，里面有一个需要实现的方法，就是 getDelay。这里的 getDelay 方法返回的是“还剩下多长的延迟时间才会被执行”，如果返回 0 或者负数则代表任务已过期。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;元素会根据延迟时间的长短被放到队列的不同位置，越靠近队列头代表越早过期。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DelayQueue 内部使用了 PriorityQueue 的能力来进行排序，而不是自己从头编写，我们在工作中可以学习这种思想，对已有的功能进行复用，不但可以减少开发量，同时避免了“重复造轮子”，更重要的是，对学到的知识进行合理的运用，让知识变得更灵活，做到触类旁通。&lt;/p&gt;
&lt;h2 id=&quot;如何选择&quot;&gt;如何选择&lt;/h2&gt;
&lt;h3 id=&quot;线程池对于阻塞队列的选择&quot;&gt;线程池对于阻塞队列的选择&lt;/h3&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;线程池&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;实现队列&lt;/th&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;FixedThreadPool&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;LinkedBlockingQueue&lt;/td&gt;
&lt;td&gt;没有额外线程，只存在核心线程，而且核心线程没有超时机制，而且任务队列没有长度的限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;SingleThreadExecutor&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;LinkedBlockingQueue&lt;/td&gt;
&lt;td&gt;内部只有一个核心线程，它确保所有的任务都在同一个线程中按顺序执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;CachedThreadPool&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;SynchronousQueue&lt;/td&gt;
&lt;td&gt;只有非核心线程，并且其最大线程数为Integer.MAX_VALUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;ScheduledThreadPool&amp;lt;br&amp;gt;SingleThreadScheduledExecutor&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;DelayedWorkQueue&lt;/td&gt;
&lt;td&gt;按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们来看线程池的选择要诀。上面表格左侧是线程池，右侧为它们对应的阻塞队列，你可以看到 5 种线程池只对应了 3 种阻塞队列，下面我们对它们进行逐一的介绍。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-042l4s7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;FixedThreadPool（SingleThreadExecutor 同理）选取的是 LinkedBlockingQueue&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为 LinkedBlockingQueue 不同于 ArrayBlockingQueue，ArrayBlockingQueue 的容量是有限的，而 LinkedBlockingQueue 是链表长度默认是可以无限延长的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于 FixedThreadPool 的线程数是固定的，在任务激增的时候，它无法增加更多的线程来帮忙处理 Task，所以需要像 LinkedBlockingQueue 这样没有容量上限的 Queue 来存储那些还没处理的 Task。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果所有的 corePoolSize 线程都正在忙，那么新任务将会进入阻塞队列等待，由于队列是没有容量上限的，队列永远不会被填满，这样就保证了对于线程池 FixedThreadPool 和 SingleThreadExecutor 而言，不会拒绝新任务的提交，也不会丢失数据。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dvvz3n2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;CachedThreadPool 选取的是 SynchronousQueue&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于 CachedThreadPool 而言，为了避免新提交的任务被拒绝，它选择了无限制的 maximumPoolSize（在专栏中，maxPoolSize 等同于 maximumPoolSize），所以既然它的线程的最大数量是无限的，也就意味着它的线程数不会受到限制，那么它就不需要一个额外的空间来存储那些 Task，因为每个任务都可以通过新建线程来处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SynchronousQueue 会直接把任务交给线程，而不需要另外保存它们，效率更高，所以 CachedThreadPool 使用的 Queue 是 SynchronousQueue。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ud35xyx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;ScheduledThreadPool（SingleThreadScheduledExecutor同理）选取的是延迟队列&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于 ScheduledThreadPool 而言，它使用的是 DelayedWorkQueue。延迟队列的特点是：不是先进先出，而是会按照延迟时间的长短来排序，下一个即将执行的任务会排到队列的最前面。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们来举个例子：例如我们往这个队列中，放一个延迟 10 分钟执行的任务，然后再放一个延迟 10 秒钟执行的任务。通常而言，如果不是延迟队列，那么按照先进先出的排列规则，也就是延迟 10 分钟执行的那个任务是第一个放置的，会放在最前面。但是由于我们此时使用的是阻塞队列，阻塞队列在排放各个任务的位置的时候，会根据延迟时间的长短来排放。所以，我们第二个放置的延迟 10 秒钟执行的那个任务，反而会排在延迟 10 分钟的任务的前面，因为它的执行时间更早。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们选择使用延迟队列的原因是，ScheduledThreadPool 处理的是基于时间而执行的 Task，而延迟队列有能力把 Task 按照执行时间的先后进行排序，这正是我们所需要的功能。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-hyjq6nh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;ArrayBlockingQueue&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除了线程池选择的 3 种阻塞队列外，还有一种常用的阻塞队列叫作 ArrayBlockingQueue，它也经常被用于我们手动创建的线程池中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种阻塞队列内部是用数组实现的，在新建对象的时候要求传入容量值，且后期不能扩容，所以 ArrayBlockingQueue的最大特点就是容量是有限且固定的。这样一来，使用 ArrayBlockingQueue 且设置了合理大小的最大线程数的线程池，在任务队列放满了以后，如果线程数也已经达到了最大值，那么线程池根据规则就会拒绝新提交的任务，而不会无限增加任务或者线程数导致内存不足，可以非常有效地防止资源耗尽的情况发生。&lt;/p&gt;
&lt;h3 id=&quot;归纳&quot;&gt;归纳&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以从以下 5 个角度考虑，来选择合适的阻塞队列：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zwsfq0k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;功能&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 1 个需要考虑的就是功能层面，比如是否需要阻塞队列帮我们排序，如优先级排序、延迟执行等。如果有这个需要，我们就必须选择类似于 PriorityBlockingQueue 之类的有排序能力的阻塞队列。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m5noux9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;容量&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 2 个需要考虑的是容量，或者说是否有存储的要求，还是只需要“直接传递”。在考虑这一点的时候，我们知道前面介绍的那几种阻塞队列，有的是容量固定的，如 ArrayBlockingQueue；有的默认是容量无限的，如 LinkedBlockingQueue；而有的里面没有任何容量，如 SynchronousQueue；而对于 DelayQueue 而言，它的容量固定就是 Integer.MAX_VALUE。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以不同阻塞队列的容量是千差万别的，我们需要根据任务数量来推算出合适的容量，从而去选取合适的 BlockingQueue。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kfsvg73&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;能否扩容&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 3 个需要考虑的是能否扩容。因为有时我们并不能在初始的时候很好的准确估计队列的大小，因为业务可能有高峰期、低谷期。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一开始就固定一个容量，可能无法应对所有的情况，也是不合适的，有可能需要动态扩容。如果我们需要动态扩容的话，那么就不能选择 ArrayBlockingQueue ，因为它的容量在创建时就确定了，无法扩容。相反，PriorityBlockingQueue 即使在指定了初始容量之后，后续如果有需要，也可以自动扩容。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以我们可以根据是否需要扩容来选取合适的队列。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gstqrzs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内存结构&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 4 个需要考虑的点就是内存结构。在上一课时我们分析过 ArrayBlockingQueue 的源码，看到了它的内部结构是“数组”的形式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和它不同的是，LinkedBlockingQueue 的内部是用链表实现的，所以这里就需要我们考虑到，ArrayBlockingQueue 没有链表所需要的“节点”，空间利用率更高。所以如果我们对性能有要求可以从内存的结构角度去考虑这个问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8tkm7fo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;性能&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第 5 点就是从性能的角度去考虑。比如 LinkedBlockingQueue 由于拥有两把锁，它的操作粒度更细，在并发程度高的时候，相对于只有一把锁的 ArrayBlockingQueue 性能会更好。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，SynchronousQueue 性能往往优于其他实现，因为它只需要“直接传递”，而不需要存储的过程。如果我们的场景需要直接传递的话，可以优先考虑 SynchronousQueue。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[阻塞队列的常用方法]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/阻塞队列/阻塞队列的常用方法</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/阻塞队列/阻塞队列的常用方法</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[阻塞队列]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;阻塞队列的常用方法&quot;&gt;阻塞队列的常用方法&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在阻塞队列中有很多的方法，而且这些方法非常的相似，在使用的过程中很容易混淆其用法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本文将会列举，这些方法异同点，是你能够更好的掌握阻塞队列的用法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们会将阻塞队列的操作，划分为三组。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当队列满了无法添加元素，或者是队列空了无法移除元素时，不同组的方法对于这种特殊情况会有不同的处理方式：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-u6vplub&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抛出异常：add、remove、element&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uvc20al&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回结果但不抛出异常：offer、poll、peek&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7x3jegz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阻塞：put、take&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;第一组-add-remove-element&quot;&gt;第一组：add、remove、element&lt;/h2&gt;
&lt;h3 id=&quot;add-方法&quot;&gt;add 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;add 方法是往队列里添加一个元素，如果队列满了，就会抛出异常来提示队列已满。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void addTest() {

    BlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new  ArrayBlockingQueue&amp;lt;Integer&amp;gt;(2);

    blockingQueue.add(1);

    blockingQueue.add(1);

    blockingQueue.add(1);

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这段代码中，我们创建了一个容量为 2 的 BlockingQueue，并且尝试往里面放 3 个值，超过了容量上限，那么在添加第三个值的时候就会得到异常：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalStateException:Queue full
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;remove-方法&quot;&gt;remove 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;remove 方法的作用是删除元素，如果我们删除的队列是空的，由于里面什么都没有，所以也无法删除任何元素，那么 remove 方法就会抛出异常。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void removeTest() {

    ArrayBlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new     ArrayBlockingQueue&amp;lt;Integer&amp;gt;(2);

    blockingQueue.add(1);

    blockingQueue.add(1);

    blockingQueue.remove();

    blockingQueue.remove();

    blockingQueue.remove();

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这段代码中，我们往一个容量为 2 的 BlockingQueue 里放入 2 个元素，并且删除 3 个元素。在删除前面两个元素的时候会正常执行，因为里面依然有元素存在，但是在删除第三个元素时，由于队列里面已经空了，所以便会抛出异常：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Exception in thread &amp;quot;main&amp;quot; java.util.NoSuchElementException
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;element-方法&quot;&gt;element 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;element 方法是返回队列的头部节点，但是并不删除。和 remove 方法一样，如果我们用这个方法去操作一个空队列，想获取队列的头结点，可是由于队列是空的，我们什么都获取不到，会抛出和前面 remove 方法一样的异常：NoSuchElementException。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void elementTest() {

    ArrayBlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new     ArrayBlockingQueue&amp;lt;Integer&amp;gt;(2);

    blockingQueue.element();

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们新建了一个容量为 2 的 ArrayBlockingQueue，直接调用 element 方法，由于之前没有往里面添加元素，默认为空，那么会得到异常：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Exception in thread &amp;quot;main&amp;quot; java.util.NoSuchElementException
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;第二组-offer-poll-peek&quot;&gt;第二组：offer、poll、peek&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实际上我们通常并不想看到第一组方法抛出的异常，这时我们可以优先采用第二组方法。第二组方法相比于第一组而言要友好一些，当发现队列满了无法添加，或者队列为空无法删除的时候，第二组方法会给一个提示，而不是抛出一个异常。&lt;/p&gt;
&lt;h3 id=&quot;offer-方法&quot;&gt;offer 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;offer 方法用来插入一个元素，并用返回值来提示插入是否成功。如果添加成功会返回 true，而如果队列已经满了，此时继续调用 offer 方法的话，它不会抛出异常，只会返回一个错误提示：false。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void offerTest() {

    ArrayBlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new ArrayBlockingQueue&amp;lt;Integer&amp;gt;(2);

    System.out.println(blockingQueue.offer(1));

    System.out.println(blockingQueue.offer(1));

    System.out.println(blockingQueue.offer(1));

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们创建了一个容量为 2 的 ArrayBlockingQueue，并且调用了三次 offer方法尝试添加，每次都把返回值打印出来，运行结果如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;true

true

false
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看出，前面两次添加成功了，但是第三次添加的时候，已经超过了队列的最大容量，所以会返回 false，表明添加失败。&lt;/p&gt;
&lt;h3 id=&quot;poll-方法&quot;&gt;poll 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;poll 方法和第一组的 remove 方法是对应的，作用也是移除并返回队列的头节点。但是如果当队列里面是空的，没有任何东西可以移除的时候，便会返回 null 作为提示。正因如此，我们是不允许往队列中插入 null 的，否则我们没有办法区分返回的 null 是一个提示还是一个真正的元素。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void pollTest() {

    ArrayBlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new ArrayBlockingQueue&amp;lt;Integer&amp;gt;(3);

    blockingQueue.offer(1);

    blockingQueue.offer(2);

    blockingQueue.offer(3);

    System.out.println(blockingQueue.poll());

    System.out.println(blockingQueue.poll());

    System.out.println(blockingQueue.poll());

    System.out.println(blockingQueue.poll());

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个代码中我们创建了一个容量为 3 的 ArrayBlockingQueue，并且先往里面放入 3 个元素，然后四次调用 poll 方法，运行结果如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;1

2

3

null
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前面三次 poll 都运行成功了，并且返回了元素内容 1、2、3，是先进先出的顺序。第四次的 poll 方法返回 null，代表此时已经没有元素可以移除了。&lt;/p&gt;
&lt;h3 id=&quot;peek-方法&quot;&gt;peek 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;peek 方法和第一组的 element 方法是对应的，意思是返回队列的头元素但并不删除。如果队列里面是空的，它便会返回 null 作为提示。示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static void peekTest() {

    ArrayBlockingQueue&amp;lt;Integer&amp;gt; blockingQueue = new ArrayBlockingQueue&amp;lt;Integer&amp;gt;(2);

    System.out.println(blockingQueue.peek());

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行结果：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;null
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们新建了一个空的 ArrayBlockingQueue，然后直接调用 peek，返回结果 null，代表此时并没有东西可以取出。&lt;/p&gt;
&lt;h3 id=&quot;带超时时间的-offer-和-poll&quot;&gt;带超时时间的 offer 和 poll&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二组还有一些额外值得讲解的内容，offer 和 poll 都有带超时时间的重载方法。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;offer(E e, long timeout, TimeUnit unit)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它有三个参数，分别是元素、超时时长和时间单位。通常情况下，这个方法会插入成功并返回 true；如果队列满了导致插入不成功，在调用带超时时间重载方法的 offer 的时候，则会等待指定的超时时间，如果时间到了依然没有插入成功，就会返回 false。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;poll(long timeout, TimeUnit unit)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;带时间参数的 poll 方法和 offer 类似：如果能够移除，便会立刻返回这个节点的内容；如果队列是空的就会进行等待，等待时间正是我们指定的时间，直到超时时间到了，如果队列里依然没有元素可供移除，便会返回 null 作为提示。&lt;/p&gt;
&lt;h3 id=&quot;第三组-put-take&quot;&gt;第三组：put、take&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第三组是我们比较熟悉的、阻塞队列最大特色的 put 和 take 方法，我们复习一下 34 课时里对于 put 和 take 方法的讲解。&lt;/p&gt;
&lt;h3 id=&quot;put-方法&quot;&gt;put 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;put 方法的作用是插入元素。通常在队列没满的时候是正常的插入，但是如果队列已满就无法继续插入，这时它既不会立刻返回 false 也不会抛出异常，而是让插入的线程陷入阻塞状态，直到队列里有了空闲空间，此时队列就会让之前的线程解除阻塞状态，并把刚才那个元素添加进去。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl4lhcOAYPonAAB1UtAAltk655.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;take-方法&quot;&gt;take 方法&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;take 方法的作用是获取并移除队列的头结点。通常在队列里有数据的时候会正常取出数据并删除；但是如果执行 take 的时候队列里无数据，则阻塞，直到队列里有数据；一旦队列里有数据了，就会立刻解除阻塞状态，并且取到数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;http://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Java%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2078%20%E8%AE%B2-%E5%AE%8C/assets/Cgq2xl4lhdWAWOz8AABp-t8dt_8107.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;组别&lt;/th&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;含义&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;第一组&lt;/td&gt;
&lt;td&gt;add&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;添加一个元素&lt;/td&gt;
&lt;td&gt;如果队列满了，抛出IllegalStateException&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td&gt;remove&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;返回并删除队列的头元素&lt;/td&gt;
&lt;td&gt;如果队列空，删除失败，抛出NoSuchElementException&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td&gt;element&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;返回队列的头元素&lt;/td&gt;
&lt;td&gt;如果队列空，抛出NoSuchElementException&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;第二组&lt;/td&gt;
&lt;td&gt;offer&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;添加一个元素&lt;/td&gt;
&lt;td&gt;队列满了，添加失败，返回false。添加成功返回true。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td&gt;poll&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;返回并删除队列的头元素&lt;/td&gt;
&lt;td&gt;如果队列空，删除失败，返回null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td&gt;peek&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;返回队列的头元素。&lt;/td&gt;
&lt;td&gt;如果队列空，操作失败，返回null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;第三组&lt;/td&gt;
&lt;td&gt;put&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;添加一个元素&lt;/td&gt;
&lt;td&gt;如果队列满，则阻塞&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td&gt;take&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;返回并删除队列的头元素&lt;/td&gt;
&lt;td&gt;如果队列空，则阻塞&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content:encoded></item><item><title><![CDATA[原子类的作用概览]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/原子类/原子类的作用概览</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/原子类/原子类的作用概览</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[原子类]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;原子类的作用概览&quot;&gt;原子类的作用概览&lt;/h1&gt;
&lt;h2 id=&quot;什么是原子类-有什么作用&quot;&gt;什么是原子类，有什么作用&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在计算机中，原子性代表着&lt;strong&gt;一组操作要么全部成功，要么全部失败，不能只操作成功的其中一部分&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;老掉牙的案例: 银行转账操作。扣钱和加钱的操作必须得同时成功，加钱成功扣钱失败，亦或是加钱失败扣钱成功，都会导致账目的不一致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而&lt;strong&gt;java.util.concurrent.atomic&lt;/strong&gt;下的类，就是具有原子性的类，可以原子性的执行添加、递增、递减等操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就比如，众所周知的i++在多线程环境下不安全的问题，就可以采用getAndIncrement方法来处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;原子类&lt;/strong&gt;的作用和&lt;em&gt;锁&lt;/em&gt;都有类似之处，都是为了保证并发情况下的线程安全。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相比于锁,原子类的优势体现在两个方面:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-mfcrgjm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;粒度更细&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;原子变量可以把竞争缩小到变量级别，通常情况下，锁的粒度都要大于变量的粒度&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hcwj0ft&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;效率更高&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果和同步互斥锁相比，原子类底层使用了CAS操作，不会阻塞线程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，在高度竞争的情况下，谁更优则是看业务代码的水平了，非绝对。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;原子类概览&quot;&gt;原子类概览&lt;/h2&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;类型&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;具体类&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Atomic* 基本类型原子类&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;AtomicInteger、AtomicLong、AtomicBoolean&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Atomic*Array 数组类型原子类&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Atomic*Reference 引用类型原子类&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;AtomicReference、AtomicStampedReference、AtomicMarkableReference&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Atomic*FieldUpdater 升级类型原子类&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;AtomicIntegerfieldupdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Adder 累加器&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LongAdder、DoubleAdder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;Accumulator 积累器&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LongAccumulator、DoubleAccumulator&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;原子更新基本类型&quot;&gt;原子更新基本类型&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4eptk1w&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicBoolean: 原子更新布尔类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-w6qdcoc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicInteger: 原子更新整型。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7uohiij&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicLong: 原子更新长整型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们来介绍一下最为典型的 AtomicInteger。对于这个类型而言，它是对于 int 类型的封装，并且提供了原子性的访问和更新。也就是说，我们如果需要一个整型的变量，并且这个变量会被运用在并发场景之下，我们可以不用基本类型 int，也不使用包装类型 Integer，而是直接使用 AtomicInteger，这样一来就自动具备了原子能力，使用起来非常方便。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以 AtomicInteger 为例，常用 API：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public final int get()：获取当前的值
public final int getAndSet(int newValue)：获取当前的值，并设置新的值
public final int getAndIncrement()：获取当前的值，并自增
public final int getAndDecrement()：获取当前的值，并自减
public final int getAndAdd(int delta)：获取当前的值，并加上预期的值
void lazySet(int newValue): 最终会设置成newValue,使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相比 Integer 的优势，多线程中让变量自增：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private volatile int count = 0;
// 若要线程安全执行执行 count++，需要加锁
public synchronized void increment() {
    count++;
}
public int getCount() {
    return count;
}
    
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用 AtomicInteger 后：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private AtomicInteger count = new AtomicInteger();
public void increment() {
    count.incrementAndGet();
}
// 使用 AtomicInteger 后，不需要加锁，也可以实现线程安全
public int getCount() {
    return count.get();
}

  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;原子更新数组&quot;&gt;原子更新数组&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们来看第二大类 Atomic*Array 数组类型原子类，数组里的元素，都可以保证其原子性，比如 AtomicIntegerArray 相当于把 AtomicInteger 聚合起来，组合成一个数组。这样一来，我们如果想用一个每一个元素都具备原子性的数组的话， 就可以使用 Atomic*Array。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它一共分为 3 种，分别是：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-l2e3qdp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicIntegerArray：整形数组原子类；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4s48cbf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicLongArray：长整形数组原子类；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pu23ix6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicReferenceArray ：引用类型数组原子类。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) throws InterruptedException {
        AtomicIntegerArray array = new AtomicIntegerArray(new int[] { 0, 0 });
        System.out.println(array);
        System.out.println(array.getAndAdd(1, 2));
        System.out.println(array);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输出:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;[0, 0]
0
[0, 2]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;原子更新引用类型&quot;&gt;原子更新引用类型&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Atomic包提供了以下三个类：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-z6b0ruv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicReference: 原子更新引用类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zn85njs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicStampedReference: 原子更新引用类型, 内部使用Pair来存储元素值及其版本号。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lj8e3oy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicMarkableReferce: 原子更新带有标记位的引用类型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这三个类提供的方法都差不多，首先构造一个引用对象，然后把引用对象set进Atomic类，然后调用compareAndSet等一些方法去进行原子操作，原理都是基于Unsafe实现，但AtomicReferenceFieldUpdater略有不同，更新的字段必须用volatile修饰。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import java.util.concurrent.atomic.AtomicReference;
public class AtomicReferenceTest {
    public static void main(String[] args){
        // 创建两个Person对象，它们的id分别是101和102。
        Person p1 = new Person(101);
        Person p2 = new Person(102);
        // 新建AtomicReference对象，初始化它的值为p1对象
        AtomicReference ar = new AtomicReference(p1);
        // 通过CAS设置ar。如果ar的值为p1的话，则将其设置为p2。
        ar.compareAndSet(p1, p2);
        Person p3 = (Person)ar.get();
        System.out.println(&amp;quot;p3 is &amp;quot;+p3);
        System.out.println(&amp;quot;p3.equals(p1)=&amp;quot;+p3.equals(p1));
    }
}

class Person {
    volatile long id;
    public Person(long id) {
        this.id = id;
    }
    public String toString() {
        return &amp;quot;id:&amp;quot;+id;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;结果输出：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;p3 is id:102
p3.equals(p1)=false
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;原子更新字段&quot;&gt;原子更新字段&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Atomic包提供了四个类进行原子字段更新：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zw1n6rl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicIntegerFieldUpdater: 原子更新整型的字段的更新器。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y0j2mua&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicLongFieldUpdater: 原子更新长整型字段的更新器。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-z0ds8fv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicStampedFieldUpdater: 原子更新带有版本号的引用类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3msojm7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AtomicReferenceFieldUpdater: 原子更新包装类型字段的更新器。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这四个类的使用方式都差不多，是基于反射的原子更新字段的值。要想原子地更新字段类需要两步:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-l57qj2o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-iczpivf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二步，更新类的字段必须使用public volatile修饰。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;举个例子：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class TestAtomicIntegerFieldUpdater {
    public static void main(String[] args){
        TestAtomicIntegerFieldUpdater tIA = new TestAtomicIntegerFieldUpdater();
        tIA.doIt();
    }
    public AtomicIntegerFieldUpdater&amp;lt;DataDemo&amp;gt; updater(String name){
        return AtomicIntegerFieldUpdater.newUpdater(DataDemo.class,name);
    }

    public void doIt(){
        DataDemo data = new DataDemo();
        System.out.println(&amp;quot;publicVar = &amp;quot;+updater(&amp;quot;publicVar&amp;quot;).getAndAdd(data, 2));
        /*
            * 由于在DataDemo类中属性value2/value3,在TestAtomicIntegerFieldUpdater中不能访问
            * */
        //System.out.println(&amp;quot;protectedVar = &amp;quot;+updater(&amp;quot;protectedVar&amp;quot;).getAndAdd(data,2));
        //System.out.println(&amp;quot;privateVar = &amp;quot;+updater(&amp;quot;privateVar&amp;quot;).getAndAdd(data,2));

        //System.out.println(&amp;quot;staticVar = &amp;quot;+updater(&amp;quot;staticVar&amp;quot;).getAndIncrement(data));//报java.lang.IllegalArgumentException
        /*
            * 下面报异常：must be integer
            * */
        //System.out.println(&amp;quot;integerVar = &amp;quot;+updater(&amp;quot;integerVar&amp;quot;).getAndIncrement(data));
        //System.out.println(&amp;quot;longVar = &amp;quot;+updater(&amp;quot;longVar&amp;quot;).getAndIncrement(data));
    }

}

class DataDemo{
    public volatile int publicVar=3;
    protected volatile int protectedVar=4;
    private volatile  int privateVar=5;

    public volatile static int staticVar = 10;
    //public  final int finalVar = 11;

    public volatile Integer integerVar = 19;
    public volatile Long longVar = 18L;

}    
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;再说下对于AtomicIntegerFieldUpdater 的使用稍微有一些限制和约束，约束如下：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-85he9ap&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;字段必须是volatile类型的，在线程之间共享变量时保证立即可见.eg:volatile int value = 3&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lmljf7q&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;字段的描述类型(修饰符public/protected/default/private)是与调用者与操作对象字段的关系一致。也就是说调用者能够直接操作对象字段，那么就可以反射进行原子操作。但是对于父类的字段，子类是不能直接操作的，尽管子类可以访问父类的字段。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-39jn6up&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只能是实例变量，不能是类变量，也就是说不能加static关键字。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kkob7yd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只能是可修改变量，不能使final变量，因为final的语义就是不可修改。实际上final的语义和volatile是有冲突的，这两个关键字不能同时存在。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-p2rgq1l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于AtomicIntegerFieldUpdater和AtomicLongFieldUpdater只能修改int/long类型的字段，不能修改其包装类型(Integer/Long)。如果要修改包装类型就需要使用AtomicReferenceFieldUpdater。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Adder-加法器和Accumulator积累器&quot;&gt;Adder 加法器和Accumulator积累器&lt;/h3&gt;
&lt;h4 id=&quot;Adder介绍&quot;&gt;Adder介绍&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们以LongAdder为例。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LongAdder相比于AtomicLong效率更高，因为对于AtomicLong而言，LongAdder引入了分段锁，当竞争不激烈的时候所有的线程都是通过CAS对同一个BASE进行变量修改，当竞争激烈的时候,LongAdder会把不同的线程对应到不同的Cell上进行修改，降低了冲突的概率，从而提高了并发性。&lt;/p&gt;
&lt;h4 id=&quot;Accumulator介绍&quot;&gt;Accumulator介绍&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Accumulator 和 Adder 非常相似，&lt;strong&gt;实际上 Accumulator 就是一个更通用版本的 Adder&lt;/strong&gt;，比如 LongAccumulator 是 LongAdder 的功能增强版，因为 LongAdder 的 API 只有对数值的加减，而 LongAccumulator 提供了自定义的函数操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) throws InterruptedException {
        LongAccumulator accumulator = new LongAccumulator((x, y) -&amp;gt; x * y, 1);
        ExecutorService executor = Executors.newFixedThreadPool(8);
        IntStream.range(1, 10).forEach(i -&amp;gt; executor.submit(() -&amp;gt; accumulator.accumulate(i)));
        Thread.sleep(2000);
        System.out.println(accumulator.getThenReset());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这段代码中：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-fk03eej&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先新建了一个 LongAccumulator，同时给它传入了两个参数；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-72vh745&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后又新建了一个 8 线程的线程池，并且利用整形流也就是 IntStream 往线程池中提交了从 1 ~ 9 这 9 个任务；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-re7zwg7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之后等待了两秒钟，这两秒钟的作用是等待线程池的任务执行完毕；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lak84b4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后把 accumulator 的值打印出来。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这段代码的运行结果是 120960，代表 1*2*3*...*8*9=120960 的结果，这个结果怎么理解呢？我们先重点看看新建的 LongAccumulator 的这一行语句：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;LongAccumulator accumulator = new LongAccumulator((x, y) -&amp;gt; x * y, 1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这个语句中，我们传入了两个参数：LongAccumulator 的构造函数的第一个参数是二元表达式；第二个参数是 x 的初始值，传入的是 1。在二元表达式中，x 是上一次计算的结果（除了第一次的时候需要传入），y 是本次新传入的值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里需要指出的是，这里的乘的顺序是不固定的，并不是说会按照顺序从 1 开始逐步往上累乘，它也有可能会变，比如说先乘 5、再乘3、再乘 6。但总之，由于乘法有交换律，所以最终加出来的结果会保证是 120960。这就是这个类的一个基本的作用和用法。&lt;/p&gt;
&lt;h4 id=&quot;拓展功能&quot;&gt;拓展功能&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们继续看一下它的功能强大之处。举几个例子，刚才我们给出的表达式是 x * y，其实同样也可以传入 x + y，或者写一个 Math.min(x, y)，相当于求 x 和 y 的最小值。同理，也可以去求 Math.max(x, y)，相当于求一个最大值。根据业务的需求来选择就可以了。代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;LongAccumulator counter = new LongAccumulator((x, y) -&amp;gt; x + y, 0);

LongAccumulator result = new LongAccumulator((x, y) -&amp;gt; x * y, 0);

LongAccumulator min = new LongAccumulator((x, y) -&amp;gt; Math.min(x, y), 0);

LongAccumulator max = new LongAccumulator((x, y) -&amp;gt; Math.max(x, y), 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这时你可能会有一个疑问：在这里为什么不用 for 循环呢？比如说我们之前的例子，从 0 加到 9，我们直接写一个 for 循环不就可以了吗？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;确实，用 for 循环也能满足需求，但是用 for 循环的话，它执行的时候是串行，它一定是按照 0+1+2+3+...+8+9 这样的顺序相加的，但是 LongAccumulator 的一大优势就是可以利用线程池来为它工作。&lt;strong&gt;一旦使用了线程池，那么多个线程之间是可以并行计算的，效率要比之前的串行高得多&lt;/strong&gt;。这也是为什么刚才说它加的顺序是不固定的，因为我们并不能保证各个线程之间的执行顺序，所能保证的就是最终的结果是确定的。&lt;/p&gt;
&lt;h4 id=&quot;适用场景&quot;&gt;适用场景&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来我们说一下 LongAccumulator 的适用场景。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一点需要满足的条件，就是需要大量的计算，并且当需要并行计算的时候，我们可以考虑使用 LongAccumulator。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当计算量不大，或者串行计算就可以满足需求的时候，可以使用 for 循环；如果计算量大，需要提高计算的效率时，我们则可以利用线程池，再加上 LongAccumulator 来配合的话，就可以达到并行计算的效果，效率非常高。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二点需要满足的要求，就是计算的执行顺序并不关键，也就是说它不要求各个计算之间的执行顺序，也就是说线程 1 可能在线程 5 之后执行，也可能在线程 5 之前执行，但是执行的先后并不影响最终的结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一些非常典型的满足这个条件的计算，就是类似于加法或者乘法，因为它们是有交换律的。同样，求最大值和最小值对于顺序也是没有要求的，因为最终只会得出所有数字中的最大值或者最小值，无论先提交哪个或后提交哪个，都不会影响到最终的结果。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[原子类的性能分析]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/原子类/原子类的性能分析</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/原子类/原子类的性能分析</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[原子类]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;原子类的性能分析&quot;&gt;原子类的性能分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在并发情况下，如果我们需要实现一个计数器，则可以利用AtomicInteger和AtomicLong来进行实现，&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样可以避免加锁和复杂的代码逻辑，并且还能有较好的性能，而我们仅仅需要调用已经封装好的方法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是,&lt;strong&gt;如果业务场景的并发量十分的大，会有较大的性能问题&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们使用AtomicLong来举例&lt;/p&gt;
&lt;h2 id=&quot;AtomicLong的问题&quot;&gt;AtomicLong的问题&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;常见的用法是调用&lt;strong&gt;incrementAndGet()&lt;/strong&gt;来实现i++的操作，我们来看下这个方法是如何实现的。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class AtomicLong extends Number implements java.io.Serializable {
...
private static final long VALUE  = U.objectFieldOffset(AtomicLong.class, &amp;quot;value&amp;quot;);
private volatile long value;
public final long incrementAndGet() {
        return U.getAndAddLong(this, VALUE, 1L) + 1L;
 }
 ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;他会调用Unsafe方法中的getAndAddLong来实现，而Unsafe中的方法都是采用CAS的形式来实现线程安全的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在大量冲突的时候，大量线程处在自旋状态，导致CPU飙升。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且，对于AtomicLong内部的value属性而言，是被volatile修饰的，这样一来每一次数值变化都需要进行flush到共享内存和reflush到本地内存。由于竞争激烈，这种flush和reflush也会浪费大量的时间。&lt;/p&gt;
&lt;h2 id=&quot;升级版LongAdder&quot;&gt;升级版LongAdder&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为 LongAdder 引入了分段累加的概念，内部一共有两个参数参与计数：第一个叫作 base，它是一个变量，第二个是 Cell[] ，是一个数组。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中的 base 是用在竞争不激烈的情况下的，可以直接把累加结果改到 base 变量上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么，当竞争激烈的时候，就要用到我们的 Cell[] 数组了。一旦竞争激烈，各个线程会分散累加到自己所对应的那个 Cell[] 数组的某一个对象中，而不会大家共用同一个。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样一来，LongAdder 会把不同线程对应到不同的 Cell 上进行修改，降低了冲突的概率，这是一种分段的理念，提高了并发性，这就和 Java 7 的 ConcurrentHashMap 的 16 个 Segment 的思想类似。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;竞争激烈的时候，LongAdder 会通过计算出每个线程的 hash 值来给线程分配到不同的 Cell 上去，每个 Cell 相当于是一个独立的计数器，这样一来就不会和其他的计数器干扰，Cell 之间并不存在竞争关系，所以在自加的过程中，就大大减少了刚才的 flush 和 refresh，以及降低了冲突的概率，这就是为什么 LongAdder 的吞吐量比 AtomicLong 大的原因，本质是空间换时间，因为它有多个计数器同时在工作，所以占用的内存也要相对更大一些。&lt;/p&gt;
&lt;h2 id=&quot;如何选择&quot;&gt;如何选择&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在低竞争的情况下，AtomicLong 和 LongAdder 这两个类具有相似的特征，吞吐量也是相似的，因为竞争不高。但是在竞争激烈的情况下，LongAdder 的预期吞吐量要高得多，经过试验，LongAdder 的吞吐量大约是 AtomicLong 的十倍，不过凡事总要付出代价，LongAdder 在保证高效的同时，也需要消耗更多的空间。&lt;/p&gt;
&lt;h3 id=&quot;AtomicLong-可否被-LongAdder-替代-&quot;&gt;AtomicLong 可否被 LongAdder 替代？&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那么我们就要考虑了，有了更高效的 LongAdder，那 AtomicLong 可否不使用了呢？是否凡是用到 AtomicLong 的地方，都可以用 LongAdder 替换掉呢？答案是不是的，这需要区分场景。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LongAdder 只提供了 add、increment 等简单的方法，适合的是统计求和计数的场景，场景比较单一，而 AtomicLong 还具有 compareAndSet 等高级方法，可以应对除了加减之外的更复杂的需要 CAS 的场景。&lt;/p&gt;
&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们的场景仅仅是需要用到加和减操作的话，那么可以直接使用更高效的 LongAdder，但如果我们需要利用 CAS 比如 compareAndSet 等操作的话，就需要使用 AtomicLong 来完成。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[waitnotifynotifyAll]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/waitnotifynotifyAll</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/waitnotifynotifyAll</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;waitnotifynotifyAll&quot;&gt;waitnotifynotifyAll&lt;/h1&gt;
&lt;h2 id=&quot;为什么wait必须在synchronized保护的代码中使用&quot;&gt;为什么wait必须在synchronized保护的代码中使用&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在使用wait方法时，必须在synchronized代码块中才能够正确的执行，否则会抛出&lt;code&gt;IllegalMonitorStateException: current thread is not owner&lt;/code&gt;异常.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;wait&lt;/code&gt; 方法的源码注释如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# “wait method should always be used in a loop:
 synchronized (obj) {
     while (condition does not hold)
         obj.wait();
     ... // Perform action appropriate to condition
}

# This method should only be called by a thread that is the owner of this object&apos;s monitor.”
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;翻译下，即： &lt;code&gt;wait&lt;/code&gt; 方法应在 &lt;code&gt;synchronized&lt;/code&gt; 保护的 &lt;code&gt;while&lt;/code&gt; 代码块中使用，并始终判断执行条件是否满足，如果满足就往下继续执行，如果不满足就执行 &lt;code&gt;wait&lt;/code&gt; 方法。在执行 &lt;code&gt;wait&lt;/code&gt; 方法之前，必须先持有对象的 &lt;code&gt;monitor&lt;/code&gt; 锁，即 &lt;code&gt;synchronized&lt;/code&gt; 锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;为什么这样设计？这样设计又有什么好处？&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反向思考，如果不要求 &lt;code&gt;wait&lt;/code&gt; 方法放在 &lt;code&gt;synchronized&lt;/code&gt; 保护的同步代码中使用，而是可以随意调用，那么就有可能写出这样的代码，如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;class BlockingQueue {
    Queue&amp;lt;String&amp;gt; buffer = new LinkedList&amp;lt;String&amp;gt;();
    public void offer(String data) {
        buffer.add(data);
        // Since someone may be waiting in take
        notify();  
    }
    
    public String take() throws InterruptedException {
        while (buffer.isEmpty()) {

            wait();
        }
        return buffer.remove();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在代码中有两个方法：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-e8tesh5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;offer&lt;/code&gt; 方法负责往 &lt;code&gt;buffer&lt;/code&gt; 中添加数据，添加完之后执行 &lt;code&gt;notify&lt;/code&gt; 方法来唤醒之前等待的线程&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0wb00nu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;take&lt;/code&gt; 方法负责检查整个 &lt;code&gt;buffer&lt;/code&gt; 是否为空，如果为空就进入等待，如果不为空就取出一个数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是这段代码并没有受 &lt;code&gt;synchronized&lt;/code&gt; 保护，于是便有可能发生以下场景：&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3wic866&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先，消费者线程调用 &lt;code&gt;take&lt;/code&gt; 方法并判断 &lt;code&gt;buffer.isEmpty&lt;/code&gt; 方法是否返回 &lt;code&gt;true&lt;/code&gt;，若为 &lt;code&gt;true&lt;/code&gt; 代表 &lt;code&gt;buffer&lt;/code&gt; 是空的，则线程希望进入等待，但是在线程调用 &lt;code&gt;wait&lt;/code&gt; 方法之前，就被调度器暂停了，所以此时还没来得及执行 &lt;code&gt;wait&lt;/code&gt; 方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m5kjubf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时生产者开始运行，执行了整个 &lt;code&gt;offer&lt;/code&gt; 方法，它往 &lt;code&gt;buffer&lt;/code&gt; 中添加了数据，并执行了 &lt;code&gt;notify&lt;/code&gt; 方法，但 &lt;code&gt;notify&lt;/code&gt; 并没有任何效果，因为消费者线程的 &lt;code&gt;wait&lt;/code&gt; 方法没来得及执行，所以没有线程在等待被唤醒。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-bei6bdd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此时，刚才被调度器暂停的消费者线程回来继续执行 &lt;code&gt;wait&lt;/code&gt; 方法并进入了等待。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;把代码改写成源码注释所要求的被 &lt;code&gt;synchronized&lt;/code&gt; 保护的同步代码块的形式，代码如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void offer(String data) {
   synchronized (this) {
      buffer.add(data);
      notify();
  }
}

public String take() throws InterruptedException {
   synchronized (this) {
    while (buffer.isEmpty()) {
         wait();
       }
     return buffer.remove();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就可以确保 &lt;code&gt;notify&lt;/code&gt; 方法永远不会在 &lt;code&gt;buffer.isEmpty&lt;/code&gt; 和 &lt;code&gt;wait&lt;/code&gt; 方法之间被调用，提升了程序的安全性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;另外，&lt;code&gt;wait&lt;/code&gt; 方法会释放 &lt;code&gt;monitor&lt;/code&gt; 锁，这也要求必须首先进入到 &lt;code&gt;synchronized&lt;/code&gt; 内持有这把锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里还存在一个“虚假唤醒”（&lt;code&gt;spurious wakeup&lt;/code&gt;）的问题，线程可能在既没有被 &lt;code&gt;notify/notifyAll&lt;/code&gt;，也没有被中断或者超时的情况下被唤醒，这种唤醒是不希望看到的。虽然在实际生产中，虚假唤醒发生的概率很小，但是程序依然需要保证在发生虚假唤醒的时候的正确性，所以就需要采用 &lt;code&gt;while&lt;/code&gt; 循环的结构。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;while (condition does not hold)
    obj.wait();
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样即便被虚假唤醒了，也会再次检查 &lt;code&gt;while&lt;/code&gt; 里面的条件，如果不满足条件，就会继续 &lt;code&gt;wait&lt;/code&gt;，也就消除了虚假唤醒的风险。&lt;/p&gt;
&lt;h2 id=&quot;为什么-wait-notify-notifyAll-被定义在-Object-类中-而-sleep-定义在-Thread-类中-&quot;&gt;为什么 wait/notify/notifyAll 被定义在 Object 类中，而 sleep 定义在 Thread 类中？&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ksnkmb2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为Java中每个对象都有一把叫做monitor的锁，由于每个对象都能够上锁，所以就要求在对象头中保存锁的信息，这个锁是对象级别的而不是线程级别的。wait/notify/notifyAll都属于锁级别的操作，他们的锁属于对象，所以把他们定义在Object类中最为合适，因为Object类是所有对象的父类。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nkur2e9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设，我们把wait/notify/notifyAll给定义在Thread中，这个时候需要一个线程需要持有多个对象的锁，以便于满足业务需求，也就是把wait定义在Thread中的时候，我们无法灵活的控制一个线程持有多把锁的逻辑，一个wait就把整个线程锁住了。既然是让线程去等待某个对象的锁，就 应该是操作对象来实现，而不是操作线程&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;wait-notify-和-sleep-方法的异同-&quot;&gt;wait/notify 和 sleep 方法的异同？&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相同点：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-486csdc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;都能够让线程进入阻塞状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-d38zmk9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;都能够响应interrupt异常，在等待的过程中能够响应中断信号，并报出InterruptedException异常&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不同点:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-v63tiwx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;wait/notify是Object的方法。sleep是Thread的方法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oqx17l5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在Synchronized包裹的代码中，调用sleep不会释放monitor锁，而调用wait会释放monitor锁&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zepssc2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用sleep需要设置时间，时间到了之后会进入runable状态继续执行，而wait调用之后，如果没有notify去唤醒则一直会阻塞下去&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8tc4igj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;wait必须在synchronized包裹的代码中使用，而sleep则不需要&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[Thread的实现方式]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/Thread的实现方式</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/Thread的实现方式</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Thread的实现方式&quot;&gt;Thread的实现方式&lt;/h1&gt;
&lt;h2 id=&quot;实现Runable接口&quot;&gt;实现Runable接口&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-fpd9zxn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现Runable接口&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-76nf8v1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现run方法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-e88vf2x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后通过实现了Runable的实例传递到Thread中，就能实现线程&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public RunableThread implements Runable {
  @Override
  public void run(){
    System.out.println(&amp;quot;实现Runable接口来实现线程&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;直接继承Thread&quot;&gt;直接继承Thread&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public ExtentsThread extend Threaad {
	 @Override
  public void run(){
    System.out.println(&amp;quot;用Thread类实现线程&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;用线程池创建线程&quot;&gt;用线程池创建线程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会给我们线程创建设置一些默认的值，比如名字，是不是守护线程，以及优先级&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private static class DefaultThreadFactory implements ThreadFactory {
    ....
    ....
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null) ? s.getThreadGroup() :
                              Thread.currentThread().getThreadGroup();
        namePrefix = &amp;quot;pool-&amp;quot; +
                      poolNumber.getAndIncrement() +
                     &amp;quot;-thread-&amp;quot;;
    }

    public Thread newThread(Runnable r) {
        Thread t = new Thread(group, r,
                              namePrefix + threadNumber.getAndIncrement(),
                              0);
        if (t.isDaemon())
            t.setDaemon(false);
        if (t.getPriority() != Thread.NORM_PRIORITY)
            t.setPriority(Thread.NORM_PRIORITY);
        return t;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;使用Callable方式创建&quot;&gt;使用Callable方式创建&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有返回值的callable也是新建线程的一种方式。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;		public class CallableTask implements Callable&amp;lt;Integer&amp;gt; {
      	@Override
       	public Integer call() throw Exception {
          	return new Random().nextInt();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;使用Timer&quot;&gt;使用Timer&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;TimerTask实现了Runable的接口，Timer中有个TimerThread继承了Thread，本质他还是Thread&lt;/p&gt;
&lt;h2 id=&quot;本质-&quot;&gt;本质?&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Thread的实现的方式从本质上来看只有一种。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看下Thread的run是如何实现的。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;    .......
		private Runnable target;		
    @Override
    public void run() {
        if (target != null) {
            target.run();
        }
    }
		.....
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-tmck0ql&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;方式1: 最终调用target.run() 方法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-v42643x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;方式2: 整个run方法被重写&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，创建线程只有一种方法：&lt;code&gt;构造Thread类&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;实现方式有两种:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-stxk825&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用Runable的方式，最后调用target.run方法进行启动&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nijiv3c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接继承Thread类，重写run方法&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[ForkJoin框架]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/ForkJoin框架</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/ForkJoin框架</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ForkJoin框架&quot;&gt;ForkJoin框架&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fork/Join框架，是JDK7中加入的 一个线程类。Fork/Join是基于分治算法的并行实现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;它是一个可以让使用者简单方便的使用并行，来对数据进行处理，极大限度的利用多处理器来提高应用的性能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大概流程如下:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将大任务拆分成一个个子任务，然后join在一起，最后输出结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/forkjoin%E6%B5%81%E7%A8%8B.png&quot; alt=&quot;forkjoin流程&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;伪代码就是这样:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Result solve(Problem problem) {
  if (problem is small) 
    directly solve problem
  else {
    split problem into independent parts
    fork new subtasks to solve each part

    join all subtasks
    compose result from subresults
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;案例-&quot;&gt;案例?&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们拿累加数字来举例。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) throws InterruptedException, ExecutionException {
        long start = 1;
        long end = 1000000000;
        sum(start, end);
 }
public static void sum(long start, long end) {
        int result = 0;
        long startTime = System.currentTimeMillis();
        for (long i = start; i &amp;lt;= end; i++) {
            result += i;
        }
        long endTime = System.currentTimeMillis();
        System.out.println(&amp;quot;sum: &amp;quot; + result + &amp;quot; in &amp;quot; + (endTime - startTime) + &amp;quot; ms.&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以将累加数字改写成下面的这种写法,使用forkJoin线程池进行运算。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) throws InterruptedException, ExecutionException {
        long startTime = System.currentTimeMillis();
        ForkJoinPool pool = new ForkJoinPool();
        ForkJoinTask&amp;lt;Integer&amp;gt; task = new SumTask(start, end);
        pool.submit(task);
        long result = task.get();
        long endTime = System.currentTimeMillis();
        System.out.println(&amp;quot;Fork/join sum: &amp;quot; + result + &amp;quot; in &amp;quot; + (endTime - startTime) + &amp;quot; ms.&amp;quot;);
    }
static final class SumTask extends RecursiveTask&amp;lt;Integer&amp;gt; {
        private static final long serialVersionUID = 1L;

        final long start; //开始计算的数
        final long end; //最后计算的数

        SumTask(long start, long end) {
            this.start = start;
            this.end = end;
        }

        @Override
        protected Integer compute() {
            //如果计算量小于1000，那么分配一个线程执行if中的代码块，并返回执行结果
            if (end - start &amp;lt; 10000) {
                int sum = 0;
                for (long i = start; i &amp;lt;= end; i++) {
                    sum += i;
                }
                return sum;
            }
            //如果计算量大于1000，那么拆分为两个任务
            SumTask task1 = new SumTask(start, (start + end) / 2);
            SumTask task2 = new SumTask((start + end) / 2 + 1, end);
            //执行任务
            task1.fork();
            task2.fork();
            //获取任务执行的结果
            return task1.join() + task2.join();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行结果:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;sum: -243309312 in 624 ms.
Fork/join sum: -243309312 in 168 ms.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们来看看，forkJoin是如何去实现的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fork/Join框架主要包含三个模块:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-cvm7pmq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务执行对象基类&lt;code&gt;ForkJoinTask&lt;/code&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-wccvwlm&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抽象类RecursiveTask: 有返回值任务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2r9e0rw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抽象类RecursiveAction: 无返回值任务&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hhp9gls&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;抽象类CountedCompleter: 无返回值任务，完成任务后可以触发回调&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9tu7j5l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行Fork/Join的线程对象&lt;code&gt;ForkJoinWorkerThread&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y5trfke&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池&lt;code&gt;ForkJoinPool&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于ForkJoinPool只接收ForkJoinTask任务，因此在使用时，我们只需要关注如何实现ForkJoinTask任务。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JDK基于ForkJoinTask提供了&lt;code&gt;RecursiveTask&lt;/code&gt;、&lt;code&gt;RecursiveAction&lt;/code&gt;、&lt;code&gt;CountedCompleter&lt;/code&gt;三种类来满足业务需求，在使用时无需直接继承ForkJoinTask。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;核心思想除了上文说的分治，还有一个就是&lt;code&gt;工作窃取&lt;/code&gt;算法&lt;/p&gt;
&lt;h3 id=&quot;work-stealing-工作窃取&quot;&gt;work-stealing 工作窃取&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;工作窃取说白了就是，比较闲的线程到比较忙的线程那边把任务给拿过来执行，分摊压力。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;两个线程访问同一个队列的任务，会存在竞争的问题，为了减少竞争任务队列会被设计成双端队列，&lt;code&gt;被窃取任务的线程&lt;/code&gt;永远从双端队列的&lt;code&gt;头部&lt;/code&gt;拿任务执行，&lt;code&gt;窃取任务的线程&lt;/code&gt;则永远从双端队列的&lt;code&gt;尾部&lt;/code&gt;拿任务执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;queue2在执行完之后，会将queue0的task，给拉入到自己的线程下进行运行&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/forkjoin-%E5%B7%A5%E4%BD%9C%E7%AA%83%E5%8F%96.png&quot; alt=&quot;forkjoin-工作窃取&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-9xrbklx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ForkJoinPool 的每个工作线程都维护着一个工作队列（WorkQueue），这是一个&lt;strong&gt;双端队列（Deque）&lt;/strong&gt;，里面存放的对象是任务（&lt;strong&gt;ForkJoinTask&lt;/strong&gt;）。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wd94q5a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个工作线程在运行中产生新的任务（通常是因为调用了 fork()）时，会放入工作队列的队尾，并且工作线程在处理自己的工作队列时，使用的是 &lt;strong&gt;LIFO&lt;/strong&gt; 方式，也就是说每次从队尾取出任务来执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-frinl4a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个工作线程在处理自己的工作队列同时，会尝试窃取一个任务（或是来自于刚刚提交到 pool 的任务，或是来自于其他工作线程的工作队列），窃取的任务位于其他线程的工作队列的队首，也就是说工作线程在窃取其他工作线程的任务时，使用的是 FIFO 方式。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0aw0ckw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在遇到 join() 时，如果需要 join 的任务尚未完成，则会先处理其他任务，并等待其完成。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y0ktsbl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在既没有自己的任务，也没有可以窃取的任务时，进入休眠。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;执行流程&quot;&gt;执行流程&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/forkjoin%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png&quot; alt=&quot;forkjoin工作流程&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上图画的就是forkjoin框架大体的运行过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果去看源码的话，肯定是一脸懵逼，里面涉及到大量的位运算。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要从整体去把握这个框架。&lt;/p&gt;
&lt;h3 id=&quot;步骤分解&quot;&gt;步骤分解&lt;/h3&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-nxb69jh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;外部任务提交，调用ForkJoinPool的invoke、execute、submit&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-mfev8x3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;子任务的提交，调用fork方法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-670ua88&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行任务，ForkJoinWorkerThread.run -&amp;gt; ForkJoinTask.doExec&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4f4oywq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取任务执行结果，ForkJoinTask.join 和 ForkJoinTask.invoke&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;外部任务提交&quot;&gt;外部任务提交&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个步骤主要是为了创建工作线程，没有工作线程则会创建一个，并且把任务给放入这个工作线程中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最终会走到externalPush的逻辑，执行流程很简单: 首先找到一个随机偶数槽位的 workQueue，然后把任务放入这个 workQueue 的任务数组中，并更新top位。如果队列的剩余任务数小于1，则尝试创建或激活一个工作线程来运行任务(防止在externalSubmit初始化时发生异常导致工作线程创建失败)。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后对调用到createWorker，在这个流程中会创建需要执行的线程，并且会进入start状态，等到CPU分配到时间片的时候就会执行了&lt;/p&gt;
&lt;h3 id=&quot;子任务提交&quot;&gt;子任务提交&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和外部任务提交类似，也是向这个工作线程中添加任务&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;子任务的提交相对比较简单，由任务的fork()方法完成。通过上面的流程图可以看到任务被分割(fork)之后调用了ForkJoinPool.WorkQueue.push()方法直接把任务放到队列中等待被执行。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public final ForkJoinTask&amp;lt;V&amp;gt; fork() {
    Thread t;
    if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
        ((ForkJoinWorkerThread)t).workQueue.push(this);
    else
        ForkJoinPool.common.externalPush(this);
    return this;
}

    
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;说明: 如果当前线程是 Worker 线程，说明当前任务是fork分割的子任务，通过ForkJoinPool.workQueue.push()方法直接把任务放到自己的等待队列中；否则调用ForkJoinPool.externalPush()提交到一个随机的等待队列中(外部任务)。&lt;/p&gt;
&lt;h3 id=&quot;执行任务&quot;&gt;执行任务&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在ForkJoinPool .createWorker()方法中创建工作线程后，会启动工作线程，系统为工作线程分配到CPU执行时间片之后会执行 ForkJoinWorkerThread 的run()方法正式开始执行任务。&lt;/p&gt;
&lt;h3 id=&quot;获取任务执行结果&quot;&gt;获取任务执行结果&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个比较复杂。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;是因为加入的任务，不知道处于哪个队列的哪个位置，如果是top位置直接等待即可，如果不是则需要等待执行到这个任务才能获取结果&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/java-thread-x-forkjoin-6.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[为什么多线程会带来性能问题]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程池/为什么多线程会带来性能问题</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程池/为什么多线程会带来性能问题</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程池]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;为什么多线程会带来性能问题&quot;&gt;为什么多线程会带来性能问题&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;多线程的性能问题，分为两类，一类是线程本身的调度，另一类是线程之间的协作开销。&lt;/p&gt;
&lt;h2 id=&quot;线程调度开销&quot;&gt;线程调度开销&lt;/h2&gt;
&lt;h3 id=&quot;上下文切换&quot;&gt;上下文切换&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在实际开发中，线程数往往是大于 CPU 核心数的，比如 CPU 核心数可能是 8 核、16 核，等等，但线程数可能达到成百上千个。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种情况下，操作系统就会按照一定的调度算法，给每个线程分配时间片，让每个线程都有机会得到运行。而在进行调度时就会引起上下文切换，上下文切换会挂起当前正在执行的线程并保存当前的状态，然后寻找下一处即将恢复执行的代码，唤醒下一个线程，以此类推，反复执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但上下文切换带来的开销是比较大的，假设我们的任务内容非常短，比如只进行简单的计算，那么就有可能发生我们上下文切换带来的性能开销比执行线程本身内容带来的开销还要大的情况。&lt;/p&gt;
&lt;h3 id=&quot;缓存失效&quot;&gt;缓存失效&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于程序有很大概率会再次访问刚才访问过的数据，所以为了加速整个程序的运行，会使用缓存，这样我们在使用相同数据时就可以很快地获取数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可一旦进行了线程调度，切换到其他线程，CPU就会去执行不同的代码，原有的缓存就很可能失效了，需要重新缓存新的数据，这也会造成一定的开销。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以线程调度器为了避免频繁地发生上下文切换，通常会给被调度到的线程设置最小的执行时间，也就是只有执行完这段时间之后，才可能进行下一次的调度，由此减少上下文切换的次数。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果程序频繁地竞争锁，或者由于 IO 读写等原因导致频繁阻塞，那么这个程序就可能需要更多的上下文切换，这也就导致了更大的开销，我们应该尽量避免这种情况的发生。&lt;/p&gt;
&lt;h2 id=&quot;协作开销&quot;&gt;协作开销&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为线程之间如果有共享数据，为了避免数据错乱，为了保证线程安全，就有可能禁止编译器和 CPU 对其进行重排序等优化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也可能出于同步的目的，反复把线程工作内存的数据 flush 到主存中，然后再从主内存 refresh 到其他线程的工作内存中，等等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这些问题在单线程中并不存在，但在多线程中为了确保数据的正确性，就不得不采取上述方法，因为线程安全的优先级要比性能优先级更高，这也间接降低了我们的性能。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[lock的常用方法]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/lock的常用方法</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/lock的常用方法</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;lock的常用方法&quot;&gt;lock的常用方法&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;方法概览:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public interface Lock {

    void lock();

    void lockInterruptibly() throws InterruptedException;

    boolean tryLock();

    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

    void unlock();

    Condition newCondition();

}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;lock--&quot;&gt;lock()&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用于加锁，然后在try代码块中进行相关业务逻辑的处理，然后在finally中释放锁。如果不进行try cache中释放，一旦发生异常，则无法正常释放锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;lock() 在执行的过程中是不能被中断，一旦进入死锁那便会永久等待。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Lock lock = new ReentrantLock();
lock.lock();
try {
  // 进入锁的保护，处理代码
} finally{
  // 解锁
  lock.unlock();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;tryLock--&quot;&gt;tryLock()&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了避免lock()会永久等待的问题，tryLock()会尝试获取锁，如果锁没有被其他线程占用则直接获取到锁，否则立刻返回false。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通常情况下使用 if 语句判断 tryLock() 的返回结果，根据是否获取到锁来执行不同的业务逻辑&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Lock lock = new ReentrantLock();
if(lock.tryLock()) {
     try{
         //处理任务
     }finally{
         lock.unlock();   //释放锁
     } 
}else {
    //如果不能获取锁，则做其他事情
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;tryLock-long-time--TimeUnit-unit-&quot;&gt;tryLock(long time, TimeUnit unit)&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;tryLock() 的重载方法是 tryLock(long time, TimeUnit unit)，这个方法和 tryLock() 很类似，区别在于 tryLock(long time, TimeUnit unit) 方法会有一个超时时间，在拿不到锁时会等待一定的时间。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果在时间期限结束后，还获取不到锁，就会返回 false；如果一开始就获取锁或者等待期间内获取到锁，则返回 true。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法解决了 lock() 方法容易发生死锁的问题，使用 tryLock(long time, TimeUnit unit) 时，在等待了一段指定的超时时间后，线程会主动放弃这把锁的获取，避免永久等待；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在等待的期间，也可以随时中断线程，这就避免了死锁的发生。&lt;/p&gt;
&lt;h2 id=&quot;lockInterruptibly--&quot;&gt;lockInterruptibly()&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和lock类似，区别的是lockInterruptibly()能够响应线程中断。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Lock lock = new ReentrantLock();
try {
  locklockInterruptibly();
  try {
          System.out.println(&amp;quot;操作资源&amp;quot;);
  } finally {
      lock.unlock();
  }
} catch (InterruptedException e) {
    e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;unlock--&quot;&gt;unlock()&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于 ReentrantLock 而言，执行 unlock() 的时候，内部会把锁的“被持有计数器”减 1，直到减到 0 就代表当前这把锁已经完全释放了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果减 1 后计数器不为 0，说明这把锁之前被“重入”了，那么锁并没有真正释放，仅仅是减少了持有的次数。&lt;/p&gt;
&lt;h2 id=&quot;newCondition--&quot;&gt;newCondition()&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;会生成一个，和锁对象绑定的Condition实例，用于处理线程的等待和通知。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public interface Condition {
     //使当前线程加入 await() 等待队列中，并释放当锁，当其他线程调用signal()会重新请求锁。与Object.wait()类似。
    void await() throws InterruptedException;

    //调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。
    //调用该方法后，结束等待的唯一方法是其它线程调用该条件对象的signal()或signalALL()方法。等待过程中如果当前线程被中断，该方法仍然会继续等待，同时保留该线程的中断状态。 
    void awaitUninterruptibly();

    // 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。
    //nanosTimeout指定该方法等待信号的的最大时间（单位为纳秒）。若指定时间内收到signal()或signalALL()则返回nanosTimeout减去已经等待的时间；
    //若指定时间内有其它线程中断该线程，则抛出InterruptedException并清除当前线程的打断状态；若指定时间内未收到通知，则返回0或负数。 
    long awaitNanos(long nanosTimeout) throws InterruptedException;

    //与await()基本一致，唯一不同点在于，指定时间之内没有收到signal()或signalALL()信号或者线程中断时该方法会返回false;其它情况返回true。
    boolean await(long time, TimeUnit unit) throws InterruptedException;

   //适用条件与行为与awaitNanos(long nanosTimeout)完全一样，唯一不同点在于它不是等待指定时间，而是等待由参数指定的某一时刻。
    boolean awaitUntil(Date deadline) throws InterruptedException;

    //唤醒一个在 await()等待队列中的线程。与Object.notify()相似
    void signal();

   //唤醒 await()等待队列中所有的线程。与object.notifyAll()相似
    void signalAll();
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[JVM锁优化]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/JVM锁优化</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/JVM锁优化</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;JVM锁优化&quot;&gt;JVM锁优化&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从JDK0.6开始，JVM对锁进行了各种各样的优化，目的是为了提高线程之间共享数据的效率，以及提高互斥同步的性能。&lt;/p&gt;
&lt;h2 id=&quot;锁消除&quot;&gt;锁消除&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;锁消除是发生在编译器级别的一种锁优化方式。&lt;br /&gt;
有时候我们写的代码完全不需要加锁，却执行了加锁操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如，StringBuffer类的append操作：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@Override
public synchronized StringBuffer append(CharSequence s) {
  toStringCache = null;
  super.append(s);
  return this;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从源码中可以看出，append方法用了synchronized关键词，它是线程安全的。但我们可能仅在线程内部把StringBuffer当作局部变量使用：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Demo {
public static void main(String[] args) {
  long start = System.currentTimeMillis();
  int size = 10000;
  for (int i = 0; i &amp;lt; size; i++) {
    createStringBuffer(&amp;quot;123&amp;quot;, &amp;quot;456&amp;quot;);
  }
  long timeCost = System.currentTimeMillis() - start;
  System.out.println(&amp;quot;createStringBuffer:&amp;quot; + timeCost + &amp;quot; ms&amp;quot;);
}
  public static String createStringBuffer(String str1, String str2) {
    StringBuffer sBuf = new StringBuffer();
    sBuf.append(str1);// append方法是同步操作
    sBuf.append(str2);
    return sBuf.toString();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码中createStringBuffer方法中的局部对象sBuf，就只在该方法内的作用域有效，不同线程同时调用createStringBuffer()方法时，都会创建不同的sBuf对象，因此此时的append操作若是使用同步操作，就是白白浪费的系统资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这时我们可以通过编译器将其优化，将锁消除，前提是java必须运行在server模式（server模式会比client模式作更多的优化），同时必须开启逃逸分析: -server -XX:+DoEscapeAnalysis -XX:+EliminateLocks&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;逃逸分析：比如上面的代码，它要看sBuf是否可能逃出它的作用域？如果将sBuf作为方法的返回值进行返回，那么它在方法外部可能被当作一个全局对象使用，就有可能发生线程安全问题，这时就可以说sBuf这个对象发生逃逸了，因而不应将append操作的锁消除，但我们上面的代码没有发生锁逃逸，锁消除就可以带来一定的性能提升。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;锁粗化&quot;&gt;锁粗化&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;for (int i = 0; i &amp;lt; 1000; i++) {
    synchronized (this) {
        //do something
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就会被粗化成:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;synchronized (this) {
   for (int i = 0; i &amp;lt; 1000; i++) {
          //do something
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;自适应锁自旋&quot;&gt;自适应锁自旋&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自适应意味着自旋的时间不再固定。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而是会根据最近自旋尝试的成功率、失败率，以及当前锁的拥有者的状态等多种因素来共同决定，自旋的持续时间是变化的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如，如果最近尝试自旋获取某一把锁成功了，那么下一次可能还会继续使用自旋，并且允许自旋更长的时间；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是如果最近自旋获取某一把锁失败了，那么可能会省略掉自旋的过程，以便减少无用的自旋，提高效率。&lt;/p&gt;
&lt;h2 id=&quot;偏向锁-轻量级锁-重量级锁&quot;&gt;偏向锁/轻量级锁/重量级锁&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-vl7ifhx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;偏向锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于偏向锁而言，它的思想是如果自始至终，对于这把锁都不存在竞争，那么其实就没必要上锁，只要打个标记就行了。一个对象在被初始化后，如果还没有任何线程来获取它的锁时，它就是可偏向的，当有第一个线程来访问它尝试获取锁的时候，它就记录下来这个线程，如果后面尝试获取锁的线程正是这个偏向锁的拥有者，就可以直接获取锁，开销很小。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-azxr9yp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;轻量级锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JVM 的开发者发现在很多情况下，synchronized 中的代码块是被多个线程交替执行的，也就是说，并不存在实际的竞争，或者是只有短时间的锁竞争，用 CAS 就可以解决。这种情况下，重量级锁是没必要的。轻量级锁指当锁原来是偏向锁的时候，被另一个线程所访问，说明存在竞争，那么偏向锁就会升级为轻量级锁，线程会通过自旋的方式尝试获取锁，不会阻塞。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rp9tx5a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重量级锁&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种锁利用操作系统的同步机制实现，所以开销比较大。当多个线程直接有实际竞争，并且锁竞争时间比较长的时候，此时偏向锁和轻量级锁都不能满足需求，锁就会膨胀为重量级锁。重量级锁会让其他申请却拿不到锁的线程进入阻塞状态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;synchronized加锁流程&quot;&gt;synchronized加锁流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于synchronized的加锁是通过对象头中的mark-word中的标记来判断的，所以我们必须得先了解对象结构。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/synchronized%E5%8E%9F%E7%90%86.png&quot; alt=&quot;synchronized原理&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在Hotspot虚拟机中，有其对应的对象结构:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/markOop.hpp&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;c++&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;64 bits:
--------
unused:25 hash:31 --&amp;gt;| unused:1   age:4    biased_lock:1 lock:2 (normal object)
JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)
PromotedObject*:61 ---------------------&amp;gt;| promo_bits:3 -----&amp;gt;| (CMS promoted object)
size:64 -----------------------------------------------------&amp;gt;| (CMS free block)
unused:25 hash:31 --&amp;gt;| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;amp;&amp;amp; normal object)
JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;amp;&amp;amp; biased object)
narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&amp;gt;| (COOPs &amp;amp;&amp;amp; CMS promoted objec
unused:21 size:35 --&amp;gt;| cms_free:1 unused:7 ------------------&amp;gt;| (COOPs &amp;amp;&amp;amp; CMS free block)
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;整个加锁过程:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;整个加锁逻辑都在这里，最好自己手绘一遍，以领会其精神&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E5%8A%A0%E9%94%81%E8%BF%87%E7%A8%8B.png&quot; alt=&quot;加锁过程&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[synchronized和Lock的对比]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/synchronized和Lock的对比</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/synchronized和Lock的对比</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;synchronized和Lock的对比&quot;&gt;synchronized和Lock的对比&lt;/h1&gt;
&lt;h2 id=&quot;相同点&quot;&gt;相同点&lt;/h2&gt;
&lt;h3 id=&quot;用来保护资源安全&quot;&gt;用来保护资源安全&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最基本的作用&lt;/p&gt;
&lt;h3 id=&quot;都可以保证可见性&quot;&gt;都可以保证可见性&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于 synchronized 而言，线程 A 在进入 synchronized 块之前或在 synchronized 块内进行操作，对于后续的获得同一个 monitor 锁的线程 B 是可见的，也就是线程 B 是可以看到线程 A 之前的操作的，这也体现了 happens-before 针对 synchronized 的一个原则。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%BB%98%E5%9B%BE2.png&quot; alt=&quot;绘图2&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而对于 Lock 而言，它和 synchronized 是一样，都可以保证可见性，如图所示，在解锁之前的所有操作对加锁之后的所有操作都是可见的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/LockHappensBefor.png&quot; alt=&quot;LockHappensBefor&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;都可重入&quot;&gt;都可重入&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可重入指的是某个线程如果已经获得了一个锁，现在试图再次请求这个它已经获得的锁，如果它无需提前释放这个锁，而是直接可以继续使用持有的这个锁。&lt;br /&gt;
如果必须释放锁后才能再次申请这个锁，就是不可重入的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而 synchronized 和 ReentrantLock 都具有可重入的特性。&lt;/p&gt;
&lt;h2 id=&quot;不同点&quot;&gt;不同点&lt;/h2&gt;
&lt;h3 id=&quot;用法不同&quot;&gt;用法不同&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yojpoki&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Lock的加锁方式是显示的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;必须使用Lock对象来加锁和解锁，通常会在finally中使用unlock进行解锁，以避免出现异常锁无法释放的情况。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-7l2hbfz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Synchronized的加锁方式是隐式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加锁解锁都不需要手动去控制，仅仅需要声明一下即可。不需要指定锁对象，可以在方法上、也可以在代码中加锁。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;加解锁顺序不同&quot;&gt;加解锁顺序不同&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-66hmj1s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Lock的加解锁顺序可以自由控制&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果有多把Lock锁，可以不按照加锁的顺序来反序解锁。如代码所示&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;lock1.lock();
lock2.lock()
....
lock1.unlock();
lock2.unlock();
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-mxavszh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Synchronized的解锁顺序必须和解锁顺序完全相反&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;synchronized(obj1){
    synchronized(obj2){
        .....
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为synchronized的由JVM控制的，在编译的时候会将上列代码解析成大致如下&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;monitorenter // 加obj1的锁
  monitorenter // 加obj2的锁

  monitorexit // 解obj2的锁
monitorexit // 解obj2的锁
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;synchronized锁不够灵活&quot;&gt;synchronized锁不够灵活&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一旦 synchronized 锁已经被某个线程获得了，此时其他线程如果还想获得，那它只能被阻塞，直到持有锁的线程运行完毕或者发生异常从而释放这个锁。如果持有锁的线程持有很长时间才释放，那么整个程序的运行效率就会降低，而且如果持有锁的线程永远不释放锁，那么尝试获取锁的线程只能永远等下去。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相比之下，Lock 类在等锁的过程中，如果使用的是 lockInterruptibly 方法，那么如果觉得等待的时间太长了不想再继续等待，可以中断退出，也可以用 tryLock() 等方法尝试获取锁，如果获取不到锁也可以做别的事，更加灵活。&lt;/p&gt;
&lt;h3 id=&quot;synchronized锁同时只能被一个线程拥有-Lock没有这个限制&quot;&gt;synchronized锁同时只能被一个线程拥有，Lock没有这个限制&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;例如在读写锁中的读锁，是可以同时被多个线程持有的，可是 synchronized 做不到。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Lock 根据实现不同，有不同的原理，例如 ReentrantLock 内部是通过 AQS 来获取和释放锁的。&lt;/p&gt;
&lt;h3 id=&quot;是否可以设置公平锁&quot;&gt;是否可以设置公平锁&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;公平锁是指多个线程在等待同一个锁时，根据先来后到的原则依次获得锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ReentrantLock 等 Lock 实现类可以根据自己的需要来设置公平或非公平，synchronized 则不能设置。&lt;/p&gt;
&lt;h3 id=&quot;性能区别&quot;&gt;性能区别&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Java 5 以及之前，synchronized 的性能比较低，但是到了 Java 6 以后，发生了变化，因为 JDK 对 synchronized 进行了很多优化，比如自适应自旋、锁消除、锁粗化、轻量级锁、偏向锁等，所以后期的 Java 版本里的 synchronized 的性能并不比 Lock 差。&lt;/p&gt;
&lt;h2 id=&quot;如何选择&quot;&gt;&lt;a href=&quot;lock的常用方法.md&quot;&gt;如何选择&lt;/a&gt;&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ar2q7tp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果能不用最好既不使用 Lock 也不使用 synchronized。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为在许多情况下你可以使用 java.util.concurrent 包中的机制，它会为你处理所有的加锁和解锁操作，也就是推荐优先使用工具类来加解锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-skui1en&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 synchronized 关键字适合你的程序， 那么请尽量使用它，这样可以减少编写代码的数量，减少出错的概率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为一旦忘记在 finally 里 unlock，代码可能会出很大的问题，而使用 synchronized 更安全。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j0tlu75&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果特别需要 Lock 的特殊功能，比如尝试获取锁、可中断、超时功能等,或者是需要实现分布式锁的时候，才使用 Lock。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[乐观锁和悲观锁]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/乐观锁和悲观锁</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/各种锁/锁的种类和特点/乐观锁和悲观锁</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[各种锁]]></category><category><![CDATA[锁的种类和特点]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;乐观锁和悲观锁&quot;&gt;乐观锁和悲观锁&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先我们看下悲观锁与乐观锁是如何进行分类的，悲观锁和乐观锁是从是否锁住资源的角度进行分类的。&lt;/p&gt;
&lt;h2 id=&quot;悲观锁&quot;&gt;悲观锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;悲观锁比较悲观，它认为如果不锁住这个资源，别的线程就会来争抢，就会造成数据结果错误，所以悲观锁为了确保结果的正确性，会在每次获取并修改数据时，都把数据锁住，让其他线程无法访问该数据，这样就可以确保数据内容万无一失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这也和我们人类中悲观主义者的性格是一样的，悲观主义者做事情之前总是担惊受怕，所以会严防死守，保证别人不能来碰我的东西，这就是悲观锁名字的含义。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CgpOIF38fTSAPhRdAABUFKF4IW4912-20211112101009781.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们举个例子，假设线程 A 和 B 使用的都是悲观锁，所以它们在尝试获取同步资源时，必须要先拿到锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl38fTSAE0T3AABXxHZ9Gus225-20211112101006617.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设线程 A 拿到了锁，并且正在操作同步资源，那么此时线程 B 就必须进行等待。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl38fTSALLQ8AABbKYnu-eg621-20211112101003886.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而当线程 A 执行完毕后，CPU 才会唤醒正在等待这把锁的线程 B 再次尝试获取锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CgpOIF38fTSAPYuRAABkLHzXEVA431.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果线程 B 现在获取到了锁，才可以对同步资源进行自己的操作。这就是悲观锁的操作流程。&lt;/p&gt;
&lt;h2 id=&quot;乐观锁&quot;&gt;乐观锁&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁比较乐观，认为自己在操作资源的时候不会有其他线程来干扰，所以并不会锁住被操作对象，不会不让别的线程来接触它，同时，为了确保数据正确性，在更新之前，会去对比在我修改数据期间，数据有没有被其他线程修改过：如果没被修改过，就说明真的只有我自己在操作，那我就可以正常的修改数据；如果发现数据和我一开始拿到的不一样了，说明其他线程在这段时间内修改过数据，那说明我迟了一步，所以我会放弃这次修改，并选择报错、重试等策略。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这和我们生活中乐天派的人的性格是一样的，乐观的人并不会担忧还没有发生的事情，相反，他会认为未来是美好的，所以他在修改数据之前，并不会把数据给锁住。当然，乐天派也不会盲目行动，如果他发现事情和他预想的不一样，也会有相应的处理办法，他不会坐以待毙，这就是乐观锁的思想。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl38fqeAFJ8QAABFSTPDdrc325.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁的实现一般都是利用 CAS 算法实现的。我们举个例子，假设线程 A 此时运用的是乐观锁。那么它去操作同步资源的时候，不需要提前获取到锁，而是可以直接去读取同步资源，并且在自己的线程内进行计算。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CgpOIF38fqeAIE65AABSE0sY_RQ235.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当它计算完毕之后、准备更新同步资源之前，会先判断这个资源是否已经被其他线程所修改过。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl38g46AE_bVAABmy6oWA2I750.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果这个时候同步资源没有被其他线程修改更新，也就是说此时的数据和线程 A 最开始拿到的数据是一致的话，那么此时线程 A 就会去更新同步资源，完成修改的过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl38fqeACYJNAACQDeJBU58075.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而假设此时的同步资源已经被其他线程修改更新了，线程 A 会发现此时的数据已经和最开始拿到的数据不一致了，那么线程 A 不会继续修改该数据，而是会根据不同的业务逻辑去选择报错或者重试。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;悲观锁和乐观锁概念并不是 Java 中独有的，这是一种广义的思想，这种思想可以应用于其他领域，比如说在数据库中，同样也有对悲观锁和乐观锁的应用。&lt;/p&gt;
&lt;h2 id=&quot;典型案例&quot;&gt;典型案例&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-o8vwc31&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;悲观锁：synchronized 关键字和 Lock 接口&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 中悲观锁的实现包括 synchronized 关键字和 Lock 相关类等，我们以 Lock 接口为例，例如 Lock 的实现类 ReentrantLock，类中的 lock() 等方法就是执行加锁，而 unlock() 方法是执行解锁。处理资源之前必须要先加锁并拿到锁，等到处理完了之后再解开锁，这就是非常典型的悲观锁思想。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-88pyb9y&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁：原子类&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁的典型案例就是原子类，例如 AtomicInteger 在更新数据时，就使用了乐观锁的思想，多个线程可以同时操作同一个原子变量。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rbzn7ts&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大喜大悲：数据库&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数据库中同时拥有悲观锁和乐观锁的思想。例如，我们如果在 MySQL 选择 select for update 语句，那就是悲观锁，在提交之前不允许第三方来修改该数据，这当然会造成一定的性能损耗，在高并发的情况下是不可取的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相反，我们可以利用一个版本 version 字段在数据库中实现乐观锁。在获取及修改数据时都不需要加锁，但是我们在获取完数据并计算完毕，准备更新数据时，会检查版本号和获取数据时的版本号是否一致，如果一致就直接更新，如果不一致，说明计算期间已经有其他线程修改过这个数据了，那我就可以选择重新获取数据，重新计算，然后再次尝试更新数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SQL语句示例如下（假设取出数据的时候 version 为1）：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;UPDATE student

    SET 

        name = ‘小李’,

        version= 2

    WHERE   id= 100

        AND version= 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;-汝之蜜糖-彼之砒霜-&quot;&gt;“汝之蜜糖,彼之砒霜”&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有一种说法认为，悲观锁由于它的操作比较重量级，不能多个线程并行执行，而且还会有上下文切换等动作，所以悲观锁的性能不如乐观锁好，应该尽量避免用悲观锁，这种说法是不正确的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为虽然悲观锁确实会让得不到锁的线程阻塞，但是这种开销是固定的。悲观锁的原始开销确实要高于乐观锁，但是特点是一劳永逸，就算一直拿不到锁，也不会对开销造成额外的影响。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;反观乐观锁虽然一开始的开销比悲观锁小，但是如果一直拿不到锁，或者并发量大，竞争激烈，导致不停重试，那么消耗的资源也会越来越多，甚至开销会超过悲观锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，同样是悲观锁，在不同的场景下，效果可能完全不同，可能在今天的这种场景下是好的选择，在明天的另外的场景下就是坏的选择，这恰恰是“汝之蜜糖，彼之砒霜”。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，我们就来看一下两种锁各自的使用场景，把合适的锁用到合适的场景中去，把合理的资源分配到合理的地方去。&lt;/p&gt;
&lt;h2 id=&quot;两种锁各自的使用场景&quot;&gt;两种锁各自的使用场景&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;悲观锁适合用于并发写入多、临界区代码复杂、竞争激烈等场景，这种场景下悲观锁可以避免大量的无用的反复尝试等消耗。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;乐观锁适用于大部分是读取，少部分是修改的场景，也适合虽然读写都很多，但是并发并不激烈的场景。在这些场景下，乐观锁不加锁的特点能让性能大幅提高。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[HashMap]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/并发容器/HashMap</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/并发容器/HashMap</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[并发容器]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;HashMap&quot;&gt;HashMap&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面说的是1.8下的HashMap&lt;/p&gt;
&lt;h2 id=&quot;HashMap实现原理&quot;&gt;HashMap实现原理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/e4a19398.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;HashMap采用Entry数组来存储key-value键值对，每个键值对组成了Node的实体，Node是一个单向链表的结构，具有next指针，指向下一个Node实体。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在链表长度&amp;gt;8的时候，链表会转换成为红黑树。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;为什么用数组+链表的方式&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;数组是用来确定桶的位置，也就是链表的头节点所在的位置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个位置是通过Key的Hash值，对数组长度取模得到。链表的作用是用来解决Hash冲突的问题，当出现Hash值一样的情形，就再数组的对应位置上形成一条链表。这种方法被称之为链地址法&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;用LinkedList代理数组结构可以么&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;为什么HashMap不用LinkedList,而选用数组?&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为用数组效率最高！LinkedList的查找时间复杂度是O(n),而数组是O(1)&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在HashMap中，定位桶的位置是利用元素的key的哈希值对数组长度取模得到。此时，我们已得到桶的位置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;显然数组的查找效率比LinkedList大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;那ArrayList，底层也是数组，查找也快啊，为啥不用ArrayList?&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为采用基本数组结构，扩容机制可以自己定义，HashMap中数组扩容刚好是2的次幂，在做取模运算的效率高,&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; 而ArrayList的扩容机制是1.5倍扩容。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;数组的长度是有限的,在什么情况下会进行扩容&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果bucket满了，超过了 &lt;strong&gt;threshold&lt;/strong&gt; 的时候进行扩容，扩容的容量是之前的两倍。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;为什么扩容是2的次幂&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高16位异或去参与运算的过程，减少碰撞。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。&lt;/p&gt;
&lt;h2 id=&quot;功能实现&quot;&gt;功能实现&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。&lt;/p&gt;
&lt;h3 id=&quot;1--确定哈希桶数组索引位置&quot;&gt;1. 确定哈希桶数组索引位置&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;方法一：
static final int hash(Object key) {   //jdk1.8 &amp;amp; jdk1.7
     int h;
     // h = key.hashCode() 为第一步 取hashCode值
     // h ^ (h &amp;gt;&amp;gt;&amp;gt; 16)  为第二步 高位参与运算
     return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);
}
方法二：
static int indexFor(int h, int length) {  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的
     return h &amp;amp; (length-1);  //第三步 取模运算
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里的Hash算法本质上就是三步：&lt;strong&gt;取key的hashCode值、高位运算、取模运算&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法非常巧妙，它通过h &amp;amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp;amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;amp;比%具有更高的效率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面举例说明下，n为table的长度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/45205ec2.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;2--分析HashMap的put方法&quot;&gt;2. 分析HashMap的put方法&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/d669d29c.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。&lt;/p&gt;
&lt;h3 id=&quot;3--扩容机制&quot;&gt;3. 扩容机制&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; 1 void resize(int newCapacity) {   //传入新的容量
 2     Entry[] oldTable = table;    //引用扩容前的Entry数组
 3     int oldCapacity = oldTable.length;         
 4     if (oldCapacity == MAXIMUM_CAPACITY) {  //扩容前的数组大小如果已经达到最大(2^30)了
 5         threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了
 6         return;
 7     }
 8  
 9     Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组
10     transfer(newTable);                         //！！将数据转移到新的Entry数组里
11     table = newTable;                           //HashMap的table属性引用新的Entry数组
12     threshold = (int)(newCapacity * loadFactor);//修改阈值
13 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; 1 void transfer(Entry[] newTable) {
 2     Entry[] src = table;                   //src引用了旧的Entry数组
 3     int newCapacity = newTable.length;
 4     for (int j = 0; j &amp;lt; src.length; j++) { //遍历旧的Entry数组
 5         Entry&amp;lt;K,V&amp;gt; e = src[j];             //取得旧Entry数组的每个元素
 6         if (e != null) {
 7             src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
 8             do {
 9                 Entry&amp;lt;K,V&amp;gt; next = e.next;
10                 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置
11                 e.next = newTable[i]; //标记[1]
12                 newTable[i] = e;      //将元素放在数组上
13                 e = next;             //访问下一个Entry链上的元素
14             } while (e != null);
15         }
16     }
17 } 
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/b2330062.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/4d8022db.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/d773f86e.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/3cc9813a.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; 1 final Node&amp;lt;K,V&amp;gt;[] resize() {
 2     Node&amp;lt;K,V&amp;gt;[] oldTab = table;
 3     int oldCap = (oldTab == null) ? 0 : oldTab.length;
 4     int oldThr = threshold;
 5     int newCap, newThr = 0;
 6     if (oldCap &amp;gt; 0) {
 7         // 超过最大值就不再扩充了，就只好随你碰撞去吧
 8         if (oldCap &amp;gt;= MAXIMUM_CAPACITY) {
 9             threshold = Integer.MAX_VALUE;
10             return oldTab;
11         }
12         // 没超过最大值，就扩充为原来的2倍
13         else if ((newCap = oldCap &amp;lt;&amp;lt; 1) &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp;
14                  oldCap &amp;gt;= DEFAULT_INITIAL_CAPACITY)
15             newThr = oldThr &amp;lt;&amp;lt; 1; // double threshold
16     }
17     else if (oldThr &amp;gt; 0) // initial capacity was placed in threshold
18         newCap = oldThr;
19     else {               // zero initial threshold signifies using defaults
20         newCap = DEFAULT_INITIAL_CAPACITY;
21         newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
22     }
23     // 计算新的resize上限
24     if (newThr == 0) {
25 
26         float ft = (float)newCap * loadFactor;
27         newThr = (newCap &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp; ft &amp;lt; (float)MAXIMUM_CAPACITY ?
28                   (int)ft : Integer.MAX_VALUE);
29     }
30     threshold = newThr;
31     @SuppressWarnings({&amp;quot;rawtypes&amp;quot;，&amp;quot;unchecked&amp;quot;})
32         Node&amp;lt;K,V&amp;gt;[] newTab = (Node&amp;lt;K,V&amp;gt;[])new Node[newCap];
33     table = newTab;
34     if (oldTab != null) {
35         // 把每个bucket都移动到新的buckets中
36         for (int j = 0; j &amp;lt; oldCap; ++j) {
37             Node&amp;lt;K,V&amp;gt; e;
38             if ((e = oldTab[j]) != null) {
39                 oldTab[j] = null;
40                 if (e.next == null)
41                     newTab[e.hash &amp;amp; (newCap - 1)] = e;
42                 else if (e instanceof TreeNode)
43                     ((TreeNode&amp;lt;K,V&amp;gt;)e).split(this, newTab, j, oldCap);
44                 else { // 链表优化重hash的代码块
45                     Node&amp;lt;K,V&amp;gt; loHead = null, loTail = null;
46                     Node&amp;lt;K,V&amp;gt; hiHead = null, hiTail = null;
47                     Node&amp;lt;K,V&amp;gt; next;
48                     do {
49                         next = e.next;
50                         // 原索引
51                         if ((e.hash &amp;amp; oldCap) == 0) {
52                             if (loTail == null)
53                                 loHead = e;
54                             else
55                                 loTail.next = e;
56                             loTail = e;
57                         }
58                         // 原索引+oldCap
59                         else {
60                             if (hiTail == null)
61                                 hiHead = e;
62                             else
63                                 hiTail.next = e;
64                             hiTail = e;
65                         }
66                     } while ((e = next) != null);
67                     // 原索引放到bucket里
68                     if (loTail != null) {
69                         loTail.next = null;
70                         newTab[j] = loHead;
71                     }
72                     // 原索引+oldCap放到bucket里
73                     if (hiTail != null) {
74                         hiTail.next = null;
75                         newTab[j + oldCap] = hiHead;
76                     }
77                 }
78             }
79         }
80     }
81     return newTab;
82 }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;为什么hashmap的在链表元素数量超过8时改为红黑树-&quot;&gt;为什么hashmap的在链表元素数量超过8时改为红黑树?&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;知道jdk1.8中hashmap改了啥么?&lt;/strong&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-boej77k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由&lt;strong&gt;数组+链表&lt;/strong&gt;的结构改为&lt;strong&gt;数组+链表+红黑树&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lbt7wdc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;优化了高位运算的hash算法：h^(h&amp;gt;&amp;gt;&amp;gt;16)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-o7x8wah&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩容后，元素要么是在原位置，要么是在原位置再移动2次幂的位置，且链表顺序不变。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;为什么在解决hash冲突的时候，不直接用红黑树?而选择先用链表，再转红黑树?&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。 当元素小于8个当时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于8个的时候，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;那为什么阀值是8呢?&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;当链表转为红黑树后，什么时候退化为链表?&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为6的时候退转为链表。中间有个差值7可以防止链表和树之间频繁的转换。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。&lt;/p&gt;
&lt;h2 id=&quot;线程安全性&quot;&gt;线程安全性&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JDK 1.8 进行了环链的修复。但还是避免在多线程环境下使用，就比如size 是通过++size() 来进行计算的，多线程下必然出现问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;java1.8解决环链的方式&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;声明两对指针，维护两个连链表&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;依次在末端添加新的元素。（在多线程操作的情况下，无非是第二个线程重复第一个线程一模一样的操作）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;java1.7下的坑&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class HashMapInfiniteLoop {  

    private static HashMap&amp;lt;Integer,String&amp;gt; map = new HashMap&amp;lt;Integer,String&amp;gt;(2，0.75f);  
    public static void main(String[] args) {  
        map.put(5， &amp;quot;C&amp;quot;);  

        new Thread(&amp;quot;Thread1&amp;quot;) {  
            public void run() {  
                map.put(7, &amp;quot;B&amp;quot;);  
                System.out.println(map);  
            };  
        }.start();  
        new Thread(&amp;quot;Thread2&amp;quot;) {  
            public void run() {  
                map.put(3, &amp;quot;A);  
                System.out.println(map);  
            };  
        }.start();        
    }  
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/7df99266.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/4c3c28fb.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/6c8d086a.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/6eed9aaf.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;参考: https://tech.meituan.com/2016/06/24/java-hashmap.html&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[什么是阻塞队列]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/阻塞队列/什么是阻塞队列</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/阻塞队列/什么是阻塞队列</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[阻塞队列]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;什么是阻塞队列&quot;&gt;什么是阻塞队列&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;顾名思义，阻塞队列就是一组阻塞的队列，由于队列的特性是先进先出 , 如果加上阻塞这个特性的话，就会变成 队列为空时，出阻塞; 队列满时,进阻塞;&lt;/p&gt;
&lt;h2 id=&quot;阻塞队列的作用&quot;&gt;阻塞队列的作用&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;利用这种特性，我们在很多场景下都可以利用线程安全来优雅的解决我们业务自身的线程安全问题，比如可以方便的编写线程安全的生产消费模型。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生产者只需要往队列里面不停地添加元素，消费者只需要从队列里面取出他们，如下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97.png&quot; alt=&quot;阻塞队列&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;左侧有三个生产者线程，它会将生产出来的结果放到中间的阻塞队列中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;右侧有三个消费者线程，它们将会从阻塞队列中取出它所需要的内容并进行处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为，阻塞队列天然是线程安全的，所以生产者和消费者都可以是多线程的，不会发生线程安全问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;既然，阻塞队列是线程安全的，那么我们就可以将开发重心从保持线程安全性，转移到具体的业务逻辑中，大大的降低了开发的难度和工作量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;与此同时，队列的使用还能够解耦业务逻辑。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如一个银行转账的程序，那么生产者线程不需要关心具体的转账逻辑，只需要把转账任务，如账户和金额放到队列中就可以，而不需要关心银行这个类如何去实现具体的转账业务，而作为银行这个类来讲，它会去从队列中取出来将要执行的具体的任务，再去通过自己的各种方法来完成本次转账。&lt;/p&gt;
&lt;h2 id=&quot;主要并发队列关系图&quot;&gt;主要并发队列关系图&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211203141948403.png&quot; alt=&quot;image-20211203141948403&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上图展示了，队列Queue主要的实现类，可以看出，Java提供线程安全的队列分别为&lt;strong&gt;阻塞队列和非阻塞队列&lt;/strong&gt;两大类。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阻塞队列都是BlockingQueue的实现类:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-95z3vg5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ArrayBlockingQueue&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-0bl2yli&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LinkedBlockingQueue&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6gxcsuf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SynchronousQueue&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b5x6u9i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DelayQueue&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-q6a8xw2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;PriorityBlockingQueue&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jgbfykc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LinkedTransferQueue&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和非阻塞队列 ConcurrentLinkedQueue.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除此之外，还有双端队列Deque: 它从头和尾都能添加和删除元素；而普通的 Queue 只能从一端进入，另一端出去。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有扩展了BlockingQueue的TransferQueue:	生产者会一直阻塞直到所添加到队列的元素被某一个消费者所消费（不仅仅是添加到队列里就完事）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;后面我们会一一介绍他们。&lt;/p&gt;
&lt;h2 id=&quot;阻塞队列的特点&quot;&gt;阻塞队列的特点&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阻塞队列区别于其他类型的队列的最主要的特点就是&amp;quot;阻塞&amp;quot;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;阻塞功能使得生产者和消费者两段的能力得以平衡，当任何一端的速度过快时，阻塞队列便会把过快的速度给降下来，阻塞最重要的两个方法是take方法和put方法。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-684f0kb&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;take 方法&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;take 方法的功能是获取并移除队列的头结点，通常在队列里有数据的时候是可以正常移除的。可是一旦执行 take 方法的时候，队列里无数据，则阻塞，直到队列里有数据。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一旦队列里有数据了，就会立刻解除阻塞状态，并且取到数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tpo0zfu&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;put方法&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;put 方法插入元素时，如果队列没有满，那就和普通的插入一样是正常的插入，但是如果队列已满，那么就无法继续插入，则阻塞，直到队列里有了空闲空间。如果后续队列有了空闲空间，比如消费者消费了一个元素，那么此时队列就会解除阻塞状态，并把需要添加的数据添加到队列中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;以上过程中的阻塞和解除阻塞，都是 BlockingQueue 完成的，不需要我们自己处理。&lt;/p&gt;
&lt;h3 id=&quot;是否有界-容量有多大-&quot;&gt;是否有界（容量有多大）&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，阻塞队列还有一个非常重要的属性，那就是容量的大小，分为有界和无界两种。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无界队列意味着里面可以容纳非常多的元素，例如 LinkedBlockingQueue 的上限是 Integer.MAX_VALUE，约为 2 的 31 次方，是非常大的一个数，可以近似认为是无限容量，因为我们几乎无法把这个容量装满。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是有的阻塞队列是有界的，例如 ArrayBlockingQueue 如果容量满了，也不会扩容，所以一旦满了就无法再往里放数据了。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[ThreadLocal使用场景]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/ThreadLocal/ThreadLocal使用场景</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/ThreadLocal/ThreadLocal使用场景</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[ThreadLocal]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ThreadLocal使用场景&quot;&gt;ThreadLocal使用场景&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在业务开发中有两种典型的使用场景。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zjrhph8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;保存线程不安全的对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-aw6sr5t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;传递全局变量&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;保存线程不安全的工具类&quot;&gt;保存线程不安全的工具类&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;典型的类: SimpleDateFormat&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果有多个线程同时调用下面这个方法，由于dateFormat是局部变量，不会有线程安全问题；但是会创建出大量的SimpleDateFormat对象，造成频繁的GC。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public String date() {
        SimpleDateFormat dateFormat = new SimpleDateFormat(&amp;quot;mm:ss&amp;quot;);
        return dateFormat.format(new Date());
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们声明成全局变量呢？&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;static SimpleDateFormat dateFormat = new SimpleDateFormat(&amp;quot;mm:ss&amp;quot;);
public String date(){
   return dateFormat.format(new Date());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多个线程访问下，不同的线程都是指向同一个对象，会有线程安全的问题、&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用传统的解决方法: 加锁&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;static SimpleDateFormat dateFormat = new SimpleDateFormat(&amp;quot;mm:ss&amp;quot;);
public synchronized String date(){
   return dateFormat.format(new Date());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加锁的方式的确能够解决线程不安全的问题，但是也带来了性能低下。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正确的方式是采用ThreadLocal来创建对象&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public synchronized String date(){
   SimpleDateFormat dateFormat = ThreadSafeFormatter.dateFormatThreadLocal.get();
   return dateFormat.format(new Date());
}
class ThreadSafeFormatter {
    public static ThreadLocal&amp;lt;SimpleDateFormat&amp;gt; dateFormatThreadLocal = new ThreadLocal&amp;lt;SimpleDateFormat&amp;gt;() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat(&amp;quot;mm:ss&amp;quot;);
        }
    };

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这种创建的方式，最多创建的对象只和线程数相同。这样既高效的使用了内存，也保证了线程安全。&lt;/p&gt;
&lt;h2 id=&quot;传递全局变量&quot;&gt;传递全局变量&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个线程内需要保存类似于全局变量的信息，可以让不同方法直接使用，避免参数传递的麻烦却不想被多线程共享。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;例如，用 ThreadLocal 保存一些业务内容，这些信息在同一个线程内相同，但是不同的线程使用的业务内容是不相同的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在线程生命周期内，都通过这个静态 ThreadLocal 实例的 get() 方法取得自己 set 过的那个对象，避免了将这个对象作为参数传递的麻烦。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;案例:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-kmfs7cc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在分布式链路追踪中，log4j的MDC对象&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-u7xs33w&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;业务系统中，使用ThreadLocal传递用户信息&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;面试题--ThreadLocal是用来解决共享资源的多线程访问吗-&quot;&gt;面试题: ThreadLocal是用来解决共享资源的多线程访问吗?&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这道题的答案很明确——不是。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ThreadLocal不是用来解决共享资源问题的。虽然ThreadLocal可以用于解决多线程情况下的线程安全问题，但是&lt;strong&gt;资源不是共享的，而是每个线程独享过的&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;面试官在忽悠你，独享资源何来的多线程访问呢？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ThreadLocal解决线程安全问题的时候，相比于使用“锁”而言，避免了竞争，采用了线程独享来进行操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;具体而言，它可以在 initialValue 中 new 出自己线程独享的资源，而多个线程之间，它们所访问的对象本身是不共享的，自然就不存在任何并发问题。这是 ThreadLocal 解决并发问题的最主要思路。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果变量变成了共享，则依然是线程不安全的:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;	public synchronized String date(){
   SimpleDateFormat dateFormat = ThreadSafeFormatter.dateFormatThreadLocal.get();
   return dateFormat.format(new Date());
}
class ThreadSafeFormatter {
  	static SimpleDateFormat format = new SimpleDateFormat();
    public static ThreadLocal&amp;lt;SimpleDateFormat&amp;gt; dateFormatThreadLocal = new ThreadLocal&amp;lt;SimpleDateFormat&amp;gt;() {
        @Override
        protected SimpleDateFormat initialValue() {
            return ThreadSafeFormatter.format;
        }
    };

}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;ThreadLocal-和-synchronized-是什么关系&quot;&gt;ThreadLocal 和 synchronized 是什么关系&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当 ThreadLocal 用于解决线程安全问题的时候，也就是把一个对象给每个线程都生成一份独享的副本的，在这种场景下，ThreadLocal 和 synchronized 都可以理解为是用来保证线程安全的手段。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是效果和实现原理不同：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-usolwxw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ThreadLocal 是通过让每个线程独享自己的副本，避免了资源的竞争。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ibr1gqh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;synchronized 主要用于临界资源的分配，在同一时刻限制最多只有一个线程能访问该资源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[ThreadLocal内存泄漏]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/ThreadLocal/ThreadLocal内存泄漏</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/ThreadLocal/ThreadLocal内存泄漏</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[ThreadLocal]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ThreadLocal内存泄漏&quot;&gt;ThreadLocal内存泄漏&lt;/h1&gt;
&lt;h2 id=&quot;ThreadLocal的实现原理&quot;&gt;ThreadLocal的实现原理&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ThreadLocal的保存变量，是维护在Thread中的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是由于每个线程在访问ThreadLocal对象之后，都会在Thread中的Map中留下ThreadLocal对象与具体实例的引用，如果不删除这些引用则这些ThreadLocal则不能进行回收，会造成内存泄漏&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/ThreadLocal.png&quot; alt=&quot;ThreadLocal&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl5Pld-AHFhJAADLtGXmSxc833.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;内存泄漏的案例&quot;&gt;内存泄漏的案例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;网上有一段说明ThreadLocal内存泄漏非常好的代码。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过线程池去持有ThreadLocal对象，由于线程池的特性，线程被用完之后不会被释放。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，总是存在&amp;lt;ThreadLocal,LocalVariable&amp;gt;的强引用，file static修饰的变量不会被释放，所以即使TreadLocalMap的key是弱引用，但由于强引用的存在，弱引用一直会有值，不会被GC回收。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内存泄漏的大小 = &lt;code&gt;核心线程数 * LocalVariable&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class ThreadLocalDemo {
    static class LocalVariable {
        private Long[] a = new Long[1024 * 1024];
    }

    // (1)
    final static ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5, 5, 1, TimeUnit.MINUTES,
            new LinkedBlockingQueue&amp;lt;&amp;gt;());
    // (2)
    final static ThreadLocal&amp;lt;LocalVariable&amp;gt; localVariable = new ThreadLocal&amp;lt;LocalVariable&amp;gt;();

    public static void main(String[] args) throws InterruptedException {
        // (3)
        Thread.sleep(5000 * 4);
        for (int i = 0; i &amp;lt; 50; ++i) {
            poolExecutor.execute(new Runnable() {
                public void run() {
                    // (4)
                    localVariable.set(new LocalVariable());
                    // (5)
                    System.out.println(&amp;quot;use local varaible&amp;quot; + localVariable.get());
                    localVariable.remove();
                }
            });
        }
        // (6)
        System.out.println(&amp;quot;pool execute over&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以, 为了避免出现内存泄露的情况, ThreadLocal提供了一个清除线程中对象的方法, 即 remove, 其实内部实现就是调用 ThreadLocalMap 的remove方法&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private void remove(ThreadLocal&amp;lt;?&amp;gt; key) {
    Entry[] tab = table;
    int len = tab.length;
    int i = key.threadLocalHashCode &amp;amp; (len-1);
    for (Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        if (e.get() == key) {
            e.clear();
            expungeStaleEntry(i);
            return;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;找到Key对应的Entry, 并且清除Entry的Key(ThreadLocal)置空, 随后清除过期的Entry即可避免内存泄露。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[FutureTask源码分析]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/Future/FutureTask源码分析</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/Future/FutureTask源码分析</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[Future]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;FutureTask源码分析&quot;&gt;FutureTask源码分析&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;FutureTask为future提供了基础实现，而且也是我们用的最多的实现方式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来，将会对FutureTask展开深入的分析。&lt;/p&gt;
&lt;h2 id=&quot;核心属性&quot;&gt;核心属性&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;    /**
     * 任务的运行状态。
     * 可能的状态转换:
     * NEW -&amp;gt; COMPLETING -&amp;gt; NORMAL
     * NEW -&amp;gt; COMPLETING -&amp;gt; EXCEPTIONAL
     * NEW -&amp;gt; CANCELLED
     * NEW -&amp;gt; INTERRUPTING -&amp;gt; INTERRUPTED
     */
    private volatile int state;
    private static final int NEW          = 0;
    private static final int COMPLETING   = 1;
    private static final int NORMAL       = 2;
    private static final int EXCEPTIONAL  = 3;
    private static final int CANCELLED    = 4;
    private static final int INTERRUPTING = 5;
    private static final int INTERRUPTED  = 6;

    /** 运行callable的线程，运行后清零 */
    private Callable&amp;lt;V&amp;gt; callable;
    /** 从get()中返回的结果或者异常 */
    private Object outcome; // non-volatile, protected by state reads/writes
    /** 运行callable的线程 */
    private volatile Thread runner;
    /** 使用Treiber保存等待线程 */
    private volatile WaitNode waiters;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中我们需要注意的就是state类型，是volatile类型的，任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;7种状态:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6d3z61d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;NEW&lt;/code&gt;: 表示是一个新的任务或者还没有被执行完的状态。初始状态&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ljr5xt6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;COMPLETING&lt;/code&gt;: 任务执行完，或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有被保存到outcome字段的时候，装填会从NEW-&amp;gt;COMPLETING。这个状态时间很短，属于中间状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ggmsvi8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;NORMAL&lt;/code&gt;:任务执行完，并且任务执行结果已经保存到outcome字段中，状态会从NEW -&amp;gt; COMPLETING -&amp;gt; NORMAL。最终态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g6vnr71&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;EXCEPTIONAL&lt;/code&gt;:任务执行发生异常，并且异常原因已经保存到outcome字段中，状态会从NEW -&amp;gt; COMPLETING -&amp;gt; EXCEPTIONAL。最终态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ufo2g5f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;CANCELLED&lt;/code&gt;:任务还没有开始执行或者已经开始执行但是还没有执行完，此时用户调用了cancel(false)方法，&lt;strong&gt;不中断任务&lt;/strong&gt;执行的情况下取消线程执行。这个时候状态则是: NEW -&amp;gt; CANCELLED。最终态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-d664mbz&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;INTERRUPTING&lt;/code&gt;:任务还没有开始执行或者已经开始执行但是还没有执行完，此时用户调用了cancel(ture)方法，&lt;strong&gt;中断任务&lt;/strong&gt;执行并且还没有执行中断操作之前。这个时候状态则是: NEW -&amp;gt; INTERRUPTING。这是一个中间状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vdbbflx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;INTERRUPTED&lt;/code&gt;:调用interrupt()中断任务执行线程会到这个状态。NEW -&amp;gt; INTERRUPTING -&amp;gt; INTERRUPTED。这是一个最终态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;值得注意的是，所有状态值大于COMPLETING的状态都是标识任务已经执行完成，无论是正常、异常、或者任务取消。&lt;/p&gt;
&lt;div data-content=&quot;graph TD;
    NEW--&amp;gt;COMPLETING;
    COMPLETING--&amp;gt;NORMAL;
    COMPLETING--&amp;gt;EXCEPTIONAL;
    NEW--&amp;gt;CANCELLED;
    NEW--&amp;gt;INTERRUPTING--&amp;gt;INTERRUPTED;&quot; data-subtype=&quot;mermaid&quot;&gt;&lt;div spin=&quot;1&quot;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;构造函数&quot;&gt;构造函数&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public FutureTask(Callable&amp;lt;V&amp;gt; callable) {
        if (callable == null)
            throw new NullPointerException();
        this.callable = callable;
        this.state = NEW;       // ensure visibility of callable
    }
public FutureTask(Runnable runnable, V result) {
        this.callable = Executors.callable(runnable, result);
        this.state = NEW;       // ensure visibility of callable
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以在构造函数中看到，初始化的状态是NEW，和我们上文中写的一致。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;callable&lt;/code&gt;:用来保存底层调用。如果直接传入runable，会将Runnable对象包装成callable对象，如果任务执行成功就会返回传入的result。如果不需要返回值，可以传入一个null。&lt;/p&gt;
&lt;h2 id=&quot;核心方法-Run--&quot;&gt;核心方法：Run()&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void run() {
  // 新建任务，CAS替换runner为当前线程。
  if (state != NEW ||
      !RUNNER.compareAndSet(this, null, Thread.currentThread()))
    return;
  try {
    Callable&amp;lt;V&amp;gt; c = callable;
    // 只有在初始状态的时候才进行执行
    if (c != null &amp;amp;&amp;amp; state == NEW) {
      V result;
      boolean ran;
      try {
        // 执行传入的操作
        result = c.call();
        ran = true;
      } catch (Throwable ex) {
        result = null;
        ran = false;
        // 如果发生异常，设置异常信息
        // NEW -&amp;gt; COMPLETING -&amp;gt; EXCEPTIONAL
        setException(ex);
      }
      if (ran)
        // 如果正常执行完成，设置执行结果
        // NEW -&amp;gt; COMPLETING -&amp;gt; NORMAL
        set(result);
    }
  } finally {
    // runner must be non-null until state is settled to
    // prevent concurrent calls to run()
    runner = null;
    // state must be re-read after nulling runner to prevent
    // leaked interrupts
    int s = state;
    if (s &amp;gt;= INTERRUPTING)。
      handlePossibleCancellationInterrupt(s);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;说明:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-1fevoqf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行任务，如果任务状态为NEW状态，则利用CAS修改为当前线程，执行完毕调用set(result)设置执行结果。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * 1. 通过CAS操作设置STATE的状态，NEW -&amp;gt; COMPLETING
 * 2. outcome复制为v
 * 3. 设置STATE为NOMAL，COMPLETING -&amp;gt; NOMAL
 * 4. 执行完毕，唤醒等待的县城
 */
protected void set(V v) {
        if (STATE.compareAndSet(this, NEW, COMPLETING)) {
            outcome = v;
            STATE.setRelease(this, NORMAL); // final state
            finishCompletion();
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-g5h8a4d&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;结果设置完毕调用finishCompletion()唤醒等待县城&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;
private void finishCompletion() {
        // assert state &amp;gt; COMPLETING;
  			// 确保当前状态是结果态，才能进行唤醒操作
        for (WaitNode q; (q = waiters) != null;) {
            if (WAITERS.weakCompareAndSet(this, q, null)) {
                for (;;) { // 自旋便等待线程
                    Thread t = q.thread;
                    if (t != null) {
                        q.thread = null;
                      	// 唤醒等待线程
                        LockSupport.unpark(t);
                    }
                    WaitNode next = q.next;
                    if (next == null)
                        break;
                  	// 将非等待的线程设置为null，帮助GC
                    q.next = null; // unlink to help gc
                    q = next;
                }
                break;
            }
        }
  			// 任务完成后调用函数，自定义扩展
        done();
        callable = null;        // to reduce footprint
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-wqqy998&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果run的运行期间被中断，需要调用handlePossibleCancellationInterrupt来处理中断逻辑，确保任何中断(例如cancel(true))只停留在当前run或runAndReset的任务中&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-auiiiqa&quot; updated=&quot;20220705131435&quot;&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
 * Ensures that any interrupt from a possible cancel(true) is only
 * delivered to a task while in run or runAndReset.
 */
private void handlePossibleCancellationInterrupt(int s) {
    // It is possible for our interrupter to stall before getting a
    // chance to interrupt us.  Let&apos;s spin-wait patiently.
    // 在中断者中断线程之前可能会延迟，所以我们只需要让出CPU时间片自旋等待
    if (s == INTERRUPTING)
        while (state == INTERRUPTING)
            Thread.yield(); // wait out pending interrupt

    // assert state == INTERRUPTED;

    // We want to clear any interrupt we may have received from
    // cancel(true).  However, it is permissible to use interrupts
    // as an independent mechanism for a task to communicate with
    // its caller, and there is no way to clear only the
    // cancellation interrupt.
    //
    // Thread.interrupted();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;核心方法-get--&quot;&gt;核心方法:get()&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public V get() throws InterruptedException, ExecutionException {
    int s = state;
    if (s &amp;lt;= COMPLETING)
      s = awaitDone(false, 0L);
    return report(s);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;说明: FutureTask通过get()方法获取任务执行结果。任务处于未完成的状态 state &amp;lt;= COMPLETEING，就调用awaitDown等待任务完成，通过report获取执行结果或者抛出异常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;report方法比较简单，如果当前状态是正常的NORMAL，则直接返回结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果方法状态&amp;gt;=CANCELLED,也就是处于CANCELLED、INTERRUPTING、INTERRUPTED这三种状态的时候，抛出CancellationException，否则（状态为EXCEPTIONAL）就抛出业务异常&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private V report(int s) throws ExecutionException {
        Object x = outcome;
        if (s == NORMAL)
            return (V)x;
        if (s &amp;gt;= CANCELLED)
            throw new CancellationException();
        throw new ExecutionException((Throwable)x);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;核心方法-awaitDone-boolean-timed-long-nanos-&quot;&gt;核心方法:awaitDone(boolean timed,long nanos)&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法就是get方法阻塞的关键所在&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;
private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
        long startTime = 0L;    // Special value 0L means not yet parked
        WaitNode q = null;
        boolean queued = false;
        for (;;) {// 自旋
            int s = state;
            // 如果状态处于完成态，置空等待节点的线程，帮助GC
            if (s &amp;gt; COMPLETING) {
                if (q != null)
                    q.thread = null;
                return s;
            }
            else if (s == COMPLETING)
              	// 如果还在等待任务的执行结果，就yield()，暂时让出时间片，让其他线程执行
                Thread.yield();
            else if (Thread.interrupted()) {
                // 如果线程被中断，则调用removeWaiter，移除节点避免堆积垃圾
                removeWaiter(q);
                throw new InterruptedException();
            }
            else if (q == null) {
              	// 如果等待时间为0 ，则意味着自旋一次就退出循环
                if (timed &amp;amp;&amp;amp; nanos &amp;lt;= 0L)
                    return s;
                q = new WaitNode();
            }
            else if (!queued)
              	// CAS修改waiter
                queued = WAITERS.weakCompareAndSet(this, q.next = waiters, q);
            else if (timed) {
                // 统计超时时间
                final long parkNanos;
              	// 首次循环，则初始化时间
                if (startTime == 0L) { // first time
                    startTime = System.nanoTime();
                    if (startTime == 0L)
                        startTime = 1L;
                    parkNanos = nanos;
                } else {
                  	// 后面的每次循环，都将记录运行时间
                    long elapsed = System.nanoTime() - startTime;
                    // 如果，超时了，就移除等待节点，返回节点状态回去
                    if (elapsed &amp;gt;= nanos) {
                        removeWaiter(q);
                        return state;
                    }
                    parkNanos = nanos - elapsed;
                }
                // nanoTime may be slow; recheck before parking
                // 如果，状态还处于未完成状态，阻塞当前线程
                if (state &amp;lt; COMPLETING)
                    LockSupport.parkNanos(this, parkNanos);
            }
            else
                // 不记录时间的话，阻塞当前线程
                LockSupport.park(this);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-pniq4qa&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前状态为结束状态(state&amp;gt;COMPLETING),则根据需要置空等待节点的线程，并返回 Future 状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rowfdli&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前状态为正在完成(COMPLETING)，说明此时 Future 还不能做出超时动作，为任务让出CPU执行时间片；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8u3l66s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果state为NEW，先新建一个WaitNode，然后CAS修改当前waiters；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-2pex6kr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果等待超时，则调用removeWaiter移除等待节点，返回任务状态；如果设置了超时时间但是尚未超时，则park阻塞当前线程；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8joolzy&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其他情况直接阻塞当前线程。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;核心方法-Cancel--&quot;&gt;核心方法:Cancel()&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public boolean cancel(boolean mayInterruptIfRunning) {
 //如果当前状态为NEW，根据参数修改状态为INTERRUPTING或CANCELLED
  if (!(state == NEW &amp;amp;&amp;amp; STATE.compareAndSet
        (this, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED)))
    return false;
  try {    // in case call to interrupt throws exception
    if (mayInterruptIfRunning) {
      //可以在运行时中断
      try {
        Thread t = runner;
        if (t != null)
          t.interrupt();
      } finally { // final state
        STATE.setRelease(this, INTERRUPTED);
      }
    }
  } finally {
    finishCompletion();//移除并唤醒所有等待线程
  }
  return true;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;说明：尝试取消任务。如果任务已经完成或已经被取消，此操作会失败。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4ufxhem&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前Future状态为NEW，根据参数修改Future状态为INTERRUPTING或CANCELLED。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zsavrs6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果当前状态不为NEW，则根据参数mayInterruptIfRunning决定是否在任务运行中也可以中断。中断操作完成后，调用finishCompletion移除并唤醒所有等待线程。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[Future主要功能]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/Future/Future主要功能</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/Future/Future主要功能</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[Future]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Future主要功能&quot;&gt;Future主要功能&lt;/h1&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Future 最主要的作用是，比如当做一定运算的时候，运算过程可能比较耗时，有时会去查数据库，或是繁重的计算，比如压缩、加密等。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这种情况下，如果我们一直在原地等待方法返回，显然是不明智的，整体程序的运行效率会大大降低。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以把运算的过程放到子线程去执行，再通过 Future 去控制子线程执行的计算过程，最后获取到计算结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样一来就可以把整个程序的运行效率提高，是一种异步的思想。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Future接口&quot;&gt;Future接口&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Future代表着未来的计算结果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有一系列方法，比如检查检查计算结果是否完成，或者获取计算的结果。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public interface Future&amp;lt;V&amp;gt; {

    boolean cancel(boolean mayInterruptIfRunning);

    boolean isCancelled();

    boolean isDone();

    V get() throws InterruptedException, ExecutionException;

    V get(long timeout, TimeUnit unit)

        throws InterruptedException, ExecutionException, TimeoutExceptio

}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;cancel方法--取消任务执行&quot;&gt;cancel方法: 取消任务执行&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;调用cancel方法有三种情况:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-sdc3auh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务还没有开始，直接取消&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xr7oxul&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务已经完成，或者已经被取消过了会返回false。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ko83lv8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果任务正在执行，会根据mayInterruptIfRunning的状态来判断&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-dm1util&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果为true，会强制将任务结束，执行任务会收到中断信号&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-dzc4zjd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果为false，会在任务结束之后进行取消&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;isCancelled---方法-判断是否被取消&quot;&gt;isCancelled() 方法:判断是否被取消&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和cancel配合使用，比较简单&lt;/p&gt;
&lt;h3 id=&quot;isDown---判断是否执行完毕&quot;&gt;isDown():判断是否执行完毕&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回有两种情况:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-etdlxpv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回值为false代表未完成&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h3fou63&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;返回值为true,有两种情况&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-h4jumr8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务抛出了异常&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kyx6n3b&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;任务正常执行完毕&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最特殊的就是返回为true的情况，不代表任务是成功执行的，只代表执行完毕了。&lt;/p&gt;
&lt;h3 id=&quot;get----获取结果&quot;&gt;get(): 获取结果&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;get 方法最主要的作用就是获取任务执行的结果，该方法在执行时的行为取决于 Callable 任务的状态，可能会发生以下 5 种情况。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xe40kca&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;执行get的时候，任务已经执行完毕&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以立刻返回，获取到任务执行结果&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uvk2x6h&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;任务还没有结果&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池积压了很多任务，执行get的时候任务还没有开始&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;或者，任务开始执行了，但是执行时间较长，调用get的时候会将当前线程阻塞，直到任务完成再把结果返回回来&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x5xw5md&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;任务执行过程中抛出异常&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在调用get的时候，会抛出ExecutionException异常。不管执行的call方法里面抛出的异常类型是什么，执行get方法所获得的异常都是ExecutionException&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-wbmrpxa&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;任务被取消了&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果任务被取消，我们用 get 方法去获取结果时则会抛出 CancellationException。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lvx2nyo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;任务超时&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;get 方法有一个重载方法，那就是带延迟参数的，调用了这个带延迟参数的 get 方法之后，如果 call 方法在规定时间内正常顺利完成了任务，那么 get 会正常返回；但是如果到达了指定时间依然没有完成任务，get 方法则会抛出 TimeoutException，代表超时了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;基础实现&quot;&gt;基础实现&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;FutureTask为Future提供了基础实现。FutureTask常用来封装Callable和Runable，也可以作为一个任务提交到线程池中执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来看一下代码实现:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;传入callable作为构造函数，实际的执行逻辑在callable中&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class FutureTask&amp;lt;V&amp;gt; implements RunnableFuture&amp;lt;V&amp;gt;{
  ...
  public FutureTask(Callable&amp;lt;V&amp;gt; callable) {
        if (callable == null)
            throw new NullPointerException();
        this.callable = callable;
        this.state = NEW;       // ensure visibility of callable
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看到，它实现了一个接口，这个接口叫作 &lt;strong&gt;RunnableFuture&lt;/strong&gt;。我们再来看一下 RunnableFuture 接口的代码实现：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public interface RunnableFuture&amp;lt;V&amp;gt; extends Runnable, Future&amp;lt;V&amp;gt; {
    void run();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;他们的关系入下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211207205138417.png&quot; alt=&quot;image-20211207205138417&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从此可以看出，FutureTask既可以作为Runable被线程执行，又可以作为Future得到Callable的返回值。&lt;/p&gt;
&lt;h3 id=&quot;FutureTask示例&quot;&gt;FutureTask示例&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接使用:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class FutureDemo {
      public static void main(String[] args) {
          ExecutorService executorService = Executors.newCachedThreadPool();
          Future future = executorService.submit(new Callable&amp;lt;Object&amp;gt;() {
              @Override
              public Object call() throws Exception {
                  Long start = System.currentTimeMillis();
                  while (true) {
                      Long current = System.currentTimeMillis();
                     if ((current - start) &amp;gt; 1000) {
                         return 1;
                     }
                 }
             }
         });
  
         try {
             Integer result = (Integer)future.get();
             System.out.println(result);
         }catch (Exception e){
             e.printStackTrace();
         }
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有配合线程的使用:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ljgumw3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一种方式: Future + ExecutorService&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-z9esrky&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二种方式: FutureTask + ExecutorService&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ed11l89&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第三种方式: FutureTask + Thread&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import java.util.concurrent.*;
public class CallDemo {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
 
        /**
         * 第一种方式:Future + ExecutorService
         * Task task = new Task();
         * ExecutorService service = Executors.newCachedThreadPool();
         * Future&amp;lt;Integer&amp;gt; future = service.submit(task1);
         * service.shutdown();
         */
 
 
        /**
         * 第二种方式: FutureTask + ExecutorService
         * ExecutorService executor = Executors.newCachedThreadPool();
         * Task task = new Task();
         * FutureTask&amp;lt;Integer&amp;gt; futureTask = new FutureTask&amp;lt;Integer&amp;gt;(task);
         * executor.submit(futureTask);
         * executor.shutdown();
         */
 
        /**
         * 第三种方式:FutureTask + Thread
         */
 
        // 2. 新建FutureTask,需要一个实现了Callable接口的类的实例作为构造函数参数
        FutureTask&amp;lt;Integer&amp;gt; futureTask = new FutureTask&amp;lt;Integer&amp;gt;(new Task());
        // 3. 新建Thread对象并启动
        Thread thread = new Thread(futureTask);
        thread.setName(&amp;quot;Task thread&amp;quot;);
        thread.start();
 
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
 
        System.out.println(&amp;quot;Thread [&amp;quot; + Thread.currentThread().getName() + &amp;quot;] is running&amp;quot;);
 
        // 4. 调用isDone()判断任务是否结束
        if(!futureTask.isDone()) {
            System.out.println(&amp;quot;Task is not done&amp;quot;);
            try {
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        int result = 0;
        try {
            // 5. 调用get()方法获取任务结果,如果任务没有执行完成则阻塞等待
            result = futureTask.get();
        } catch (Exception e) {
            e.printStackTrace();
        }
 
        System.out.println(&amp;quot;result is &amp;quot; + result);
 
    }
 
    // 1. 继承Callable接口,实现call()方法,泛型参数为要返回的类型
    static class Task  implements Callable&amp;lt;Integer&amp;gt; {
        @Override
        public Integer call() throws Exception {
            System.out.println(&amp;quot;Thread [&amp;quot; + Thread.currentThread().getName() + &amp;quot;] is running&amp;quot;);
            int result = 0;
            for(int i = 0; i &amp;lt; 100;++i) {
                result += i;
            }
 
            Thread.sleep(3000);
            return result;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[使用CyclicBarrier解决团建问题]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程协作/使用CyclicBarrier解决团建问题</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程协作/使用CyclicBarrier解决团建问题</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程协作]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;使用CyclicBarrier解决团建问题&quot;&gt;使用CyclicBarrier解决团建问题&lt;/h1&gt;
&lt;h2 id=&quot;团建问题介绍&quot;&gt;团建问题介绍&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设有一家公司要全体员工进行团建活动，活动内容为爬山，但是由于每一个人爬山的时间都是不一样的，因此需要等到所有人都爬过山头之后才能够一起去吃饭，但是每个饭桌只能容纳2个人。&lt;/p&gt;
&lt;h2 id=&quot;模拟场景&quot;&gt;模拟场景&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们用代码模拟这个场景:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class PartyBuilding {
    public static void main(String[] args) {
        CyclicBarrier cyclicBarrier = new CyclicBarrier(2, () -&amp;gt; System.out.println(&amp;quot;有两人到齐了,干饭~~~&amp;quot;));
        Climbing employee1 = new Climbing(&amp;quot;甲&amp;quot;, cyclicBarrier);
        Climbing employee2 = new Climbing(&amp;quot;乙&amp;quot;, cyclicBarrier);
        Climbing employee3 = new Climbing(&amp;quot;丙&amp;quot;, cyclicBarrier);
        Climbing employee4 = new Climbing(&amp;quot;丁&amp;quot;, cyclicBarrier);
        Climbing employee5 = new Climbing(&amp;quot;戊&amp;quot;, cyclicBarrier);
        Climbing employee6 = new Climbing(&amp;quot;己&amp;quot;, cyclicBarrier);
        ExecutorService executorService = Executors.newFixedThreadPool(5);
        executorService.submit(employee1);
        executorService.submit(employee2);
        executorService.submit(employee3);
        executorService.submit(employee4);
        executorService.submit(employee5);
        executorService.submit(employee6);
    }

    public static class Climbing implements Runnable {
        private String name;
        private CyclicBarrier cyclicBarrier;

        public Climbing(String name, CyclicBarrier cyclicBarrier) {
            this.name = name;
            this.cyclicBarrier = cyclicBarrier;
        }

        @Override
        public void run() {
            System.out.println(&amp;quot;员工:&amp;quot; + name + &amp;quot;开始爬山~~&amp;quot;);
            try {
                long climbingTime = (long) (Math.random() * 4000);
                Thread.sleep(climbingTime);
                System.out.println(&amp;quot;员工:&amp;quot; + name + &amp;quot; 用时:&amp;quot; + climbingTime + &amp;quot;,等待人齐去吃饭~~&amp;quot;);
                cyclicBarrier.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行结果如下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;员工:乙开始爬山~~
员工:戊开始爬山~~
员工:甲开始爬山~~
员工:丁开始爬山~~
员工:丙开始爬山~~
员工:丁 用时:813,等待人齐去吃饭~~
员工:丙 用时:2022,等待人齐去吃饭~~
有两人到齐了,干饭~~~
员工:己开始爬山~~
员工:乙 用时:2500,等待人齐去吃饭~~
员工:己 用时:933,等待人齐去吃饭~~
有两人到齐了,干饭~~~
员工:甲 用时:3215,等待人齐去吃饭~~
员工:戊 用时:3898,等待人齐去吃饭~~
有两人到齐了,干饭~~~
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;能够看到，这段代码输出的结果，符合我们的预期&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从这段代码中，首先建了参数为2的一个CyclicBarrier，这意味着需要等待2个线程到达这个集结点才统一放行，每2个执行一次runable里面的干饭逻辑。&lt;/p&gt;
&lt;h2 id=&quot;CyclicBarrier-和-CountDownLatch-的异同&quot;&gt;CyclicBarrier 和 CountDownLatch 的异同&lt;/h2&gt;
&lt;h3 id=&quot;相同点&quot;&gt;相同点&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;都能够阻塞一个或一组线程，直到某个预设的条件达成发送，再统一出发。&lt;/p&gt;
&lt;h3 id=&quot;不同点&quot;&gt;不同点&lt;/h3&gt;
&lt;h4 id=&quot;作用对象不同&quot;&gt;作用对象不同&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CyclicBarrier作用于线程，需要等到线程执行完成之后，计数器则减一，到0的时候就继续执行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CountDownLatch作用于事件，需要通过调用countDown才能够计数器减一，直到0才继续执行。&lt;/p&gt;
&lt;h4 id=&quot;可重用性不同&quot;&gt;可重用性不同&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CyclicBarrier可以重复使用，在计时器归零后，会重置计时器重新开始计数，甚至还能通过reset主动重置计数器，如果重置时有线程已经调用await并开始等待，等待的线程会抛出BrokenBarrierException异常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CountDownLatch在倒数到0的时候，就不能再次使用了，除非新建一个新的实例。&lt;/p&gt;
&lt;h4 id=&quot;执行动作不同&quot;&gt;执行动作不同&lt;/h4&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CyclicBarrier有执行动作，在满足计数器归零的时候会调用barrierAction执行一个回调操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CountDownLatch没有这个功能&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[使用CompletableFuture解决旅游平台问题]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程协作/使用CompletableFuture解决旅游平台问题</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程协作/使用CompletableFuture解决旅游平台问题</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程协作]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;使用CompletableFuture解决旅游平台问题&quot;&gt;使用CompletableFuture解决旅游平台问题&lt;/h1&gt;
&lt;h2 id=&quot;旅游平台问题介绍&quot;&gt;旅游平台问题介绍&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果要搭建一个旅游平台，经常会有这样的需求，就是用户想同时获取多个航空公司的航班信息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如: 北京到上海的票价。由于有很多公司都有这样的航班信息，所以应该获取到所有航空公司的信息，然后聚合输出。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CompletableFuture.png&quot; alt=&quot;CompletableFuture&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;串行获取&quot;&gt;串行获取&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最传统的解决方案&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E4%B8%B2%E8%A1%8C%E8%8E%B7%E5%8F%96%E7%A4%BA%E6%84%8F%E5%9B%BE.png&quot; alt=&quot;串行获取示意图&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们获取价格的时候，先去访问&lt;code&gt;国航&lt;/code&gt;等&lt;code&gt;国航&lt;/code&gt;有响应之后，再去访问下一个航空公司，如果航空公司较多，每个响应都需要1s的话，十几个航空公司就是几十秒，用户肯定等不及。&lt;/p&gt;
&lt;h3 id=&quot;并行获取&quot;&gt;并行获取&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E5%B9%B6%E8%A1%8C%E8%8E%B7%E5%8F%96.png&quot; alt=&quot;并行获取&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们换成并行的去请求各个网站信息，效果就能好很多。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只需要规定一个超时的总时长，比如3s，3s之后返回的响应一概不管，只把前3s获取到的结果进行返回，即使数据有所丢失，但是也比一直等待的强。&lt;/p&gt;
&lt;h2 id=&quot;使用线程池实现&quot;&gt;使用线程池实现&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class PriceDemo {
    ExecutorService threadPool = Executors.newFixedThreadPool(3);
    public static void main(String[] args) throws InterruptedException {
        PriceDemo priceDemo = new PriceDemo();
        System.out.println(priceDemo.getPrices());
    }
    private Set&amp;lt;String&amp;gt; getPrices() throws InterruptedException {
        Set&amp;lt;String&amp;gt; prices = Collections.synchronizedSet(new HashSet&amp;lt;&amp;gt;());
        threadPool.submit(new Task(&amp;quot;国行&amp;quot;, prices));
        threadPool.submit(new Task(&amp;quot;海航&amp;quot;, prices));
        threadPool.submit(new Task(&amp;quot;东航&amp;quot;, prices));
        Thread.sleep(3000);
        return prices;
    }
    /**
     * 获取价格
     */
    private class Task implements Runnable {
        private String name;
        private Set&amp;lt;String&amp;gt; prices;

        public Task(String name, Set&amp;lt;String&amp;gt; prices) {
            this.name = name;
            this.prices = prices;
        }
        @Override
        public void run() {
            try {
                int price = (int) (Math.random() * 4000);
                Thread.sleep(price);
                prices.add(name + &amp;quot;: &amp;quot; + price);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在代码中，新建了一个线程安全的set，用于存储各个航空公司的价格信息。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后通过向线程池提交获取价格的任务，最后线程睡3s，模拟用户等待的时间，最后在3s之内获取到的结果进行返回。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这就是使用线程池去实现的最基础的方案。&lt;/p&gt;
&lt;h2 id=&quot;CountDownLatch&quot;&gt;&lt;a href=&quot;CountDownLatch详解.md&quot;&gt;CountDownLatch&lt;/a&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以采用CountDownLatch去对上面的代码进行一个优化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;上面的代码，最大的问题是无论如何都需要等待3秒，假如网络特别好，处理速度特别快，可能几百毫秒就返回了，所以就会白白等待一段时间。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以需要改进一下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class PriceDemo {
    ExecutorService threadPool = Executors.newFixedThreadPool(3);
    public static void main(String[] args) throws InterruptedException {
        PriceDemo priceDemo = new PriceDemo();
        System.out.println(priceDemo.getPrices());
    }
    private Set&amp;lt;String&amp;gt; getPrices() throws InterruptedException {
        Set&amp;lt;String&amp;gt; prices = Collections.synchronizedSet(new HashSet&amp;lt;&amp;gt;());
        CountDownLatch countDownLatch = new CountDownLatch(3);
        threadPool.submit(new Task(&amp;quot;国行&amp;quot;, prices, countDownLatch));
        threadPool.submit(new Task(&amp;quot;海航&amp;quot;, prices, countDownLatch));
        threadPool.submit(new Task(&amp;quot;东航&amp;quot;, prices, countDownLatch));
        countDownLatch.await(3, TimeUnit.SECONDS);
        return prices;
    }

    /**
     * 获取价格
     */
    private class Task implements Runnable {
        private String name;
        private Set&amp;lt;String&amp;gt; prices;
        private CountDownLatch countDownLatch;
        public Task(String name, Set&amp;lt;String&amp;gt; prices, CountDownLatch countDownLatch) {
            this.name = name;
            this.prices = prices;
            this.countDownLatch = countDownLatch;
        }
        @Override
        public void run() {
            try {
                int price = (int) (Math.random() * 4000);
                Thread.sleep(price);
                prices.add(name + &amp;quot;: &amp;quot; + price);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                countDownLatch.countDown();
            }
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用CoutDownLatch，来进行任务执行的统计，每完成一个任务，CoutDownLatch的数量则减一。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后使用await进行等待，await方法会阻塞当前线程，只有任务执行完，或者在规定时间内没有响应才会往下走。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这就可以保证，总用时会永远小于等于3s.&lt;/p&gt;
&lt;h2 id=&quot;CompletableFuture&quot;&gt;CompletableFuture&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CompletableFuture 提供了简单快速的方法让我们去实现上面使用CountDownLatch实现的代码逻辑。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static void main(String[] args) throws InterruptedException {
        PriceDemo priceDemo = new PriceDemo();
        System.out.println(priceDemo.getPrices());
    }

    private Set&amp;lt;String&amp;gt; getPrices() throws InterruptedException {
        Set&amp;lt;String&amp;gt; prices = Collections.synchronizedSet(new HashSet&amp;lt;&amp;gt;());
        CompletableFuture&amp;lt;Void&amp;gt; task1 = CompletableFuture.runAsync(new Task(&amp;quot;国行&amp;quot;, prices));
        CompletableFuture&amp;lt;Void&amp;gt; task2 = CompletableFuture.runAsync(new Task(&amp;quot;海航&amp;quot;, prices));
        CompletableFuture&amp;lt;Void&amp;gt; task3 = CompletableFuture.runAsync(new Task(&amp;quot;东航&amp;quot;, prices));
        CompletableFuture&amp;lt;Void&amp;gt; allTask = CompletableFuture.allOf(task1, task2, task3);
        try {
            allTask.get(3,TimeUnit.SECONDS);
        } catch (ExecutionException | TimeoutException e) {
            e.printStackTrace();
        }
        return prices;
    }
    /**
     * 获取价格
     */
    private class Task implements Runnable {
        private String name;
        private Set&amp;lt;String&amp;gt; prices;
        public Task(String name, Set&amp;lt;String&amp;gt; prices) {
            this.name = name;
            this.prices = prices;
        }
        @Override
        public void run() {
            try {
                int price = (int) (Math.random() * 4000);
                Thread.sleep(price);
                prices.add(name + &amp;quot;: &amp;quot; + price);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以从代码中看到，CompletableFuture对Task进行了包装，然后通过allOf将所有任务聚合起来，最后通过allTask.get()阻塞线程，如果任务超时会进入异常中，我们可以根据异常再去做对应的异常处理，相对于自己使用CountDownLatch实现的，功能性会多一些。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[CountDownLatch详解]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程协作/CountDownLatch详解</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程协作/CountDownLatch详解</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程协作]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;CountDownLatch详解&quot;&gt;CountDownLatch详解&lt;/h1&gt;
&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CountDownLatch是由AQS实现的，用来同步一个或多个任务的并发工具类。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;利用它可以实现类似计数器的功能，比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就像下面的这个例子，主线程会阻塞到&lt;code&gt;Thread-1&lt;/code&gt;、和&lt;code&gt;Thread-2&lt;/code&gt;都执行完成之后，才能往下执行&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Test {
    public static void main(String[] args) {
        final CountDownLatch latch = new CountDownLatch(2);
        new Thread() {
            public void run() {
                try {
                    System.out.println(&amp;quot;子线程&amp;quot; + Thread.currentThread().getName() + &amp;quot;正在执行&amp;quot;);
                    Thread.sleep(3000);
                    System.out.println(&amp;quot;子线程&amp;quot; + Thread.currentThread().getName() + &amp;quot;执行完毕&amp;quot;);
                    latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            };
        }.start();
        new Thread() {
            public void run() {
                try {
                    System.out.println(&amp;quot;子线程&amp;quot; + Thread.currentThread().getName() + &amp;quot;正在执行&amp;quot;);
                    Thread.sleep(3000);
                    System.out.println(&amp;quot;子线程&amp;quot; + Thread.currentThread().getName() + &amp;quot;执行完毕&amp;quot;);
                    latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            };
        }.start();
        try {
            System.out.println(&amp;quot;等待2个子线程执行完毕...&amp;quot;);
            latch.await();
            System.out.println(&amp;quot;2个子线程已经执行完毕&amp;quot;);
            System.out.println(&amp;quot;继续执行主线程&amp;quot;);
        } catch (InterruptedException e) { e.printStackTrace();   }    }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;输出结果:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;等待2个子线程执行完毕...
子线程Thread-1正在执行
子线程Thread-0正在执行
子线程Thread-0执行完毕
子线程Thread-1执行完毕
2个子线程已经执行完毕
继续执行主线程
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Semaphore信号量]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/线程协作/Semaphore信号量</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/线程协作/Semaphore信号量</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[线程协作]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Semaphore信号量&quot;&gt;Semaphore信号量&lt;/h1&gt;
&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Semaphore，通常我们叫它信号量，用于控制同时访问特定资源的线程数量，用于协调各个线程，以确保合理利用资源。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示，Semaphore在图中充当一个保镖的角色，在同一时刻只允许放行3个线程进来，其他的线程就在外面排队。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Semaphore.png&quot; alt=&quot;Semaphore&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Semaphore会维护一个计数器，用于标记许可证的计数，线程去访问共享资源之前，需要先获取许可证，这时Semaphore持有的信号量需要-1，只要持有的数量为0 ，这时新的线程想要继续访问受保护的资源时，只有等待，等到其他持有许可证的线程释放了手中的许可证。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;利用这种特性，可以很容易做出限流的功能&lt;/p&gt;
&lt;h2 id=&quot;限流实现&quot;&gt;限流实现&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;请求访问到我们的应用上面，而这个应用又依赖这个慢服务&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E6%85%A2%E6%9C%8D%E5%8A%A1.png&quot; alt=&quot;慢服务&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，就为了保证那个慢服务不被打垮，就需要对进来的请求进行一个限流的操作。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class TestSemaphore2 {
    final static Semaphore semaphore = new Semaphore(3);
    public static void main(String[] args) {
        ExecutorService pool = Executors.newFixedThreadPool(30);
        for (int i = 0; i &amp;lt; 1000; i++) {
            pool.submit(new Task());
        }
    }
    static class Task implements Runnable {
        @Override
        public void run() {
            try {
                semaphore.acquire();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName() + &amp;quot;拿到了许可证&amp;quot;);
            try {
                // 模拟业务耗时操作
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(&amp;quot;慢服务执行完毕，&amp;quot; + Thread.currentThread().getName() + &amp;quot;释放了许可证&amp;quot;);
            semaphore.release();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这段代码中新建了一个数量为3的信号量，也就意味着同时只有3个线程可以访问我们的慢服务，其他线程则处于等待状态。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在线程最开始，通过acquire方法申请许可证（信号量持有的许可证会-1）,然后进行业务耗时操作，执行完成之后通过release()方法释放许可证。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;许可证为0的情况下，调用accquire会阻塞。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最后打印出来的结果:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;pool-1-thread-2拿到了许可证
pool-1-thread-3拿到了许可证
pool-1-thread-4拿到了许可证
慢服务执行完毕，pool-1-thread-2释放了许可证
慢服务执行完毕，pool-1-thread-3释放了许可证
慢服务执行完毕，pool-1-thread-4释放了许可证
pool-1-thread-1拿到了许可证
pool-1-thread-6拿到了许可证
pool-1-thread-7拿到了许可证
慢服务执行完毕，pool-1-thread-6释放了许可证
慢服务执行完毕，pool-1-thread-7释放了许可证
慢服务执行完毕，pool-1-thread-1释放了许可证
....
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过运行结果可以看出，最多只有3个线程可以访问我们的慢服务&lt;/p&gt;
&lt;h2 id=&quot;思考--FixedThreadPool可以替代Semaphore么-&quot;&gt;思考: FixedThreadPool可以替代Semaphore么?&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果我们把上面的例子，声明线程池的时候数量直接限死为3，是不是也能达到Semaphore的效果。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;来尝试一下:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class TestSemaphore2 {
    public static void main(String[] args) {
        ExecutorService pool = Executors.newFixedThreadPool(3);
        for (int i = 0; i &amp;lt; 1000; i++) {
            pool.submit(new Task());
        }
    }
    static class Task implements Runnable {
        @Override
        public void run() {
            System.out.println(Thread.currentThread().getName() + &amp;quot;拿到了许可证&amp;quot;);
            try {
                // 模拟业务耗时操作
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(&amp;quot;慢服务执行完毕，&amp;quot; + Thread.currentThread().getName() + &amp;quot;释放了许可证&amp;quot;);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行结果:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;pool-1-thread-1拿到了许可证
pool-1-thread-3拿到了许可证
pool-1-thread-2拿到了许可证
慢服务执行完毕，pool-1-thread-3释放了许可证
慢服务执行完毕，pool-1-thread-2释放了许可证
慢服务执行完毕，pool-1-thread-1释放了许可证
pool-1-thread-3拿到了许可证
pool-1-thread-1拿到了许可证
pool-1-thread-2拿到了许可证
慢服务执行完毕，pool-1-thread-1释放了许可证
pool-1-thread-1拿到了许可证
慢服务执行完毕，pool-1-thread-2释放了许可证
pool-1-thread-2拿到了许可证
慢服务执行完毕，pool-1-thread-3释放了许可证
pool-1-thread-3拿到了许可证
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从执行结果看出来，好像和使用Semaphore的结果一样的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其原因是，线程池最大就限制了3个线程，那么自然最多只有三个线程同时去访问。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;那意味着，是不是固定数量的FixedThreadPool能够被Semaphore替代了呢？&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;答案是否定的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为在实际的业务场景中，Semaphore是搭配着某些限制条件来进行使用的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就比如，每天秒杀系统，在秒杀的那个时刻我们只希望有少量的单子可以成功下单，但是在绝大部分的时候，我们就不应该限制，那么用线程池去控制灵活度就不高了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此外，Semaphore作为一个类单独来使用，可以具备跨线程、跨线程池的特定，所以即便是在不同的线程、线程池中都发起请求，我们也能够限制访问的数量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用FixedThreadPool去限制，那就做不到这么灵活控制，功能会大大的削弱。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[伪共享]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/伪共享</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/伪共享</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;伪共享&quot;&gt;伪共享&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在看ForkjoinPool源码的时候可以看到class上加上了@sun.misc.Contended的注解。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个注解，在业务中鲜有用到，不过在极端并发倒是常用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个注解就是为了避免进行&amp;quot;伪共享&amp;quot;。&lt;/p&gt;
&lt;h2 id=&quot;什么是伪共享&quot;&gt;什么是伪共享&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;伪共享的诞生是有因为有CPU缓存。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现代CPU的架构:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/CPU.png&quot; alt=&quot;CPU&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CPU和内存之间有个缓存的概念。有L1、L2、L3三种等级，离CPU越近容量越小、速度越快；离CPU越远容量越大、速度越慢；&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;L1、L2集成在CPU上，L3集成在主板上。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CPU是通过缓存行来进行缓存的，大小为2的整数幂，主流大小为64个字节。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果，多个变量同属于同一个缓存行，在并发情况下修改的时候，由于写屏障和内存一致性协议，导致同一时间只有一个线程能对这个缓存行进行操作，进而导致竞争性能下降。这就是&lt;code&gt;伪共享&lt;/code&gt;的概念,原本不应该共享的变量，由于硬件的特性导致性能下降。&lt;/p&gt;
&lt;h2 id=&quot;JVM中的伪共享&quot;&gt;JVM中的伪共享&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E4%BC%AA%E5%85%B1%E4%BA%AB.png&quot; alt=&quot;伪共享&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在程序运行的过程中，缓存每次更新都从主内存中加载连续的 64 个字节。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此，如果访问一个 long 类型的数组时，当数组中的一个值被加载到缓存中时，另外 7 个元素也会被加载到缓存中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假如，我们使用的是数组进行存储的话，这种自动加载机制可以带来新能上的提升。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，也就意味着，假如要加载变量A的话，不是数组而是单独的一个变量，这时相邻的有个B变量，B变量也将被载入进来。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前者修改 a 时，会把 a 和 b 同时加载到前者核心的缓存行中，更新完 A 后其它所有包含 A 的缓存行都将失效，因为其它缓存中的 A 不是最新值了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而当后者读取 B 时，发现这个缓存行已经失效了，需要从主内存中重新加载。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就出现了一个问题，A 和 B完全不相干，每次却要因为 A 的更新需要从主内存重新读取，它被缓存未命中给拖慢了。&lt;/p&gt;
&lt;h3 id=&quot;如何避免&quot;&gt;如何避免&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就是利用@sun.misc.Contended注解，这个注解是java1.8之后提出的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加上这个注解的类会自动补齐缓存行，需要注意的是此注解默认是无效的，需要在 jvm 启动时设置 &lt;code&gt;-XX:-RestrictContended&lt;/code&gt; 才会生效。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;比如原本变量A的长度仅有8个字节，它会前后帮我们补上54个字节。这样我们的变量就能独占一个缓存行，也就避免了多线程同时更新同一个缓存行带来的伪共享问题。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Java内存模型介绍]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/java内存模型/Java内存模型介绍</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/java内存模型/Java内存模型介绍</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><category><![CDATA[java内存模型]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Java内存模型介绍&quot;&gt;Java内存模型介绍&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java内存模型，又被称之为JMM，即Java Memory Model。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个模型用于并发编程中的，线程之间通讯以及线程之间的同步&lt;/p&gt;
&lt;h2 id=&quot;容易混淆的JVM内存结构和Java内存模型&quot;&gt;容易混淆的JVM内存结构和Java内存模型&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JVM内存结构，有的也称之为Java内存结构，与内存模型是截然不同的两种东西。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JVM的内存结构，是用于描述Java代码在编译成class是如何存储运行的，划分为两类:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-v17nhgq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程共享的&lt;code&gt;堆&lt;/code&gt;、&lt;code&gt;方法区&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-d8hfs1c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程独享的&lt;code&gt;栈&lt;/code&gt;,栈中包含程序运行时的&lt;code&gt;程序计数器&lt;/code&gt;、&lt;code&gt;本地方法栈&lt;/code&gt;、&lt;code&gt;虚拟机栈&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而Java内存模型，则是描述的是线程之间的通讯和线程之间的同步，与变法变成有关。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以可以看出，这两种概念还是有所区别的。&lt;/p&gt;
&lt;h3 id=&quot;JVM内存结构&quot;&gt;JVM内存结构&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们都知道编写的代码是要运行在虚拟机上的，而虚拟机在执行Java程序的过程中会把所管理的内存划分成不同功能的数据区域。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下乳所示，就是从1.6版本的内存结构，逐渐进化到1.8的结构&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/JVM.png&quot; alt=&quot;JVM&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-p15zkqc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;虚拟机栈: 保存局部变量和部分结果，方法调用和变量的存储都需要通过它。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-idbkdor&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本地方法栈: 和虚拟机栈类似，只不过代表着调用操作系统级别的操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-47dwazk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;程序计数器: 是最小的一块区域，保存着当前正在执行的JVM的指令地址，通俗来说，代码执行到哪里了。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-qj62ssx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行时常量池: 保留着各种常量，在编译时候定义的常量就会在这个里面&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ffvu7mw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;方法区: 存储这每个类的结构。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rkoo4ck&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;堆: 内存划分中最大的一块，用于存储类实例和数组的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;JMM的引入&quot;&gt;JMM的引入&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们从上图中能够看到，线程A和线程B 如果同时要对堆中实例进行操作，就会出现问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为，线程只能够访问自己的线程堆栈，如果要操作堆中的实例，需要将堆中的实例给同步到自己的栈中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程A和线程B同时将堆中的一个变量C同步到栈中，那么线程A对C的修改，这个时候B是无感知的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以就有了JMM内存模型，这个模型就是为了解决线程和线程之间的通讯同步问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png&quot; alt=&quot;内存模型&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;JMM的含义&quot;&gt;JMM的含义&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JMM是针对多线程开发的一组规范，由于JVM是由各个不同的厂商开发的，所以要求各个厂商开发JVM的时候得统一遵循多线程开发规范，以便于使用者可以利用这些规范更加方便的开发多线程程序。这样一来即便是同一段程序在不同的虚拟机上运行，得到的结果也是一致的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们在使用了各种同步工具和关键字的时候，比如synchronized、Lock等，它们的底层原理都涉及到JMM。&lt;/p&gt;
&lt;h2 id=&quot;JMM与硬件结构的关系&quot;&gt;JMM与硬件结构的关系&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现代硬件内存架构与JMM的模型略有不同，Java的内存模型是基于现代内存架构的更高级别的抽象。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这是现代计算机硬件架构的示意图:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%A1%AC%E4%BB%B6%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84.png&quot; alt=&quot;硬件内存架构&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现代计算机通常有2个或更多CPU。 其中一些CPU也可能有多个内核。 关键是，在具有2个或更多CPU的现代计算机上，可以同时运行多个线程。 每个CPU都能够在任何给定时间运行一个线程。 这意味着如果您的Java应用程序是多线程的，线程真的在可能同时运行.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个CPU基本上都包含一组在CPU内存中的寄存器。 CPU可以在这些寄存器上执行的操作比在主存储器中对变量执行的操作快得多。 这是因为CPU可以比访问主存储器更快地访问这些寄存器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;每个CPU还可以具有CPU高速缓存存储器层。 事实上，大多数现代CPU都有一些大小的缓存存储层。 CPU可以比主存储器更快地访问其高速缓存存储器，但通常不会像访问其内部寄存器那样快。 因此，CPU高速缓存存储器介于内部寄存器和主存储器的速度之间。 某些CPU可能有多个缓存层(级别1和级别2)，但要了解Java内存模型如何与内存交互，这一点并不重要。 重要的是要知道CPU可以有某种缓存存储层。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;计算机还包含主存储区(RAM)。 所有CPU都可以访问主内存。 主存储区通常比CPU的高速缓存存储器大得多。同时访问速度也就较慢.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通常，当CPU需要访问主存储器时，它会将部分主存储器读入其CPU缓存。 它甚至可以将部分缓存读入其内部寄存器，然后对其执行操作。 当CPU需要将结果写回主存储器时，它会将值从其内部寄存器刷新到高速缓冲存储器，并在某些时候将值刷新回主存储器。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;是不是和上面的JMM内存模型十分相似。在多个CPU，读取同一块的内存信息时候，也存在着竞争的操作。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[happens-before规则]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/java内存模型/happens-before规则</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/java内存模型/happens-before规则</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><category><![CDATA[java内存模型]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;happens-before规则&quot;&gt;happens-before规则&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在JSR-133规范中，提出了happens-before的概念，通过这个概念来阐述操作之间的内存可见性。&lt;/p&gt;
&lt;h2 id=&quot;什么是happens-before关系&quot;&gt;什么是happens_before关系&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果一个操作的执行结果需要对另一个操作可见，那么这两个操作必须存在happens-before的关系。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也就是说，在第二个操作执行的时候一都能够保证看到第一个操作执行的结果。&lt;/p&gt;
&lt;h2 id=&quot;不具备happens-before的例子&quot;&gt;不具备happens_before的例子&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Visibility {
    int x = 0;
    public void write() {
        x = 1;
    }
    public void read() {
        int y = x;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果有两个线程，分别执行write和read方法，由于这两个线程没有相互配合的机制，所以write和read方法内的代码不具备happens_before关系, 其中的变量的可见性无法保证。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;假设线程 1 已经先执行了 write 方法，修改了共享变量 x 的值，然后线程 2 执行 read 方法去读取 x 的值，此时我们并不能确定线程 2 现在是否能读取到之前线程 1 对 x 所做的修改，线程 2 有可能看到这次修改，所以读到的 x 值是 1，也有可能看不到本次修改，所以读到的 x 值是最初始的 0。既然存在不确定性，那么 write 和 read 方法内的代码就不具备 happens-before 关系。相反，如果第一个操作 happens-before 第二个操作，那么第一个操作对于第二个操作而言一定是可见的。&lt;/p&gt;
&lt;h2 id=&quot;happens-before的规则有哪些&quot;&gt;happens_before的规则有哪些&lt;/h2&gt;
&lt;h3 id=&quot;单线程规则&quot;&gt;单线程规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在一个单独的线程中，按照代码的顺序，先执行的操作happens-before后执行的操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;单线程，无需考虑happens-before，反过来想，如果单线程的代码执行不能保证，岂不是乱套了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/happens-before.png&quot; alt=&quot;happens-before&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注意: 在单线程中，即使发生了指令重排，重排后的语义也必须符合happens-before的原则。&lt;/p&gt;
&lt;h3 id=&quot;锁操作规则&quot;&gt;锁操作规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;synchronized和lock接口。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果操作A是解锁，而操作B是对同一个锁的加锁，那么hb(A,B)&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/LockHappensBefor.png&quot; alt=&quot;LockHappensBefor&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从上图中可以看到，有线程 A 和线程 B 这两个线程。线程 A 在解锁之前的所有操作，对于线程 B 的对同一个锁的加锁之后的所有操作而言，都是可见的。&lt;/p&gt;
&lt;h3 id=&quot;volatile变量规则&quot;&gt;volatile变量规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对volatile变量的写操作happens-before后面对该变量的操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这就代表了呗volatile修饰的变量，每次修改之后，其他线程读取这个变量的时候，可以读取到这个变量的最新值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;volatile可以保证可见性，就是由于这条规则规定的&lt;/p&gt;
&lt;h3 id=&quot;线程启动规则&quot;&gt;线程启动规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt; Thread 对象的 start 方法 happen-before 此线程 run 方法中的每一个操作。如下图所示：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl57Dw6AdKyOAADBt-00qXo349.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在图中的例子中，左侧区域是线程 A 启动了一个子线程 B，而右侧区域是子线程 B，那么子线程 B 在执行 run 方法里面的语句的时候，它一定能看到父线程在执行 threadB.start() 前的所有操作的结果。&lt;/p&gt;
&lt;h3 id=&quot;线程join规则&quot;&gt;线程join规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们知道 join 可以让线程之间等待，假设线程 A 通过调用 threadB.start() 启动了一个新线程 B，然后调用 threadB.join() ，那么线程 A 将一直等待到线程 B 的 run 方法结束（不考虑中断等特殊情况），然后 join 方法才返回。在 join 方法返回后，线程 A 中的所有后续操作都可以看到线程 B 的 run 方法中执行的所有操作的结果，也就是线程 B 的 run 方法里面的操作 happens-before 线程 A 的 join 之后的语句。如下图所示：&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/Cgq2xl57Dw6ADE7rAADRJKFrbWE816.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;中断规则&quot;&gt;中断规则&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;对线程的interrupt方法的调用happens-before检测该线程的中断事件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也就是说，如果一个线程被其他线程 interrupt，那么在检测中断时（比如调用 Thread.interrupted 或者 Thread.isInterrupted 方法）一定能看到此次中断的发生，不会发生检测结果不准的情况。&lt;/p&gt;
&lt;h3 id=&quot;并发工具类的规则&quot;&gt;并发工具类的规则&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-g85w22j&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程安全的并发容器（如 HashTable）在 get 某个值时一定能看到在此之前发生的 put 等存入操作的结果。也就是说，线程安全的并发容器的存入操作 happens-before 读取操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-eajvops&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;信号量（Semaphore）它会释放许可证，也会获取许可证。这里的释放许可证的操作 happens-before 获取许可证的操作，也就是说，如果在获取许可证之前有释放许可证的操作，那么在获取时一定可以看到。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-30mhep4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Future：Future 有一个 get 方法，可以用来获取任务的结果。那么，当 Future 的 get 方法得到结果的时候，一定可以看到之前任务中所有操作的结果，也就是说 Future 任务中的所有操作 happens-before Future 的 get 操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-optpn9i&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;线程池：要想利用线程池，就需要往里面提交任务（Runnable 或者 Callable），这里面也有一个 happens-before 关系的规则，那就是提交任务的操作 happens-before 任务的执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要重点掌握的是，锁操作的happens-before和volatile的happens-before规则。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这两个规则与synchronized和volatile的使用有紧密的联系。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;除这两个之外的规则，可以不作为重点了解，这些规则都是被当做已知条件去使用的。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Thread的状态]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发基础/线程基础/Thread的状态</link><guid isPermaLink="false">/topic/Java并发工具包/并发基础/线程基础/Thread的状态</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发基础]]></category><category><![CDATA[线程基础]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Thread的状态&quot;&gt;Thread的状态&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20211101163645288.png&quot; alt=&quot;image-20211101163645288&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;New&quot;&gt;New&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;new状态标识Thread已经创建了，也就是new Thread() ,但是没有调用start方法。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一旦调用start方法，状态就会从New 转换成 Runable&lt;/p&gt;
&lt;h2 id=&quot;Runable&quot;&gt;Runable&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java中的Runable状态，对应着操作系统中的两种状态Running 或者 Ready&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java重处于Runable中的线程，有可能处于正在&lt;code&gt;执行&lt;/code&gt;的状态，也有可能处于没有正在&lt;code&gt;执行&lt;/code&gt;等待分配CPU资源&lt;/p&gt;
&lt;h2 id=&quot;阻塞态&quot;&gt;阻塞态&lt;/h2&gt;
&lt;h3 id=&quot;Block&quot;&gt;Block&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从Runable进入到Block只会有一种情况，在Synchronized修饰的代码运行时没有获取到monitor锁的时候，会进入Block状态&lt;/p&gt;
&lt;h3 id=&quot;Timed-Watting&quot;&gt;Timed Watting&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;进入timed watting有三种可能性&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-x0w7zk0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;设置timeout参数的Object.wait()&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ej1nkfi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;设置timeout参数的Thread.join()&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-vr0myz0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LockSuport.parkUntil(timeout)或LockSuport.parkNanos(timeout)方法&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Watting&quot;&gt;Watting&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;进入watting有三种可能性&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-4bsfc12&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;没有设置timeout参数的Object.wait()&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5bgyo6p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;没有设置timeout参数的Thread.join()&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-r7l70sw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;LockSuport.park()方法&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果其他线程调用notify或者notifyAll方法来唤醒线程，会直接进入到block状态。因为唤醒watting的线程必须要持有monitor，所以处于watting状态的线程被唤醒时拿不到monitor锁则会进入block状态&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[分布式事务]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案/数据调度/分布式事务</link><guid isPermaLink="false">/topic/分布式解决方案/数据调度/分布式事务</guid><category><![CDATA[分布式解决方案]]></category><category><![CDATA[数据调度]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式事务&quot;&gt;分布式事务&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[分布式解决方案]]></title><link>https://www.ztianzeng.com/topic/分布式解决方案</link><guid isPermaLink="false">/topic/分布式解决方案</guid><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;分布式解决方案&quot;&gt;分布式解决方案&lt;/h1&gt;
&lt;br/&gt;
</content:encoded></item><item><title><![CDATA[ConcurrentHashMap详解]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/并发容器/ConcurrentHashMap详解</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/并发容器/ConcurrentHashMap详解</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[并发容器]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;ConcurrentHashMap详解&quot;&gt;ConcurrentHashMap详解&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConcurrentHashMap是JUC包中提供的一个高性能并且线程安全的map集合。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相对于Hashtable这种, 对操作进行synchronized加锁的，ConcurrentHashMap却是用分段锁或者cas来操作的极大地提高了效率。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConcurrentHashMap在JDK 1.7和1.8中的实现并不相同，所以我们分开来说。&lt;/p&gt;
&lt;h2 id=&quot;ConcurrentHashMap-JDK7&quot;&gt;ConcurrentHashMap_JDK7&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在JDK1.5~1.7版本，Java使用了分段锁机制实现ConcurrentHashMap。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分段锁，简单来说就是将Hash表划分成多段——Segment数组，每段单独进行上锁，每个段这个时候就相当于一个线程安全的HashTable。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在进行put的时候，根据Hash算法定位到某个Segment元素上，然后对此Segment进行加锁即可，避免了整个Hash表加锁。&lt;/p&gt;
&lt;h3 id=&quot;数据结构&quot;&gt;数据结构&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在不指定的时候，ConcurrentHashMap会将默认初始化一个长度为16的segment数组。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConcurrentHashMap本质上是一个Segment 数组，Segment通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/ConcurrentHashMap.png&quot; alt=&quot;ConcurrentHashMap&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;初始化&quot;&gt;初始化&lt;/h3&gt;
&lt;h3 id=&quot;初始化-&quot;&gt;初始化&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;/**
     * 初始化创建一个指定了初始容量、负载因子、并行等级的map
     * 
     * @param initialCapacity 初始容量，这个值指的是整个ConcurrentHashMap的初始容量,实际操作的时候需要平均分给每个 
     * Segment。
     * @param loadFactor 负载因子，用于判断扩容的临界值
     * @param concurrencyLevel 默认16，并发数、Segment数组大小、并行级别。
     * 默认16就意味着最多只有16个线程同时写
     */
    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
    public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor &amp;gt; 0) || initialCapacity &amp;lt; 0 || concurrencyLevel &amp;lt;= 0)
            throw new IllegalArgumentException();
        if (concurrencyLevel &amp;gt; MAX_SEGMENTS)
            concurrencyLevel = MAX_SEGMENTS;
        // Find power-of-two sizes best matching arguments
        int sshift = 0;
        int ssize = 1;
        // 计算并行级别 ssize，因为要保持并行级别是 2 的 n 次方
        while (ssize &amp;lt; concurrencyLevel) {
            ++sshift;
            ssize &amp;lt;&amp;lt;= 1;
        }
       // concurrencyLevel 为 16，sshift 为 4
       // 那么计算出 segmentShift 为 28，segmentMask 为 15，后面会用到这两个值
        this.segmentShift = 32 - sshift;
        this.segmentMask = ssize - 1;
        if (initialCapacity &amp;gt; MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
      // initialCapacity 是设置整个 map 初始的大小，
      // 这里根据 initialCapacity 计算 Segment 数组中每个位置可以分到的大小
      // 如 initialCapacity 为 64，那么每个 Segment 或称之为&amp;quot;槽&amp;quot;可以分到 4 个
        int c = initialCapacity / ssize;
        if (c * ssize &amp;lt; initialCapacity)
            ++c;
         // 默认 MIN_SEGMENT_TABLE_CAPACITY 是 2，这个值也是有讲究的，因为这样的话，对于具体的槽上，
        // 插入一个元素不至于扩容，插入第二个的时候才会扩容
        int cap = MIN_SEGMENT_TABLE_CAPACITY;
        while (cap &amp;lt; c)
            cap &amp;lt;&amp;lt;= 1;
        // create segments and segments[0]
        // 创建 Segment 数组，
      // 并创建数组的第一个元素 segment[0]
        Segment&amp;lt;K,V&amp;gt; s0 =
            new Segment&amp;lt;K,V&amp;gt;(loadFactor, (int)(cap * loadFactor),
                             (HashEntry&amp;lt;K,V&amp;gt;[])new HashEntry[cap]);
        Segment&amp;lt;K,V&amp;gt;[] ss = (Segment&amp;lt;K,V&amp;gt;[])new Segment[ssize];
        // 往数组写入segment[0]
        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
        this.segments = ss;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;初始化完成，我们得到了一个 Segment 数组。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们就当是用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-2laoo7a&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Segment 数组长度为 16，不可以扩容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ykrdenx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ej41nry&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tennlox&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当前 segmentShift 的值为 32 - 4 = 28，segmentMask 为 16 - 1 = 15，姑且把它们简单翻译为移位数和掩码，这两个值马上就会用到&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;put过程分析&quot;&gt;put过程分析&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConcurrentHashMap是通过key的hash寻找两次进行插入，第一次是找出Segment，第二次是找出具体的Hash&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; public V put(K key, V value) {
        Segment&amp;lt;K,V&amp;gt; s;
        if (value == null)
            throw new NullPointerException();
   			// 计算key的Hash值
        int hash = hash(key.hashCode());
        //  根据 hash 值找到 Segment 数组中的位置 j
        //    hash 是 32 位，无符号右移 segmentShift(28) 位，剩下高 4 位，
        //    然后和 segmentMask(15) 做一次与操作，也就是说 j 是 hash 值的高 4 位，也就是槽的数组下标
        int j = (hash &amp;gt;&amp;gt;&amp;gt; segmentShift) &amp;amp; segmentMask;
   			// 初始化的时候初始化了 segment[0]，但是其他位置还是 null，
       // ensureSegment(j) 对 segment[j] 进行初始化
        if ((s = (Segment&amp;lt;K,V&amp;gt;)UNSAFE.getObject          // nonvolatile; recheck
             (segments, (j &amp;lt;&amp;lt; SSHIFT) + SBASE)) == null) //  in ensureSegment
            s = ensureSegment(j);
         // 找到槽s了，通过槽s暴露出的方法进行put操作
        return s.put(key, hash, value, false);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Segment暴露出来的put方法:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;final V put(K key, int hash, V value, boolean onlyIfAbsent) {
            // 分段锁来了~，这一步只对这一段进行了一个加锁，以确保线程安全
            HashEntry&amp;lt;K,V&amp;gt; node = tryLock() ? null :
                scanAndLockForPut(key, hash, value);
            V oldValue;
            try {
                // segment内部的数组,存放元素的地方
                HashEntry&amp;lt;K,V&amp;gt;[] tab = table;
              	// 第二次，利用hash值取得在内部数组中的位置
                int index = (tab.length - 1) &amp;amp; hash;
                // first 是数组该位置处的链表的表头
                HashEntry&amp;lt;K,V&amp;gt; first = entryAt(tab, index);
              	// 接下来就是一大段循环链表的操作，用于插入具体元素
                for (HashEntry&amp;lt;K,V&amp;gt; e = first;;) {
                  	// 当链表中的元素不为空的时候
                    if (e != null) {
                        K k;
                      	// 加入，put的元素正好存在链表中，则把老的给替换掉
                        if ((k = e.key) == key ||
                            (e.hash == hash &amp;amp;&amp;amp; key.equals(k))) {
                            oldValue = e.value;
                            if (!onlyIfAbsent) {
                                e.value = value;
                                ++modCount;
                            }
                            break;
                        }
                      	// 寻找下一个
                        e = e.next;
                    }
                    else {
                        // 到这个判断逻辑中，则说明了链表到了末尾 
                       // node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。
                       // 采用头插法进行插入。
                       // 如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。																		 // 这也是区别于HashMap的地方，HashMap1.7中也是采用头插法但由于没有锁，扩容时会导致循环链表的出现
                        if (node != null)
                            node.setNext(first);
                        else
                            node = new HashEntry&amp;lt;K,V&amp;gt;(hash, key, value, first);
                        int c = count + 1;
                        // 如果超过了该 segment 的阈值，这个 segment 需要扩容
                        if (c &amp;gt; threshold &amp;amp;&amp;amp; tab.length &amp;lt; MAXIMUM_CAPACITY)
                            rehash(node);
                        else
                            // 没有达到阈值，将 node 放到数组 tab 的 index 位置，
                          // 其实就是将新的节点设置成原链表的表头
                            setEntryAt(tab, index, node);
                        ++modCount;
                        count = c;
                        oldValue = null;
                        break;
                    }
                }
            } finally {
               // 解锁
                unlock();
            }
            return oldValue;
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;初始化槽--ensureSegment&quot;&gt;初始化槽: ensureSegment&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConcurrentHashMap 初始化的时候会初始化第一个槽 segment[0]，对于其他槽来说，在插入第一个值的时候进行初始化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里需要考虑并发，因为很可能会有多个线程同时进来初始化同一个槽 segment[k]，不过只要有一个成功了就可以。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private Segment&amp;lt;K,V&amp;gt; ensureSegment(int k) {
    final Segment&amp;lt;K,V&amp;gt;[] ss = this.segments;
    long u = (k &amp;lt;&amp;lt; SSHIFT) + SBASE; // raw offset
    Segment&amp;lt;K,V&amp;gt; seg;
    if ((seg = (Segment&amp;lt;K,V&amp;gt;)UNSAFE.getObjectVolatile(ss, u)) == null) {
        // 这里看到为什么之前要初始化 segment[0] 了，
        // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k]
        // 为什么要用“当前”，因为 segment[0] 可能早就扩容过了
        Segment&amp;lt;K,V&amp;gt; proto = ss[0];
        int cap = proto.table.length;
        float lf = proto.loadFactor;
        int threshold = (int)(cap * lf);

        // 初始化 segment[k] 内部的数组
        HashEntry&amp;lt;K,V&amp;gt;[] tab = (HashEntry&amp;lt;K,V&amp;gt;[])new HashEntry[cap];
        if ((seg = (Segment&amp;lt;K,V&amp;gt;)UNSAFE.getObjectVolatile(ss, u))
            == null) { // 再次检查一遍该槽是否被其他线程初始化了。

            Segment&amp;lt;K,V&amp;gt; s = new Segment&amp;lt;K,V&amp;gt;(lf, threshold, tab);
            // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出
            while ((seg = (Segment&amp;lt;K,V&amp;gt;)UNSAFE.getObjectVolatile(ss, u))
                   == null) {
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}   
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总的来说，ensureSegment(int k) 比较简单，对于并发操作使用 CAS 进行控制。&lt;/p&gt;
&lt;h3 id=&quot;获取写入锁-scanandlockforput&quot;&gt;获取写入锁-scanandlockforput&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前面我们看到，在往某个 segment 中 put 的时候，首先会调用 node = tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们来具体分析这个方法中是怎么控制加锁的。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private HashEntry&amp;lt;K,V&amp;gt; scanAndLockForPut(K key, int hash, V value) {
    HashEntry&amp;lt;K,V&amp;gt; first = entryForHash(this, hash);
    HashEntry&amp;lt;K,V&amp;gt; e = first;
    HashEntry&amp;lt;K,V&amp;gt; node = null;
    int retries = -1; // negative while locating node
    // 循环获取锁
    while (!tryLock()) {
        HashEntry&amp;lt;K,V&amp;gt; f; // to recheck first below
        if (retries &amp;lt; 0) {
            if (e == null) {
                if (node == null) // speculatively create node
                    // 进到这里说明数组该位置的链表是空的，没有任何元素
                    // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置
                    node = new HashEntry&amp;lt;K,V&amp;gt;(hash, key, value, null);
                retries = 0;
            }
            else if (key.equals(e.key))
                retries = 0;
            else
                // 顺着链表往下走
                e = e.next;
        }
        // 重试次数如果超过 MAX_SCAN_RETRIES(单核1多核64)，那么不抢了，进入到阻塞队列等待锁
        //    lock() 是阻塞方法，直到获取锁后返回
        else if (++retries &amp;gt; MAX_SCAN_RETRIES) {
            lock();
            break;
        }
        else if ((retries &amp;amp; 1) == 0 &amp;amp;&amp;amp;
                 // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头
                 //     所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法
                 (f = entryForHash(this, hash)) != first) {
            e = first = f; // re-traverse if entry changed
            retries = -1;
        }
    }
    return node;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个方法就是看似复杂，但是其实就是做了一件事，那就是获取该 segment 的独占锁，如果需要的话顺便实例化了一下 node。&lt;/p&gt;
&lt;h3 id=&quot;扩容-rehash&quot;&gt;扩容-rehash&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;重复一下，segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry&amp;lt;K,V&amp;gt;[] 进行扩容，扩容后，容量为原来的 2 倍。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先，我们要回顾一下触发扩容的地方，put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么先进行扩容，再插值，读者这个时候可以回去 put 方法看一眼。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;该方法不需要考虑并发，因为到这里的时候，是持有该 segment 的独占锁的。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// 方法参数上的 node 是这次扩容后，需要添加到新的数组中的数据。
private void rehash(HashEntry&amp;lt;K,V&amp;gt; node) {
    HashEntry&amp;lt;K,V&amp;gt;[] oldTable = table;
    int oldCapacity = oldTable.length;
    // 2 倍
    int newCapacity = oldCapacity &amp;lt;&amp;lt; 1;
    threshold = (int)(newCapacity * loadFactor);
    // 创建新数组
    HashEntry&amp;lt;K,V&amp;gt;[] newTable =
        (HashEntry&amp;lt;K,V&amp;gt;[]) new HashEntry[newCapacity];
    // 新的掩码，如从 16 扩容到 32，那么 sizeMask 为 31，对应二进制 ‘000...00011111’
    int sizeMask = newCapacity - 1;
    // 遍历原数组，老套路，将原数组位置 i 处的链表拆分到 新数组位置 i 和 i+oldCap 两个位置
    for (int i = 0; i &amp;lt; oldCapacity ; i++) {
        // e 是链表的第一个元素
        HashEntry&amp;lt;K,V&amp;gt; e = oldTable[i];
        if (e != null) {
            HashEntry&amp;lt;K,V&amp;gt; next = e.next;
            // 计算应该放置在新数组中的位置，
            // 假设原数组长度为 16，e 在 oldTable[3] 处，那么 idx 只可能是 3 或者是 3 + 16 = 19
            int idx = e.hash &amp;amp; sizeMask;
            if (next == null)   // 该位置处只有一个元素，那比较好办
                newTable[idx] = e;
            else { // Reuse consecutive sequence at same slot
                // e 是链表表头
                HashEntry&amp;lt;K,V&amp;gt; lastRun = e;
                // idx 是当前链表的头结点 e 的新位置
                int lastIdx = idx;
                // 下面这个 for 循环会找到一个 lastRun 节点，这个节点之后的所有元素是将要放到一起的
                for (HashEntry&amp;lt;K,V&amp;gt; last = next;
                     last != null;
                     last = last.next) {
                    int k = last.hash &amp;amp; sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }
                // 将 lastRun 及其之后的所有节点组成的这个链表放到 lastIdx 这个位置
                newTable[lastIdx] = lastRun;
                // 下面的操作是处理 lastRun 之前的节点，
                //    这些节点可能分配在另一个链表中，也可能分配到上面的那个链表中
                for (HashEntry&amp;lt;K,V&amp;gt; p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h &amp;amp; sizeMask;
                    HashEntry&amp;lt;K,V&amp;gt; n = newTable[k];
                    newTable[k] = new HashEntry&amp;lt;K,V&amp;gt;(h, p.key, v, n);
                }
            }
        }
    }
    // 将新来的 node 放到新数组中刚刚的 两个链表之一 的 头部
    int nodeIndex = node.hash &amp;amp; sizeMask; // add the new node
    node.setNext(newTable[nodeIndex]);
    newTable[nodeIndex] = node;
    table = newTable;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;get-过程分析&quot;&gt;get 过程分析&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相对于 put 来说，get 就很简单了。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-m1gaxs0&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;计算 hash 值，找到 segment 数组中的具体位置，或我们前面用的“槽”&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9534c7v&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;槽中也是一个数组，根据 hash 找到数组中具体的位置&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-kfdzfuc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;到这里是链表了，顺着链表进行查找即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public V get(Object key) {
    Segment&amp;lt;K,V&amp;gt; s; // manually integrate access methods to reduce overhead
    HashEntry&amp;lt;K,V&amp;gt;[] tab;
    // 1. hash 值
    int h = hash(key);
    long u = (((h &amp;gt;&amp;gt;&amp;gt; segmentShift) &amp;amp; segmentMask) &amp;lt;&amp;lt; SSHIFT) + SBASE;
    // 2. 根据 hash 找到对应的 segment
    if ((s = (Segment&amp;lt;K,V&amp;gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;amp;&amp;amp;
        (tab = s.table) != null) {
        // 3. 找到segment 内部数组相应位置的链表，遍历
        for (HashEntry&amp;lt;K,V&amp;gt; e = (HashEntry&amp;lt;K,V&amp;gt;) UNSAFE.getObjectVolatile
                 (tab, ((long)(((tab.length - 1) &amp;amp; h)) &amp;lt;&amp;lt; TSHIFT) + TBASE);
             e != null; e = e.next) {
            K k;
            if ((k = e.key) == key || (e.hash == h &amp;amp;&amp;amp; key.equals(k)))
                return e.value;
        }
    }
    return null;
}    
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;并发问题分析&quot;&gt;并发问题分析&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;现在我们已经说完了 put 过程和 get 过程，我们可以看到 get 过程中是没有加锁的，那自然我们就需要去考虑并发问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;添加节点的操作 put 和删除节点的操作 remove 都是要加 segment 上的独占锁的，所以它们之间自然不会有问题，我们需要考虑的问题就是 get 的时候在同一个 segment 中发生了 put 或 remove 操作。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-jzwukx9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;put 操作的线程安全性。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-rh1uwhe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;初始化槽，这个我们之前就说过了，使用了 CAS 来初始化 Segment 中的数组。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-h4b8v3z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-107nxn8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-e83jesv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;remove 操作的线程安全性。&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-7q20365&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;remove 操作我们没有分析源码，所以这里说的读者感兴趣的话还是需要到源码中去求实一下的。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-y44eg48&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;get 操作需要遍历链表，但是 remove 操作会&amp;quot;破坏&amp;quot;链表。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-upqbvv3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cyahrq5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头结点，那么需要将头结点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组，请看方法 setEntryAt。2、如果要删除的节点不是头结点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;ConcurrentHashMap-JDK8&quot;&gt;ConcurrentHashMap_JDK8&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 Java 8 中，几乎完全重写了 ConcurrentHashMap，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行，所以也大大提高了源码的阅读难度。而为了方便我们理解，我们还是先从整体的结构示意图出发，看一看总体的设计思路，然后再去深入细节。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/1.8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png&quot; alt=&quot;1.8数据结构&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;图中的节点有三种类型:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8hqvjbl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;空着的位置代表还没有元素来填充&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ahmk36l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;相同hash值使用链表向后进行延伸，此举和hashmap相同&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-68ko4p7&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在链表长度超过8，会将链表转换成为红黑树&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们先来看看最基础的内部存储结构 Node，这就是一个一个的节点，如这段代码所示：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;static class Node&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final int hash;
    final K key;
    volatile V val;
    volatile Node&amp;lt;K,V&amp;gt; next;
    // ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看出，每个 Node 里面是 key-value 的形式，并且把 value 用 volatile 修饰，以便保证可见性，同时内部还有一个指向下一个节点的 next 指针，方便产生链表结构。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下面我们看两个最重要、最核心的方法。&lt;/p&gt;
&lt;h3 id=&quot;put-方法源码分析&quot;&gt;put 方法源码分析&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;put 方法的核心是 putVal 方法，为了方便阅读，我把重要步骤的解读用注释的形式补充在下面的源码中。我们逐步分析这个最重要的方法，这个方法相对有些长，我们一步一步把它看清楚。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) {
        throw new NullPointerException();
    }
    //计算 hash 值
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node&amp;lt;K, V&amp;gt;[] tab = table; ; ) {
        Node&amp;lt;K, V&amp;gt; f;
        int n, i, fh;
        //如果数组是空的，就进行初始化
        if (tab == null || (n = tab.length) == 0) {
            tab = initTable();
        }
        // 找该 hash 值对应的数组下标
        else if ((f = tabAt(tab, i = (n - 1) &amp;amp; hash)) == null) {
            //如果该位置是空的，就用 CAS 的方式放入新值
            if (casTabAt(tab, i, null,
                    new Node&amp;lt;K, V&amp;gt;(hash, key, value, null))) {
                break;
            }
        }
        //hash值等于 MOVED 代表在扩容
        else if ((fh = f.hash) == MOVED) {
            tab = helpTransfer(tab, f);
        }
        //槽点上是有值的情况
        else {
            V oldVal = null;
            //用 synchronized 锁住当前槽点，保证并发安全
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    //如果是链表的形式
                    if (fh &amp;gt;= 0) {
                        binCount = 1;
                        //遍历链表
                        for (Node&amp;lt;K, V&amp;gt; e = f; ; ++binCount) {
                            K ek;
                            //如果发现该 key 已存在，就判断是否需要进行覆盖，然后返回
                            if (e.hash == hash &amp;amp;&amp;amp;
                                    ((ek = e.key) == key ||
                                            (ek != null &amp;amp;&amp;amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent) {
                                    e.val = value;
                                }
                                break;
                            }
                            Node&amp;lt;K, V&amp;gt; pred = e;
                            //到了链表的尾部也没有发现该 key，说明之前不存在，就把新值添加到链表的最后
                            if ((e = e.next) == null) {
                                pred.next = new Node&amp;lt;K, V&amp;gt;(hash, key, value, null);
                                break;
                            }
                        }
                    }
                    //如果是红黑树的形式
                    else if (f instanceof TreeBin) {
                        Node&amp;lt;K, V&amp;gt; p;
                        binCount = 2;
                        //调用 putTreeVal 方法往红黑树里增加数据
                        if ((p = ((TreeBin&amp;lt;K, V&amp;gt;) f).putTreeVal(hash, key,value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent) {
                                p.val = value;
                            }
                        }
                    }
                }
            }
            if (binCount != 0) {
                //检查是否满足条件并把链表转换为红黑树的形式，默认的 TREEIFY_THRESHOLD 阈值是 8
                if (binCount &amp;gt;= TREEIFY_THRESHOLD) {
                    treeifyBin(tab, i);
                }
                //putVal 的返回是添加前的旧值，所以返回 oldVal
                if (oldVal != null) {
                    return oldVal;
                }
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过以上的源码分析，我们对于 putVal 方法有了详细的认识，可以看出，方法中会逐步根据当前槽点是未初始化、空、扩容、链表、红黑树等不同情况做出不同的处理。&lt;/p&gt;
&lt;h3 id=&quot;get-方法源码分析&quot;&gt;get 方法源码分析&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;get 方法比较简单，我们同样用源码注释的方式来分析一下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public V get(Object key) {
    Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; e, p; int n, eh; K ek;
    //计算 hash 值
    int h = spread(key.hashCode());
    //如果整个数组是空的，或者当前槽点的数据是空的，说明 key 对应的 value 不存在，直接返回 null
    if ((tab = table) != null &amp;amp;&amp;amp; (n = tab.length) &amp;gt; 0 &amp;amp;&amp;amp;
            (e = tabAt(tab, (n - 1) &amp;amp; h)) != null) {
        //判断头结点是否就是我们需要的节点，如果是则直接返回
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null &amp;amp;&amp;amp; key.equals(ek)))
                return e.val;
        }
        //如果头结点 hash 值小于 0，说明是红黑树或者正在扩容，就用对应的 find 方法来查找
        else if (eh &amp;lt; 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        //遍历链表来查找
        while ((e = e.next) != null) {
            if (e.hash == h &amp;amp;&amp;amp; ((ek = e.key) == key || (ek != null &amp;amp;&amp;amp; key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;总结一下 get 的过程：&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-raqe5fe&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;计算 Hash 值，并由此值找到对应的槽点；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-l96rckn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果数组是空的或者该位置为 null，那么直接返回 null 就可以了；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-yv2oqjg&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果该位置处的节点刚好就是我们需要的，直接返回该节点的值；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j3f00jj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果该位置节点是红黑树或者正在扩容，就用 find 方法继续查找；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3f803et&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;否则那就是链表，就进行遍历链表查找。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;对比Java7-和Java8-的异同和优缺点&quot;&gt;对比Java7 和Java8 的异同和优缺点&lt;/h2&gt;
&lt;h3 id=&quot;并发度&quot;&gt;并发度&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 7 中，每个 Segment 独立加锁，最大并发个数就是 Segment 的个数，默认是 16。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是到了 Java 8 中，锁粒度更细，理想情况下 table 数组元素的个数（也就是数组长度）就是其支持并发的最大个数，并发度比之前有提高。&lt;/p&gt;
&lt;h3 id=&quot;保证并发安全的原理&quot;&gt;保证并发安全的原理&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 7 采用 Segment 分段锁来保证安全，而 Segment 是继承自 ReentrantLock。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 8 中放弃了 Segment 的设计，采用 Node + CAS + synchronized 保证线程安全。&lt;/p&gt;
&lt;h3 id=&quot;遇到-Hash-碰撞&quot;&gt;遇到 Hash 碰撞&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 7 在 Hash 冲突时，会使用拉链法，也就是链表的形式。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 8 先使用拉链法，在链表长度超过一定阈值时，将链表转换为红黑树，来提高查找效率。&lt;/p&gt;
&lt;h3 id=&quot;查询时间复杂度&quot;&gt;查询时间复杂度&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 7 遍历链表的时间复杂度是 O(n)，n 为链表长度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Java 8 如果变成遍历红黑树，那么时间复杂度降低为 O(log(n))，n 为树的节点个数。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;参考链接：https://www.pdai.tech/md/java/thread/java-thread-x-juc-collection-ConcurrentHashMap.html&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[CopyOnWriteArrayList]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/并发工具/并发容器/CopyOnWriteArrayList</link><guid isPermaLink="false">/topic/Java并发工具包/并发工具/并发容器/CopyOnWriteArrayList</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[并发工具]]></category><category><![CDATA[并发容器]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;CopyOnWriteArrayList&quot;&gt;CopyOnWriteArrayList&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在CopyOnWrite诞生之前，就有了ArrayList和LinkedList作为List的数组，也有了线程安全的Vector和Collections.synchronizedList()可以使用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们先来列举几个，Vector的实现:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public synchronized boolean add(E e) {
        modCount++;
        ensureCapacityHelper(elementCount + 1);
        elementData[elementCount++] = e;
        return true;
}
public synchronized boolean removeElement(Object obj) {
        modCount++;
        int i = indexOf(obj);
        if (i &amp;gt;= 0) {
            removeElementAt(i);
            return true;
        }
        return false;
}
public synchronized E get(int index) {
        if (index &amp;gt;= elementCount)
            throw new ArrayIndexOutOfBoundsException(index);

        return elementData(index);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们可以看到，Vector内部是采用synchronized来保证线程安全的，并且锁的颗粒度比较大，直接作用在方法体上面。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在并发的情况下很容易发生竞争，并发效率比较低。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从这种做法来看，Vector和Hashtable很类似，都是粗粒的锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正因如此，JUC中提供了使用CopyOnWrite机制来实现并发容器，并推出了CopyOnWriteList作为主要的并发List。&lt;/p&gt;
&lt;h2 id=&quot;特点&quot;&gt;特点&lt;/h2&gt;
&lt;h2 id=&quot;复制修改&quot;&gt;复制修改&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从 CopyOnWriteArrayList 的名字就能看出它是满足 CopyOnWrite 的 ArrayList，CopyOnWrite 的意思是说，当容器需要被修改的时候，不直接修改当前容器，而是先将当前容器进行 Copy，复制出一个新的容器，然后修改新的容器，&lt;strong&gt;完成修改之后，再将原容器的引用指向新的容器&lt;/strong&gt;。这样就完成了整个修改过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样做的好处是，CopyOnWriteArrayList 利用了“不变性”原理，因为容器每次修改都是创建新副本，所以对于旧容器来说，其实是不可变的，也是线程安全的，无需进一步的同步操作。我们可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素，也不会有修改。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CopyOnWriteArrayList 的所有修改操作（add，set等）都是通过创建底层数组的新副本来实现的，所以 CopyOnWrite 容器也是一种读写分离的思想体现，读和写使用不同的容器。&lt;/p&gt;
&lt;h3 id=&quot;迭代期间允许修改集合内容&quot;&gt;迭代期间允许修改集合内容&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们知道 ArrayList 在迭代期间如果修改集合的内容，会抛出 ConcurrentModificationException 异常。让我们来分析一下 ArrayList 会抛出异常的原因。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 ArrayList 源码里的 ListItr 的 next 方法中有一个 checkForComodification 方法，代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这里会首先检查 modCount 是否等于 expectedModCount。modCount 是保存修改次数，每次我们调用 add、remove 或 trimToSize 等方法时它会增加，expectedModCount 是迭代器的变量，当我们创建迭代器时会初始化并记录当时的 modCount。后面迭代期间如果发现 modCount 和 expectedModCount 不一致，就说明有人修改了集合的内容，就会抛出异常。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;和 ArrayList 不同的是，CopyOnWriteArrayList 的迭代器在迭代的时候，如果数组内容被修改了，CopyOnWriteArrayList 不会报 ConcurrentModificationException 的异常，因为迭代器使用的依然是旧数组，只不过迭代的内容可能已经过时了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CopyOnWriteArrayList 的迭代器一旦被建立之后，如果往之前的 CopyOnWriteArrayList 对象中去新增元素，在迭代器中既不会显示出元素的变更情况，同时也不会报错，这一点和 ArrayList 是有很大区别的。&lt;/p&gt;
&lt;h2 id=&quot;缺点&quot;&gt;缺点&lt;/h2&gt;
&lt;h3 id=&quot;内存占用大&quot;&gt;内存占用大&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为 CopyOnWrite 的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，这一点会占用额外的内存空间。&lt;/p&gt;
&lt;h3 id=&quot;元素较多或者复杂的情况下-复制的开销大&quot;&gt;元素较多或者复杂的情况下，复制的开销大&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;复制过程不仅会占用双倍内存，还需要消耗 CPU 等资源，会降低整体性能。在原数组内容较多的情况下，可能导致yong gc 或者 full gc。&lt;/p&gt;
&lt;h3 id=&quot;数据一致性无法保证&quot;&gt;数据一致性无法保证&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于 CopyOnWrite 容器的修改是先修改副本，所以这次修改对于其他线程来说，并不是实时能看到的，只有在修改完之后才能体现出来。如果你希望写入的的数据马上能被其他线程看到，CopyOnWrite 容器是不适用的。&lt;/p&gt;
&lt;h3 id=&quot;只适合读多写少的场景&quot;&gt;只适合读多写少的场景&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为谁也没法保证CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次add/set都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。&lt;/p&gt;
&lt;h2 id=&quot;源码分析&quot;&gt;源码分析&lt;/h2&gt;
&lt;h3 id=&quot;数据结构&quot;&gt;数据结构&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;		/** 保护竞争操作的可重入锁 **/    
    final transient ReentrantLock lock = new ReentrantLock();
   /** 底层存放数据的数组，用volatile保证可见性 ,并且不能被序列化 **/
    private transient volatile Object[] array;

    /**
     * 获取数组对象
     */
    final Object[] getArray() {
        return array;
    }
    final void setArray(Object[] a) {
        array = a;
    }
    /** 在构造函数中初始化数组 **/
    public CopyOnWriteArrayList() {
        setArray(new Object[0]);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;add方法&quot;&gt;add方法&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public boolean add(E e) {
        // 加锁
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
           // 得到原数组的长度
            Object[] elements = getArray();
            int len = elements.length;
            // 拷贝新的一个出来
            Object[] newElements = Arrays.copyOf(elements, len + 1);
          	// 新元素添加到新数组中
            newElements[len] = e;
          	// 将新的数组设置回去
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在添加的时候首先上锁，并复制一个新数组，增加操作在新数组上完成，然后将 array 指向到新数组，最后解锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CopyOnWrite 的思想：写操作是在原来容器的拷贝上进行的，并且在读取数据的时候不会锁住 list。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且可以看到，如果对容器拷贝操作的过程中有新的读线程进来，那么读到的还是旧的数据，因为在那个时候对象的引用还没有被更改。&lt;/p&gt;
&lt;h3 id=&quot;get操作&quot;&gt;get操作&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public E get(int index) {
    return get(getArray(), index);
}
final Object[] getArray() {
    return array;
}
private E get(Object[] a, int index) {
    return (E) a[index];
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;get操作没有加锁，这样就能够保证了读取的速度，但遗憾的是，没有办法保证读取的一致性，因为只有容器在解锁的时候，get的才能是新的值&lt;/p&gt;
&lt;h3 id=&quot;迭代器COWIterator类&quot;&gt;迭代器&lt;strong&gt;COWIterator&lt;/strong&gt;类&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;迭代器中有两个重要的类，一个是当前数组的快照，另一个是迭代器的游标。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在构建迭代器的时候，会将当前的数组赋值给snapshot，之后所有的操作都是基于这个snapshot，在迭代的过程中，即使有修改，那对于当前正在迭代的程序是不可兼见的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就是由于这个特性，迭代过程中元素是不可删的，因为删了也没有用。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;    /** Snapshot of the array */
    private final Object[] snapshot;
    /** Index of element to be returned by subsequent call to next.  */
    private int cursor;

    private COWIterator(Object[] elements, int initialCursor) {
        cursor = initialCursor;
        snapshot = elements;
    }
    public E next() {
            if (! hasNext())
                throw new NoSuchElementException();
            return (E) snapshot[cursor++];
        }
		public void remove() {
            throw new UnsupportedOperationException();
    }
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[AQS框架]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/AQS框架</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/AQS框架</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;AQS框架&quot;&gt;AQS框架&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AQS框架，全名叫做&lt;strong&gt;A&lt;/strong&gt;bstract&lt;strong&gt;Q&lt;/strong&gt;ueued&lt;strong&gt;S&lt;/strong&gt;ynchronizer。是目前JUC中，各个Lock锁的核心实现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AQS提供了一系列的方式方法，用于我们去实现自己的&amp;quot;锁&amp;quot;结构。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来，我们会从&lt;strong&gt;ReentrantLock&lt;/strong&gt;开始，剖析AQS框架的整体结构。&lt;/p&gt;
&lt;h2 id=&quot;模拟场景&quot;&gt;模拟场景&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有三个用户A、B、C，排队去银行取款，银行只有一个窗口。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户A办理业务的时间比较长，需要办理20分钟，在A办理窗口的时候，B、C只能在等待。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码如下：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public static final ReentrantLock lock = new ReentrantLock();
    public static void main(String[] args) throws InterruptedException, NoSuchFieldException {
       Thread A = new Thread(() -&amp;gt; {
           lock.lock();
           try {
               System.out.println(&amp;quot;用户A开始办理业务&amp;quot;);
               try { TimeUnit.MINUTES.sleep(20); } catch (InterruptedException e) {e.printStackTrace();}
               System.out.println(&amp;quot;用户A办理业务完成&amp;quot;);   
           }finally {
               lock.unlock();
           }
       },&amp;quot;用户A&amp;quot;);
       Thread B = new Thread(() -&amp;gt; {
           lock.lock();
           try {
               System.out.println(&amp;quot;用户B开始办理业务&amp;quot;);
           }finally {
               lock.unlock();
           }
       },&amp;quot;用户B&amp;quot;);
       Thread C = new Thread(() -&amp;gt; {
           lock.lock();
           try {
               System.out.println(&amp;quot;用户C开始办理业务&amp;quot;);
           }finally {
               lock.unlock();
           }
       },&amp;quot;用户C&amp;quot;);
       A.start();
       // 让线程A先启动
       Thread.sleep(100);
       B.start();
       C.start();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们使用lock来模拟银行单个柜台的操作，在办理业务之前必须先拿到柜台的锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示，B、C正在座位上排队，A正在办理业务&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214133706380.png&quot; alt=&quot;image-20211214133706380&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;源码分析&quot;&gt;源码分析&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我们调用lock的方法，才能够获取到办理业务的锁。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; public void lock() {
        sync.lock();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;lock方法的实现，非常简单，就是调用sync对象进行加锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;sync对象是继承自AbstractQueuedSynchronizer而实现的锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;内部定义了一个lock的抽象方法（我们接下来都以默认的&lt;strong&gt;非公平锁&lt;/strong&gt;来进行说明）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;lock的抽象方法交由给NonfairSync的lock实现。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;abstract static class Sync extends AbstractQueuedSynchronizer {
	abstract void lock();
}
static final class NonfairSync extends Sync {
  private static final long serialVersionUID = 7316153563782823691L;

  final void lock() {
    if (compareAndSetState(0, 1))
      setExclusiveOwnerThread(Thread.currentThread());
    else
      acquire(1);
  }

  protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;额外说明:在AQS框架中，有个state字段，这是给实现类用的，谁使用谁实现。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在ReentrantLock的Sync中，state字段: 0代表着被占用;1代表着锁已经被占用。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;接下来，会结合具体场景，来剖析整个流程。&lt;/p&gt;
&lt;h2 id=&quot;获取锁流程&quot;&gt;获取锁流程&lt;/h2&gt;
&lt;h3 id=&quot;用户A加锁&quot;&gt;用户A加锁&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在第一次调用lock方法的时候，会通过CAS的方式去判断state的值。state在第一次调用时，肯定是0，所以这个时候可以通过setExclusiveOwnerThread(Thread.currentThread())方法，设置当前获取这个锁的线程为&lt;strong&gt;用户A&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;final void lock() {
    if (compareAndSetState(0, 1))
      setExclusiveOwnerThread(Thread.currentThread());
    else
      acquire(1);
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/%E7%94%A8%E6%88%B7A%E8%BF%9B%E6%9D%A5.png&quot; alt=&quot;用户A进来&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;用户B加锁&quot;&gt;用户B加锁&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用户B加锁的这种情况，就会走到整个AQS的核心。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在用户B加锁的时候，会发现&amp;quot;柜台&amp;quot;已经被A占用了，只能到一旁的小板凳去等待，会调用acquire(1)方法，获取一张&amp;quot;小板凳&amp;quot;；&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;amp;&amp;amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以看到在这个if方法中，会尝试获取锁，并且加入到队列中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;tryAcquire方法:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;strong&gt;AQS&lt;/strong&gt;采用模板方法的模式，将tryAcquire交由给子类进行实现,最后调用到nonfairTryAcquire。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public abstract class AbstractQueuedSynchronizer{
  protected boolean tryAcquire(int arg) {
          throw new UnsupportedOperationException();
  }
}
abstract static class Sync extends AbstractQueuedSynchronizer {
  final boolean nonfairTryAcquire(int acquires) {
    // 获取当前线程。
    final Thread current = Thread.currentThread();
    // 获取当前的执行状态，因为用户A还没有释放锁，所以这个state是1
    int c = getState();
    // 跳过第一个if逻辑
    if (c == 0) {
      if (compareAndSetState(0, acquires)) {
        setExclusiveOwnerThread(current);
        return true;
      }
    }
    // 这里进来的线程是用户B，当前持有锁的线程是用户A，所以这个if也进行跳过，直接return false
    else if (current == getExclusiveOwnerThread()) {
      int nextc = c + acquires;
      if (nextc &amp;lt; 0) // overflow
        throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
      setState(nextc);
      return true;
    }
    return false;
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在tryAcquire方法返回false之后，将会进入第二个逻辑: &lt;strong&gt;acquireQueued(addWaiter(Node.EXCLUSIVE), arg)&lt;/strong&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;首先进入的是addWaiter，用户B的进入队列的逻辑:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;addWaiter(Node.EXCLUSIVE);
private Node addWaiter(Node mode) {
  // 创建出node对象，node中存储了当前线程 和 Node的类型（目前是独占模式）
  Node node = new Node(Thread.currentThread(), mode);
  // 尾巴结点，目前没有东西
  Node pred = tail;
  // 所以跳过第一个if判断
  if (pred != null) {
    node.prev = pred;
    if (compareAndSetTail(pred, node)) {
      pred.next = node;
      return node;
    }
  }
  // 将节点插入队列
  enq(node);
  return node;
}
// 将节点插入到队列中
private Node enq(final Node node) {
  for (;;) {
    // 第一次循环——尾结点，目前是null
    // 第二次循环——尾结点，目前是new Node
    Node t = tail;
    // 第一次循环——进入初始化
    if (t == null) { // Must initialize
      // 第一次循环——设置头尾结点为一个新的节点，注意：此时头结点不是 用户B，将进入下一个循环
      if (compareAndSetHead(new Node()))
        tail = head;
    } else {
      // 用户B真正的入队逻辑
      // 第二次循环——用户B的前驱节点是
      node.prev = t;
      // 第二次循环——将用户B设置成尾结点
      if (compareAndSetTail(t, node)) {
        // 第二次循环——头结点的后继节点是 用户B
        t.next = node;
        return t;
      }
    }
  }
}
最后进入队列的用户B会呈现出这样的状态
  new Node() ----next---&amp;gt; 用户B
  new Node() &amp;lt;---prev---— 用户B
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214151453981.png&quot; alt=&quot;image-20211214151453981&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;再来看: acquireQueued方法,这个方法实现了 用户B 的阻塞&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// node现在是addWaiter返回的 用户B
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 获取 用户B 的 前驱节点，目前是个空节点
            final Node p = node.predecessor();
						// p == head 是成立的, 但是 由于 用户A依然占有线程，tryAcquire 返回的是false
            // 所以跳过这if判断
            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            // shouldParkAfterFailedAcquire是只，在抢占失败之后阻塞线程，会将头结点的waitStatus从0设置成-1，并返回true
            // parkAndCheckInterrupt将会真正的阻塞线程在这，会调用LockSupport.park(this)进入阻塞态。
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如下图所示，头结点的waitStatus变成了-1&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214162714865.png&quot; alt=&quot;image-20211214162714865&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;用户C加锁&quot;&gt;用户C加锁&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其逻辑和用户B相类似，直接看排队的代码&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private Node addWaiter(Node mode) {
  // 创建出node对象，node中存储了当前线程 和 Node的类型（目前是独占模式）
  Node node = new Node(Thread.currentThread(), mode);
  // 尾结点，因为B已经进来了，这个节点是用户B
  Node pred = tail;
  // 因为pred不为空
  if (pred != null) {
    // 用户C 的前驱节点设置成 用户B
    // 尾结点指向 用户C
    // 用户B的 后驱设置成 用户C
    node.prev = pred;
    if (compareAndSetTail(pred, node)) {
      pred.next = node;
      return node;
    }
  }
  // 不会走到这
  enq(node);
  return node;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214163207041.png&quot; alt=&quot;image-20211214163207041&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在 B、C入队之后，整个获取锁的流程就结束了，接下来就等待A执行完业务流程释放锁即可。&lt;/p&gt;
&lt;h2 id=&quot;释放锁流程&quot;&gt;释放锁流程&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;同样的，在解锁时也是调用AQS的release方法&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public void unlock() {
	sync.release(1);
}
AQS:
...
public final boolean release(int arg) {
  if (tryRelease(arg)) {
    Node h = head;
    if (h != null &amp;amp;&amp;amp; h.waitStatus != 0)
      unparkSuccessor(h);
    return true;
  }
  return false;
}
...
  
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后通过tryRelease()模板方法，调用回Sync中的tryRelease&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;// 尝试释放锁
protected final boolean tryRelease(int releases) {
 		// 当前状态 - 1 = 0
    int c = getState() - releases;
  	// 如果当前线程不是持有锁的线程，不能释放锁
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
  	// 如果状态为0 说明可以释放锁
    if (c == 0) {
        free = true;
      	// 将设置线程持有锁的线程为null
        setExclusiveOwnerThread(null);
    }
    // 将状态设置为0
    setState(c);
    return free;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在这一步执行完之后，状态是这样的:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214163224576.png&quot; alt=&quot;image-20211214163224576&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在tryRelease执行成功之后，会执行下面这段代码:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt; Node h = head;
if (h != null &amp;amp;&amp;amp; h.waitStatus != 0)
   unparkSuccessor(h);
 return true;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取头结点，如果头结点不为空且waitStatus为-1时，就调用unparkSuccessor(h)&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;private void unparkSuccessor(Node node) {
       // 获取waitStatus，我们知道，这个时候waitStatus为头结点的-1
        int ws = node.waitStatus;
  			// 将node的状态从-1设置成0
        if (ws &amp;lt; 0)
            compareAndSetWaitStatus(node, ws, 0);
  			// 获取头结点的后驱节点，即 用户B
        Node s = node.next;
  			// 后面的节点状态是取消的状态，就从最后向前寻找可执行的节点
        if (s == null || s.waitStatus &amp;gt; 0) {
            s = null;
            for (Node t = tail; t != null &amp;amp;&amp;amp; t != node; t = t.prev)
                if (t.waitStatus &amp;lt;= 0)
                    s = t;
        }
        if (s != null)
          	// 唤醒线程
            LockSupport.unpark(s.thread);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在unparkSuccessor执行成功之后，会唤醒 用户B的线程, 现在线程被阻塞在 parkAndCheckInterrupt 这一行。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为这个是自旋的方法，所以唤醒之后，会再次进入判断&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 唤醒之后，会进入到这里
          	// 用户B 的 前驱节点依然是 哨兵节点
            final Node p = node.predecessor();
						// p == head 是成立的
            // 由于 用户A 已经释放锁，tryAcquire 也成立
            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {
                // 设置头节点为 用户B
                setHead(node);
              	// 将 哨兵 节点的 next 设置为空，也就是
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp; parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
// 设置头节点为 用户B , 然后将线程清空，前置节点清空
 private void setHead(Node node) {
        head = node;
        node.thread = null;
        node.prev = null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/image-20211214165737590.png&quot; alt=&quot;image-20211214165737590&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，我们的整个AQS的状态已经和最初B进来的时候一致。也就意味着，原本的用户C 占用了 用户B 的位置，排队向前占了一格。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;然后，不断循环处理。就成就了加锁和解锁的逻辑。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;至此，整个AQS就基本算是结束了。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，我们再倒过来看AQS中抽象的概念。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/7132e4cef44c26f62835b197b239147b18062.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-8skd2d9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;CLH&lt;/code&gt;队列，虚拟双向队列，Craig,Landin,and Hagersten。仅存在结点之间的关联关系。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其中Sync queue，即同步队列，是双向链表，包括head结点和tail结点，head结点主要用作后续的调度。‘&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-coakkka&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;结点状态&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;// CANCELLED，值为1，表示当前的线程被取消&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;// SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;// CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;// PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;// 值为0，表示当前节点在sync队列中，等待着获取锁&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AQS就是靠着这个数据结构来对线程来进行处理的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AQS还有其他各种各样的api，这里就不展开赘述了，可以看去看https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://www.shiyitopo.tech/uPic/82077ccf14127a87b77cefd1ccf562d3253591.png&quot; alt=&quot;img&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[CAS原理]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包/底层原理/CAS原理</link><guid isPermaLink="false">/topic/Java并发工具包/底层原理/CAS原理</guid><category><![CDATA[Java并发工具包]]></category><category><![CDATA[底层原理]]></category><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;CAS原理&quot;&gt;CAS原理&lt;/h1&gt;
&lt;h2 id=&quot;CAS介绍&quot;&gt;CAS介绍&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Cas的全拼是 Compare and Swap ，翻译过来是比较和交换，这是一种思想、一种算法，也被称之为无锁更新。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Cas是一种非常常见的算法，也是面试中的常客，同时也是原子类和乐观锁的底层原理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在多线程的情况下，访问一个共享资源是线程不安全的，通常我们会使用互斥锁，即一个时刻只能有一个线程访问共享资源。但是，互斥锁由于需要CPU切换上下文线程，进而导致性能低下。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而CAS另辟蹊径，没有通过互斥锁，而是当多个线程同时使用CAS算法去更新共享资源时，只会有一个线程能够成功更新，而其他线程都会更新失败，不过与互斥锁不同的是，更新失败的线程并不会阻塞，而是告知此次操作竞争失败，但是还可以再次尝试。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就比如，sql中的条件更新一样：update set id=3 from table where id=2。因为单条sql执行具有原子性，如果有多个线程同时执行此sql语句，只有一条能更新成功。&lt;/p&gt;
&lt;h2 id=&quot;CAS的思路&quot;&gt;CAS的思路&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在大多数的处理器中，都会实现CAS相关的指令，这一条指令就能够实现比较和交换的操作。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;也正是由于这一条CPU指令，所以CAS相关的操作是具备原子性的，这个操作再执行期间不会被打算，这样能够保证并发的安全性。而这个原子性是由CPU进行提供，在使用时无需程序猿来操心。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;CAS有三个操作数，内存值V，预期值A，要修改的值B。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;处理逻辑是，当预期值和内存值相同时，才会将内存值修改为B。在执行CAS的时候，如果内存中的V正好等于传入的A，则会把V的值修改成B；如果内存中的V和传入的A不相等，则说明A的值已经被其他线程修改过，那么本次的CAS修改失败。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。&lt;/p&gt;
&lt;h2 id=&quot;使用示例&quot;&gt;使用示例&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不使用CAS，在高并发下，多线程同时修改一个变量的值我们需要synchronized加锁(可能有人说可以用Lock加锁，Lock底层的AQS也是基于CAS进行获取锁的)。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Test {
    private int i=0;
    public synchronized int add(){
        return i++;
    }
}
    
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;java中为我们提供了AtomicInteger 原子类(底层基于CAS进行更新数据的)，不需要加锁就在多线程并发场景下实现数据的一致性。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;public class Test {
    private  AtomicInteger i = new AtomicInteger(0);
    public int add(){
        return i.addAndGet(1);
    }
}    
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;CAS的问题&quot;&gt;CAS的问题&lt;/h2&gt;
&lt;h3 id=&quot;ABA问题&quot;&gt;ABA问题&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有一种情况，原本的值是A变成了B然后又变成了A，CAS在检查这种情况的时候，会认为值没有发送变化，实际上是已经发生了变化。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ABA解决的方案就是&lt;strong&gt;每次更新就加上版本号,1A-&amp;gt;2B-3A&lt;/strong&gt;。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。&lt;/p&gt;
&lt;h3 id=&quot;循环时间长开销大&quot;&gt;循环时间长开销大&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;pause指令有两个作用：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-iesuijo&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一，它可以延迟流水线执行命令(de-pipeline)，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-arwvs5p&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第二，它可以避免在退出循环的时候因内存顺序冲突(Memory Order Violation)而引起CPU流水线被清空(CPU Pipeline Flush)，从而提高CPU的执行效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;只能保证一个共享变量的原子操作&quot;&gt;只能保证一个共享变量的原子操作&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i = 2，j = a，合并一下ij = 2a，然后用CAS来操作ij。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Java并发工具包]]></title><link>https://www.ztianzeng.com/topic/Java并发工具包</link><guid isPermaLink="false">/topic/Java并发工具包</guid><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Java并发工具包&quot;&gt;Java并发工具包&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[topic]]></title><link>https://www.ztianzeng.com/topic</link><guid isPermaLink="false">/topic</guid><pubDate>Thu, 21 Apr 2022 11:40:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;topic&quot;&gt;topic&lt;/h1&gt;
</content:encoded></item><item><title><![CDATA[兜兜转转，最后用Gastby重写了我的博客]]></title><link>https://www.ztianzeng.com/posts/兜兜转转，最后用Gastby重写了我的博客</link><guid isPermaLink="false">/posts/兜兜转转，最后用Gastby重写了我的博客</guid><pubDate>Thu, 21 Apr 2022 09:07:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;兜兜转转-最后用Gastby重写了我的博客&quot;&gt;兜兜转转，最后用Gastby重写了我的博客&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;6年前，我建立的自己的一个个人博客。最开始是采用WordPress进行构建，但是由于那个时候由于还是学生，可以通过腾讯云学生优惠拿到10块钱一个月的机器，勉强还算能玩。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随着，腾讯云优惠的结束，服务器开销着实承担不起，后面就尝试寻找在线博客，当时的简书、CSDN、博客园等在线博客平台都注册了账号，体验过后都不是很满意。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;后面，随着以Hexo为首的静态站点生成框架的兴起，可以通过OSS方便的生成自己的网站，后面采用Hexo尝试了一段时间&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;随着时间的流逝~~~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有几个月没有写博客，就导致Hexo的命令完全就忘光了~~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且当时为了国内能够顺利的访问还把源码托管在国内的某个平台上，长达半年多没写，甚至连托管在哪个平台上都不知道了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;后面有继续转站带有客户端的静态网站生成工具Gridea，也由于无法满足自己的需要，所以最后也放弃了~~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;索性自己就推导重来，都是静态网站，React搞一搞，难度也不是很大~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;经过一番折腾选择了Gastby作为基础框架来生成自己的网站~~~&lt;/p&gt;
&lt;h2 id=&quot;为啥是Gastby嘞&quot;&gt;为啥是Gastby嘞&lt;/h2&gt;
&lt;table updated=&quot;20220705131435&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;博客系统&lt;/th&gt;
&lt;th&gt;开发语言&lt;/th&gt;
&lt;th&gt;模板语言&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;优势&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://hexo.io/&quot;&gt;&lt;strong&gt;Hexo&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Node.js&lt;/td&gt;
&lt;td&gt;EJS&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;中文资料多&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://gohugo.io/&quot;&gt;&lt;strong&gt;Hugo&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;编译超快&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;&lt;strong&gt;Jekyll&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Ruby&lt;/td&gt;
&lt;td&gt;Liquid&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://ghost.org/&quot;&gt;Ghost&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Node.js&lt;/td&gt;
&lt;td&gt;Handlebars&lt;/td&gt;
&lt;td&gt;CMS&lt;/td&gt;
&lt;td&gt;默认主题好看&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;gatsbyjs.com&quot;&gt;&lt;strong&gt;Gatsby&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;JS(React)&lt;/td&gt;
&lt;td&gt;JS(React)&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;React&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://typecho.org/&quot;&gt;Typecho&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;PHP&lt;/td&gt;
&lt;td&gt;PHP&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://wordpress.org/&quot;&gt;WordPress&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;PHP&lt;/td&gt;
&lt;td&gt;PHP&lt;/td&gt;
&lt;td&gt;CMS&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://gridea.dev&quot;&gt;Gridea&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;JS(Vue)&lt;/td&gt;
&lt;td&gt;EJS&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://gridsome.org/&quot;&gt;&lt;strong&gt;Gridsome&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;JS(Vue)&lt;/td&gt;
&lt;td&gt;JS(Vue)&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;Vue&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://halo.run/&quot;&gt;Halo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Java&lt;/td&gt;
&lt;td&gt;Freemarker&lt;/td&gt;
&lt;td&gt;CMS&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://blog.getpelican.com/&quot;&gt;&lt;strong&gt;Pelican&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;Jinja&lt;/td&gt;
&lt;td&gt;静态&lt;/td&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-3qqi3oj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;支持Markdown语法&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s3b13qw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;生态繁荣&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g3kag5k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无后端&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9xu06ou&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可定制化程度高&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-so3xmdp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;得是熟悉的技术栈！！！&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前前端就会个React，所以自然就选择了Gastby。&lt;/p&gt;
&lt;h2 id=&quot;界面设计&quot;&gt;界面设计&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大部分的界面是我抄的，css调起来要人命，还不一定有别人的好看&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;唯一有特色的，就是扫描markdown文件来生成思维导图&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大概长这样：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/VaXToq.png&quot; alt=&quot;VaXToq&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;数据哪来-&quot;&gt;数据哪来?&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在整个网站中，系统分为两个部分&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-potgtuv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;posts: 记录日常的文章&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-g890jmh&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;topic: 体系化的知识，不会东一点西一点&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于topic的知识，是需要通过扫描本地文件的，所以目前还是和工程放置在一起的。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而posts的文章，是通过思源笔记来进行生成的&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;得益于思源笔记开放的API，可以通过API将在笔记上写的文章，导出到对应的文件夹下，达到了共存。。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;代码大概是这样:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;js&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;const fs = require(&apos;fs&apos;)
const fetch = require(&apos;isomorphic-fetch&apos;);
const param = (data) =&amp;gt; {
    return {
        method: &apos;POST&apos;,
        headers: {
            &apos;Accept&apos;: &apos;application/json&apos;,
            &apos;Content-Type&apos;: &apos;application/json&apos;
        },
        body: JSON.stringify(data)
    }
}
const getHead = ({title, date, tags}) =&amp;gt; {
    const formatDate = `${date.slice(0, 4)}-${date.slice(4, 6)}-${date.slice(6, 8)} ${date.slice(8, 10)}:${date.slice(10, 12)}  `;
    return `---\n` +
        `title: ${title}\n` +
        `date: ${formatDate}\n` +
        `tags: [${tags}]\n` +
        `---\n`
}
const host = &apos;http://127.0.0.1:6806/api/&apos;

function getData(url, data) {
    return fetch(host + url, param(data)).then(res =&amp;gt; {
        if (res.status &amp;gt;= 400) {
            console.log(res);
            const err = new Error(&apos;http server error&apos;);
            err.res = res;
            throw err;
        }
        return res.json();
    })
}

function delDir(path) {
    let files = [];
    if (fs.existsSync(path)) {
        files = fs.readdirSync(path);
        files.forEach((file, index) =&amp;gt; {
            let curPath = path + &amp;quot;/&amp;quot; + file;
            if (fs.statSync(curPath).isDirectory()) {
                delDir(curPath); //递归删除文件夹
            } else {
                fs.unlinkSync(curPath); //删除文件
            }
        });
        fs.rmdirSync(path);
    }
}

async function getSiyuan({path, box}) {
    delDir(path)
    fs.mkdirSync(path)
    const pathArray = path.split(&apos;/&apos;)
    const json = await getData(&apos;query/sql&apos;, {stmt: `select * from blocks where box = &apos;${box}&apos; and type=&apos;d&apos;`});
    for (let i = 0; i &amp;lt; json.data.length; i++) {
        const {id, content, created} = json.data[i];
        const {data} = await getData(&apos;export/exportMdContent&apos;, {id});
        if (!data.content.trim()) {
            continue
        }
        const tags = data.hPath.split(&apos;/&apos;).filter(e =&amp;gt; !pathArray.includes(e)).slice(0,-1)
        console.log(content, tags)
        const head = getHead({title: content, date: created, tags})
        fs.writeFile(path + content + &apos;.md&apos;, head + data.content, err =&amp;gt; {
            if (err) {
                console.error(err)
            }
        })
    }
}

try {
    getSiyuan({path: &apos;./content/posts/&apos;, box: &apos;20220420112442-p6q6e8w&apos;}).catch(e =&amp;gt; {
        console.log(e)
    })
} catch (e) {
    console.log(e);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样就能将思源笔记中的文章，导出成markdown文档写入到项目中。。这样就不需要找额外的客户端来编写markdown，all in one&lt;/p&gt;
&lt;h2 id=&quot;&quot;&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这样其实还有个缺陷，就是修改文档的时候需要重新生成，提交给github进行打包~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前此点无解，除非哪天思源提供了在线API的服务~~~&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;利用graphql来生成文章，就避免了持续生成的烦恼~~~&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[稀缺读后感]]></title><link>https://www.ztianzeng.com/posts/稀缺读后感</link><guid isPermaLink="false">/posts/稀缺读后感</guid><category><![CDATA[Other]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;稀缺读后感&quot;&gt;稀缺读后感&lt;/h1&gt;
&lt;h1 id=&quot;我们是如何陷入贫穷与忙碌的&quot;&gt;我们是如何陷入贫穷与忙碌的&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作者在这本书里面，总共提到了我认为最重要的三个概念 —— 带宽、余闲、管窥&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一切的稀缺都能够用这三个词语来进行结束。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;余闲不够，导致带宽变窄，进而导致管窥心态，管窥的心态进一步导致余闲不足，形成恶性循环。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;就好比，信奉商家推崇的消费主义，手头钱不够就向你推销信用卡贷款，买了一大堆没有任何作用的东西，还款日一到手头没有钱怎么办？就需要另一张信用卡来进行周转，以贷养贷，最后导致贷款利率远超过自己所能负担的起的水平。。直接崩盘&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而解决这一切的源头，需要扩大自己的余闲，也就是有能力赚钱，或者节约自己的带宽，就能跳出这种恶性循环。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;忙碌与焦虑，是绝大多是人都会遇到的问题，重要的是，如何去平衡这些心态。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[使用yt-dlp下载youyube视频并转换成MP3]]></title><link>https://www.ztianzeng.com/posts/使用yt-dlp下载youyube视频并转换成MP3</link><guid isPermaLink="false">/posts/使用yt-dlp下载youyube视频并转换成MP3</guid><category><![CDATA[Other]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;使用yt-dlp下载youyube视频并转换成MP3&quot;&gt;使用yt-dlp下载youyube视频并转换成MP3&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;yt-dlp是从youtube-dl中fork出来的一个分支，担负着继续维护的重任。&lt;br /&gt;
yt-dlp继承了youtube-dl所有的命令，并且还修复了youtube-dl下载速度过慢的bug。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;本文介绍了如何使用yt-dlp，将youtube的视频转化为mp3.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;项目github页面: https://github.com/yt-dlp/yt-dlp&lt;/p&gt;
&lt;h2 id=&quot;基本环境&quot;&gt;基本环境&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在mac下，只需要brew命令，即可完成安装&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 安装基本命令
brew install yt-dlp
# 安装转码器
brew install ffmpeg
# 安装多线程下载工具
brew install aria2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;下载命令&quot;&gt;下载命令&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;yt-dlp --ignore-errors  --output &amp;quot;%(title)s.%(ext)s&amp;quot; --audio-quality 160K --extract-audio  --audio-format mp3 --proxy 127.0.0.1:6152  --cookies cookies.txt --external-downloader aria2c --external-downloader-args &amp;quot;-x 4&amp;quot; --playlist-start 94 --yes-playlist &apos;&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;命令说明：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zvhee1t&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--ignore-errors 如果发生错误，请继续下载。例如，跳过已删除的播放列表中的视频或跳过您所在国家/地区不可用的视频。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ihg9cxr&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--proxy 使用代理进行下载&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ene3vm9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--cookies cookies.txt 保存cookie到文件，在有些私人网站上下载非常游泳&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hln6znv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--external-downloader aria2c 指定下载器为aria2c&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3jc8wvf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--external-downloader-args &amp;quot;-x 4&amp;quot; 指定aria2c 使用4个线程进行下载&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zae6sku&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--format bestaudio 下载可用的最佳音频质量格式&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hyiuowk&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--extract-audio 从视频中提取音频&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-cjwmz0k&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--audio-format mp3 指定音频格式-在这种情况下为mp3&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-9e6jw1z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--audio-quality 160K 指定在这种情况下转换为mp3时ffmpeg / avconv使用的音频质量。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-hjexlmx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--output &amp;quot;%(title)s.%(ext)s&amp;quot; 代表 输出文件名模板&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-gmz94ns&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--playlist-start 94 从播放列表的第94个开始下载，默认为1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pjhucf6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;--yes-playlist 即使URL指向视频和播放列表，也要下载整个播放列表。&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tuyrt71&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&apos;&apos; 是要下载的YouTube播放列表的URL。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[七牛云自定义处理图片]]></title><link>https://www.ztianzeng.com/posts/七牛云自定义处理图片</link><guid isPermaLink="false">/posts/七牛云自定义处理图片</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;七牛云自定义处理图片&quot;&gt;七牛云自定义处理图片&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于七牛云提供的图片处理服务无法满足业务需求，因此是需要，自定义数据处理服务，对图片进行处理。&lt;br /&gt;
目前支持两种类型的处理:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5de7zmn&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将图片置灰 &amp;lt;ufop&amp;gt;/grey&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-x5dpw7m&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;png图片加上背景颜色 &amp;lt;ufop&amp;gt;/background/&amp;lt;颜色16进制代码&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;go&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;package main

import (
	&amp;quot;bytes&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;image&amp;quot;
	_ &amp;quot;image&amp;quot;
	&amp;quot;image/color&amp;quot;
	&amp;quot;image/draw&amp;quot;
	&amp;quot;image/png&amp;quot;
	_ &amp;quot;image/png&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net/http&amp;quot;
	url2 &amp;quot;net/url&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;strings&amp;quot;
)

// HTTPGetMaxSize 最大处理的文件长度
const HTTPGetMaxSize = 2 * 1024 * 1024

func httpGet(url string) (body []byte, err error, res *http.Response) {
	res, err = http.Get(url)
	if err != nil {
		return nil, fmt.Errorf(&amp;quot;httpGet error: %s&amp;quot;, err), res
	}
	defer res.Body.Close()
	body, err = ioutil.ReadAll(http.MaxBytesReader(nil, res.Body, HTTPGetMaxSize))
	if err != nil {
		return nil, fmt.Errorf(&amp;quot;httpGet read body error: %s&amp;quot;, err), res
	}
	return
}

func handler(rw http.ResponseWriter, req *http.Request) {
	log.Println(&amp;quot;获取到请求&amp;quot;, req.URL.RawQuery)
	println(&amp;quot;获取到请求&amp;quot;, req.URL.RawQuery)
	var err error
	defer func() {
		if err != nil {
			http.Error(rw, err.Error(), 500)
		}
	}()

	defer req.Body.Close()
	var body []byte
	var res *http.Response

	cmd, _ := url2.QueryUnescape(req.URL.Query().Get(&amp;quot;cmd&amp;quot;))
	op := strings.Split(cmd, &amp;quot;/&amp;quot;)

	url := req.URL.Query().Get(&amp;quot;url&amp;quot;)
	if url != &amp;quot;&amp;quot; {
		body, err, res = httpGet(url)
		if err != nil {
			log.Println(&amp;quot;handler http get error:&amp;quot;, err.Error())
		}
	} else {
		body, err = ioutil.ReadAll(req.Body)
		if err != nil {
			log.Printf(&amp;quot;handler body read error: %s\n&amp;quot;, err.Error())
			return
		}
	}

	img, err := png.Decode(bytes.NewReader(body))
	switch op[1] {
	// handler/grey
	case &amp;quot;grey&amp;quot;:
		img = greyImage(img)
		break
	// handler/background
	case &amp;quot;background&amp;quot;:
		img = backGroundImage(img, op[2])
		break

	}
	write(rw, img, res)

}

/**
 * 给图片增加背景颜色
 */
func backGroundImage(srcImage image.Image, color string) image.Image {
	bounds := srcImage.Bounds()
	newRgba := image.NewRGBA(bounds)
	c, _ := ParseHexColor(color)
	for x := 0; x &amp;lt; newRgba.Bounds().Dx(); x++ { // 将背景图涂黑
		for y := 0; y &amp;lt; newRgba.Bounds().Dy(); y++ {
			newRgba.Set(x, y, c)
		}
	}
	// 在中间贴图
	draw.Draw(newRgba, newRgba.Bounds(), srcImage, image.Pt(0, 0), draw.Over)
	return newRgba
}
func ParseHexColor(s string) (c color.RGBA, err error) {
	c.A = 0xff
	switch len(s) {
	case 6:
		_, err = fmt.Sscanf(s, &amp;quot;%02x%02x%02x&amp;quot;, &amp;amp;c.R, &amp;amp;c.G, &amp;amp;c.B)
	case 3:
		_, err = fmt.Sscanf(s, &amp;quot;%1x%1x%1x&amp;quot;, &amp;amp;c.R, &amp;amp;c.G, &amp;amp;c.B)
		// Double the hex digits:
		c.R *= 17
		c.G *= 17
		c.B *= 17
	case 5:
		s = &amp;quot;0&amp;quot; + s
		_, err = fmt.Sscanf(s, &amp;quot;%02x%02x%02x&amp;quot;, &amp;amp;c.R, &amp;amp;c.G, &amp;amp;c.B)
	default:
		err = fmt.Errorf(&amp;quot;invalid length, must be 7 or 4&amp;quot;)

	}
	return
}

/**
 * 图片灰化处理
 */
func greyImage(m image.Image) *image.RGBA {
	bounds := m.Bounds()
	dx := bounds.Dx()
	dy := bounds.Dy()
	newRgba := image.NewRGBA(bounds)
	for i := 0; i &amp;lt; dx; i++ {
		for j := 0; j &amp;lt; dy; j++ {
			colorRgb := m.At(i, j)
			_, g, _, a := colorRgb.RGBA()
			gUint8 := uint8(g &amp;gt;&amp;gt; 8)
			aUint8 := uint8(a &amp;gt;&amp;gt; 8)
			newRgba.SetRGBA(i, j, color.RGBA{R: gUint8, G: gUint8, B: gUint8, A: aUint8})
		}
	}
	return newRgba
}
func write(rw http.ResponseWriter, img image.Image, res *http.Response) {
	if res != nil {
		rw.Header().Set(&amp;quot;content-type&amp;quot;, res.Header.Get(&amp;quot;content-type&amp;quot;))
		rw.Header().Set(&amp;quot;Content-Disposition&amp;quot;, res.Header.Get(&amp;quot;Content-Disposition&amp;quot;))
	}
	png.Encode(rw, img)
}

func health(rw http.ResponseWriter, req *http.Request) {
	rw.Write([]byte(&amp;quot;ok&amp;quot;))
}

func main() {
	port := os.Getenv(&amp;quot;PORT_HTTP&amp;quot;)
	if port == &amp;quot;&amp;quot; {
		port = &amp;quot;9100&amp;quot;
	}
	http.HandleFunc(&amp;quot;/handler&amp;quot;, handler)
	http.HandleFunc(&amp;quot;/health&amp;quot;, health)
	log.Fatalln(http.ListenAndServe(&amp;quot;0.0.0.0:&amp;quot;+port, nil))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;github: https://github.com/zxcvbnmzsedr/ufop-golang-demo&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[苹果 macOS 12 Monterey 升级]]></title><link>https://www.ztianzeng.com/posts/苹果 macOS 12 Monterey 升级</link><guid isPermaLink="false">/posts/苹果 macOS 12 Monterey 升级</guid><category><![CDATA[Other]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;苹果-macOS-12-Monterey-升级&quot;&gt;苹果 macOS 12 Monterey 升级&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;苹果6.7号大半夜开wwdc，发布了一系列新的系统，被戏称mac on  Harmony。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;第一时间从 https://developer.apple.com/download/ 上下载了描述文件，第一波尝鲜。&lt;/p&gt;
&lt;h1 id=&quot;目前有问题的软件&quot;&gt;目前有问题的软件&lt;/h1&gt;
&lt;h2 id=&quot;微信闪退&quot;&gt;微信闪退&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;更新之后闪退，而且无法安装微信小助手。从网上的讨论来看只涉及到Intel的芯片，M1的能够打开，但是点击图片闪退。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;无论从官网重新下载还是通过appstore重新安装，都无法正常打开。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;del&gt;只有下载2.0的内测版本，能够勉强登录微信，时不时也会闪退。只有等着官方适配了&lt;/del&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;del&gt;内测版下载地址:  https://mac.weixin.qq.com/?beta=1&lt;/del&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;官方已经发布了新的版本，解决了闪退问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;a href=&quot;https://support.qq.com/products/292433/faqs/96666&quot;&gt;https://support.qq.com/products/292433/faqs/96666&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;WPSwps也时不时闪退-看官网已经说升级了-10-12-但是还是闪退&quot;&gt;WPS&lt;del&gt;wps也时不时闪退，看官网已经说升级了 10.12。但是还是闪退&lt;/del&gt;&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;wps官网已经更新到3.7.0，正常了&lt;/p&gt;
&lt;h2 id=&quot;Alfred&quot;&gt;Alfred&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;破解版打不开了，支持正版吧&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Maven包管理]]></title><link>https://www.ztianzeng.com/posts/Maven包管理</link><guid isPermaLink="false">/posts/Maven包管理</guid><category><![CDATA[Other]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Maven包管理&quot;&gt;Maven包管理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;今天面试被问到maven包管理的机制。&lt;/p&gt;
&lt;blockquote updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;A引用B A引用C ，B引用D1.0版本，C引用D2.0版本。。那么A引用的是1.0还是2.0&lt;br /&gt;
这个问题没答上来，不过按照自己的多年的经验来进行推断，推断出来是依赖隔离那套，明显是有点问题。哈哈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;平常在排查mavenjar冲突的时候，使用mvn dependency:tree找出有问题的jar,然后粗暴的用exclusion将出现问题的jar包给排除掉。还真没了解过其中奥妙。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;maven 是有两种规则来尽可能规避依赖冲突问题，广度优先 和 声明优先。&lt;/p&gt;
&lt;h2 id=&quot;广度优先&quot;&gt;广度优先&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;看下图这种依赖关系，最终项目中存在的是哪个？&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;A
├── B
│   └── C
│       └── D 2.0
└── E
    └── D 1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从A到D有两条路径，A-&amp;gt;B-&amp;gt;C-&amp;gt;D 2.0 和 A-&amp;gt;E-&amp;gt;D 1.0 。根据广度优先的规则，先扫描到的是D 1.0 这个版本，后面再扫描到了D 2.0 就不会加入依赖，因此最后的版本是1.0;&lt;/p&gt;
&lt;h2 id=&quot;声明优先&quot;&gt;声明优先&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;看下图这种依赖关系，最终项目中存在的是哪个？&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;A
├── B
│ └── D 2.0
└── C
    └── D 1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;根据广度优先的理论，从A到D都是三层，A-&amp;gt;B-&amp;gt;D 2.0 和 A-&amp;gt;C-&amp;gt;D 1.0 。在扫描时发现有两个D，会将先声明的D 2.0 加入到依赖中，也就是D 2.0.&lt;/p&gt;
&lt;h2 id=&quot;依赖隔离&quot;&gt;依赖隔离&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;A
├── B
│ └── D 2.0
└── C
    └── D 1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;有的时候我们的jar在修改的时候没有考虑到兼容升级的问题，导致1.0和2.0的版本差异非常大。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个时候，无论怎么修改jar版本其实都没有办法满足需求，其最好的方式还是采用C依赖D1.0，B依赖2.0。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;各依赖各自的版本，这样就不会出现jar冲突了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前有两个解决思路，打包时解决和运行时解决&lt;/p&gt;
&lt;h2 id=&quot;打包时解决&quot;&gt;打包时解决&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;maven-shade-plugin将B或者C打成一个独立的jar包来解决。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;maven-shade-plugin 在打包时，可以将项目中依赖的 jar 包中的一些类文件打包到项目构建生成的 jar 包中，在打包的时候把类重命名。&lt;/p&gt;
&lt;h2 id=&quot;运行时解决&quot;&gt;运行时解决&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行时解决只有通过我们神奇的classLoader了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这块官方并没有什么比较好的解决方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前支付宝开源的sofa可以了解一下，https://www.sofastack.tech/projects/sofa-boot/sofa-ark-readme/&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[使用Centos7构建安卓apk包]]></title><link>https://www.ztianzeng.com/posts/使用Centos7构建安卓apk包</link><guid isPermaLink="false">/posts/使用Centos7构建安卓apk包</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;使用Centos7构建安卓apk包&quot;&gt;使用Centos7构建安卓apk包&lt;/h1&gt;
&lt;h2 id=&quot;基础环境&quot;&gt;基础环境&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sh&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;yum install -y java-1.8.0-openjdk-devel.x86_64 wget unzip

# nodejs
curl --silent --location https://rpm.nodesource.com/setup_10.x | sudo bash -
yum install -y nodejs
curl --silent --location https://dl.yarnpkg.com/rpm/yarn.repo | sudo tee /etc/yum.repos.d/yarn.repo
sudo rpm --import https://dl.yarnpkg.com/rpm/pubkey.gpg
yum install -y yarn

# 文件数限制
cat &amp;gt;&amp;gt; /etc/sysctl.conf &amp;lt;&amp;lt; EOF
fs.inotify.max_user_watches=524288
EOF
sysctl -p

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;安卓环境&quot;&gt;安卓环境&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sh&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;cd /home
mkdir andoird
mkdir gradle

# 安装gradle
cd gradle
export gradle_version=6.7.1
wget https://downloads.gradle-dn.com/distributions/gradle-$gradle_version-bin.zip
unzip gradle-$gradle_version-bin.zip &amp;amp;&amp;amp; rm -rf  gradle-$gradle_version-bin.zip
## 环境变量
cat &amp;gt;&amp;gt; /etc/profile.d/andoird.sh &amp;lt;&amp;lt; EOF
export GRADLE_USER_HOME=/home/gradle/gradle-$gradle_version
export PATH=$PATH:$GRADLE_USER_HOME/bin
EOF
source /etc/profile
cd /home

# 安装安卓相关的类库
cd android
# 安装commandlinetools-linux
wget https://dl.google.com/android/repository/commandlinetools-linux-7583922_latest.zip
unzip commandlinetools-linux-7583922_latest.zip &amp;amp;&amp;amp; rm -rf commandlinetools-linux-7583922_latest.zip
## 安装环境
sh cmdline-tools/bin/sdkmanager &amp;quot;platform-tools&amp;quot; &amp;quot;platforms;android-24&amp;quot; --sdk_root=/home/android/
cd /home
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Mac使用Fuse挂载NTFS]]></title><link>https://www.ztianzeng.com/posts/Mac使用Fuse挂载NTFS</link><guid isPermaLink="false">/posts/Mac使用Fuse挂载NTFS</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Mac使用Fuse挂载NTFS&quot;&gt;Mac使用Fuse挂载NTFS&lt;/h1&gt;
&lt;h2 id=&quot;步骤&quot;&gt;步骤&lt;/h2&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-ae2upu9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;安装Fuse和nefs-3g&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;brew install --cask macfuse
brew install gromgit/fuse/ntfs-3g
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-tpih9u5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取相关参数&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;id  ## 获取当前mac登录用户的id和gid，替换下面的参数
df -h ## 获取外挂盘的盘符，可以根据磁盘大小来推测，我的盘符是/dev/disk2s1
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-thrroi9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;挂载&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;cd ~
mkdir disk
sudo ntfs-3g -o uid={uid},gid={gid},dmask=022,fmask=133 -o auto_xattr /dev/disk2s1 ~/disk 
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[私有云笔记调研]]></title><link>https://www.ztianzeng.com/posts/私有云笔记调研</link><guid isPermaLink="false">/posts/私有云笔记调研</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;私有云笔记调研&quot;&gt;私有云笔记调研&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;前两年买了在打折时，购入了印象笔记 VIP，原以为充值了印象笔记能够比较好用一点，事实上是我想多了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我需求其实比较简单，能够编辑 markdown 文档，然后保存编辑即可，不需要那么多华丽呼哨的功能，基本上也 用不到。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;所以，在需要搭建一个比较简单的，私有云笔记。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前世面上，能够常用的三种云笔记有第三种&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6eek1or&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;蚂蚁笔记&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ua8db3c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Markidea&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-tnrkgn5&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;觅道文档&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最终采用了思源笔记作为主要的笔记软件，真香&lt;/p&gt;
&lt;h2 id=&quot;蚂蚁笔记&quot;&gt;蚂蚁笔记&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;市面上，最多见的 NAS 私有云笔记的方案，但是其界面不是很能欣赏的来。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;其次，我比较喜欢 Typora 这种所见即所得的编辑方案，因此弃用了这套&lt;/p&gt;
&lt;h2 id=&quot;Markidea&quot;&gt;Markidea&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这个 star 数比较少，是用 Java 写的，利用了&lt;a href=&quot;https://hacpai.com/article/1549638745630&quot;&gt;vditor&lt;/a&gt;来作为编辑器。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且，能够将文档上传到 git 上面，无需担心私有云的硬盘挂掉而带来的数据丢失。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可问题是，界面不是很好看，交互比较诡异，部署也不方便，使用了一天放弃了，没有办法作为生产力工具来使用，可能哪天有钱有闲，会参与这个项目的研发，现在着实没得空。&lt;/p&gt;
&lt;h2 id=&quot;觅道文档&quot;&gt;觅道文档&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;支持掏钱的专业版部署，也有开源版本，目前看来是最好用的一款软件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果把它作为一个写笔记的软件，应该说是大材小用，它这个高颜值的界面可以在几分钟之内搭建自己的网站，它的定位也是面向中小企业的内部文档管理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果说有什么不好，那就是没有办法支持 git，图床也是用的本地的图床，也许哪天服务器挂了东西就不存在了，得自己再手动对这个文件进行一个备份。&lt;/p&gt;
&lt;h2 id=&quot;思源笔记&quot;&gt;思源笔记&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;思源笔记，不多说了，真香。。。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;整体结构和Notion差不多，但是远比Notion更加易用&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Openwrt搭建免流服务器]]></title><link>https://www.ztianzeng.com/posts/Openwrt搭建免流服务器</link><guid isPermaLink="false">/posts/Openwrt搭建免流服务器</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Openwrt搭建免流服务器&quot;&gt;Openwrt搭建免流服务器&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之前在阿里云上通过V2Ray搭建了免流服务器，奈何固定带宽速度太慢，而流量计费高达0.8元/G的成本又和绝大多数的互联网套餐价格相差无几。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因此就琢磨着，是不是可以在家中，通过公网IP来自建免流服务器。&lt;/p&gt;
&lt;h1 id=&quot;要求&quot;&gt;要求&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-w8n98u9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Openwrt 必须能够获取到公网地址(IPV4或者PV6)&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-rtvpte8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;卡里面需要有定向的免费流量套餐&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s02sr76&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DDNS内网穿透&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-613qew9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果是联通卡的话，得是80端口&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;原理&quot;&gt;原理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为运营商的代理服务器和运营商的计费检测系统是分离的，通过欺骗的方式，把真实的流量代理成免费的流量&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;步骤&quot;&gt;步骤&lt;/h1&gt;
&lt;h2 id=&quot;安装V2RAY&quot;&gt;安装V2RAY&lt;/h2&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-zp84tht&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;v2ray-core ipk安装包&lt;br /&gt;
https://github.com/kuoruan/openwrt-v2ray/releases&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-ngxn8oa&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;luci界面和中文支持&lt;br /&gt;
https://github.com/kuoruan/luci-app-v2ray/releases&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;编写配置文件&quot;&gt;编写配置文件&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;{
	&amp;quot;log&amp;quot;: {
		&amp;quot;loglevel&amp;quot;: &amp;quot;warning&amp;quot;
	},
	&amp;quot;inbound&amp;quot;: {
		&amp;quot;protocol&amp;quot;: &amp;quot;vmess&amp;quot;,
		&amp;quot;port&amp;quot;: 80,
		&amp;quot;settings&amp;quot;: {
			&amp;quot;clients&amp;quot;: [{
				&amp;quot;id&amp;quot;: &amp;quot;ad806487-2d26-4636-98b6-ab85cc8521f7&amp;quot;,
				&amp;quot;alterId&amp;quot;: 64,
				&amp;quot;security&amp;quot;: &amp;quot;chacha20-poly1305&amp;quot;
			}]
		},
		&amp;quot;streamSettings&amp;quot;: {
			&amp;quot;network&amp;quot;: &amp;quot;tcp&amp;quot;,
			&amp;quot;httpSettings&amp;quot;: {
				&amp;quot;path&amp;quot;: &amp;quot;/&amp;quot;
			},
			&amp;quot;tcpSettings&amp;quot;: {
				&amp;quot;header&amp;quot;: {
					&amp;quot;type&amp;quot;: &amp;quot;http&amp;quot;,
					&amp;quot;response&amp;quot;: {
						&amp;quot;version&amp;quot;: &amp;quot;1.1&amp;quot;,
						&amp;quot;status&amp;quot;: &amp;quot;200&amp;quot;,
						&amp;quot;reason&amp;quot;: &amp;quot;OK&amp;quot;,
						&amp;quot;headers&amp;quot;: {
							&amp;quot;Content-Type&amp;quot;: [&amp;quot;application/octet-stream&amp;quot;, &amp;quot;application/x-msdownload&amp;quot;, &amp;quot;text/html&amp;quot;, &amp;quot;application/x-shockwave-flash&amp;quot;],
							&amp;quot;Transfer-Encoding&amp;quot;: [&amp;quot;chunked&amp;quot;],
							&amp;quot;Connection&amp;quot;: [&amp;quot;keep-alive&amp;quot;],
							&amp;quot;Pragma&amp;quot;: &amp;quot;no-cache&amp;quot;
						}
					}
				}
			}
		}
	},
	&amp;quot;inboundDetour&amp;quot;: [],
	&amp;quot;outbound&amp;quot;: {
		&amp;quot;protocol&amp;quot;: &amp;quot;freedom&amp;quot;,
		&amp;quot;settings&amp;quot;: {}
	}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;防火墙开放端口&quot;&gt;防火墙开放端口&lt;/h2&gt;
&lt;h1 id=&quot;手机设置&quot;&gt;手机设置&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;手机上安装V2RAY客户端&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;家里动态域名&lt;br /&gt;
协议就是websocks (WS)&lt;br /&gt;
加密方式任意.&lt;br /&gt;
端口83&lt;br /&gt;
id填写配置文件.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;伪装协议为http&lt;br /&gt;
伪装host为免流host&lt;/p&gt;
&lt;h1 id=&quot;最后&quot;&gt;最后&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;慎用，哈哈&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[在上Alpine Linux安装Adguard Home]]></title><link>https://www.ztianzeng.com/posts/在上Alpine Linux安装Adguard Home</link><guid isPermaLink="false">/posts/在上Alpine Linux安装Adguard Home</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;在上Alpine-Linux安装Adguard-Home&quot;&gt;在上Alpine Linux安装Adguard Home&lt;/h1&gt;
&lt;hr /&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;title: &apos;在上Alpine Linux安装Adguard Home&apos;&lt;br /&gt;
date: 2021-12-19 14:52:15&lt;br /&gt;
tags: [软路由]&lt;br /&gt;
published: true&lt;br /&gt;
hideInList: false&lt;br /&gt;
feature:&lt;br /&gt;
isTop: false&lt;/p&gt;
&lt;hr /&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于没有Systemd, Adguard Home的官网的安装方法在Alpine Linux上无法工作。&lt;br /&gt;
然而，需要用OpenRC运行它非常简单。&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-juvbak6&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过 &lt;code&gt;curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v&lt;/code&gt; 进行安装&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-6trtkxx&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;编写命令  &lt;code&gt;vim /etc/init.d/AdguardHome&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;sh&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;#!/sbin/openrc-run
#
# openrc service-script for AdGuardHome
#
# place in /etc/init.d/
# start on boot: &amp;quot;rc-update add adguardhome&amp;quot;
# control service: &amp;quot;service adguardhome &amp;lt;start|stop|restart|status|checkconfig&amp;gt;&amp;quot;
#

description=&amp;quot;AdGuard Home: Network-level blocker&amp;quot;

pidfile=&amp;quot;/run/$RC_SVCNAME.pid&amp;quot;
command=&amp;quot;/opt/AdGuardHome/AdGuardHome&amp;quot;
command_args=&amp;quot;-s run&amp;quot;
command_background=true

extra_commands=&amp;quot;checkconfig&amp;quot;

depend() {
  need net
  provide dns
  after firewall
}

checkconfig() {
  &amp;quot;$command&amp;quot; --check-config || return 1
}

stop() {
  if [ &amp;quot;${RC_CMD}&amp;quot; = &amp;quot;restart&amp;quot; ] ; then
    checkconfig || return 1
  fi

  ebegin &amp;quot;Stopping $RC_SVCNAME&amp;quot;
  start-stop-daemon --stop --exec &amp;quot;$command&amp;quot; \
    --pidfile &amp;quot;$pidfile&amp;quot; --quiet
  eend $?
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li id=&quot;20220705131435-u1gdnhi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;启动服务，并开启自启动&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;code&gt;chmod +x /etc/init.d/AdguardHome&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;rc-update add AdguardHome&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;rc-service  AdguardHome start&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[定时备份数据]]></title><link>https://www.ztianzeng.com/posts/定时备份数据</link><guid isPermaLink="false">/posts/定时备份数据</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;定时备份数据&quot;&gt;定时备份数据&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了防止硬盘的损坏，因此需要定时将数据同步到阿里云盘中。。。。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过 rclone 命令将定时任务挂载到阿里云盘中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在配置 rclone 的时候，如果是 webdav 一定要选择 webdav，而不能选择 http，如果选择了 http 协议在挂载和读取的过程中没有任何问题，但是在上传文件的时候会爆出权限异常，&lt;code&gt;http remotes are read only&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;rclone 同步的命令是:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# transfers 指定同时上传数量
rclone sync /home ali:/omv/back/home --transfers=8 -P
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将 rclone 配置成服务:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vim /etc/systemd/system/backup.service

[Unit]
Description=backup
After=network.target

[Service]
Type=oneshot
User=root
ExecStart=/usr/bin/rclone sync /home ali:/omv/back/home --transfers=8 -P
Restart=on-failure

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将 rclone 配置成定时任务:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vim /etc/systemd/system/backup.timer

[Unit]
Description=backUp Timer

[Timer]
OnUnitActiveSec=1h
Unit=backup.service

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之后只需要开启定时任务即可:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl daemon-reload
systemctl enable backup.timer
systemctl start backup.timer
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不放心，手动启动一遍看有没有错:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl start backup
# 查看状态
systemctl status backup
# 连续打印日志
journalctl -u backup -n 20 -f
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[PVE下的软路由组网]]></title><link>https://www.ztianzeng.com/posts/PVE下的软路由组网</link><guid isPermaLink="false">/posts/PVE下的软路由组网</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;PVE下的软路由组网&quot;&gt;PVE下的软路由组网&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从最开始折腾iKuai+OpenWrt到单Openwrt，到最后使用PVE搭建路由环境，前后将近快一年的时间。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;经历过频繁的断网，断流，死机，已经摸索出一套相对稳定的方案。&lt;/p&gt;
&lt;h2 id=&quot;软路由&quot;&gt;软路由&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我对软路由的需求有三个:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-eh6rqi9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分流设备，全局翻墙&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-3hbj95x&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;DNS去广告&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-c5vmny9&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;局域网存储用于播放内网视频&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;基于这些需求，我选择了J3160作为软路由的硬件配置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;硬件:&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6mujrvi&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;J3160 + 4G内存 + 32G固态 + 500G机械&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s4kt2wl&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;小米A3600做的AP&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;网络拓扑图如下:&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/%E8%BD%AF%E8%B7%AF%E7%94%B1.png&quot; alt=&quot;软路由&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;PVE系统&quot;&gt;PVE系统&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了在折腾其他比如NAS，DNS的时候，依然能够保证网络的畅通，所以选用了PVE来当做底层系统，这样即使路由挂了，依然能够通过网页访问PVE中的各种系统。&lt;/p&gt;
&lt;h3 id=&quot;接口&quot;&gt;接口&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我买的提供了4个网口，Lan 3口接入光猫，Lan1口接入路由。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20211221165148379.png&quot; alt=&quot;image-20211221165148379&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;PVE中安装的系统&quot;&gt;PVE中安装的系统&lt;/h2&gt;
&lt;h3 id=&quot;Lede&quot;&gt;Lede&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;lede作为主路由，承担了拨号、科学上网的职责。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;固件是自己编译的:  https://github.com/zxcvbnmzsedr/Actions-OpenWrt-Template&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了运行的稳定，只保留了相对基础的功能，以及 &lt;code&gt;OpenClash&lt;/code&gt;、&lt;code&gt;Zerotier&lt;/code&gt;、&lt;code&gt;Ipv6&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;AdguardHome&quot;&gt;AdguardHome&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接通过PVE的LXC容器的alpine系统安装，最简化配置。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;分离DNS是由于OpenClash和DNS的依赖性太强了，而且AdguardHome和OpenClash共存方案都不够优雅，就直接分离了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注意事项参考: https://www.ztianzeng.com/post/zai-shang-alpine-linux-an-zhuang-adguard-home/&lt;/p&gt;
&lt;h3 id=&quot;openmediavault&quot;&gt;openmediavault&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;采用OMV作为NAS的原因是它的资源远比群晖的低，且开源。&lt;/p&gt;
&lt;h2 id=&quot;硬路由&quot;&gt;硬路由&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;硬路由就是普通的家用路由。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作用就两个:&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-0mzpzbs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作为小型交换机，扩展LAN口&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zc0fp3z&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;提供wifi信号&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;唯一需要注意的是，在设置路由的时候，将路由模式设置成桥接模式，这样对于硬路由而言它不再提供上网服务，只是作为流量的中间站，流量全会交给软路由进行处理。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20211221171438933.png&quot; alt=&quot;image-20211221171438933&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;PS: 光猫需要改桥接，以获得最佳性能。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[在Spring2.4中使用NacosConfig]]></title><link>https://www.ztianzeng.com/posts/在Spring2.4中使用NacosConfig</link><guid isPermaLink="false">/posts/在Spring2.4中使用NacosConfig</guid><category><![CDATA[Spring]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;在Spring2-4中使用NacosConfig&quot;&gt;在Spring2.4中使用NacosConfig&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为spring cloud alibaba没有进行升级，导致在spring2.4下，无法通过最新的方式引用配置文件。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;心中甚是不爽，因此基于最新的配置规则，给nacos打了个布丁。&lt;/p&gt;
&lt;h1 id=&quot;修改原始配置文件&quot;&gt;修改原始配置文件&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将原本的工程的application.yml改成这样，重点是optional:nacos 后面的一定要是nacos&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;别的就基本遵循nacos原本的配置就好了，该是啥样就啥样&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;yml&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;spring:
  cloud:
    nacos:
      server-addr: www.nacos.com:80
      config:
        shared-configs:
          - data-id: ...
        file-extension: yaml
        namespace: ${spring.profiles.active}
  config:
    import: optional:nacos:${spring.cloud.nacos.server-addr}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;新增spring-factories&quot;&gt;新增spring.factories&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;properties&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;文件位置在这里
resources/
   META-INF/
      spring.factories
# 自己在前面添加包名
org.springframework.boot.context.config.ConfigDataLocationResolver=\
NacosConfigDataLocationResolver

org.springframework.boot.context.config.ConfigDataLoader=\
NacosServerConfigDataLoader
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;创建对应的配置文件位置解析和配置文件夹在&quot;&gt;创建对应的配置文件位置解析和配置文件夹在&lt;/h1&gt;
&lt;h2 id=&quot;NacosConfigDataLocationResolver-java&quot;&gt;NacosConfigDataLocationResolver.java&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import com.alibaba.cloud.nacos.NacosConfigManager;
import com.alibaba.cloud.nacos.NacosConfigProperties;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.context.config.*;
import org.springframework.boot.context.properties.bind.BindHandler;
import org.springframework.boot.context.properties.bind.Bindable;
import org.springframework.boot.context.properties.bind.Binder;
import org.springframework.context.annotation.Bean;
import org.springframework.core.Ordered;
import org.springframework.core.env.StandardEnvironment;
import org.springframework.util.StringUtils;

import java.util.Collections;
import java.util.List;

public class NacosConfigDataLocationResolver implements ConfigDataLocationResolver&amp;lt;NacosServerConfigDataResource&amp;gt;, Ordered {

    /**
     * 就这个是让配置文件找到这个解析器的核心字符串，千万不能写错了
     */
    public static final String PREFIX = &amp;quot;nacos:&amp;quot;;

    public NacosConfigDataLocationResolver() {

    }

    @Bean
    @ConditionalOnMissingBean
    public NacosConfigProperties nacosConfigProperties() {
        return new NacosConfigProperties();
    }

    @Override
    public int getOrder() {
        return -1;
    }

    @Override
    public boolean isResolvable(ConfigDataLocationResolverContext context, ConfigDataLocation location) {
        return location.hasPrefix(PREFIX);
    }

    @Override
    public List&amp;lt;NacosServerConfigDataResource&amp;gt; resolve(ConfigDataLocationResolverContext context, ConfigDataLocation location) throws ConfigDataLocationNotFoundException, ConfigDataResourceNotFoundException {
        return Collections.emptyList();
    }

    @Override
    public List&amp;lt;NacosServerConfigDataResource&amp;gt; resolveProfileSpecific(ConfigDataLocationResolverContext context, ConfigDataLocation location, Profiles profiles) throws ConfigDataLocationNotFoundException {
        String uris = location.getNonPrefixedValue(PREFIX);
        final NacosConfigProperties properties = loadProperties(context);
        properties.setServerAddr(uris);

        return Collections.singletonList(new NacosServerConfigDataResource(new NacosConfigManager(properties)));
    }

    protected NacosConfigProperties loadProperties(ConfigDataLocationResolverContext context) {
        Binder binder = context.getBinder();
        BindHandler bindHandler = getBindHandler(context);
        NacosConfigProperties configClientProperties = binder
                .bind(NacosConfigProperties.PREFIX, Bindable.of(NacosConfigProperties.class), bindHandler)
                .orElseGet(NacosConfigProperties::new);
        configClientProperties.setEnvironment(new StandardEnvironment());
        if (!StringUtils.hasText(configClientProperties.getName())) {
            // default to spring.application.name if name isn&apos;t set
            String applicationName = binder.bind(&amp;quot;spring.application.name&amp;quot;, Bindable.of(String.class), bindHandler)
                    .orElse(&amp;quot;application&amp;quot;);
            configClientProperties.setPrefix(applicationName);
        }
        return configClientProperties;
    }

    private BindHandler getBindHandler(ConfigDataLocationResolverContext context) {
        return context.getBootstrapContext().getOrElse(BindHandler.class, null);
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;NacosServerConfigDataLoader-java&quot;&gt;NacosServerConfigDataLoader.java&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import com.alibaba.cloud.nacos.NacosConfigManager;
import com.alibaba.cloud.nacos.client.NacosPropertySourceLocator;
import org.springframework.boot.context.config.ConfigData;
import org.springframework.boot.context.config.ConfigDataLoader;
import org.springframework.boot.context.config.ConfigDataLoaderContext;
import org.springframework.boot.context.config.ConfigDataResourceNotFoundException;
import org.springframework.core.env.PropertySource;
import org.springframework.core.env.StandardEnvironment;

import java.util.Collections;


public class NacosServerConfigDataLoader implements ConfigDataLoader&amp;lt;NacosServerConfigDataResource&amp;gt; {


    @Override
    public ConfigData load(ConfigDataLoaderContext context, NacosServerConfigDataResource resource) throws ConfigDataResourceNotFoundException {
        NacosConfigManager nacosConfigManager = resource.getNacosConfigManager();
        final NacosPropertySourceLocator nacosPropertySourceLocator = new NacosPropertySourceLocator(nacosConfigManager);
        final PropertySource&amp;lt;?&amp;gt; locate = nacosPropertySourceLocator.locate(new StandardEnvironment());
        return new ConfigData(Collections.singletonList(locate));
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;NacosServerConfigDataResource-java&quot;&gt;NacosServerConfigDataResource.java&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;import com.alibaba.cloud.nacos.NacosConfigManager;
import org.springframework.boot.context.config.ConfigDataResource;

public class NacosServerConfigDataResource extends ConfigDataResource {
    private NacosConfigManager nacosConfigManager;

    public NacosServerConfigDataResource(NacosConfigManager nacosConfigManager) {
        this.nacosConfigManager = nacosConfigManager;
    }

    public NacosConfigManager getNacosConfigManager() {
        return nacosConfigManager;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;后续&quot;&gt;后续&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;创建好这些文件，如果不出意外的话应该能够将工程运行起来&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;主要核心就是继承 ConfigDataLocationResolver 和 ConfigDataLoader&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConfigDataLocationResolver 用于冷启动时，初始化各种参数，打包成一个ConfigDataResource交由给ConfigDataLoader使用&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;ConfigDataLoader则是通过ConfigDataResource进行配置文件的加载，加载到Environment中供应用程式使用&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[spring24]]></title><link>https://www.ztianzeng.com/posts/spring24</link><guid isPermaLink="false">/posts/spring24</guid><category><![CDATA[Spring]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;spring24&quot;&gt;spring24&lt;/h1&gt;
&lt;h1 id=&quot;全新的配置文件处理&quot;&gt;全新的配置文件处理&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我感觉最大的改变是提供了新的配置文件的加载方式，为了去适应k8s容器化部署中的configMap。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不想使用新的加载方式，依然提供了旧版的加载方式&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;引入依赖&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;xml&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-cloud-starter-bootstrap&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.0.3&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在配置文件中加上 spring.config.use-legacy-processing=true &lt;/p&gt;
&lt;h2 id=&quot;新版加载方式spring-config-import属性&quot;&gt;新版加载方式spring.config.import属性&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;spring.config.import属性可被视作这个版本最为牛逼的属性。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;可以从不同的位置加载数据&lt;/p&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-z3s7vaw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加载classpath数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;properties&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;spring.config.import=optional:file:./dev.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-g360a78&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加载文件系统的数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;properties&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;spring.config.import=file:/etc/config/myconfig[.yaml]
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;3&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-saxrb67&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;加载Kubernetes的configMap(先将Kubernetes的数据挂载到卷轴上，然后在进行引用)&lt;br /&gt;
&lt;a href=&quot;https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-files-from-a-pod&quot;&gt;如何配置看这里&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;properties&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;spring.config.import=optional:configtree:/etc/config/
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;4&quot; updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-5ibajci&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自定义加载数据，你可以通过自己喜欢的方式去从任意位置加载配置文件&lt;br /&gt;
&lt;a href=&quot;/post/zai-spring24-zhong-shi-yong-nacosconfig/&quot;&gt;😃具体使用方式看这里&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;新的版本描述方案&quot;&gt;新的版本描述方案&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了更加照顾英语非母语的开发者，spring采用了新的命名方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之前那套用英文命名的真的让人摸不着头脑，英语也就算了，还整些个不常用的生词。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;单词的拼写很困难，版本号全靠复制。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且版本号上面也难以看出版本向下兼容性，很难做出判断而做出风险预估。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了解决这些问题&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring采用了日历化版本，并且使用的规则/公式是YYYY.MINOR.MICRO[-MODIFIER]，&lt;/p&gt;
&lt;h3 id=&quot;对各部分解释如下-&quot;&gt;对各部分解释如下：&lt;/h3&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-6uljn9c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;YYYY：年份全称。eg：2020&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-n8uvzdc&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MINOR：辅助版本号（一般升级些非主线功能），在当前年内从0递增&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j22ry7l&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MICRO：补丁版本号（一般修复些bug），在当前年内从0递增&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uj09u7g&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MODIFIER：非必填。后缀，它用于修饰一些关键节点，用这些字母表示&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5zue8j8&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;M数字：里程碑版本，如2020.0.0-M1、2020.0.0-M2&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-5hodpqp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RC数字：发布候选版本，如2020.0.0-RC1、2020.0.0-RC2&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lthihl1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;SNAPSHOT：快照版本（后无数字），如2020.0.0-SNAPSHOT&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fb2rx48&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;啥都木有：正式版本（可放心使用，相当于之前的xxx-RELEASE），如2020.0.0&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1 id=&quot;R2DBC&quot;&gt;R2DBC&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AR2dbcEntityTemplate可用于通过实体简化 Reactive R2DBC 的使用&lt;/p&gt;
&lt;h1 id=&quot;Java-15-支持&quot;&gt;Java 15 支持&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Boot 2.4 现在完全支持（并针对）Java 15。支持的最低版本仍然是 Java 8。&lt;/p&gt;
&lt;h1 id=&quot;自定义属性名称支持&quot;&gt;自定义属性名称支持&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果想注入的名称和java关键字想冲突可以使用@Name属性进行注入&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;java&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;@ConfigurationProperties(prefix = &amp;quot;sample&amp;quot;)
@ConstructorBinding
public class SampleConfigurationProperties {

  private final String importValue;

  public SampleConfigurationProperties(@Name(&amp;quot;import&amp;quot;) String importValue) {
    this.importValue = importValue;
  }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;依赖升级&quot;&gt;依赖升级&lt;/h1&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-yycvy4o&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring AMQP 2.3&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-78qk0ao&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Batch 4.&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-osyt32f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Data 2020.0&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-pbehelj&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Framework 5.3&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fc3cpve&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Integration 5.4&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-lydzxcv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring HATEOAS 1.2&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-z755g2m&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Kafka 2&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-xdqhiaf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Retry 1.3&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jsaxa8f&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Security 5.4&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-r0gbsms&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Spring Session 2020.0&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还更新了许多第三方依赖项：&lt;/p&gt;
&lt;ul updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xm6ynhw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Artemis 2.13&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-polx5cp&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;AssertJ 3.18&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-s2wy828&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Cassandra Driver 4.7&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j10rmca&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Elasticsearch 7.9&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-k6nh15e&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Flyway 7&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-fwq9m16&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Jersey 2.31&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jgg2ukw&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;JUnit 5.7&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-jxf00eq&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Liquibase 3.10&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-4h9n5vf&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Lettuce 6.0&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m010l6c&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Micrometer 1.6&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-uo33iag&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Mockito 3.4&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-34kn0qd&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;MongoDB 4.1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-8uvz21s&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Oracle Database 19.7&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b9qtlfs&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Reactor 2020.0&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-j5pomp2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;RSocket 1.1&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-oxuumk1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Undertow 2.2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title><![CDATA[K8S从入门到放弃 —— 安装Ingress]]></title><link>https://www.ztianzeng.com/posts/K8S从入门到放弃 —— 安装Ingress</link><guid isPermaLink="false">/posts/K8S从入门到放弃 —— 安装Ingress</guid><category><![CDATA[K8S]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;K8S从入门到放弃----安装Ingress&quot;&gt;K8S从入门到放弃 —— 安装Ingress&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Ingress 是提供了一个路由，用于反向代理到集群内部的服务中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这是官网的一张请求示例图。能清晰的看到Ingress所提供的功能。&lt;/p&gt;
&lt;h1 id=&quot;Ingress-Controller&quot;&gt;Ingress Controller&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Ingress 提供了好多种实现方式，比如 traefic / Kong / Istio / Nginx 等&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;最恶心的是，Nginx 还提供了两个版本 :&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一个是Nginx公司实现的 &lt;a href=&quot;https://github.com/nginxinc/kubernetes-ingress&quot;&gt;nginx-ingress&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;还有一个是K8S 社区实现的 &lt;a href=&quot;https://github.com/kubernetes/ingress-nginx/&quot;&gt;ingress-nginx&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;特性&lt;/th&gt;
            &lt;th&gt;K8S 实现版本&lt;/th&gt;
            &lt;th&gt;Nginx 实现版本 (NGINX)&lt;/th&gt;
            &lt;th&gt;Nginx 实现版本 (NGINX Plus)&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot; colspan=&quot;4&quot;&gt;&lt;strong&gt;基础&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;作者&lt;/td&gt;
            &lt;td&gt;K8S 社区&lt;/td&gt;
            &lt;td&gt;Nginx 公司和社区&lt;/td&gt;
            &lt;td&gt;Nginx 公司和社区&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Nginx版本&lt;/td&gt;
            &lt;td&gt;包含一些三方模块的定制的 Nginx 版本&lt;/td&gt;
            &lt;td&gt;Nginx 官方版本&lt;/td&gt;
            &lt;td&gt;Nginx Plus&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;商业支持&lt;/td&gt;
            &lt;td&gt;N/A&lt;/td&gt;
            &lt;td&gt;N/A&lt;/td&gt;
            &lt;td&gt;包含&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot; colspan=&quot;4&quot; &lt;strong=&quot;&quot;&gt;通过Ingress资源配置负载均衡&lt;/strong&gt;&lt;/td&gt;
        &lt;tr&gt;
            &lt;td&gt;合并同一host的Ingress规则&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;通过 &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/nginxinc/kubernetes-ingress/blob/master/examples/mergeable-ingress-types&quot;&gt;Mergeable Ingresses&lt;/a&gt; 支持&lt;/td&gt;
            &lt;td&gt;通过 &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/nginxinc/kubernetes-ingress/blob/master/examples/mergeable-ingress-types&quot;&gt;Mergeable Ingresses&lt;/a&gt; 支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;HTTP负载均衡扩展 -- 注解方式&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/&quot;&gt;K8S 支持的注解&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/ingress-resources/advanced-configuration-with-annotations/&quot;&gt;Nginx 支持的注解&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/ingress-resources/advanced-configuration-with-annotations/&quot;&gt;Nginx 支持的注解&lt;/a&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;HTTP负载均衡扩展 -- ConfigMap 方式&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/&quot;&gt;K8S 支持的 ConfigMap 主键&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/configmap-resource/&quot;&gt;Nginx 支持的 ConfigMap 主键&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/configmap-resource/&quot;&gt;Nginx 支持的 ConfigMap 主键&lt;/a&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;TCP/UDP&lt;/td&gt;
            &lt;td&gt;通过 ConfigMap 支持&lt;/td&gt;
            &lt;td&gt;通过 ConfigMap (原生 NGINX 配置) 支持&lt;/td&gt;
            &lt;td&gt;通过 ConfigMap (原生 NGINX 配置) 支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Websocket&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;通过注解支持&lt;/td&gt;
            &lt;td&gt;通过注解支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;TCP SSL Passthrough&lt;/td&gt;
            &lt;td&gt;通过 ConfigMap 支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;JWT 验证&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Session 持久化&lt;/td&gt;
            &lt;td&gt;通过三方库支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;金丝雀测试 (通过 header, cookie, weight)&lt;/td&gt;
            &lt;td&gt;通过注解支持&lt;/td&gt;
            &lt;td&gt;通过定制的资源支持&lt;/td&gt;
            &lt;td&gt;通过定制的资源支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;配置模板 *1&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/template/nginx.tmpl&quot;&gt;模板&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/nginxinc/kubernetes-ingress/blob/master/internal/configs/version1&quot;&gt;模板&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/nginxinc/kubernetes-ingress/blob/master/internal/configs/version1&quot;&gt;模板&lt;/a&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot; colspan=&quot;4&quot;&gt;&lt;strong&gt;通过定制化资源配置负载均衡配置&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;HTTP负载均衡&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/virtualserver-and-virtualserverroute-resources/&quot;&gt;VirtualServer 和 VirtualServerRoute&lt;/a&gt; 资源&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/virtualserver-and-virtualserverroute-resources/&quot;&gt;VirtualServer 和 VirtualServerRoute&lt;/a&gt; 资源&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan=&quot;4&quot;&gt;&lt;strong&gt;部署&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;命令行参数 *2&lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://kubernetes.github.io/ingress-nginx/user-guide/cli-arguments/&quot;&gt;K8S 版 参数列表&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;见 &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/command-line-arguments/&quot;&gt;Nginx 版 参数列表&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;同左&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;默认 Server 的 TLS 证书和秘钥&lt;/td&gt;
            &lt;td&gt;必需(命令行参数) / 自动生成&lt;/td&gt;
            &lt;td&gt;必需(命令行参数)&lt;/td&gt;
            &lt;td&gt;必需(命令行参数)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Helm Chart&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&quot;center&quot; colspan=&quot;4&quot;&gt;&lt;strong&gt;运维&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;上报 Ingress 控制器的 IP地址到Ingress资源&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;扩展的状态&lt;/td&gt;
            &lt;td&gt;通过三方模块支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Prometheus 整合&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;动态配置 endpoints (无需重新加载配置)&lt;/td&gt;
            &lt;td&gt;通过三方模块支持&lt;/td&gt;
            &lt;td&gt;不支持&lt;/td&gt;
            &lt;td&gt;支持&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我自己一开始使用的是Nginx出品的那个，后面发现Stack Overflow上讨论的问题都没有K8S出品的多，就使用上了K8S的版本Ingress。&lt;/p&gt;
&lt;h1 id=&quot;安装&quot;&gt;安装&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 正常情况下就能装上，但是国内由于某些特殊原因导致访问不了谷歌服务，所以需要手动修改镜像地址
curl  https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.46.0/deploy/static/provider/cloud/deploy.yaml -O

kubectl apply -f deploy.yaml
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[K8S入门到放弃 —— 初始化节点]]></title><link>https://www.ztianzeng.com/posts/K8S入门到放弃 —— 初始化节点</link><guid isPermaLink="false">/posts/K8S入门到放弃 —— 初始化节点</guid><category><![CDATA[K8S]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;K8S入门到放弃----初始化节点&quot;&gt;K8S入门到放弃 —— 初始化节点&lt;/h1&gt;
&lt;hr /&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;title: &apos;K8S入门到放弃 —— 初始化节点&apos;&lt;br /&gt;
date: 2021-06-02 13:40:09&lt;br /&gt;
tags: [K8S]&lt;br /&gt;
published: true&lt;br /&gt;
hideInList: false&lt;br /&gt;
feature:&lt;br /&gt;
isTop: false&lt;/p&gt;
&lt;hr /&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;执行下面操作之前先执行&lt;a href=&quot;/post/k8s-ru-men-dao-fang-qi-qian-zhi-huan-jing-zhun-bei/&quot;&gt;前置环境&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;初始化master节点&quot;&gt;初始化master节点&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;hostnamectl set-hostname master1
# 只在第一个 master 节点执行
# 替换 apiserver.demo 为 您想要的 dnsName
export APISERVER_NAME=apiserver.demo
# Kubernetes 容器组所在的网段，该网段安装完成后，由 kubernetes 创建，事先并不存在于您的物理网络中
export POD_SUBNET=10.100.0.1/16
echo &amp;quot;127.0.0.1    ${APISERVER_NAME}&amp;quot; &amp;gt;&amp;gt; /etc/hosts

cat &amp;lt;&amp;lt;EOF &amp;gt; ./kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.16.2
imageRepository: registry.aliyuncs.com/google_containers
controlPlaneEndpoint: &amp;quot;${APISERVER_NAME}:6443&amp;quot;
networking:
  serviceSubnet: &amp;quot;10.96.0.0/16&amp;quot;
  podSubnet: &amp;quot;${POD_SUBNET}&amp;quot;
  dnsDomain: &amp;quot;cluster.local&amp;quot;
EOF

# kubeadm init
kubeadm init --config=kubeadm-config.yaml --upload-certs

# 配置 kubectl
rm -rf /root/.kube/
mkdir /root/.kube/
cp -i /etc/kubernetes/admin.conf /root/.kube/config
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;初始化完成后安装网络插件&quot;&gt;初始化完成后安装网络插件&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;只有安装网络插件之后，pod直接才能够正常进行通讯&lt;/p&gt;
&lt;h3 id=&quot;安装calico插件&quot;&gt;安装calico插件&lt;/h3&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 要是服务器上网络不好，从本地下载下来传上去也行
curl https://docs.projectcalico.org/manifests/calico.yaml -O
# calico默认子网是192.168.0.0，需要替换成自己设置的子网，这步非常重要！！！
sed -i &amp;quot;s#192\.168\.0\.0/16#${POD_SUBNET}#&amp;quot; calico.yaml 
kubectl apply -f calico.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;加入第二master个节点做高可用&quot;&gt;加入第二master个节点做高可用&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 执行master安装完成后打印出来的代码
# 替换 x.x.x.x 为 ApiServer LoadBalancer 的 IP 地址
export APISERVER_IP=x.x.x.x
# 替换 apiserver.demo 为 前面已经使用的 dnsName
export APISERVER_NAME=apiserver.demo
echo &amp;quot;${APISERVER_IP}    ${APISERVER_NAME}&amp;quot; &amp;gt;&amp;gt; /etc/hosts

  kubeadm join apiserver.k8s:6443 --token 4z3r2v.2p43g28ons3b475v \
    --discovery-token-ca-cert-hash sha256:959569cbaaf0cf3fad744f8bd8b798ea9e11eb1e568c15825355879cf4cdc5d6 \
    --control-plane --certificate-key 41a741533a038a936759aff43b5680f0e8c41375614a873ea49fde8944614dd6

&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果显示过期了，则重新生成token进行请求&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 生成证书
kubeadm init phase upload-certs --upload-certs
# 生成加入命令
kubeadm token create --print-join-command

# 最后拼接出来就大概是这样
kubeadm join apiserver.demo:6443 --token mpfjma.4vjjg8flqihor4vt     --discovery-token-ca-cert-hash sha256:6f7a8e40a810323672de5eee6f4d19aa2dbdb38411845a1bf5dd63485c43d303
--control-plane --certificate-key  $证书
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;初始化worker节点&quot;&gt;初始化worker节点&lt;/h1&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;hostnamectl set-hostname node1
# 如果dns能解析到APISERVER_NAME的域名，则不需要写入到hosts中
export MASTER_IP=x.x.x.x
# 替换 apiserver.demo 为初始化 master 节点时所使用的 APISERVER_NAME
export APISERVER_NAME=apiserver.demo
echo &amp;quot;${MASTER_IP}    ${APISERVER_NAME}&amp;quot; &amp;gt;&amp;gt; /etc/hosts

# 替换为前面 kubeadm token create --print-join-command 的输出结果,如果过期了就再执行一下
kubeadm join apiserver.demo:6443 --token mpfjma.4vjjg8flqihor4vt     --discovery-token-ca-cert-hash sha256:6f7a8e40a810323672de5eee6f4d19aa2dbdb38411845a1bf5dd63485c43d303
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;正常情况下，这个时候能够可以在master节点上通过下面这个命令&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;获取到对应的节点信息以及状态&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[K8S入门到放弃 —— 前置环境准备]]></title><link>https://www.ztianzeng.com/posts/K8S入门到放弃 —— 前置环境准备</link><guid isPermaLink="false">/posts/K8S入门到放弃 —— 前置环境准备</guid><category><![CDATA[K8S]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;K8S入门到放弃----前置环境准备&quot;&gt;K8S入门到放弃 —— 前置环境准备&lt;/h1&gt;
&lt;h1 id=&quot;安装-docker---kubelet&quot;&gt;安装 docker / kubelet&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在每台要安装的机器上都执行这段脚本，安装所有k8s运行时需要的软件。&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;#!/bin/bash
# 卸载旧版本
sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
 sudo yum install -y yum-utils
 yum-config-manager \
    --add-repo \
    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

sed -i &apos;s/download.docker.com/mirrors.aliyun.com\/docker-ce/g&apos; /etc/yum.repos.d/docker-ce.repo
# 安装并启动 docker
sudo yum -y install docker-ce docker-ce-cli containerd.io    
systemctl enable docker
systemctl start docker
systemctl stop firewalld
systemctl disable firewalld

# 安装 nfs-utils
# 必须先安装 nfs-utils 才能挂载 nfs 网络存储
yum install -y nfs-utils
yum install -y wget

# 关闭 SeLinux
setenforce 0
sed -i &amp;quot;s/SELINUX=enforcing/SELINUX=disabled/g&amp;quot; /etc/selinux/config

# 关闭 swap
swapoff -a
yes | cp /etc/fstab /etc/fstab_bak
cat /etc/fstab_bak |grep -v swap &amp;gt; /etc/fstab
# 修改 /etc/sysctl.conf
# 如果有配置，则修改
sed -i &amp;quot;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g&amp;quot;  /etc/sysctl.conf
sed -i &amp;quot;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g&amp;quot;  /etc/sysctl.conf
sed -i &amp;quot;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g&amp;quot;  /etc/sysctl.conf
# 可能没有，追加
echo &amp;quot;net.ipv4.ip_forward = 1&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &amp;quot;net.bridge.bridge-nf-call-ip6tables = 1&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &amp;quot;net.bridge.bridge-nf-call-iptables = 1&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf
# 执行命令以应用
sysctl -p

# 卸载旧版本
sudo yum remove -y kubelet kubeadm kubectl
sudo yum install -y kubelet kubeadm kubectl

# 重启 docker，并启动 kubelet
systemctl daemon-reload
systemctl restart docker
systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Linux WinOMV5 安装WebDAV服务]]></title><link>https://www.ztianzeng.com/posts/Linux WinOMV5 安装WebDAV服务</link><guid isPermaLink="false">/posts/Linux WinOMV5 安装WebDAV服务</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Linux-WinOMV5-安装WebDAV服务&quot;&gt;Linux WinOMV5 安装WebDAV服务&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此安装方法通用于所有*unix系统、Windows系统。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在OMV5（openmediavault）中安装WebDAV服务器端的方法不同于旧版本。在OMV5之前的版本，可以直接在管理界面的“插件”中安装并启用WebDAV服务，但是新版本去除了此插件，需要手工进行安装。目前相关资料较为匮乏，网上的WebDAV镜像质量也参差不齐。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过对比目前较为受欢迎的WebDAV服务器端软件，https://github.com/hacdias/webdav 较为稳定（唯一遗憾的是，此仓库作者提供的Docker镜像竟然在Docker Hub中排名非常靠后，以至于完全搜不到）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;此开源项目是使用GoLang开发的，因此兼容性非常强悍，仅作者预编译针对不同操作系统和CPU架构的二进制文件就有34种，可以说涵盖了几乎所有运行环境。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作者默认使用此软件的都是专业选手，因此没有手把手的文档可以参考。这对于非程序员甚至非GoLang程序员不太友好。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;作者给出的配置参考已经非常详细，但需要注意的是，你需要全部复制并做出对应修改，程序中并没有做默认值合并。注释中的will be merged仅仅针对当前配置文件下文的用户默认值。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二进制安装&lt;br /&gt;
访问&lt;a href=&quot;https://github.com/hacdias/webdav/releases/&quot;&gt;https://github.com/hacdias/webdav/releases/&lt;/a&gt;，对应下载作者预编译的二进制版本。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;参考Systemd Example，注册为*unix服务，实现开机自动启动。此步骤有疑问的话，搜索对应操作系统+systemd关键词。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;需要特别注意的是：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;二进制文件所在的执行目录需要和Systemd配置文件中的ExecStart目录保持一致。&lt;br /&gt;
作者说明了支持JSON, YAML and TOML配置文件格式，因此你需要加上相应后缀，否则配置文件不生效。例如JSON添加.json、YAML添加.yml。&lt;br /&gt;
OMV5(Debian)中二进制文件安装例子：&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;wget https://github.com/hacdias/webdav/releases/download/v4.1.0/linux-amd64-webdav.tar.gz
tar -zxvf linux-amd64-webdav.tar.gz
vim /etc/systemd/system/webdav.service
webdav.service（注意确保路径/opt/webdav.config.yml下的配置文件已存在）:

[Unit]
Description=WebDAV server
After=network.target

[Service]
Type=simple
User=root
ExecStart=/usr/bin/webdav --config /opt/webdav.config.yml
Restart=on-failure

[Install]
WantedBy=multi-user.target
设置开机启动并启动服务：

systemctl enable webdav
systemctl start webdav
Docker安装
使用SSH连接后，执行命令：

docker run --restart always --name=webdav -itd \
-v /export:/data \
-v /opt/webdav.config.yml:/opt/webdav.config.yml \
-p 8081:80 \
hacdias/webdav:v4.1.0 --config /opt/webdav.config.yml

命令内容一目了然了，相应配置文件参考

# Server related settings
address: 0.0.0.0
port: 80
auth: true
tls: false
prefix: /

# Default user settings (will be merged)
scope: .
modify: true
rules: []

cors:
  enabled: false
  credentials: false

users:
  - username: admin
    password: &amp;quot;{bcrypt}$2a$12$xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;quot;
    scope: /data
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;scope即为根目录本地映射地址。password可以用明文，也可以加密，Bcrypt密码在线生成地址： https://bcrypt-generator.com/。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;配置文件同样需要注意后缀问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关于内网穿透&lt;br /&gt;
为NAS搭建内网穿透有很多种方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;针对SSL证书部署，可以采用：&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;直接在配置文件中设置tls为true并配置相应的SSL证书地址。&lt;br /&gt;
配置文件中保持tls为false，在FRP或其它内网穿透工具中配置HTTPS并加载相应证书。&lt;br /&gt;
配置文件中保持tls为false，在FRP或其它内网穿透工具中仅穿透TCP协议（可配置加密和压缩），在公网服务器（FRP或其它内网穿透工具所在的服务器）中配置Nginx反向代理搞定证书问题。&lt;br /&gt;
强烈推荐第三个方案，简单也安全。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;关于Nginx反向代理的关键配置信息，此webdav服务端作者hacdias已经在README.md中注明。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;请大家不要咨询在OMV中如何安装Docker或如何在Portainer中安装webdav之类的问题。此类问题太过于基础（例如后者，可以先进SSH直接执行命令，然后回到Portainer中看Container配置发生了什么变化）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;推荐大家使用Mountain Duck这样的工具挂载带有SSL证书的WebDAV地址，可以实现和OneDrive或Dropbox一样的智能同步功能（始终在此设备上保留、释放空间）。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;from: https://www.joyk.com/dig/detail/1628887225532246&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Jenkins容器安装python3环境]]></title><link>https://www.ztianzeng.com/posts/Jenkins容器安装python3环境</link><guid isPermaLink="false">/posts/Jenkins容器安装python3环境</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Jenkins容器安装python3环境&quot;&gt;Jenkins容器安装python3环境&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在docker环境中安装jenkins，jenkins的构建环境是docker中的环境，默认的docker中默认只有python2而没有python3，因此需要再docker中手动装python3&lt;/p&gt;
&lt;h1 id=&quot;进入jenkins容器&quot;&gt;进入jenkins容器&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;docker exec -it -u root 容器id /bin/bash&lt;/p&gt;
&lt;h1 id=&quot;容器内部安装python3&quot;&gt;容器内部安装python3&lt;/h1&gt;
&lt;h2 id=&quot;下载python3安装包&quot;&gt;下载python3安装包&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;cd /var/jenkins_home/
mkdir python3 &amp;amp;&amp;amp; cd python3
wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tgz
tar -xvf Python-3.6.8.tgz
cd Python-3.6.8
./configure --prefix=/var/jenkins_home/python3
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果执行后报错 configure: error: no acceptable C compiler found in $PATH 则是因为缺少gcc相关的依赖包&lt;/p&gt;
&lt;h2 id=&quot;安装依赖包&quot;&gt;安装依赖包&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;自行根据docker的系统镜像选用apt-get 或者 yum 进行安装&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;yum -y install gcc automake autoconf libtool make
yum -y install make*
yum -y install zlib*
yum -y install openssl libssl-dev
yum install sudo
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;make-编译&quot;&gt;make 编译&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在python-3.6.8这个目录下重新执行安装&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;./configure --prefix=/var/jenkins_home/python3 --with-ssl
make
make install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;添加软连接&quot;&gt;添加软连接&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;ln -s /var/jenkins_home/python3/bin/python3.6 /usr/bin/python3
ln -s /var/jenkins_home/python3/bin/pip3 /usr/bin/pip3
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;检查是否安装成功&quot;&gt;检查是否安装成功&lt;/h2&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;pip3
python3
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[记:多线程中调用feign失败]]></title><link>https://www.ztianzeng.com/posts/记:多线程中调用feign失败</link><guid isPermaLink="false">/posts/记:多线程中调用feign失败</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;记-多线程中调用feign失败&quot;&gt;记:多线程中调用feign失败&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在代码运行的时候，在第一次调用feign抛出异常&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;Could not find class [org.springframework.boot.autoconfigure.condition.OnPropertyCondition]
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;一查发现github上有个issus:&lt;br /&gt;
&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-openfeign/issues/475&quot;&gt;https://github.com/spring-cloud/spring-cloud-openfeign/issues/475&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前暂无解决方案&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目前只有启动时监听配置文件，让其能够主动先将feign初始化好，以免后续在调用的时候进行初始化&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;大佬的pr:&lt;br /&gt;
&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-openfeign/pull/512&quot;&gt;https://github.com/spring-cloud/spring-cloud-openfeign/pull/512&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;但是，openfeign的作者认为这个并没有解决本质的问题，还是考虑在ForkjoinPool中以异步的方式初始化feignclient&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;不过，这个PR是目前，对代码侵入性最小的解决方案。&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[Fig介绍]]></title><link>https://www.ztianzeng.com/posts/Fig介绍</link><guid isPermaLink="false">/posts/Fig介绍</guid><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;Fig介绍&quot;&gt;Fig介绍&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在使用Mac终端的时候，经常需要通过自动补全来输入命令，系统自带的补全功能不是很好用，尤其是对参数类型的补全可是说是十分鸡肋，即使有了zsh对命令进行了增强，依然达不到IDE的那种友好提示。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;恰好，在Twitter看到了JetBrains上在推Fig这个Mac终端的自动补全命令，与zsh相比，Fig不仅仅在命令的支持上有所增强，更重要的是Fig带来了一个可交互的界面，可以降低命令行的使用难度。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fig官网: &lt;a href=&quot;https://fig.io/&quot;&gt;https://fig.io/&lt;/a&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fig将IDE的这种自动完成功能，附加到了终端上，让终端更加强大。&lt;/p&gt;
&lt;div class=&quot;iframe&quot;&gt;&lt;video autoplay=&quot;&quot; muted=&quot;&quot; src=&quot;https://www.shiyitopo.tech/uPic/main-demo-grey.mp4&quot;&gt;&lt;/video&gt;&lt;/div&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;而且不需要安装新的终端，直接集成到现有的终端中去，降低了学习成本&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220421095108575.png&quot; alt=&quot;image-20220421095108575&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当你在终端中输入命令后，会看到实时的提示，把可执行的命令以菜单的形式展示出来，你可以使用键盘选择想要输入的命令，也可以直接用鼠标点击，而且支持连续提示&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220421094618377.png&quot; alt=&quot;image-20220421094618377&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;像git这种命令，也能够有所提示,在运行一些不熟悉的命令时，可以直接用它来查看可用的参数，还会给你相应的说明，不用再去查看文档&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220421094820812.png&quot; alt=&quot;image-20220421094820812&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fig 支持多种命令，系统文件操作、Git、NPM、Docker、SSH、Heroku库等，用途很广泛&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220421094959691.png&quot; alt=&quot;image-20220421094959691&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;Fig 是一款非常好用的终端增强工具，如果你的工作中经常用到终端命令 ，可以去尝试一下&lt;/p&gt;
</content:encoded></item><item><title><![CDATA[定时备份数据]]></title><link>https://www.ztianzeng.com/posts/定时备份数据</link><guid isPermaLink="false">/posts/定时备份数据</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;定时备份数据&quot;&gt;定时备份数据&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了防止硬盘的损坏，因此需要定时将数据同步到阿里云盘中。。。。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;通过 rclone 命令将定时任务挂载到阿里云盘中。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在配置 rclone 的时候，如果是 webdav 一定要选择 webdav，而不能选择 http，如果选择了 http 协议在挂载和读取的过程中没有任何问题，但是在上传文件的时候会爆出权限异常，&lt;code&gt;http remotes are read only&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;rclone 同步的命令是:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# transfers 指定同时上传数量
rclone sync /home ali:/omv/back/home --transfers=8 -P
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将 rclone 配置成服务:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vim /etc/systemd/system/backup.service

[Unit]
Description=backup
After=network.target

[Service]
Type=oneshot
User=root
ExecStart=/usr/bin/rclone sync /home ali:/omv/back/home --transfers=8 -P
Restart=on-failure

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将 rclone 配置成定时任务:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vim /etc/systemd/system/backup.timer

[Unit]
Description=backUp Timer

[Timer]
OnUnitActiveSec=1h
Unit=backup.service

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;之后只需要开启定时任务即可:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl daemon-reload
systemctl enable backup.timer
systemctl start backup.timer
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;如果不放心，手动启动一遍看有没有错:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl start backup
# 查看状态
systemctl status backup
# 连续打印日志
journalctl -u backup -n 20 -f
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[2021年XBOX最新解锁的方法]]></title><link>https://www.ztianzeng.com/posts/2021年XBOX最新解锁的方法</link><guid isPermaLink="false">/posts/2021年XBOX最新解锁的方法</guid><category><![CDATA[游戏]]></category><category><![CDATA[游戏]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;2021年XBOX最新解锁的方法&quot;&gt;2021年XBOX最新解锁的方法&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从刚买来xbox就开始锁区，去年六月份买的，到现在整一年了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;当了一年的国行勇士，一年之后才有了新的解锁方案。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;打工人实惨。😭😭😭😭&lt;/p&gt;
&lt;h1 id=&quot;最新解锁方法&quot;&gt;最新解锁方法&lt;/h1&gt;
&lt;ol updated=&quot;20220705131435&quot;&gt;
&lt;li id=&quot;20220705131435-xqqylu1&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XBOX 系统更新为最新的系统&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-zcezv7m&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;XBOX 更新完系统后在连线模式 （有线或者无线都可以）&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-e49gt0r&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;U盘格式为NTFS&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-m18oht2&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;插入U盘后 重新启动主机&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-b2ehhwv&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在主机系统中区域显示有外区后 再次重新启动主机&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;20220705131435-nj7s1me&quot; updated=&quot;20220705131435&quot;&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;选择对应的国家或者地区&lt;br /&gt;
U盘中 $ConsoleGen8--------对应 XBOX ONE XBOX ONE S XBOX ONE X&lt;br /&gt;
U盘中 $ConsoleGen9--------对应 XSX XSS&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title><![CDATA[记录一次NAS系统崩溃]]></title><link>https://www.ztianzeng.com/posts/记录一次NAS系统崩溃</link><guid isPermaLink="false">/posts/记录一次NAS系统崩溃</guid><category><![CDATA[软路由]]></category><pubDate>Thu, 21 Apr 2022 07:48:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;记录一次NAS系统崩溃&quot;&gt;记录一次NAS系统崩溃&lt;/h1&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;由于之前没有考虑到nas的强大，在不断的装docker之后，磁盘竟然满了，后面扩容就一不小心将扩展分区给删除了，虽然成功的扩容了磁盘，但只成功运行了几天，后面一次断点重启，就直接导致无法开机（grub的问题），因为里面就一些电影文件，所以索性心一横直接重装了系统。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我重新审视了一下我自己的需求，无非是影音文件的共享，顺带装个逼，又考虑到J3160这颗垃圾U着实撑不起场面，所以就抛弃了之前用OMV5装docker这种庞大臃肿的方案，能原生的就原生去装。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;OMV5的插件比OMV4少了太多，原生插件堪称基类，基本上都是docker的方案来解决，既然如此，那么用OMV6其实并没有太大的区别，反正都没啥插件，还能体验新系统，所以就折腾起OMV6了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;再次记录一下装OMV6的过程。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用ISO傻瓜式安装过程就不在此叙述了~~~~&lt;/p&gt;
&lt;h2 id=&quot;安装完之后的问题&quot;&gt;安装完之后的问题&lt;/h2&gt;
&lt;h3 id=&quot;中文乱码&quot;&gt;中文乱码&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;安装完，第一件要解决的就是中文乱码问题。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;装完之后使用&lt;code&gt;local&lt;/code&gt;e命令输出的编码是&lt;code&gt;zh_CN.UTF-8&lt;/code&gt; 不知道为啥会导致ls 查看中文目录的时候乱码。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;解决方案: 使用 &lt;code&gt;dpkg-reconfigure locales&lt;/code&gt; 重新配置编码方式 为 &lt;code&gt;en_US.UTF-8&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;smb协议兼容问题&quot;&gt;smb协议兼容问题&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我用小米电视连接smb的时候，始终无法连接上，网上查询得知小米电视采用的是&lt;code&gt;SMB1.0&lt;/code&gt;的协议 ,然后OMV6的需要手动修改一下SMB支持的最低版本&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;在图形化界面的SMB设置那里设置 &lt;code&gt;server min protocol = CORE&lt;/code&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://image.ztianzeng.com/uPic/image-20220108225924680.png&quot; alt=&quot;image-20220108225924680&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;需要安装的软件&quot;&gt;需要安装的软件&lt;/h2&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这些软件原本我是采用docker进行安装，现在都改为原生安装&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;为了这颗破U，能省则省&lt;/p&gt;
&lt;h3 id=&quot;airconnect&quot;&gt;airconnect&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;目的为了能将苹果的音频投放到我的小爱音箱&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;从 https://github.com/philippe44/AirConnect 下载对应架构的 airupnp&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我的是 airupnp-x86-64,&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;wget https://github.com/philippe44/AirConnect/raw/master/bin/airupnp-x86-64
mv airupnp-x86-64 /usr/bin/air
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;设置服务&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vim /usr/lib/systemd/system/air.service	
## 写入
[Unit]
Description=air server
After=network.target

[Service]
Type=simple
User=root
ExecStart=/usr/bin/air  -Z
Restart=on-failure

[Install]
WantedBy=multi-user.target

## 执行
systemctl daemon-reload
systemctl start air
systemctl enable air
systemctl status air
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;webdav&quot;&gt;webdav&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将smb转为更加通用的webdav协议&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;用的是&lt;a href=&quot;https://github.com/hacdias/webdav&quot;&gt;https://github.com/hacdias/webdav&lt;/a&gt;，发现这个用go写的，最为轻量才几M&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;下载对应架构的webdav执行文件，放到/usr/bin目录下面&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;配置文件说明:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 监听任意网卡，多网卡可指定对应ip
address: 0.0.0.0
port: 8081
auth: true
prefix: /

modify: true
rules: []

# 跨域设置
cors:
  enabled: true
  credentials: true
  allowed_headers:
    - Depth
  allowed_hosts:
    - http://localhost:8081
  allowed_methods:
    - GET
  exposed_headers:
    - Content-Length
    - Content-Range

# 用户信息，如果 auth 为 true 生效
users:
  - username: admin
    password: admin
    # 配置自己的硬盘路径
    scope: /srv/dev-disk-by-uuid-c78a92c0-7c20-4480-b997-1f88c9d0cd4d/
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;更多的就去找官网吧，我将这个文件保存为 /home/webdav/webdav.config.yml （个人习惯保存在home目录下）&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;将webdav 配置成服务&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;[Unit]
Description=WebDAV server
After=network.target

[Service]
Type=simple
User=root
ExecStart=/usr/bin/webdav --config /home/webdav/webdav.config.yml
Restart=on-failure

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;systemctl daemon-reload
systemctl start webdav
systemctl enable webdav
systemctl status webdav
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;远程挂载webdav&quot;&gt;远程挂载webdav&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为有大佬将阿里云盘封装成webdav协议，所以我们可以通过挂载webdav的方式将阿里云盘作为我们的本地盘.&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;原本的挂载阿里云盘的服务使用docker部署的，着实太重，后面我就给迁移到了openwrt上面去了，就不在nas上进行挂载了，nas上只需要挂载阿里云盘的webdav服务即可，挂载教程 https://github.com/messense/aliyundrive-webdav&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;del&gt;nas上挂载webdav的方法是采用davfs2&lt;/del&gt;&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;## 安装davfs2
 apt-get install davfs2 -y
 ## 挂载，自行修改webdav的ip 和 挂载路径
 mount  -t davfs -o noexec http://192.168.31.3:8080 /srv/dev-disk-by-uuid-c78a92c0-7c20-4480-b997-1f88c9d0cd4d/aliyun/
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;&lt;del&gt;如果想要开机自动挂载 WebDAV，并且自动输入用户名和密码，需要将&lt;code&gt;/etc/davfs2/davfs2.conf&lt;/code&gt; 中的 &lt;code&gt;use_lock&lt;/code&gt; 解除注释，并将值修改为 &lt;code&gt;0&lt;/code&gt;，接下来在 &lt;code&gt; /etc/davfs2/secrets&lt;/code&gt; 末尾添加 &lt;code&gt;WebDAV地址 用户名 密码&lt;/code&gt;，最后在 &lt;code&gt;/etc/fstab&lt;/code&gt; 末尾添加 &lt;code&gt;WebDAV地址 /mnt/webdav davfs rw,user,_netdev 0 0&lt;/code&gt;。&lt;/del&gt;&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;使用过程中发现，davfs2挂载的时候会出现无法播放以及网络资源占用的莫名情况，故改为rclone挂载。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;安装rclone:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;curl https://rclone.org/install.sh | sudo bash
rclone
## 根据命令行给出的提示进行配置操作
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;修改&lt;code&gt;/etc/fuse.conf&lt;/code&gt;,加上&lt;code&gt;user_allow_other&lt;/code&gt; 表示允许非root用户可以登录&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;挂载文件的命令:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;rclone mount ali:/ /srv/dev-disk-by-uuid-c78a92c0-7c20-4480-b997-1f88c9d0cd4d/aliyun --cache-dir /tmp --allow-other --vfs-cache-mode full --allow-non-empty  
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;注册成服务&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;command=&amp;quot;mount ali:/ /srv/dev-disk-by-uuid-c78a92c0-7c20-4480-b997-1f88c9d0cd4d/aliyun --cache-dir /tmp --allow-other --vfs-cache-mode full --allow-non-empty&amp;quot;
cat &amp;gt; /etc/systemd/system/rclone.service &amp;lt;&amp;lt;EOF
[Unit]
Description=Rclone
After=network-online.target

[Service]
Type=simple
ExecStart=$(command -v rclone) ${command}
Restart=on-abort
User=root

[Install]
WantedBy=default.target
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;内网穿透&quot;&gt;内网穿透&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;我发现国内某头部厂商基于&lt;code&gt;ngork&lt;/code&gt;提供了一个不限速的内网穿透工具，为了它能存活的久一点，我就不透露它的名字了。&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;因为是基于&lt;code&gt;ngork&lt;/code&gt;，使用&lt;code&gt;nohup&lt;/code&gt;无法使其在后台运行，使用&lt;code&gt;screen&lt;/code&gt;能够后台运行但是无法开机启动，因此我们需要安装&lt;code&gt;supervisord&lt;/code&gt;来控制进程的启动&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;安装: supervisor&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;apt-cache show supervisor
apt install supervisor
supervisord -v
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;设置启动服务&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;vi /etc/supervisor/conf.d/ngrok.conf

# 项目名称，对应前面supervisorctl命令里的服务名称
[program:ngrok] 
# 目录
directory = /usr/local/bin/
# 执行的命令
command = /usr/local/bin/ngrok http -log stdout --authtoken yourtoken 192.168.0.200:4000
# 在 supervisord 启动的时候也自动启动
autostart = true
# 启动 5 秒后没有异常退出，就当作已经正常启动了
startsecs = 5
# 程序异常退出后自动重启
autorestart = true
# 启动失败自动重试次数，默认是 3
startretries = 3
# 执行命令的用户
user = root
# 把 stderr 重定向到 stdout，默认 false
redirect_stderr = true
# stdout 日志文件大小，默认 50MB
stdout_logfile_maxbytes = 50MB
# stdout 日志文件备份数
stdout_logfile_backups = 20
# stdout 日志文件
stdout_logfile = /var/log/supervisor/ngrok.log
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;运行:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;# 加载 ngrok 服务
supervisorctl start ngrok
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;zidr-管理文件&quot;&gt;zidr 管理文件&lt;/h3&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;这也是一个神器&lt;/p&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;nginx配置，直接使用omv的php 的socket进行通讯:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;nginx&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;server {
      listen 80;
      server_name zidr;
      index zdir/index.php index.html index.htm index.php;
      root /data/wwwroot/default;
      access_log /var/log/zdir.log combined;
      #rewrite
      rewrite ^/static/(.+) /zdir/static/$1 break;
     
      #error_page 404 /404.html;
      #error_page 502 /502.html;

      location ~ [^/]\.php(/|$) {
        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        fastcgi_pass unix:/run/php/php7.4-fpm-openmediavault-webgui.sock;
        fastcgi_index index.php;
        fastcgi_read_timeout 60s;
        include fastcgi.conf;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
      }

      location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|mp4|ico)$ {
        expires 30d;
        access_log off;
      }
      location ~ .*\.(js|css)?$ {
        expires 7d;
        access_log off;
      }
      location ~ /\.ht {
        deny all;
      }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p updated=&quot;20220705131435&quot;&gt;创建路径:&lt;/p&gt;
&lt;pre class=&quot;code-block&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;mkdir -p  /data/wwwroot/default &amp;amp;&amp;amp; cd /data/wwwroot/default
git clone https://github.com/helloxz/zdir.git
## 将目录软连接到这里
ln -s /srv/dev dev
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item></channel></rss>
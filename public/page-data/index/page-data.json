{"componentChunkName":"component---src-templates-index-template-js","path":"/","result":{"data":{"site":{"siteMetadata":{"title":"天增"}},"allSiYuan":{"nodes":[{"field":{"slug":"/posts/Gatsby4.0升级"},"excerpt":"Gastby发布了4.0的版本，引入了巨大的性能改进。 最大的特点是最多减少40%的构建时间和两个新的渲染选项:延迟静态生成和服务端渲染。 处理旧的依赖 在升级到V4版本之前，最好将所有的插件都升级到V3版本，这样可以竟可能避免出现问题。 ...","timeToRead":2,"frontmatter":{"date":"2022-05-20","title":"Gatsby4.0升级","description":"Gastby发布了4.0的版本，引入了巨大的性能改进。 最大的特点是最多减少40%的构建时间和两个新的渲染选项:延迟静态生成和服务端渲染。 处理旧的依赖 在升级到V4版本之前，最好将所有的插件都升级到V3版本，这样可以竟可能避免出现问题。 ...","tags":[]}},{"field":{"slug":"/posts/Log Structured Merge Tree LSM原理"},"excerpt":"最近在看Google十年前发表的BigTable论文，BigTable这玩意，最骚的一点就是改变了大多数传统数据库所使用的文件组织方法,业界对这种新一代的文件组织方法进行了实现，叫做Log Structured Merge Tree，简称L...","timeToRead":8,"frontmatter":{"date":"2022-05-18","title":"Log Structured Merge Tree LSM原理","description":"最近在看Google十年前发表的BigTable论文，BigTable这玩意，最骚的一点就是改变了大多数传统数据库所使用的文件组织方法,业界对这种新一代的文件组织方法进行了实现，叫做Log Structured Merge Tree，简称L...","tags":[]}},{"field":{"slug":"/posts/从CPU亲缘性探究Thread.currentThread"},"excerpt":"在美团这篇文章: 《Redis 高负载下的中断优化》看到了一个叫做CPU亲缘性的东西 > 如果某个CPU Core正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交...","timeToRead":9,"frontmatter":{"date":"2022-05-12","title":"从CPU亲缘性探究Thread.currentThread","description":"在美团这篇文章: 《Redis 高负载下的中断优化》看到了一个叫做CPU亲缘性的东西 > 如果某个CPU Core正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交...","tags":[]}},{"field":{"slug":"/posts/人菜瘾大，用python监控羽毛球场余票"},"excerpt":"人到中年，迷上了羽毛球，苦于所住的地方周边球场着实火爆，票出秒没。 有必要通过一些技术手段，扒拉出余票数，将有票的场地给提取出来，发送通知到手机上。 因为球场都是下单减库存的，所以为了尽快实现这套逻辑则不去对接支付相关的东西，通过及时通知到...","timeToRead":3,"frontmatter":{"date":"2022-05-12","title":"人菜瘾大，用python监控羽毛球场余票","description":"人到中年，迷上了羽毛球，苦于所住的地方周边球场着实火爆，票出秒没。 有必要通过一些技术手段，扒拉出余票数，将有票的场地给提取出来，发送通知到手机上。 因为球场都是下单减库存的，所以为了尽快实现这套逻辑则不去对接支付相关的东西，通过及时通知到...","tags":[]}},{"field":{"slug":"/posts/RocketMQ/RocketMQ Rebalance流程"},"excerpt":"RocketMQ存在Rebalance机制，这个机制的作用是将一个Topic下的多个队列，在同一个消费者组下的多个consumer之间重新进行分配。 Rebalance机制目的是为了提升消息的并行处理能力。 假设不存在Rebalance机制...","timeToRead":9,"frontmatter":{"date":"2022-05-11","title":"RocketMQ Rebalance流程","description":"RocketMQ存在Rebalance机制，这个机制的作用是将一个Topic下的多个队列，在同一个消费者组下的多个consumer之间重新进行分配。 Rebalance机制目的是为了提升消息的并行处理能力。 假设不存在Rebalance机制...","tags":["RocketMQ"]}},{"field":{"slug":"/posts/RocketMQ/RocketMQ顺序消息"},"excerpt":"消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 > 电商的订单创建，以订单ID作为Sharding Key，那么同一个订单相关的创建订单消息、订单支付消息、订单...","timeToRead":6,"frontmatter":{"date":"2022-05-09","title":"RocketMQ顺序消息","description":"消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 > 电商的订单创建，以订单ID作为Sharding Key，那么同一个订单相关的创建订单消息、订单支付消息、订单...","tags":["RocketMQ"]}},{"field":{"slug":"/posts/RocketMQ/RocketMQ持久化原理"},"excerpt":"消息的持久化是RocketMQ中最为复杂和重要的一部分，由于持久化机制的存在才能够实现RocketMQ的高可靠性。 图1展示了RocketMQ的整体的工作逻辑 Productor按照顺序写入CommitLog Consumer顺序读取Con...","timeToRead":8,"frontmatter":{"date":"2022-05-07","title":"RocketMQ持久化原理","description":"消息的持久化是RocketMQ中最为复杂和重要的一部分，由于持久化机制的存在才能够实现RocketMQ的高可靠性。 图1展示了RocketMQ的整体的工作逻辑 Productor按照顺序写入CommitLog Consumer顺序读取Con...","tags":["RocketMQ"]}},{"field":{"slug":"/posts/RocketMQ/RocketMQ延迟消息原理"},"excerpt":"RocketMQ提供了延迟消息的功能，消息在发送到RocketMQ服务端之后不会马上投递，而是根据消息中的属性延迟固定时间之后才会投递到消费者那。 使用场景 电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是...","timeToRead":7,"frontmatter":{"date":"2022-05-06","title":"RocketMQ延迟消息原理","description":"RocketMQ提供了延迟消息的功能，消息在发送到RocketMQ服务端之后不会马上投递，而是根据消息中的属性延迟固定时间之后才会投递到消费者那。 使用场景 电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是...","tags":["RocketMQ"]}},{"field":{"slug":"/posts/RocketMQ/RocketMQ事务消息实现原理"},"excerpt":"RocketMQ提供了事务消息的功能，采用了2PC+事务回查来实现事务，最终能通过RocketMQ提供的事务消息，能够简单方便的实现分布式事务。 概念介绍 事务消息 RocketMQ提供类似XA或Open XA的分布式事务功能，通过Rock...","timeToRead":17,"frontmatter":{"date":"2022-05-05","title":"RocketMQ事务消息实现原理","description":"RocketMQ提供了事务消息的功能，采用了2PC+事务回查来实现事务，最终能通过RocketMQ提供的事务消息，能够简单方便的实现分布式事务。 概念介绍 事务消息 RocketMQ提供类似XA或Open XA的分布式事务功能，通过Rock...","tags":["RocketMQ"]}}]},"siYuan":{"raw":"# 天增的博客\n\n一期一会，世当珍惜\n","frontmatter":{"title":"天增的博客"}}},"pageContext":{"slug":"/"}},"staticQueryHashes":["1284643331","2841359383"]}
{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/从CPU亲缘性探究Thread.currentThread","result":{"data":{"siYuan":{"excerpt":"在美团这篇文章: 《Redis 高负载下的中断优化》看到了一个叫做CPU亲缘性的东西 > 如果某个CPU Core正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交...","raw":"在美团这篇文章: [《Redis 高负载下的中断优化》](https://tech.meituan.com/2018/03/16/redis-high-concurrency-optimization.html)看到了一个叫做CPU亲缘性的东西\n\n> 如果某个`CPU Core`正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交给其他core继续运行，必须等处理完中断后才能继续运行。Redis本身定位就是高速缓存，线上的平均端到端响应时间小于1ms，如果频繁被中断，那么响应时间必然受到极大影响。容易想到，由最初的`CPU 0`单核处理中断，改进到多核处理中断，Redis进程被中断影响的几率增大了，因此我们需要对Redis进程也设置CPU亲缘性，使其与处理中断的Core互相错开，避免受到影响。\n>\n\n在网卡收集到数据包的时候，需要CPU进行一个软中断，告诉操作系统内核有数据进来了。\n\n所以，在大量的网络请求过来之后，可能Redis处理数据的CPU的核心、和响应中断的CPU的核心是同一个核心。\n\n那就意味着，一旦CPU中断了（即使速度很快），也会影响Redis的处理速度。\n\n作者还提到: \n\n> 由于`Linux wake affinity`特性，如果两个进程频繁互动，调度系统会觉得它们很有可能共享同样的数据，把它们放到同一CPU核心或`NUMA Node`有助于提高缓存和内存的访问性能，所以当一个进程唤醒另一个的时候，被唤醒的进程可能会被放到相同的`CPU core`或者相同的NUMA节点上。此特性对中断唤醒进程时也起作用，在上一节所述的现象中，所有的网络中断都分配给`CPU 0`去处理，当中断处理完成时，由于`wakeup affinity`特性的作用，所唤醒的用户进程也被安排给`CPU 0`或其所在的numa节点上其他core。而当两个`NUMA node`处理中断时，这种调度特性有可能导致Redis进程在`CPU core`之间频繁迁移，造成性能损失。\n>\n\n也就是说，如果CPU核心一直在交替处理Redis和网络请求，那么就会导致没有办法进行有效缓存，进而影响性能。\n\n# 探究\n\n所以从美团的这篇文章上来看，我觉得JVM实际上也会有这样的问题，就突发奇想了一下，如果JVM的线程调度归个类，让相似的线程使用同一个CPU核心处理，这样不就能够进一步加强并发效率么？\n\n然后就查询了各种资料，最后发现有个叫做`Java Thread Affinity`的东西。\n\n# Java Thread Affinity简介\n\ngit地址: [https://github.com/OpenHFT/Java-Thread-Affinity](https://github.com/OpenHFT/Java-Thread-Affinity)\n\n`Java Thread Affinity`是将Java代码中的线程绑定到`CPU`特定的核上，用来提升程序的性能。底层使用了`JNA技术`来提供对底层线程的访问能力\n\n> JNA（Java Native Access ）提供封装好的java函数用JNI来调用本地共享文件.dll/.so中的函数\n>\n\n在双核的服务器上使用`lscpu`命令来查看系统的CPU情况，如下所示\n\n```python\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                2\nOn-line CPU(s) list:   0,1\nThread(s) per core:    2\nCore(s) per socket:    1\n座：                 1\nNUMA 节点：         1\n厂商 ID：           GenuineIntel\nCPU 系列：          6\n型号：              79\n型号名称：        Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz\n步进：              1\nCPU MHz：             2494.220\nBogoMIPS：            4988.44\n超管理器厂商：  KVM\n虚拟化类型：     完全\nL1d 缓存：          32K\nL1i 缓存：          32K\nL2 缓存：           256K\nL3 缓存：           40960K\nNUMA 节点0 CPU：    0,1\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt\n```\n\n从上面的输出我们可以看到，这个服务器有两个socket，每个socket有一个core，每个*core*可以同时处理2个线程。\n\n完整的信息在`/proc/cpuinfo`中：\n\n```python\nprocessor\t: 0\nvendor_id\t: GenuineIntel\ncpu family\t: 6\nmodel\t\t: 79\nmodel name\t: Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz\nstepping\t: 1\nmicrocode\t: 0x1\ncpu MHz\t\t: 2494.220\ncache size\t: 40960 KB\nphysical id\t: 0\nsiblings\t: 2\ncore id\t\t: 0\ncpu cores\t: 1\napicid\t\t: 0\ninitial apicid\t: 0\nfpu\t\t: yes\nfpu_exception\t: yes\ncpuid level\t: 13\nwp\t\t: yes\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt\nbogomips\t: 4988.44\nclflush size\t: 64\ncache_alignment\t: 64\naddress sizes\t: 46 bits physical, 48 bits virtual\npower management:\n\nprocessor\t: 1\nvendor_id\t: GenuineIntel\ncpu family\t: 6\nmodel\t\t: 79\nmodel name\t: Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz\nstepping\t: 1\nmicrocode\t: 0x1\ncpu MHz\t\t: 2494.220\ncache size\t: 40960 KB\nphysical id\t: 0\nsiblings\t: 2\ncore id\t\t: 0\ncpu cores\t: 1\napicid\t\t: 1\ninitial apicid\t: 1\nfpu\t\t: yes\nfpu_exception\t: yes\ncpuid level\t: 13\nwp\t\t: yes\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt\nbogomips\t: 4988.44\nclflush size\t: 64\ncache_alignment\t: 64\naddress sizes\t: 46 bits physical, 48 bits virtual\npower management:\n```\n\n`Java Thread Affinity`会读取`/proc/cpuinfo`来确定CPU的`layout`信息，代码中有个CpuLayout与之对应：\n\n![](https://image.ztianzeng.com/uPic/20220513103640.png)\n\n根据`CPU layout`的信息， `AffinityStrategies`提供了一些基本的Affinity策略，用来安排不同的`thread`之间的分布关系：\n\n```python\npublic enum AffinityStrategies implements AffinityStrategy {\n\n    /**\n     * 任何CPU都行.\n     */\n    ANY {\n        @Override\n        public boolean matches(int cpuId, int cpuId2) {\n            return true;\n        }\n    },\n    /**\n     * 运行在同一个core中.\n     */\n    SAME_CORE {\n        @Override\n        public boolean matches(int cpuId, int cpuId2) {\n            CpuLayout cpuLayout = AffinityLock.cpuLayout();\n            return cpuLayout.socketId(cpuId) == cpuLayout.socketId(cpuId2) &&\n                    cpuLayout.coreId(cpuId) == cpuLayout.coreId(cpuId2);\n        }\n    },\n    /**\n     * 运行在同一个socket中，但是不在同一个core上。.\n     */\n    SAME_SOCKET {\n        @Override\n        public boolean matches(int cpuId, int cpuId2) {\n            CpuLayout cpuLayout = AffinityLock.cpuLayout();\n            return cpuLayout.socketId(cpuId) == cpuLayout.socketId(cpuId2) &&\n                    cpuLayout.coreId(cpuId) != cpuLayout.coreId(cpuId2);\n        }\n    },\n    /**\n     * 运行在不同的socket中\n     */\n    DIFFERENT_CORE {\n        @Override\n        public boolean matches(int cpuId, int cpuId2) {\n            CpuLayout cpuLayout = AffinityLock.cpuLayout();\n            return cpuLayout.socketId(cpuId) != cpuLayout.socketId(cpuId2) ||\n                    cpuLayout.coreId(cpuId) != cpuLayout.coreId(cpuId2);\n        }\n    },\n    /**\n     * 运行在不同的core上\n     */\n    DIFFERENT_SOCKET {\n        @Override\n        public boolean matches(int cpuId, int cpuId2) {\n            CpuLayout cpuLayout = AffinityLock.cpuLayout();\n            return cpuLayout.socketId(cpuId) != cpuLayout.socketId(cpuId2);\n        }\n    }\n}\n```\n\n由于MacOS系统的局限性，没有办法通过`/proc/cpuinfo`获取到CPU信息，全部都是走的默认`NoCpuLayout`来进行处理，我的Mac是16核，默认16核全部参与工作。\n\n## 使用方式\n\n* 限制线程在单个CPU核心上运行\n\n```java\ntry (AffinityLock al = AffinityLock.acquireLock()) {\n    // do some work while locked to a CPU.\n    System.out.println(al.cpuId());\n    while(true) {}\n}\n```\n\n* 指定CPU运行\n\n```java\ntry (AffinityLock al = AffinityLock.acquireLock(5)) {\n    // do some work while locked to a CPU.\n    System.out.println(al.cpuId());\n    while(true) {}\n}\n```\n\n* 线程池指定\n\n`Affinity`提供了线程工厂方法，可以构造自己的线程池的亲缘策略\n\n```java\nExecutorService ES = Executors.newFixedThreadPool(4,new AffinityThreadFactory(\"bg\", SAME_CORE, DIFFERENT_SOCKET, ANY));\n```\n\n## 原理\n\n一般服务器都是Linux的，所以只看Linux下的实现。\n\n`Java Thread Affinity`有个`CLibrary`的匿名内部类，用来封装操作系统提供的API\n\n```java\n interface CLibrary extends Library {\n        CLibrary INSTANCE = (CLibrary) Native.loadLibrary(LIBRARY_NAME, CLibrary.class);\n\n        int sched_setaffinity(final int pid,\n                              final int cpusetsize,\n                              final cpu_set_t cpuset) throws LastErrorException;\n\n        int sched_getaffinity(final int pid,\n                              final int cpusetsize,\n                              final cpu_set_t cpuset) throws LastErrorException;\n\n        int getpid() throws LastErrorException;\n\n        int sched_getcpu() throws LastErrorException;\n\n        int uname(final utsname name) throws LastErrorException;\n\n        int syscall(int number, Object... args) throws LastErrorException;\n    }\n```\n\nsched_setaffinity可以将某个进程绑定到一个特定的CPU，这是Linux提供了设置CPU亲和力的方法。\n\n通过调用这个方法，将cpu的掩码绑定到对应的pid上面，就能够形成亲和。\n\n# 总结\n\n`Java Thread Affinity`可以从JAVA代码中对程序中Thread使用的CPU进行控制。\n\n能够通过自行设置亲和力的方式，来避免操作系统本身的调度。\n","field":{"slug":"/posts/从CPU亲缘性探究Thread.currentThread"},"frontmatter":{"title":"从CPU亲缘性探究Thread.currentThread","tags":[],"date":"2022-05-12","description":"在美团这篇文章: 《Redis 高负载下的中断优化》看到了一个叫做CPU亲缘性的东西 > 如果某个CPU Core正在处理Redis的调用，执行到一半时产生了中断，那么CPU不得不停止当前的工作转而处理中断请求，中断期间Redis也无法转交..."}},"prev":{"frontmatter":{"title":"Log Structured Merge Tree LSM原理"},"field":{"slug":"/posts/Log Structured Merge Tree LSM原理"}},"next":{"frontmatter":{"title":"人菜瘾大，用python监控羽毛球场余票"},"field":{"slug":"/posts/人菜瘾大，用python监控羽毛球场余票"}}},"pageContext":{"slug":"/posts/从CPU亲缘性探究Thread.currentThread","prevSlug":"/posts/Log Structured Merge Tree LSM原理","nextSlug":"/posts/人菜瘾大，用python监控羽毛球场余票"}},"staticQueryHashes":["1284643331","2841359383"]}